############################################################################################
検索システム 実務者のための開発改善ガイドブック 11章 検索を成功させるための支援
############################################################################################

https://www.lambdanote.com/products/ir-system

11章の著者

- 河野晋策 (リクルート)

*********************************************************************
ABSTRACT
*********************************************************************

本章では、検索体験を向上させるために5つの観点を解説している。

1. 検索クエリの意図を読み解く分類
2. 検索前後でのクエリ難易度（パフォーマンス）予測
3. 精度と再現率を両立させるクエリ書き換え
4. 検索者からの明示的／暗黙的フィードバックの活用
5. 探索的検索システムを多面的に評価する方法。

検索ログとドキュメントの構造を活かしつつ、ルールベースから機械学習・統計手法まで段階的に実装し、継続的に改善する姿勢が重要である


*********************************************************************
11.1 検索クエリはどのようなカテゴリに分類できるか
*********************************************************************



紹介するけど、正解はないから自分の目指す方向に沿ってカスタマイズしろとのこと。

A taxonomy of web search
==============================================

A taxonomy of web search (A. Broder, IGIR Forum, 2002.) `[Google Scholar] <https://scholar.google.co.jp/scholar?q=A+taxonomy+of+web+search>`_, `[PDF] <https://sigir.org/files/forum/F2002/broder.pdf>`_ の分類を紹介している。

この論文の目的は以下

1. ウェブ検索意図を3型タクソノミー(分類学、分類法的な意味)で定義・分析すること
2. 実際の検索クエリを調査し、各型の出現比率を定量評価すること
3. 検索エンジン技術の世代的進化を、このタクソノミーの観点から再解釈すること


.. csv-table:: 検索意図の分類表
   :header: "クラス", "目的", "典型例", "割合(定性評価)"
   :widths: 20, 20, 25, 20

   "**Navigational（案内型）**", "特定ドキュメントへの到達", "「厚労省」", "20%"
   "**Informational（情報収集型）**", "情報獲得・学習", "「IRとは」, 「浅草 観光」","48%"
   "**Transactional（取引型）**", "購入・予約・DL", "「東京 広島 飛行機」、「ドル 円 変換」","30%"

検索エンジンの進化の考察

- 第1世代 (1995–97): ページ内要素のみを用い、Informational 型中心。　クエリの高速・高精度解決はブランドロイヤルティに寄与。
- 第2世代 (1998–): リンク解析・アンカーテキスト・クリック率を利用し Navigational 型にも対応（Google、DirectHit 等）。
- 第3世代 (2001–): 意図推定と外部DBブレンディングにより Transactional 型を直接支援（ホテル予約、地図、天気などを統合表示）。直接収益化しやすく、エンジン各社が重点投資。

.. raw:: html

    <br>

どう使うかについては11.1節では特に言及なし

さらに細かい分類として、 

Understanding user goals in web search
==============================================


Understanding user goals in web search (D. E. Rose and D. Levinson, WWW, 2004) `[Google Scholar] <https://scholar.google.co.jp/scholar?q=Understanding+user+goals+in+web+search>`_, `[PDF] <https://www.cse.iitb.ac.in/~soumen/doc/www2013/QirWoo/RoseL2004FunctionalIntent.pdf>`_ を紹介している。

**概要**

- 従来のWeb検索研究は、ユーザが「どのように検索するか」「何を探しているか」に注目されていた。
- 一方で「なぜ検索するか（検索の背後にある目的＝goal）」は十分に扱われていなかった。
- この研究は Broder (2002) の三分法（navigational／informational／transactional）を出発点に、検索目標をさらに細分化して扱う枠組みを提案。

**目的**

- ユーザ検索目標を体系化する概念を提示
- 実際の検索ログに適用して分類可能性と分布傾向を評価
- 最終的には検索エンジン側で goal-sensitive なランキングや UI を実現する基盤知識を得ることを目指す。

わかりやすい `[論文紹介: Understanding User Goals in Web Search 書いた人: @nikezono] <https://the-weekly-paper.github.io/jekyll/update/2017/08/20/understanding-user-goals-in-web-search.html>`_ 

  一方でこの論文が明らかにしたのは,キーワード型の検索エンジンにおいて同じクエリが入力されていても，その目的(Goal)は異なる という点である.
  この問題意識について,インタフェースの側からユーザに寄り添い, たとえばかつてのディレクトリ型検索のような発展を遂げていくのか
  それともキーワード型の「思いついたものは何でも入力できる」検索ボックスというインタフェースは変えずに
  検索エンジン自体の仕組みを考えていくのか，というアプローチの違いが存在するわけである. -- https://the-weekly-paper.github.io/jekyll/update/2017/08/20/understanding-user-goals-in-web-search.html

**手法**

- AltaVista(かつて存在したロボット型全文検索エンジン、Googleに淘汰されたひとつ、Yahoo Inc.に買収され運用後サービス終了)のログを使う
- 人手によってユーザーの行動ログ(クエリそのもの、クリックログ、後続クエリ等)を分析し、ユーザーの目的を100~200に分類
- それを上位3カテゴリ→下位9カテゴリに分類

.. csv-table:: 検索意図カテゴリと下位分類（Leaf Goal）
   :header: "上位カテゴリ", "下位カテゴリ（Leaf Goal）", "比率*", "補足"
   :widths: 20, 25, 10, 45

   "**Informational**", "Directed", "3 %", "具体的に「◯◯について知りたい」型"
   "", "Undirected", "31 %", "トピック全般を網羅的に知りたい"
   "", "Advice", "2 %", "ノウハウ・手順・提案を求める"
   "", "Locate", "24 %", "商品・サービスの入手先を調べる"
   "", "List", "3 %", "候補サイト／オプションを一覧取得"
   "**Resource-Seeking**", "Download", "4 %", "ファイル・ソフトをダウンロード"
   "", "Entertainment", "4 %", "視聴・閲覧そのものが目的"
   "", "Interact", "6 %", "天気・株価など Web サービスと対話"
   "", "Obtain", "8 %", "レシピ・歌詞などオフライン利用目的"
   "**Navigational**", "（単一カテゴリ）", "15%", "既知サイトへのジャンプ"

.. raw:: html

    <br>

雑感等

- 両論文とも「分類結果をどう活かすか」の設計方針は提示するが、モデルの特徴量, 設計学習・推定アルゴリズムといった詳細までは踏み込んでいない。
- 「Advice ならリンク/利用ログ重視」などランキング要因の優先度切替を具体例で示唆し、 Broder は「外部 DB ブレンド」「アンカーテキスト依存」は言及がある。
- ChatGPT先生に実際どうするか聞いてみた結果

  1. クエリ＋クリックログで多クラス分類器を訓練（既存研究では SVM／BERT 系が主流）。
  2. 推定 Goal をフィーチャに持つ Learning-to-Rank（LambdaMART など）を構築。
  3. Goal ごとに UI コンポーネント（リッチカード、ショッピングタブ等）のトリガールールを設定。

.. raw:: html

    <br>


実際どう分類するか？では、**Determining the user intent of web search engine queries** (B. Jansen et al., WWW, 2007) 次の論文を引用している。


**手法**

- 質的分析フェーズ
  
  - 5百万件超のクエリからランダムサンプルを抽出し、人手で三分類にラベリング。
  - 反復的に「クエリ選択 → 分類 → 特徴再定義」を行い、最終的に各意図に対するヒューリスティック特徴（例：URL断片・社名→案内型、“download” 含む→取引型、疑問語含む→情報要求型…）を確定。

- 自動分類フェーズ

  - 上記特徴をベースに分類プログラムを実装
  - 400件を人手再分類し、分類精度74%


また、`Query Intent Understanding (Z. Dou and J. Guo, Springer, 2020) <https://link.springer.com/chapter/10.1007/978-3-030-58334-7_4>`_ (本) を引用して 線形回帰、SVM、GBDT など、さまざまな機械学習の手法を検索クエリ分類のタスクに使えると言っている。
特徴量としては、以下。

- 閲覧の回数や閲覧の時間
- クリックデータから得られるクリックの分布やエントロピー
- 検索クエリと閲覧されたドキュメントから作成したTF-IDF


*********************************************************************
11.2 検索クエリのパフォーマンス測定
*********************************************************************


(あんまり興味なかったので簡単に)


「その検索クエリで十分に高品質な結果を返せるか」を事前・事後に数値で推し量る技術 を体系的に整理しています。具体的には

1. 検索前に文書統計だけで難易度を推定する手法
2. 検索後に得点分布や検索結果の頑健性を調べて精度を高める手法
3. これらを実務で活かすユースケース （選択的クエリ拡張・UI 提案・検索コスト最適化など）

を解説し、主要指標（Clarity, NQC, WIGなど）の計算式と使い分けを紹介している。
これにより検索エンジンは難しいクエリを早期に検知し、失敗検索を減らしつつ処理資源を賢く配分できる。


クエリパフォーマンス予測（QPP）とは



QPP は関連判定（評価用ジャッジ）が無くても、クエリ単位で期待検索性能を推測する研究分野です。古くは TREC を契機に広まり、現在は Dense Retrieval や Conversational Search でも活発に採用されている。

- 検索前予測: 文書集合の語統計や IDF 値を使うため高速でオンライン実装に向く。
- 検索後予測: 実際の得点リストを解析するため精度が高く、難クエリの検知率が向上。


.. csv-table:: **クエリ難易度に基づく活用局面**
   :header: "利用局面", "効果", "具体例"
   :widths: 25, 33, 33

   "**選択的クエリ拡張**", "ドリフトを抑えつつ有効なときだけ拡張", "QPP スコアが高いクエリだけに Pseudo-Relevance Feedback を適用 (`[論文] <https://arxiv.org/abs/2504.01101>`_)"
   "**UI/検索ガイダンス**", "難クエリと判定したら「単語を増やす/減らす」等のヒントを提示", "Google検索"
   "**動的ランカ選択・結果統合**", "クエリごとに最適なランキング関数やソースを選ぶ", "ランキング融合やシステム間メタ検索 (`[論文] <https://irlab.science.uva.nl/wp-content/papercite-data/pdf/arabzadeh2024query.pdf>`_, `[論文] <https://arxiv.org/abs/2504.01101>`_ )"
   "**インデックス拡充／ログ分析**", "難易度の高いトピックを可視化しコンテンツ不足を補填", "管理者向けフィードバック"


.. csv-table:: **検索前指標**
   :header: "カテゴリ", "主な尺度", "イメージ"
   :widths: 15, 30, 55

   "**特異性**", "ICTF, SCS", "単語がレアほどヒット集合は絞れ精度↑"
   "**類似性**", "SCQ, sumSCQ, maxSCQ", "クエリ語が文書に良く現れれば容易"
   "**一貫性/曖昧性**", "Coherence, PMI", "クエリ語が共起しやすいとトピックが明確"
   "**語関係**", "PMI, term correlation 指標", "関係が強いほど結果品質が安定"

.. csv-table::  **検索後指標**
   :header: "カテゴリ", "主な尺度", "イメージ"
   :widths: 20, 30, 50

   "**得点分布系**", "**WIG** 、**NQC**", "上位 *k* 件のスコア散らばりが大きい＝“良い回答がある”"
   "**明瞭度系**", "**Clarity**", "上位結果モデルとコレクションモデルの KL 距離"
   "**頑健性／凝集性**", "ドキュメントやクエリを摂動し結果順位の安定度を測定", "難クエリほど順位が揺れやすい"
   "**スコア自己相関**", "Spatial autocorrelation", "似た文書が似たスコアなら良質"


*********************************************************************
11.3 検索エンジンへのクエリを書き換える
*********************************************************************

- 検索者の意図を 精度（適合率）と 網羅性（再現率）の両面から最適化するために、クエリを書き換える方法論を説明している

- 適合率を上げる手法

  - Query Segmentation : 「白 フラワー ベース」 → (白い花に合う花瓶ではなく)「白  "フラワー ベース"」 
  - Query Scoping: 「ナイキ 黒 27cm」→ brand:"nike" AND color: "black" AND size:"27cm" で検索する

- 再現率を上げる手法

  - Query Expansion: 「機械学習」→ (機械学習 OR "machine learning")
  - Query Relaxation: 「SONY PS5 ソフト」→ 「PS5 ソフト」



Query Segmentation
==============================================



ヒューリスティックな手法として引用している論文は3つ。


Query segmentation revisited
---------------------------------------------------------------------

M. Hagen, et al., WWW, 2011. `[PDF] <https://www.cse.iitb.ac.in/~soumen/doc/www2013/QirWoo/HagenPSB2011QuerySegmentRevisit.pdf>`_


Generating query substitutions
---------------------------------------------------------------------

R. Jones, et al., WWW, 2006. (PDF見れない)


Query Segmentation for Web Search
---------------------------------------------------------------------

K. Risvik, et al., WWW(poster), 2003. `[PDF] <https://www.areto.ethz.ch/CDstore/www2003/papers/poster/p052/querysegmentation.pdf>`_

.. raw:: html

    <br>

教師あり学習を利用した手法として引用している論文は1つ。

Learning noun phrase query segmentation
---------------------------------------------------------------------

S. Bergsma and Q. Wang, EMNLP-CoNLL, 2007. `[PDF] <https://aclanthology.org/D07-1086.pdf>`_


.. raw:: html

    <br>

教師なし学習を利用した手法として引用している論文は1つ。

Unsupervised query segmentation using generative language models and wikipedia
------------------------------------------------------------------------------------------------------------------------------------------


B. Tan and F. Peng, WWW, 2008. `[PDF] <https://www.cse.iitb.ac.in/~soumen/doc/www2013/QirWoo/TanP2008QuerySegment.pdf>`_


.. raw:: html

    <br>

Query Segmentationをランキングに利用することで、よりよい検索結果を得られるとして引用している論文は以下の2つ。

A new approach to query segmentation for relevance ranking in web search
------------------------------------------------------------------------------------------------------------------------------------------

H. Wu, et al., Inf. Retr., Feb. 2015 `[PDF] <https://arxiv.org/pdf/1312.0182>`_


**背景**

- Web検索のクエリは “let it go mp3 download” のように複数単語が連なるが、そのまま n-gram（連続語列）として扱うと「let it」「it go」など意味の薄い結合が多数生まれ、ランキング精度を下げる要因になる。
- Query Segmentationを行い、その結果をランキングに活用する研究が盛んだが、①分割精度がまだ不十分、②分割結果の使い方が限定的、という課題が残っていた

**目的**

- 再ランキング型クエリ分割を提案し、既存分割法（Wikipedia-Based Normalization など）より高精度な分割を実現する。
- 分割結果を“フレーズ n-gram”として BM25・Key n-gram・Term Dependency の3種ランキングモデルで使い、検索精度を検証する


**手法**

- step1. 再ランキング型クエリ分割

  - WBNを用いて上位k=6の候補分割を生成（k=6で正解含有率 94%)
  - SVM による判別モデルで候補を再ランキング。特徴はWBN スコア関連（rank, score, segment weight など）, 相互情報量, Wikipedia タイトル一致フラグ, 位候補との類似度等々

- step2. ランキングへの統合

  - Wordベースn-gram, Phaseベースn-gram, BM25, などの特徴量でLambdaMartを学習


Improving document ranking for long queries with nested query segmentation
------------------------------------------------------------------------------------------------------------------------------------------


R. Roy, et al., Microsoft Research, Tech. Repp, December 2015


難しかったので省略、簡単にいうと

- クエリを木構造で表現 



.. raw:: html

    <br>

Query Scoping
==============================================

イメージ:「ナイキ 黒 27cm」→ brand:"nike" AND color: "black" AND size:"27cm" で検索する

- 最初からユーザーに指定させてらいいのでは?

  - ユーザーが検索したいものを明確に把握している必要がある
  - ユーザーが指定するのは手間がかかる

- Query Scopingの流れ

  - Query Segmentationでクエリを意味単位（セグメント）に分割する。
  - 各セグメントを固有表現 (Named Entity)とコンテキストに分ける。
  - NER (Named Entity Recognition)を用いて固有表現を属性クラスへマッピングし、クエリを書き換える


**固有表現とコンテキストとは**

- 固有表現は人や組織の名前などの固有名詞・日付・数値表現、コンテキストはそれ以外
- 例「スイッチ ソフト 新作」

  - 固有表現: スイッチ
  - コンテキスト: ソフト 新作

- NER: セグメントの固有表現を識別し 、あらかじめ定義されたクラスに分類する

**NERの手法概要**

.. csv-table:: 固有表現抽出の代表手法と特徴
   :header: "手法", "特徴", "留意点"
   :widths: 30, 40, 40

   "教師あり学習（SVM, CRF など）", "検索ログや属性付きドキュメントを教師データにできる", "クエリは短く大文字判定などが効かないので特徴設計が難しい"
   "弱教師あり／トピックモデル（WS‑LDA 等）", "少数のシード固有表現から確率分布をブートストラップ学習", "ドメイン特化モデルを段階的に拡張できる"
   "ブートストラッピング", "シード→文抽出→シード拡張を反復", "初期シードの質と多様性が重要"

NERの論文たくさんあるとは思うが、ここで引用されているのは以下


最初はNLPの分野で研究されていたとして、以下の3つ。

- D. Bikel, S. Miller, R. Schwartz, and R. Weischedel, “Nymble: A high-performance learning name-finder,”  ANLC ’97
- A. Borthwick, “A maximum entropy approach to named entity recognition,” Ph.D. dissertation, 1999.
- J. Kim, I. Kang, and K. Choi, “Unsupervised named entity classi- fication models and their ensembles,” COLING, 2002.


トピックモデルを利用した手法として以下。

- J. Guo, G. Xu, X. Cheng, and H. Li, “Named entity recognition in query,” SIGIR, 2009. `[PDF] <https://www.cse.iitb.ac.in/~soumen/doc/www2013/QirWoo/GuoXCL2009nerq.pdf>`_


CRF を用いた教師あり学習で検索クエリにおける NER を解くこともできるとして以下。

- A. Eiselt and A. Figueroa, “A two-step named entity recognizer for open- domain search queries,” IJCNLP-AACL, 2013. `[PDF] <https://aclanthology.org/I13-1101.pdf>`_


Query Expansion
==============================================

(あんまり興味なかったので省略)

イメージ: 機械学習」→ (機械学習 OR "machine learning")


**クエリ拡張が必要な理由**

- Web 検索ログでは平均クエリ長は約2語と短く、語彙のずれや同義・多義・表記ゆれで関連文書を取り逃しやすい。
- ただし無関係語を足すと意図がそれる「クエリドリフト」が発生するため、拡張語の選定と適用条件が鍵となる

体系的にみると4つの方針があるとして以下のサーベイ論文を引用

-　C. Carpineto and G. Romano., A survey of automatic query expansion in information retrieval, 2012.

.. csv-table:: **クエリ拡張の代表的な類型と手法**
   :header: "類型", "発想", "主な手法 / 指標"
   :widths: 15, 35, 70

   "一対一関連利用", "単語/フレーズ１つに対して類語を追加", "形態素正規化、外部辞書（WordNet 等）による同義語、Dice・Jaccard・PMI などのターム共起類似度"
   "一対多関連利用", "追加候補とクエリ全語との総合相関を計算して低相関候補を除外", "平均相関 x<sub>q,t</sub>、語義曖昧性軽減（WordNet を用いたヒューリスティック）"
   "検索結果分布利用", "上位文書から特徴語を抽出 (Feedback)", "①利用者の明示選択＝Relevance Feedback（OW 重み）②上位 k 件を擬似適合とみなす PRF（BIM, KLD, PMING など）"
   "クエリ言語モデル", "統計モデルで「クエリが生成される確率」が高い語を追加", "Relevance‑Based LM、トピック混合 LM (EM で θ 推定)"


**クエリドリフト対策 & 適用条件**


- 性能予測に基づく選択的拡張

  - クエリのパフォーマンスが高い場合のみ拡張を適用し、低い場合は拡張を抑制して精度低下を防ぐ

- ランキング側での重み付け

  - 拡張語だけにマッチした文書のスコアを下げる、あるいは拡張語に信頼度重みを持たせることでドリフトを緩和する


Query Relaxation
==============================================

(あんまり興味なかったので省略)


イメージ: 「SONY PS5 ソフト」→ 「PS5 ソフト」


- ヒット件数ゼロ（または極端に少ない）状況を救済し、再現率を引き上げるために 検索語を削る・一般化する手法
- 具体的には (1) 削除する語の選定、(2) 削除後サブクエリの評価、(3) 副作用（精度低下・UX 低下）の抑制


.. csv-table:: 
   :header: "タスク", "説明", "代表ツール／ヒント"
   :widths: 20, 30, 30

   "ストップワード除去", "機能語（日本語の「は／の」、英語の a, the など)を削除", "Lucene `StopFilter` を有効化"
   "特異性計算", "一番ピンポイントな語」を落とす (「SONY PS5 ソフト」のPS5を消す)", "11.2 節の ICTF / SCS を再利用"
   "語義階層で一般化", "「キクラゲ　きのこ」→「キクラゲ」", " "
   "品詞・構文分析", "品詞解析や構文解析で 修飾句・形容詞 を検出し、削除", "MeCab / GiNZA で名詞‐非名詞を切り分け"
   "ログ解析", "検索セッション内で ユーザが実際に削った語 を統計化し、緩和候補を学習する", "“削除語率は 5%” という実測値をベースラインに設計"
   "Selective Relax.", "NQC などでゼロ件リスクが高いときのみ発動", " "


*********************************************************************
11.4 検索者からのフィードバックを活用する
*********************************************************************

(とくに目新しいこともないので省略)

ユーザーフィードバックを使ってシステムの改善できるということを説明している


.. csv-table:: **フィードバック情報の区分と特徴**
   :header: "区分", "例", "特徴", "取得方法"
   :widths: 25, 45, 30, 30

   "**明示的 (explicit)**", "「役に立った」ボタン、Good/Bad 評価、検索途中のアンケート", "直接的で粒度は細かいが協力度に依存", "UI に評価 UI と保存機能を設置"
   "**暗黙的 (implicit / blind)**", "クリック有無、閲覧時間、スクロール量", "ユーザ負荷ゼロで大量収集可。ノイズを含む", "行動ログを自動収集"


活用ステップ

- step1. 小さく始めて観察する

  - まずは頻度ベースや単純ルールでクリック・閲覧時間を重み付けしたランキング補正を導入し、効果をログで検証する。

- step2. 複数指標のダッシュボード化

  - CTR／平均閲覧秒数／Good‑Bad 比率などを並行モニタリングし、単一指標依存を避ける。

- step3. ユーザセグメントを分けて評価

  - 初回訪問・リピータ・専門ユーザでフィードバック傾向が異なるため、セグメント別に A/B テストを行うと偏りを検知しやすい。

- step4. ランキング・クエリ処理の連携

　　- クエリレベルの補正だけでなく、LtRの特徴量として「クリックされた回数」「平均 dwell time」などのフィードバック統計を渡し、モデルが自動で重み付けを学習できる設計が望ましい。


*********************************************************************
11.5 探索的検索の観点で検索システムを評価する
*********************************************************************

問題意識

- 探索的検索においては検索者の学習目標や検索方針がセッション中に変化するため、伝統的な「精度↔再現率」だけでは十分にシステム性能を測れないという問題がある
- 評価はコンポーネント単体ではなく システム横断で複数指標を並行監視し、その相互作用まで視野に入れる必要がある



.. csv-table:: **評価指標**
   :header: "評価観点", "具体的な尺度", "重点ポイント"
   :widths: 35, 35, 30

   "**没頭と楽しみ**", "閲覧・ブックマーク・購入・フィードバックなど行動量をカウント", "相互作用の深さ・満足度を反映"
   "**情報の新規性**", "新しい情報に遭遇する率", "“未知との出会い”の有効性を測定"
   "**検索タスクの成功**", "ゴール到達までに得た情報量・詳細度", "結果だけでなく経路の充実度を評価"
   "**タスク完全までの時間**", "知識状態を自覚できるまでの所要時間", "速さが常に善ではなく、文脈で最適値が変わる"
   "**学習と理解**", "認知負荷・知識獲得・情報空間の広さなど", "指標同士がしばしばトレードオフ"

.. csv-table:: **評価方法**
   :header: "手法", "概要", "長所 / 短所"
   :widths: 25, 35, 40

   "**ヒューリスティック評価**", "事前に定めたルールで専門家がレビュー", "潜在問題を早期発見できるが評価者依存が大きい"
   "**チェックリストレビュー**", "テスト項目に基づく受入テスト型評価", "初心者でも実施しやすいが網羅性に課題"
   "**ユーザビリティ調査**", "参加者に実タスクを行ってもらい観察", "生の声と行動を取得できるがコスト高"
   "**定量ログ分析 / ABテスト**", "クリック率・コンバージョン等をログで比較", "大規模・継続計測が可能だがデータ基盤が必須"


**ポイント**

- 複数指標を併用する: 指標間の因果関係や矛盾を把握し、単独では見落とす問題を補完する 
- システム全体で効果を測る: コンポーネント改修時は局所スコアだけでなく全体指標の変動を追跡する 
- 検索者行動の多様性に留意する: 一方向の提案やランキングで探索幅を狭めないよう、多様性と観察を重視する 



