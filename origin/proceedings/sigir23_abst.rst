
==================================
SIGIR'23 ABSTRACT
==================================


.. raw:: html

    <div class="menu">

        <label for="Panel0">
        <strong> Adaptive Popularity Debiasing Aggregator for Graph Collaborative Filtering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huachi+Zhou">Huachi Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Chen">Hao Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junnan+Dong">Junnan Dong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daochen+Zha">Daochen Zha</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chuang+Zhou">Chuang Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Huang">Xiao Huang</a> (1) </u>  <br>
        1:  The Hong Kong Polytechnic University, 2:  Rice University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591635">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Adaptive Popularity Debiasing Aggregator for Graph Collaborative Filtering">Google Scholar</a></div>
        (0)
        <br>
        <b>概要:　</b> グラフニューラルネットワーク(GNN)に基づく協調フィルタリング(CF)は、ユーザーとアイテムのインタラクションを二部グラフとしてモデル化し、反復的な集約を行うことで性能を向上させます。しかしながら、この集約プロセスは人気バイアスを増大させ、ユーザーがニッチな(不人気の)アイテムにアクセスしにくくする可能性があります。一部の研究ではCFにおける人気バイアスについて検討されていますが、これらはしばしば損失関数の修正に焦点を当てており、GNNベースのCFモデルにおける人気バイアスを完全には対処できません。これは、逆伝播時にデバイアス損失が非ターゲットノードに誤って伝播される可能性があるためです。本研究では、GNNベースのCFモデルの集約プロセスにおける人気バイアスを根本的に中和できるかどうかを探ります。これには以下の二つの課題があります：1) 高次の隣接ノードからの集約によって引き起こされる人気の変動が大きいため、人気の効果を推定するのが難しいこと、2) データのスパース性のため、学習可能な人気デバイアス集約関数の訓練が困難であること。これを解決するために、理論的に人気バイアスの原因を分析し、表現空間における人気の影響を測定するための定量的指標「逆人気スコア」を提案します。この指標に基づき、集約における人気バイアスを中和するためのエッジ毎の重みを学習する新しいグラフアグリゲータであるAPDAを提案します。さらに、重みスケーリングメカニズムおよび残差接続を使用してデバイアス効果を強化します。APDAを二つのベースモデルに適用し、三つの実世界のデータセットで大規模な実験を行いました。結果として、APDAは推薦性能および人気デバイアスの観点で最先端のベースラインを大幅に上回ることを示しました。
        </label>
        <input type="checkbox" id="Panel0" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The graph neural network-based collaborative filtering (CF) models user-item interactions as a bipartite graph and performs iterative aggregation to enhance performance. Unfortunately, the aggregation process may amplify the popularity bias, which impedes user engagement with niche (unpopular) items. While some efforts have studied the popularity bias in CF, they often focus on modifying loss functions, which can not fully address the popularity bias in GNN-based CF models. This is because the debiasing loss can be falsely backpropagated to non-target nodes during the backward pass of the aggregation. In this work, we study whether we can fundamentally neutralize the popularity bias in the aggregation process of GNN-based CF models. This is challenging because 1) estimating the effect of popularity is difficult due to the varied popularity caused by the aggregation from high-order neighbors, and 2) it is hard to train learnable popularity debiasing aggregation functions because of data sparsity. To this end, we theoretically analyze the cause of popularity bias and propose a quantitative metric, named inverse popularity score, to measure the effect of popularity in the representation space. Based on it, a novel graph aggregator named APDA is proposed to learn per-edge weight to neutralize popularity bias in aggregation. We further strengthen the debiasing effect with a weight scaling mechanism and residual connections. We apply APDA to two backbones and conduct extensive experiments on three real-world datasets. The results show that APDA significantly outperforms the state-of-the-art baselines in terms of recommendation performance and popularity debiasing.
        </div> </ul> <br>



        <label for="Panel1">
        <strong> On the Impact of Outlier Bias on User Clicks </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fatemeh+Sarvi">Fatemeh Sarvi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ali+Vardasbi">Ali Vardasbi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mohammad+Aliannejadi">Mohammad Aliannejadi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sebastian+Schelter">Sebastian Schelter</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (1) </u>  <br>
        1:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591745">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=On the Impact of Outlier Bias on User Clicks">Google Scholar</a></div>
        (1)
        <br>
        <b>概要:　</b> ユーザーインタラクションデータは、反事実的学習ランキング（CLTR）における監督の重要な情報源です。しかし、このデータには提示バイアスが付き物です。無バイアス学習ランキング（ULTR）に関する多くの研究では、位置バイアス、すなわち高位にあるアイテムがより多く閲覧されクリックされやすいことに焦点を当てています。さらに、アイテム間の依存関係も閲覧確率に影響を及ぼし、その例としてランキング内の外れ値アイテムが挙げられます。外れ値アイテムは他のアイテムから顕著に逸脱し、ランキング内で目立つものと定義されます。本論文では、外れ値アイテムによって引き起こされるバイアスを特定し紹介します。すなわち、ユーザーは外れ値アイテムとその近接アイテムをより多くクリックする傾向があります。まず、外れ値がユーザーのクリックに与える影響を研究するための制御実験を行います。次に、我々の研究結果が自然な状況にも一般化するかどうかを検討するため、実際のeコマースプラットフォームから取得したクリックログを解析します。両方のシナリオにおいて、ユーザーが非外れ値アイテムと比較して外れ値アイテムを顕著に多くクリックする傾向があることを示します。この傾向はすべての位置において見られ、つまり特定の位置において、外れ値アイテムが非外れ値アイテムよりも多くのインタラクションを受けることがわかります。分析の結果、外れ値のクリックへの影響はULTRにおいて対処すべきバイアスの一種であると結論付けます。したがって、外れ値バイアスと位置バイアスの両方を考慮する外れ値対応型クリックモデル（OPBM）を提案します。OPBMを基にクリック傾向を推定し、実際のeコマースデータと半合成データで行った広範な実験を通じて、この外れ値対応型クリックモデルの有効性を確認します。結果として、外れ値バイアスが厳しい場合において、ランキング性能の面でOPBMがベースラインモデルよりも優れていることを示します。
        </label>
        <input type="checkbox" id="Panel1" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> User interaction data is an important source of supervision in counterfactual learning to rank (CLTR). Such data suffers from presentation bias. Much work in unbiased learning to rank (ULTR) focuses on position bias, i.e., items at higher ranks are more likely to be examined and clicked. Inter-item dependencies also influence examination probabilities, with outlier items in a ranking as an important example. They are defined as items that observably deviate from the rest and therefore stand out in the ranking. In this paper, we identify and introduce the bias brought about by outlier items: users tend to click more on outlier items and their close neighbors. To this end, we first conduct a controlled experiment to study the effect of outliers on user clicks. Next, to examine whether the findings of our study generalize to naturalistic situations, we explore real-world click logs from an e-commerce platform. We show that, in both scenarios, users tend to click significantly more on outlier items compared to non-outlier items in the same rankings. We show that this tendency holds for all positions, i.e., for any specific position, an item receives more interactions when presented as an outlier as opposed to a non-outlier item. We conclude from our analysis that the outliers' effect on clicks is a type of bias that should be addressed in ULTR. We therefore propose an outlier-aware click model that accounts for both outlier and position bias, called outlier-aware position-based model (OPBM). We estimate click propensities based on OPBM; through extensive experiments performed on both real-world e-commerce data and semi-synthetic data, we verify the effectiveness of our outlier-aware click model. Our results show the superiority of OPBM against baselines in terms of ranking performance when outlier bias is severe.
        </div> </ul> <br>



        <label for="Panel2">
        <strong> Rectifying Unfairness in Recommendation Feedback Loop </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mengyue+Yang">Mengyue Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Wang">Jun Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jean-Francois+Ton">Jean-Francois Ton</a> (2) </u>  <br>
        1:  University College London, 2:  ByteDance Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591754">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Rectifying Unfairness in Recommendation Feedback Loop">Google Scholar</a></div>
        (2)
        <br>
        <b>概要:　</b> レコメンデーションシステムにおける公平性の問題は、機械学習モデルによるバイアスの可能性から、学術界と産業界の双方でますます関心を集めています。その一例がフィードバックループによるバイアスであり、不公平なオンラインシステムから収集されたデータがユーザーとアイテム間の関連性スコアの正確な評価を妨げます。レコメンデーションシステムはしばしば人気のあるコンテンツやベンダーを推薦するため、トレーニングデータにおいて、ユーザーとアイテム間の本来の関連性スコアが正確に表現されていない可能性があります。その結果、ユーザーの推薦は、本来の関連性スコアではなく、バイアスのかかったトレーニングデータに基づいて行われるフィードバックループが発生します。このフィードバックループの問題に対処するために、我々はB-FAIRという二段階の表現学習フレームワークを提案します。このフレームワークは、変分オートエンコーダーを使用してコンテキストデータをセンシティブな成分と非センシティブな成分に分離し、次に観測データのバイアスを排除するための新しいバランスフェアネスオブジェクティブ（BFO）を適用してレコメンデーションモデルをトレーニングします。B-FAIRの有効性は、合成データセットと実世界のベンチマークの両方で行った実験により証明されており、最新のアルゴリズムよりも優れたパフォーマンスを示しています。
        </label>
        <input type="checkbox" id="Panel2" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The issue of fairness in recommendation systems has recently become a matter of growing concern for both the academic and industrial sectors due to the potential for bias in machine learning models. One such bias is that of feedback loops, where the collection of data from an unfair online system hinders the accurate evaluation of the relevance scores between users and items. Given that recommendation systems often recommend popular content and vendors, the underlying relevance scores between users and items may not be accurately represented in the training data. Hence, this creates a feedback loop in which the user is not longer recommended based on their true relevance score but instead based on biased training data. To address this problem of feedback loops, we propose a two-stage representation learning framework, B-FAIR, aimed at rectifying the unfairness caused by biased historical data in recommendation systems. The framework disentangles the context data into sensitive and non-sensitive components using a variational autoencoder and then applies a novel Balanced Fairness Objective (BFO) to remove bias in the observational data when training a recommendation model. The efficacy of B-FAIR is demonstrated through experiments on both synthetic and real-world benchmarks, showing improved performance over state-of-the-art algorithms.
        </div> </ul> <br>



        <label for="Panel3">
        <strong> Contrastive Box Embedding for Collaborative Reasoning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tingting+Liang">Tingting Liang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuanqing+Zhang">Yuanqing Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qianhui+Di">Qianhui Di</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Congying+Xia">Congying Xia</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Youhuizi+Li">Youhuizi Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuyu+Yin">Yuyu Yin</a> (1) </u>  <br>
        1:  Hangzhou Dianzi University, 2:  Salesforce AI Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591654">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Contrastive Box Embedding for Collaborative Reasoning">Google Scholar</a></div>
        (3)
        <br>
        <b>概要:　</b> 既存のパーソナライズド推薦手法の多くは、潜在空間においてユーザーの表現を一致させることで、ユーザーが次にアイテムとどのように関わるかの確率を予測しています。しかし、認知タスクとして優れたレコメンダーシステムは、過去のインタラクションのパターンを学習するマッチングベースの目的でユーザーの次の行動を決定するのではなく、認知能力を獲得することが重要です。そこで本論文では、推薦を知的なレコメンダーシステムにより近い論理的推論タスクとしてモデル化することを提案します。従来の研究と異なり、ベクトル空間内の単一の点としてではなく、ボックスとして各クエリを埋め込むことで、ユーザーやアイテムの集合とボックスに対する論理演算（例えば、交差）をより自然にモデル化できます。ボックス埋め込みで論理クエリをモデル化することは、推論ベースの推薦の従来の研究を大幅に改良しますが、ボックス埋め込みの集約とボックスのクリティカルポイントにおける訓練行き詰まりという2つの難解な問題が残っています。これらの制限に対処するため、共同推論のためのコントラスト・ボックス学習フレームワーク（CBox4CR）を提案します。具体的には、CBox4CRは滑らかなボックス体積に基づくコントラスト学習目的を論理推論目的と組み合わせ、歴史的なインタラクションシーケンスに基づくユーザーの好みと論理クエリのための独特なボックス表現を学習します。4つの公開済データセットで実施した広範な実験により、推薦タスクにおける最先端モデルに対するCBox4CRの優位性が実証されました。
        </label>
        <input type="checkbox" id="Panel3" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Most of the existing personalized recommendation methods predict the probability that one user might interact with the next item by matching their representations in the latent space. However, as a cognitive task, it is essential for an impressive recommender system to acquire the cognitive capacity rather than to decide the users' next steps by learning the pattern from the historical interactions through matching-based objectives. Therefore, in this paper, we propose to model the recommendation as a logical reasoning task which is more in line with an intelligent recommender system. Different from the prior works, we embed each query as a box rather than a single point in the vector space, which is able to model sets of users or items enclosed and logical operators (e.g., intersection) over boxes in a more natural manner. Although modeling the logical query with box embedding significantly improves the previous work of reasoning-based recommendation, there still exist two intractable issues including aggregation of box embeddings and training stalemate in critical point of boxes. To tackle these two limitations, we propose a Contrastive Box learning framework for Collaborative Reasoning (CBox4CR). Specifically, CBox4CR combines a smoothed box volume-based contrastive learning objective with the logical reasoning objective to learn the distinctive box representations for the user's preference and the logical query based on the historical interaction sequence. Extensive experiments conducted on four publicly available datasets demonstrate the superiority of our CBox4CR over the state-of-the-art models in recommendation task.
        </div> </ul> <br>



        <label for="Panel4">
        <strong> Learning to Re-rank with Constrained Meta-Optimal Transport </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrés+Hoyos-Idrobo">Andrés Hoyos-Idrobo</a> (1) </u>  <br>
        1:  Rakuten Institute of Technology & Rakuten Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591714">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Learning to Re-rank with Constrained Meta-Optimal Transport">Google Scholar</a></div>
        (4)
        <br>
        <b>概要:　</b> 検索システムにおける多くの再ランキング戦略は、期待されるランキング制約（例えば、露出の公平性（FOE））を満たす確率的ランキングポリシーに依存しています。これらのポリシーは、二重確率行列（DS行列）として符号化され、一般的に2段階のパイプラインを持ちます：（i）オフラインでの再ランキングポリシー構築ステップと（ii）オンラインでのランキングサンプリングステップです。再ランキングポリシーの構築には、発行されるクエリごとに制約付き最適化問題を繰り返し解く必要があります。したがって、新しいまたは未知のクエリに対して最適化手続きを再計算する必要があります。サンプリングに関しては、Birkhoff-von-Neumann分解（BvND）が一般的にDSベースのポリシーからランキングを引き出すために使用されます。しかしながら、BvNDはオンラインで計算するにはコストがかかりすぎます。したがって、BvNDをサンプリングソリューションとして使用すると、N件のクエリとn件のドキュメントに対してO(N n^2)のメモリを消費します。本論文では、公平な確率的再ランキングポリシーを予測するための新しく、迅速で軽量な方法である「制約付きメタ最適輸送（CoMOT）」を提案します。この方法は、ランク付け学習システムのようにクエリ全体で共有されるニューラルネットワークに適合します。また、DSベースのポリシーからオンラインでサンプリングするための手法として「Gumbelマッチングサンプリング（GumMS）」を導入します。提案されたパイプラインCoMOT + GumMSは、単一モデルのパラメータのみを保存する必要があり、未知のクエリにも一般化できます。私たちは、このパイプラインをTREC 2019および2020データセット上でFOE制約のもとで実験的に評価しました。実験の結果、CoMOTは保持されたデータに対して迅速に公平な再ランキングポリシーを予測し、1クエリあたりの平均ドキュメント数に比例したスピードアップを示しました。また、元の最適化ベースのポリシーに匹敵する公平性とランキングパフォーマンスも示しました。さらに、GumMSが期待値においてDSベースのポリシーを近似する効果的な手法であることも実験的に検証しました。これらの手法は、情報検索における最適化問題を解決するための予測ソリューションに向けた重要な一歩です。
        </label>
        <input type="checkbox" id="Panel4" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Many re-ranking strategies in search systems rely on stochastic ranking policies, encoded as Doubly-Stochastic (DS) matrices, that satisfy desired ranking constraints in expectation, e.g., Fairness of Exposure (FOE). These strategies are generally two-stage pipelines: (i) an offline re-ranking policy construction step and (ii) an online sampling of rankings step. Building a re-ranking policy requires repeatedly solving a constrained optimization problem, one for each issued query. Thus, it is necessary to recompute the optimization procedure for any new/unseen query. Regarding sampling, the Birkhoff-von-Neumann decomposition (BvND) is the favored approach to draw rankings from any DS-based policy. Nonetheless, the BvND is too costly to compute online. Hence, the BvND as a sampling solution is memory-consuming as it can grow as O(N n2) for N queries and n documents. This paper proposes a novel, fast, lightweight way to predict fair stochastic re-ranking policies: Constrained Meta-Optimal Transport (CoMOT). This method fits a neural network shared across queries like a learning-to-rank system. We also introduce Gumbel-Matching Sampling (GumMS), an online sampling approach from DS-based policies. Our proposed pipeline, CoMOT + GumMS, only needs to store the parameters of a single model, and it can generalize to unseen queries. We empirically evaluated our pipeline on the TREC 2019 and 2020 datasets under FOE constraints. Our experiments show that CoMOT rapidly predicts fair re-ranking policies on held-out data, with a speed-up proportional to the average number of documents per query. It also displays fairness and ranking performance similar to the original optimization-based policy. Furthermore, we empirically validate the effectiveness of GumMS to approximate DS-based policies in expectation. Together, our methods are an important step in learning-to-predict solutions to optimization problems in information retrieval.
        </div> </ul> <br>



        <label for="Panel5">
        <strong> Ensemble Modeling with Contrastive Knowledge Distillation for Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hanwen+Du">Hanwen Du</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huanhuan+Yuan">Huanhuan Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pengpeng+Zhao">Pengpeng Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuzhen+Zhuang">Fuzhen Zhuang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guanfeng+Liu">Guanfeng Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Zhao">Lei Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanchi+Liu">Yanchi Liu</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Victor+S.+Sheng">Victor S. Sheng</a> (5) </u>  <br>
        1:  Soochow University, 2:  Beihang University, 3:  Macquarie University, 4:  Rutgers University, 5:  Texas Tech University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591679">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Ensemble Modeling with Contrastive Knowledge Distillation for Sequential Recommendation">Google Scholar</a></div>
        (5)
        <br>
        <b>概要:　</b> シーケンシャルレコメンデーションは、ユーザーの動的な興味を捉え、次にユーザーが好むアイテムを予測することを目的としています。多くのシーケンシャルレコメンデーション手法は、シーケンスエンコーダーとしてディープニューラルネットワークを使用し、ユーザーとアイテムの表現を生成します。既存の研究は主に、より強力なシーケンスエンコーダーの設計に焦点を当てています。しかし、パラレルネットワークのアンサンブルをシーケンスエンコーダーとして訓練するという試みはほとんど行われていません。これは、アンサンブルネットワークが多様な予測結果をもたらし、より高い精度を実現できるためです。本論文では、シーケンシャルレコメンデーションのためのコントラスト知識蒸留を用いたアンサンブルモデリング（EMKD）を提案します。我々のフレームワークは、シーケンスエンコーダーのアンサンブルとして複数のパラレルネットワークを採用し、これらのネットワークの出力分布に基づいてアイテムを推薦します。パラレルネットワーク間での知識移転を促進するために、我々は新しいコントラスト知識蒸留アプローチを提案します。このアプローチは、表現レベルでのネットワーク内コントラスト学習（ICL）とネットワーク間コントラスト学習（CCL）を介して知識移転を行い、教師ネットワークと学生ネットワークの出力分布間のカラバック・ライブラー情報量を最小化することによってロジットレベルからの知識蒸留（KD）を実行します。コンテクスト情報を活用するために、主要なマスクドアイテム予測タスクと補助的な属性予測タスクをマルチタスク学習方式で訓練します。公共ベンチマークデータセットでの広範な実験により、EMKDが最先端の手法と比較して大幅な改善を達成することが示されました。また、我々のアンサンブル手法は、他のシーケンシャルレコメンデーションシステムの性能も向上させることができる一般的なアプローチであることを示しています。我々のコードは以下のリンクで入手可能です：https://github.com/hw-du/EMKD。
        </label>
        <input type="checkbox" id="Panel5" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Sequential recommendation aims to capture users' dynamic interest and predicts the next item of users' preference. Most sequential recommendation methods use a deep neural network as sequence encoder to generate user and item representations. Existing works mainly center upon designing a stronger sequence encoder. However, few attempts have been made with training an ensemble of networks as sequence encoders, which is more powerful than a single network because an ensemble of parallel networks can yield diverse prediction results and hence better accuracy. In this paper, we present Ensemble Modeling with contrastive Knowledge Distillation for sequential recommendation (EMKD). Our framework adopts multiple parallel networks as an ensemble of sequence encoders and recommends items based on the output distributions of all these networks. To facilitate knowledge transfer between parallel networks, we propose a novel contrastive knowledge distillation approach, which performs knowledge transfer from the representation level via Intra-network Contrastive Learning (ICL) and Cross-network Contrastive Learning (CCL), as well as Knowledge Distillation (KD) from the logits level via minimizing the Kullback-Leibler divergence between the output distributions of the teacher network and the student network. To leverage contextual information, we train the primary masked item prediction task alongside the auxiliary attribute prediction task as a multi-task learning scheme. Extensive experiments on public benchmark datasets show that EMKD achieves a significant improvement compared with the state-of-the-art methods. Besides, we demonstrate that our ensemble method is a generalized approach that can also improve the performance of other sequential recommenders. Our code is available at this link: https://github.com/hw-du/EMKD.
        </div> </ul> <br>



        <label for="Panel6">
        <strong> MELT: Mutual Enhancement of Long-Tailed User and Item for Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kibum+Kim">Kibum Kim</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongmin+Hyun">Dongmin Hyun</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sukwon+Yun">Sukwon Yun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chanyoung+Park">Chanyoung Park</a> (1) </u>  <br>
        1:  KAIST, 2:  POSTECH <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591725">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MELT: Mutual Enhancement of Long-Tailed User and Item for Sequential Recommendation">Google Scholar</a></div>
        (6)
        <br>
        <b>概要:　</b> ロングテール問題は、Sequential Recommender Systems（SRS）において長年の課題です。この問題はユーザーとアイテムの両方の観点で存在します。多くの既存研究はSRSにおけるロングテール問題に対処していますが、それらはユーザーまたはアイテムのどちらか一方の視点に注目するのみです。しかし、我々はロングテールユーザーとアイテムの問題が同時に存在し、一方のみを考慮することがもう一方のパフォーマンスの低下を招くことを発見しました。そこで本論文では、ユーザーとアイテムの両方の観点からロングテール問題を共同で緩和する新しいフレームワーク、Mutual Enhancement of Long-Tailed user and item（MELT）を提案します。MELTは、それぞれロングテールユーザーとアイテムを担当する二つのブランチで構成され、それらのブランチは互いに強化し合うように、カリキュラム学習に基づくトレーニングによって効果的に訓練されます。MELTは既存のSRSモデルとシームレスに統合できるモデル不可知性を持っています。八つのデータセットに対する広範な実験により、主要なユーザーおよびアイテムのパフォーマンスを犠牲にすることなく、ユーザーとアイテムの両方の観点からロングテール問題を緩和する効果が示されました。私たちの知る限り、SRSにおいてユーザーとアイテムのロングテール問題を共同で緩和するのはMELTが初めての試みです。
        </label>
        <input type="checkbox" id="Panel6" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The long-tailed problem is a long-standing challenge in Sequential Recommender Systems (SRS) in which the problem exists in terms of both users and items. While many existing studies address the long-tailed problem in SRS, they only focus on either the user or item perspective. However, we discover that the long-tailed user and item problems exist at the same time, and considering only either one of them leads to sub-optimal performance of the other one. In this paper, we propose a novel framework for SRS, called Mutual Enhancement of Long-Tailed user and item (MELT), that jointly alleviates the long-tailed problem in the perspectives of both users and items. MELT consists of bilateral branches each of which is responsible for long-tailed users and items, respectively, and the branches are trained to mutually enhance each other, which is trained effectively by a curriculum learning-based training. MELT is model-agnostic in that it can be seamlessly integrated with existing SRS models. Extensive experiments on eight datasets demonstrate the benefit of alleviating the long-tailed problems in terms of both users and items even without sacrificing the performance of head users and items, which has not been achieved by existing methods. To the best of our knowledge, MELT is the first work that jointly alleviates the long-tailed user and item problems in SRS.
        </div> </ul> <br>



        <label for="Panel7">
        <strong> Frequency Enhanced Hybrid Attention Network for Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinyu+Du">Xinyu Du</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huanhuan+Yuan">Huanhuan Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pengpeng+Zhao">Pengpeng Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianfeng+Qu">Jianfeng Qu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuzhen+Zhuang">Fuzhen Zhuang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guanfeng+Liu">Guanfeng Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanchi+Liu">Yanchi Liu</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Victor+S.+Sheng">Victor S. Sheng</a> (5) </u>  <br>
        1:  Soochow University, 2:  Beihang University, 3:  Macquarie University, 4:  Rutgers University, 5:  Texas Tech University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591689">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Frequency Enhanced Hybrid Attention Network for Sequential Recommendation">Google Scholar</a></div>
        (7)
        <br>
        <b>概要:　</b> 長期依存関係のモデリングに優れた自己注意メカニズムは、逐次推奨システムの分野で広く利用されている技術の一つです。しかし、最近の多くの研究は、現行の自己注意ベースのモデルが低周波フィルターであり、高周波情報を捉えるには不十分であることを示しています。さらに、ユーザーの行動中のアイテムは相互に絡み合っているため、これらのモデルは時間領域に隠れた固有の周期性を区別するには不完全です。本研究では視点を周波数領域にシフトし、新しい周波数強化ハイブリッド注意ネットワーク（FEARec）を提案します。このモデルでは、まず低周波情報と高周波情報の両方を明示的に学習できるように、元の時間領域の自己注意を周波数領域においてランプ構造を使って改善します。さらに、周期的な特性を捉えるために、周波数領域で自己相関を介じた類似の注意メカニズムを設計し、時間領域と周波数領域の注意を融合させたユニオンモデルに統合しました。最後に、複数のビューが時間領域と周波数領域の両方で整列することを保証するために、対比学習と周波数正則化を利用しています。4つの広く使用されているベンチマークデータセットで行った広範な実験により、提案モデルが最先端のアプローチよりも大幅に優れていることが示されました。
        </label>
        <input type="checkbox" id="Panel7" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The self-attention mechanism, which equips with a strong capability of modeling long-range dependencies, is one of the extensively used techniques in the sequential recommendation field. However, many recent studies represent that current self-attention based models are low-pass filters and are inadequate to capture high-frequency information. Furthermore, since the items in the user behaviors are intertwined with each other, these models are incomplete to distinguish the inherent periodicity obscured in the time domain. In this work, we shift the perspective to the frequency domain, and propose a novel Frequency Enhanced Hybrid Attention Network for Sequential Recommendation, namely FEARec. In this model, we firstly improve the original time domain self-attention in the frequency domain with a ramp structure to make both low-frequency and high-frequency information could be explicitly learned in our approach. Moreover, we additionally design a similar attention mechanism via auto-correlation in the frequency domain to capture the periodic characteristics and fuse the time and frequency level attention in a union model. Finally, both contrastive learning and frequency regularization are utilized to ensure that multiple views are aligned in both the time domain and frequency domain. Extensive experiments conducted on four widely used benchmark datasets demonstrate that the proposed model performs significantly better than the state-of-the-art approaches.
        </div> </ul> <br>



        <label for="Panel8">
        <strong> Meta-optimized Contrastive Learning for Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiuyuan+Qin">Xiuyuan Qin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huanhuan+Yuan">Huanhuan Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pengpeng+Zhao">Pengpeng Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junhua+Fang">Junhua Fang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuzhen+Zhuang">Fuzhen Zhuang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guanfeng+Liu">Guanfeng Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanchi+Liu">Yanchi Liu</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Victor+Sheng">Victor Sheng</a> (5) </u>  <br>
        1:  Soochow University, 2:  Beihang University, 3:  Macquarie University, 4:  Rutgers University, 5:  Texas Tech University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591727">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Meta-optimized Contrastive Learning for Sequential Recommendation">Google Scholar</a></div>
        (8)
        <br>
        <b>概要:　</b> コントラスト学習（Contrastive Learning, CL）は、希少でノイズの多い推薦データの課題に対処するための新しいアプローチとして注目されています。有望な結果を達成しているにも関わらず、現在のほとんどのCL手法は、対比ペアを生成するために手作りのデータやモデルの拡張のみを実行しており、異なるデータセットに適した拡張操作を見つけるのが難しく、モデルの汎化が困難です。また、不十分な入力データはエンコーダーがコラプスした埋め込みを学習する原因となるため、これらのCL手法は対比するために比較的大量のトレーニングデータ（例：大きなバッチサイズやメモリバンク）を必要とします。しかし、すべての対比ペアが常に情報量が豊富で識別力があるとは限りません。そこで、本研究では、一般的なCLベースの推薦モデルとして、MCLRec（Meta-optimized Contrastive Learning for sequential Recommendation）が提案されています。本研究では、データ拡張と学習可能なモデル拡張の両方を適用することにより、ランダムなデータ拡張に隠された情報豊富な特徴を適応的に捕捉するためにデータとモデルの拡張ビューを対比する標準的なCLフレームワークを革新しています。さらに、MCLRecはメタ学習の手法を活用し、モデルの拡張機能の更新を導き、入力データの量を増やすことなく対比ペアの質を向上させます。最後に、対比正則化項を考慮して、拡張モデルがより情報豊富な拡張ビューを生成し、メタ更新内であまりにも類似した対比ペアを回避することを促しています。一般的に使用されるデータセットでの実験結果により、MCLRecの有効性が立証されました。
        </label>
        <input type="checkbox" id="Panel8" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Contrastive Learning (CL) performances as a rising approach to address the challenge of sparse and noisy recommendation data. Although having achieved promising results, most existing CL methods only perform either hand-crafted data or model augmentation for generating contrastive pairs to find a proper augmentation operation for different datasets, which makes the model hard to generalize. Additionally, since insufficient input data may lead the encoder to learn collapsed embeddings, these CL methods expect a relatively large number of training data (e.g., large batch size or memory bank) to contrast. However, not all contrastive pairs are always informative and discriminative enough for the training processing. Therefore, a more general CL-based recommendation model called Meta-optimized Contrastive Learning for sequential Recommendation (MCLRec) is proposed in this work. By applying both data augmentation and learnable model augmentation operations, this work innovates the standard CL framework by contrasting data and model augmented views for adaptively capturing the informative features hidden in stochastic data augmentation. Moreover, MCLRec utilizes a meta-learning manner to guide the updating of the model augmenters, which helps to improve the quality of contrastive pairs without enlarging the amount of input data. Finally, a contrastive regularization term is considered to encourage the augmentation model to generate more informative augmented views and avoid too similar contrastive pairs within the meta updating. The experimental results on commonly used datasets validate the effectiveness of MCLRec.
        </div> </ul> <br>



        <label for="Panel9">
        <strong> Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chengkai+Huang">Chengkai Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shoujin+Wang">Shoujin Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xianzhi+Wang">Xianzhi Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lina+Yao">Lina Yao</a> (3) </u>  <br>
        1:  The University of New South Wales, 2:  University of Technology Sydney, 3:  CSIRO's Data 61 and UNSW <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591672">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation">Google Scholar</a></div>
        (9)
        <br>
        <b>概要:　</b> シーケンシャル推薦システム（SRS）は、ユーザーとアイテムの相互作用のシーケンスに埋め込まれたユーザーの複雑な嗜好を包括的にモデル化することにより、ユーザーに興味を持たせる可能性のある次のアイテムを予測することを目的としています。しかし、既存のSRSの多くは、アイテムID情報に基づいてユーザーの単一の低レベル嗜好をモデル化する一方で、アイテム属性情報（例えば、アイテムのカテゴリ）によって明らかにされる高レベルの嗜好を無視しがちです。さらに、これらは次のアイテムを予測するために限られたシーケンス文脈情報を利用し、より豊かなアイテム間の意味的関係を見落とすことが多いです。これを解決するために、本研究では、正確なシーケンシャル推薦のために複雑な低レベルおよび高レベルの嗜好ダイナミクスを実質的にモデル化する、階層的嗜好モデルフレームワークを提案しました。具体的には、このフレームワークで新しいデュアル・トランスフォーマーモジュールと新しいデュアル・コントラスト学習スキームが設計されており、ユーザーの低レベルおよび高レベルの嗜好を識別的に学習し、それぞれの嗜好学習を効果的に強化します。さらに、新しいセマンティクス強化型コンテキスト埋め込みモジュールが考案され、推薦パフォーマンスをさらに向上させるために、より情報豊富なコンテキスト埋め込みを生成します。6つの実世界のデータセットでの広範な実験により、提案手法が最先端手法よりも優れていることと、我々の設計が合理的であることが示されました。
        </label>
        <input type="checkbox" id="Panel9" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Sequential recommender systems (SRSs) aim to predict the subsequent items which may interest users via comprehensively modeling users' complex preference embedded in the sequence of user-item interactions. However, most of existing SRSs often model users' single low-level preference based on item ID information while ignoring the high-level preference revealed by item attribute information, such as item category. Furthermore, they often utilize limited sequence context information to predict the next item while overlooking richer inter-item semantic relations. To this end, in this paper, we proposed a novel hierarchical preference modeling framework to substantially model the complex low- and high-level preference dynamics for accurate sequential recommendation. Specifically, in the framework, a novel dual-transformer module and a novel dual contrastive learning scheme have been designed to discriminatively learn users' low- and high-level preference and to effectively enhance both low- and high-level preference learning respectively. In addition, a novel semantics-enhanced context embedding module has been devised to generate more informative context embedding for further improving the recommendation performance. Extensive experiments on six real-world datasets have demonstrated both the superiority of our proposed method over the state-of-the-art ones and the rationality of our design.
        </div> </ul> <br>



        <label for="Panel10">
        <strong> A Symmetric Dual Encoding Dense Retrieval Framework for Knowledge-Intensive Visual Question Answering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alireza+Salemi">Alireza Salemi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Juan+Altmayer+Pizzorno">Juan Altmayer Pizzorno</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hamed+Zamani">Hamed Zamani</a> (1) </u>  <br>
        1:  University of Massachusetts Amherst <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591629">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Symmetric Dual Encoding Dense Retrieval Framework for Knowledge-Intensive Visual Question Answering">Google Scholar</a></div>
        (10)
        <br>
        <b>概要:　</b> Knowledge-Intensive Visual Question Answering (KI-VQA)とは、画像自体に答えが存在しない質問に対し、その解答を行うことを指します。本論文では、KI-VQAタスクに対する新たなパイプラインを提案します。このパイプラインは、リトリーバーとリーダーの二つの部品から構成されます。まず、我々はDEDRという対称的なデュアルエンコーディング密リトリーバーフレームワークを紹介します。文書とクエリは、単一モーダル（テキスト）およびマルチモーダルエンコーダーを使用して共有の埋め込み空間へエンコードされます。そして、これら二つのエンコーダーの表示空間のギャップを埋めるための反復的な知識蒸留アプローチを導入します。<br><br>二つのよく確立されたKI-VQAデータセット（OK-VQAとFVQA）に対する広範な評価により、DEDRがそれぞれ11.6%および30.9%の精度で、最先端のベースラインを上回ることを示します。DEDRによってリトリーブされたパッセージを利用し、KI-VQAタスクのテキスト回答を生成するため、MM-FiDというエンコーダ・デコーダ型のマルチモーダルFusion-in-Decoderモデルをさらに提案します。MM-FiDは、質問、画像、および各リトリーブされたパッセージを個別にエンコードし、すべてのパッセージをデコーダー内で統合して使用します。文献における競争力の高いベースラインと比較して、このアプローチはOK-VQAとFVQAでそれぞれ5.5%および8.5%の質問回答精度の向上をもたらします。
        </label>
        <input type="checkbox" id="Panel10" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge-Intensive Visual Question Answering (KI-VQA) refers to answering a question about an image whose answer does not lie in the image. This paper presents a new pipeline for KI-VQA tasks, consisting of a retriever and a reader. First, we introduce DEDR, a symmetric dual encoding dense retrieval framework in which documents and queries are encoded into a shared embedding space using uni-modal (textual) and multi-modal encoders. We introduce an iterative knowledge distillation approach that bridges the gap between the representation spaces in these two encoders. Extensive evaluation on two well-established KI-VQA datasets, i.e., OK-VQA and FVQA, suggests that DEDR outperforms state-of-the-art baselines by 11.6% and 30.9% on OK-VQA and FVQA, respectively. Utilizing the passages retrieved by DEDR, we further introduce MM-FiD, an encoder-decoder multi-modal fusion-in-decoder model, for generating a textual answer for KI-VQA tasks. MM-FiD encodes the question, the image, and each retrieved passage separately and uses all passages jointly in its decoder. Compared to competitive baselines in the literature, this approach leads to 5.5% and 8.5% improvements in terms of question answering accuracy on OK-VQA and FVQA, respectively.
        </div> </ul> <br>



        <label for="Panel11">
        <strong> A Personalized Dense Retrieval Framework for Unified Information Access </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hansi+Zeng">Hansi Zeng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Surya+Kallumadi">Surya Kallumadi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zaid+Alibadi">Zaid Alibadi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rodrigo+Nogueira">Rodrigo Nogueira</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hamed+Zamani">Hamed Zamani</a> (1) </u>  <br>
        1:  University of Massachusetts Amherst, 2:  Lowe's Companies, 3:  University of Campinas <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591626">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Personalized Dense Retrieval Framework for Unified Information Access">Google Scholar</a></div>
        (11)
        <br>
        <b>概要:　</b> 情報アクセス要求（情報検索、レコメンデーション、質問応答など）に効率的かつ効果的に応答できる汎用モデルの開発は、情報検索コミュニティにおいて長年の目標でした。本論文では、高密度検索と近似最近傍検索の最新の発展からもたらされる柔軟性、効率性、そして効果性が、この目標達成への道を滑らかにしたと主張します。我々は、キーワード検索、クエリ・バイ・エグザンプル、補完アイテムのレコメンデーションなど、幅広い（個別化された）情報アクセス要求に対応できる、汎用性かつ拡張性のある高密度検索フレームワーク「framework」を開発しました。我々の提案するアプローチは、個別化された注意ネットワークの開発を通じて、高密度検索モデルの能力をアドホック検索タスクに拡張し、ユーザー固有の好みを取り入れることで、より個別化された正確な情報アクセス体験を可能にします。実世界のeコマースデータに対する実験結果は、これらの個々の情報アクセスタスク専用に開発された競争力のあるベースラインと比較しても、著しい改善があることを示し、汎用情報アクセスモデルの開発の可能性を示唆しています。本研究は、今後の探求のための基本的な研究方向性を数多く開きます。
        </label>
        <input type="checkbox" id="Panel11" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Developing a universal model that can efficiently and effectively respond to a wide range of information access requests-from retrieval to recommendation to question answering---has been a long-lasting goal in the information retrieval community. This paper argues that the flexibility, efficiency, and effectiveness brought by the recent development in dense retrieval and approximate nearest neighbor search have smoothed the path towards achieving this goal. We develop a generic and extensible dense retrieval framework, called framework, that can handle a wide range of (personalized) information access requests, such as keyword search, query by example, and complementary item recommendation. Our proposed approach extends the capabilities of dense retrieval models for ad-hoc retrieval tasks by incorporating user-specific preferences through the development of a personalized attentive network. This allows for a more tailored and accurate personalized information access experience. Our experiments on real-world e-commerce data suggest the feasibility of developing universal information access models by demonstrating significant improvements even compared to competitive baselines specifically developed for each of these individual information access tasks. This work opens up a number of fundamental research directions for future exploration.
        </div> </ul> <br>



        <label for="Panel12">
        <strong> Constructing Tree-based Index for Efficient and Effective Dense Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haitao+Li">Haitao Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qingyao+Ai">Qingyao Ai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingtao+Zhan">Jingtao Zhan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiaxin+Mao">Jiaxin Mao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiqun+Liu">Yiqun Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zheng+Liu">Zheng Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhao+Cao">Zhao Cao</a> (3) </u>  <br>
        1:  Tsinghua University & Zhongguancun Laboratory, 2:  Renmin University of China, 3:  Huawei Poisson Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591651">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Constructing Tree-based Index for Efficient and Effective Dense Retrieval">Google Scholar</a></div>
        (12)
        <br>
        <b>概要:　</b> 最近の研究により、Dense Retrieval（DR）技術がIRシステムにおける第一段階の検索性能を大幅に向上させることが示されている。その実証的な有効性にもかかわらず、DRの適用は依然として限られている。高効率な逆インデックス解を用いる統計的検索モデルとは異なり、DRモデルは密な埋め込みを構築し、既存の多数の検索インデックスシステムで前処理することが困難である。これを避けるために、高価なブルートフォース検索のコストを避け、Approximate Nearest Neighbor（ANN）アルゴリズムと対応するインデックスが広く適用され、DRモデルの推論過程を高速化している。しかしながら、ANNはDRモデルの効率を向上させる一方で、検索性能に大きな代償を伴うことが多い。この問題を解決するために、我々はJoint optimization of TRee-based index and query encoding（JTR）を提案する。具体的には、木構造インデックスとクエリエンコーダを統一的に訓練する新しいコントラスト学習損失を設計した。木構造型のネガティブサンプリング戦略を適用し、木に最大ヒープ特性を持たせ、ビームサーチの効果を高めている。さらに、クラスタ割り当てを最適化問題として扱い、オーバーラップクラスターを可能とする木構造インデックスの更新を図った。我々はJTRを多数の人気のある検索ベンチマークで評価し、実験結果はJTRが広く採用されているベースラインと比較して、高いシステム効率を維持しながらより優れた検索性能を達成することを示している。これはニューラル検索システム設計において効率と有効性のバランスを取るための潜在的な解決策を提供するものである。
        </label>
        <input type="checkbox" id="Panel12" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recent studies have shown that Dense Retrieval (DR) techniques can significantly improve the performance of first-stage retrieval in IR systems. Despite its empirical effectiveness, the application of DR is still limited. In contrast to statistic retrieval models that rely on highly efficient inverted index solutions, DR models build dense embeddings that are difficult to be pre-processed with most existing search indexing systems. To avoid the expensive cost of brute-force search, the Approximate Nearest Neighbor (ANN) algorithm and corresponding indexes are widely applied to speed up the inference process of DR models. Unfortunately, while ANN can improve the efficiency of DR models, it usually comes with a significant price on retrieval performance. To solve this issue, we propose JTR, which stands for Joint optimization of TRee-based index and query encoding. Specifically, we design a new unified contrastive learning loss to train tree-based index and query encoder in an end-to-end manner. The tree-based negative sampling strategy is applied to make the tree have the maximum heap property, which supports the effectiveness of beam search well. Moreover, we treat the cluster assignment as an optimization problem to update the tree-based index that allows overlapped clustering. We evaluate JTR on numerous popular retrieval benchmarks. Experimental results show that JTR achieves better retrieval performance while retaining high system efficiency compared with widely-adopted baselines. It provides a potential solution to balance efficiency and effectiveness in neural retrieval system designs.
        </div> </ul> <br>



        <label for="Panel13">
        <strong> One Blade for One Purpose: Advancing Math Information Retrieval using Hybrid Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Zhong">Wei Zhong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sheng-Chieh+Lin">Sheng-Chieh Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jheng-Hong+Yang">Jheng-Hong Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jimmy+Lin">Jimmy Lin</a> (1) </u>  <br>
        1:  University of Waterloo <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591746">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=One Blade for One Purpose: Advancing Math Information Retrieval using Hybrid Search">Google Scholar</a></div>
        (13)
        <br>
        <b>概要:　</b> ニューラルリトリーバーは、数式認識検索において効果的であることが示されています。数式シンボルの不一致に対処する能力、高度に文脈化された意味を表現する能力、そして効果的な表現を学習する能力は、数式情報検索を向上させるために重要です。しかし、最も効果的なリトリーバーは、各数式トークンのトークンレベルの高密度な表現に依存しているため、数式の内容が一般的に多くのトークンを消費することを考えると、過大なストレージ需要が発生し、実用的ではありません。本研究では、ハイブリッド検索を通じてこの効率性のボトルネックを緩和しながら、数式情報検索の効果を高めることを目指します。この目的のために、私たちはMABOWDOR（Math-Aware Best-of-Worlds Domain Optimized Retriever）を提案します。このリトリーバーは、教師なし構造検索コンポーネント、高密度リトリーバー、および必要に応じて疎なリトリーバーをドメイン適応型バックボーンに基づいて文脈強化事前学習により学習させたものであり、数式文書から異種データを取得する際のさまざまなニーズに対応します。私たちのハイブリッド検索は、以前の最先端数式情報検索システムを上回り、効率性のボトルネックを解消します。私たちのシステムはhttps://github.com/approach0/pya0で利用可能です。
        </label>
        <input type="checkbox" id="Panel13" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Neural retrievers have been shown to be effective for math-aware search. Their ability to cope with math symbol mismatches, to represent highly contextualized semantics, and to learn effective representations are critical to improving math information retrieval. However, the most effective retriever for math remains impractical as it depends on token-level dense representations for each math token, which leads to prohibitive storage demands, especially considering that math content generally consumes more tokens. In this work, we try to alleviate this efficiency bottleneck while boosting math information retrieval effectiveness via hybrid search. To this end, we propose MABOWDOR, a Math-Aware Bestof-Worlds Domain Optimized Retriever, which has an unsupervised structure search component, a dense retriever, and optionally a sparse retriever on top of a domain-adapted backbone learned by context-enhanced pretraining, each addressing a different need in retrieving heterogeneous data from math documents. Our hybrid search outperforms the previous state-of-the-art math IR system while eliminating efficiency bottlenecks. Our system is available at https://github.com/approach0/pya0.
        </div> </ul> <br>



        <label for="Panel14">
        <strong> Lexically-Accelerated Dense Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hrishikesh+Kulkarni">Hrishikesh Kulkarni</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sean+MacAvaney">Sean MacAvaney</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nazli+Goharian">Nazli Goharian</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ophir+Frieder">Ophir Frieder</a> (1) </u>  <br>
        1:  Georgetown University, 2:  University of Glasgow <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591715">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Lexically-Accelerated Dense Retrieval">Google Scholar</a></div>
        (14)
        <br>
        <b>概要:　</b> 学習された高密度なベクトルに基づいて文書のスコアリングを行う検索手法（すなわち、密な検索）は、従来の語彙信号に基づく検索手法（すなわち、従来型検索）に比べてますます人気が高まっています。これらの手法は、ユーザーのクエリに含まれる語彙と同じ単語を含まない関連する文書を特定できる能力（それによって再現率を向上させる）という重要な利点を持っています。しかし、実際にこれらの利点を享受するためには、密な検索手法は通常、文書コレクションに対する網羅的な検索が必要であり、クエリ処理時に従来の語彙検索手法よりもはるかに高価になります。いくつかの手法は、完全な密な検索の結果を近似することでこの計算負荷を軽減することを目指しています。これらの手法は上位の結果をそこそこ近似できますが、密な検索の主要な利点の一つである再現率においては劣ります。そこで我々は既存の密な検索モデルの効率を損なうことなく改善するシンプルかつ効果的な手法、'LADR' (Lexically-Accelerated Dense Retrieval) を導入します。LADRは、文書近接グラフを使用した密な検索探索の始点として語彙検索技術を利用します。広範な実験を通じて、LADRが近似的なk-NN手法の中で新しい密な検索の効果-効率性のパレートフロンティアを確立することがわかりました。我々のハードウェアではクエリごとの検索待ち時間を約8ミリ秒に調整した場合でも、LADRは標準ベンチマークで網羅的検索と同等の精度と再現率を一貫して達成します。重要なのは、LADRが単一のCPUを使用するだけでGPUのようなハードウェアアクセラレータを必要としないため、密な検索システムの展開コストを削減できるという点です。
        </label>
        <input type="checkbox" id="Panel14" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Retrieval approaches that score documents based on learned dense vectors (i.e., dense retrieval) rather than lexical signals (i.e., conventional retrieval) are increasingly popular. Their ability to identify related documents that do not necessarily contain the same terms as those appearing in the user's query (thereby improving recall) is one of their key advantages. However, to actually achieve these gains, dense retrieval approaches typically require an exhaustive search over the document collection, making them considerably more expensive at query-time than conventional lexical approaches. Several techniques aim to reduce this computational overhead by approximating the results of a full dense retriever. Although these approaches reasonably approximate the top results, they suffer in terms of recall -- one of the key advantages of dense retrieval. We introduce 'LADR' (Lexically-Accelerated Dense Retrieval), a simple-yet-effective approach that improves the efficiency of existing dense retrieval models without compromising on retrieval effectiveness. LADR uses lexical retrieval techniques to seed a dense retrieval exploration that uses a document proximity graph. Through extensive experiments, we find that LADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier among approximate k nearest neighbor techniques. When tuned to take around 8ms per query in retrieval latency on our hardware, LADR consistently achieves both precision and recall that are on par with an exhaustive search on standard benchmarks. Importantly, LADR accomplishes this using only a single CPU -- no hardware accelerators such as GPUs -- which reduces the deployment cost of dense retrieval systems.
        </div> </ul> <br>



        <label for="Panel15">
        <strong> Multivariate Representation Learning for Information Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hamed+Zamani">Hamed Zamani</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michael+Bendersky">Michael Bendersky</a> (2) </u>  <br>
        1:  University of Massachusetts Amherst, 2:  Google Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591740">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multivariate Representation Learning for Information Retrieval">Google Scholar</a></div>
        (15)
        <br>
        <b>概要:　</b> 密集検索モデルは、クエリと文書の表現を学習するためにバイエンコーダーネットワークアーキテクチャを使用します。これらの表現は通常、ベクトル表現の形式であり、その類似性はしばしばドット積関数を用いて計算されます。本論文では、密集検索のための新しい表現学習フレームワークを提案します。各クエリと文書のベクトルを学習する代わりに、我々のフレームワークは多変量分布を学習し、負の多変量KLダイバージェンスを使用して分布間の類似性を計算します。単純さと効率性のために、分布は多変量正規分布であると仮定し、大規模言語モデルを用いてこれらの分布の平均ベクトルと分散ベクトルを生成します。我々は、提案されたフレームワークの理論的基盤を提供し、既存の近似最近傍アルゴリズムにシームレスに統合して効率的に検索を実行できることを示します。幅広いデータセットに対して広範な実験を行い、競争力のある密集検索モデルと比較して有意な改善を実証します。
        </label>
        <input type="checkbox" id="Panel15" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Dense retrieval models use bi-encoder network architectures for learning query and document representations. These representations are often in the form of a vector representation and their similarities are often computed using the dot product function. In this paper, we propose a new representation learning framework for dense retrieval. Instead of learning a vector for each query and document, our framework learns a multivariate distribution and uses negative multivariate KL divergence to compute the similarity between distributions. For simplicity and efficiency reasons, we assume that the distributions are multivariate normals and then train large language models to produce mean and variance vectors for these distributions. We provide a theoretical foundation for the proposed framework and show that it can be seamlessly integrated into the existing approximate nearest neighbor algorithms to perform retrieval efficiently. We conduct an extensive suite of experiments on a wide range of datasets, and demonstrate significant improvements compared to competitive dense retrieval models.
        </div> </ul> <br>



        <label for="Panel16">
        <strong> Large Language Models are Versatile Decomposers: Decomposing Evidence and Questions for Table-based Reasoning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunhu+Ye">Yunhu Ye</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Binyuan+Hui">Binyuan Hui</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Min+Yang">Min Yang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Binhua+Li">Binhua Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Huang">Fei Huang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongbin+Li">Yongbin Li</a> (2) </u>  <br>
        1:  University of Science and Technology of China, 2:  Alibaba Group, 3:  SIAT <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591708">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Large Language Models are Versatile Decomposers: Decomposing Evidence and Questions for Table-based Reasoning">Google Scholar</a></div>
        (16)
        <br>
        <b>概要:　</b> テーブルベースの推論は、多様なテーブルベースのタスクにおいて顕著な進展を示しています。ただし、このタスクは、自由形式の自然言語（NL）の質問と（半）構造化された表データの両方に対する推論を必要とするため、非常に挑戦的です。従来のテーブルベースの推論ソリューションは、「巨大な」証拠（表）に対して顕著な性能低下を引き起こすことがよくあります。さらに、既存の多くの方法は、必要な情報が異なる場所に散在しているため、複雑な質問に対する推論に苦労します。これらの課題を解決するために、我々は大規模言語モデル（LLM）をデコンポーザーとして活用し、効果的なテーブルベースの推論を行います。具体的には、（i）巨大な証拠（巨大な表）をサブエビデンス（小さな表）に分解し、テーブル推論における無用な情報の干渉を軽減し、（ii）複雑な質問をより簡単なサブ質問に分解してテキスト推論を行います。まず、強力なLLMを使用して、現在の質問に関連する証拠を保持し、残りの不要な情報を除外するサブエビデンスに分解します。次に、新しい「解析-実行-補填」戦略を提案し、中間的なSQLクエリを生成することにより、複雑な質問を段階的なサブ質問に分解し、数値および論理的なサブ質問を強力なLLMを用いて生成します。最後に、分解されたサブエビデンスとサブ質問を活用して、少数のコンテキストプロンプティング例を使って最終的な回答を得ます。TabFact, WikiTableQuestion, FetaQAの三つのベンチマークデータセットに対する精緻な実験により、本手法が競争力のあるベースラインを大幅に上回る成果を上げることが実証されました。特に、我々の手法はTabFactデータセットにおいて初めて人間の性能を上回りました。印象的な全体的な性能に加えて、本手法は返される結果のある程度の追跡可能性を伴うことから、解釈可能性の利点も持ちます。再現性のために、我々のソースコードとデータを以下のリンクで公開しています: https://github.com/AlibabaResearch/DAMO-ConvAI.
        </label>
        <input type="checkbox" id="Panel16" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Table-based reasoning has shown remarkable progress in a wide range of table-based tasks. It is a challenging task, which requires reasoning over both free-form natural language (NL) questions and (semi-)structured tabular data. However, previous table-based reasoning solutions usually suffer from significant performance degradation on ''huge'' evidence (tables). In addition, most existing methods struggle to reason over complex questions since the essential information is scattered in different places. To alleviate the above challenges, we exploit large language models (LLMs) as decomposers for effective table-based reasoning, which (i) decompose huge evidence (a huge table) into sub-evidence (a small table) to mitigate the interference of useless information for table reasoning, and (ii) decompose a complex question into simpler sub-questions for text reasoning. First, we use a powerful LLM to decompose the evidence involved in the current question into the sub-evidence that retains the relevant information and excludes the remaining irrelevant information from the ''huge'' evidence. Second, we propose a novel ''parsing-execution-filling'' strategy to decompose a complex question into simper step-by-step sub-questions by generating intermediate SQL queries as a bridge to produce numerical and logical sub-questions with a powerful LLM. Finally, we leverage the decomposed sub-evidence and sub-questions to get the final answer with a few in-context prompting examples. Extensive experiments on three benchmark datasets (TabFact, WikiTableQuestion, and FetaQA) demonstrate that our method achieves significantly better results than competitive baselines for table-based reasoning. Notably, our method outperforms human performance for the first time on the TabFact dataset. In addition to impressive overall performance, our method also has the advantage of interpretability, where the returned results are to some extent tractable with the generated sub-evidence and sub-questions. For reproducibility, we release our source code and data at: https://github.com/AlibabaResearch/DAMO-ConvAI.
        </div> </ul> <br>



        <label for="Panel17">
        <strong> MGeo: Multi-Modal Geographic Language Model Pre-Training </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruixue+Ding">Ruixue Ding</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Boli+Chen">Boli Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pengjun+Xie">Pengjun Xie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Huang">Fei Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Li">Xin Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiang+Zhang">Qiang Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yao+Xu">Yao Xu</a> (2) </u>  <br>
        1:  Damo Academy, 2:  Gaode Map <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591728">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MGeo: Multi-Modal Geographic Language Model Pre-Training">Google Scholar</a></div>
        (17)
        <br>
        <b>概要:　</b> 問い合わせとポイント・オブ・インタレスト（POI）のマッチングは、ナビゲーションマップなどの位置情報サービス（LBS）における主要なタスクです。このタスクはユーザーの意図と実世界の地理情報を結びつけます。近年、事前学習された言語モデル（PLM）は多くの自然言語処理（NLP）タスクで顕著な進歩を遂げてきました。一般的なPLMが問いとPOIのマッチングに必要な地理的知識が欠如しているという限界を克服するために、関連文献ではドメイン固有のコーパスを使った継続的な事前学習を試みています。しかし、問い合わせは一般的にその目的地に関する地理的文脈（GC）を記述し、近くの道路や関心領域（ROI）などの複数の地理的オブジェクトへの言及を含みます。これら多様な地理的オブジェクトとその相関性は、最も関連性の高いPOIを検索するために極めて重要です。テキストベースの単一モーダルPLMは、この重要なGCをほとんど活用できないため、限界があります。本研究では、問い合わせとPOIのマッチングのために、新しい手法であるマルチモーダル地理言語モデル（MGeo）を提案します。このモデルは地理エンコーダとマルチモーダルインタラクションモジュールで構成されています。GCを新しいモダリティとして表現することで、MGeoはマルチモーダルな相関性を完全に抽出し、正確な問い合わせとPOIのマッチングを実行することができます。さらに、公開されている問い合わせとPOIのマッチングのベンチマークは存在しません。さらなる研究を促進するために、我々はこのトピックのための新しいオープンソースの大規模なベンチマーク、すなわちGeographic Textual Similarity（GeoTES）を構築しました。POIはオープンソースの地理情報システム（GIS）から取得し、プライバシー問題を防ぐために問い合わせはアノテータによって手動で生成されています。いくつかの強力なベースラインと比較した結果、広範な実験結果と詳細なアブレーション解析は、提案するマルチモーダル地理事前トレーニング法がユーザーの位置情報の有無にかかわらず、PLMの問い合わせとPOIのマッチング能力を大幅に向上させることを示しています。我々のコードとベンチマークはhttps://github.com/PhantomGrapes/MGeoで公開されています。
        </label>
        <input type="checkbox" id="Panel17" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Query and point of interest (POI) matching is a core task in location-based services~(LBS), e.g., navigation maps. It connects users' intent with real-world geographic information. Lately, pre-trained language models (PLMs) have made notable advancements in many natural language processing (NLP) tasks. To overcome the limitation that generic PLMs lack geographic knowledge for query-POI matching, related literature attempts to employ continued pre-training based on domain-specific corpus. However, a query generally describes the geographic context (GC) about its destination and contains mentions of multiple geographic objects like nearby roads and regions of interest (ROIs). These diverse geographic objects and their correlations are pivotal to retrieving the most relevant POI. Text-based single-modal PLMs can barely make use of the important GC and are therefore limited. In this work, we propose a novel method for query-POI matching, namely Multi-modal Geographic language model (MGeo), which comprises a geographic encoder and a multi-modal interaction module. Representing GC as a new modality, MGeo is able to fully extract multi-modal correlations to perform accurate query-POI matching. Moreover, there exists no publicly available query-POI matching benchmark. Intending to facilitate further research, we build a new open-source large-scale benchmark for this topic, i.e., Geographic TExtual Similarity (GeoTES). The POIs come from an open-source geographic information system (GIS) and the queries are manually generated by annotators to prevent privacy issues. Compared with several strong baselines, the extensive experiment results and detailed ablation analyses demonstrate that our proposed multi-modal geographic pre-training method can significantly improve the query-POI matching capability of PLMs with or without users' locations. Our code and benchmark are publicly available at https://github.com/PhantomGrapes/MGeo.
        </div> </ul> <br>



        <label for="Panel18">
        <strong> Adapting Generative Pretrained Language Model for Open-domain Multimodal Sentence Summarization </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dengtian+Lin">Dengtian Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liqiang+Jing">Liqiang Jing</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuemeng+Song">Xuemeng Song</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Meng+Liu">Meng Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Teng+Sun">Teng Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liqiang+Nie">Liqiang Nie</a> (3) </u>  <br>
        1:  Shandong University, 2:  Shandong Jianzhu University, 3:  Harbin Institute of Technology (Shenzhen) <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591633">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Adapting Generative Pretrained Language Model for Open-domain Multimodal Sentence Summarization">Google Scholar</a></div>
        (18)
        <br>
        <b>概要:　</b> マルチモーダル文は、ソース文と画像の簡潔なを生成することを目指した新しいが難しい課題です。既存の方法は成功を収めていますが、以下の2つの重要な制限に苦しんでいます：1）生成型事前学習言語モデルのオープンドメインMMSSへの適用の欠如、2）明示的な重要情報モデリングの欠如。これらの制限に対処するために、我々はBARTをバックボーンとして採用したBART-MMSSフレームワークを提案します。具体的には、ソース画像の特徴を抽出するためのプロンプトガイドイメージエンコーディングモジュールを提案します。これは、画像パッチ埋め込みのためのいくつかのソフトな学習プロンプトを活用し、オープンドメインMMSSタスクへの視覚コンテンツの注入を容易にします。その後、ソース画像を参照してソース文の重要なトークンを直接捕捉するための明示的なソースクリティカルトークン学習モジュールを考案し、明示的な監視を組み込んで性能を向上させます。公開データセット上での広範な実験により、提案手法の優位性が完全に立証されました。さらに、ビジョンガイドのキートークンハイライトモジュールによって予測されたトークンは人間にも容易に理解されるため、モデルの解釈性を向上させます。
        </label>
        <input type="checkbox" id="Panel18" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multimodal sentence summarization, aiming to generate a brief summary of the source sentence and image, is a new yet challenging task. Although existing methods have achieved compelling success, they still suffer from two key limitations: 1) lacking the adaptation of generative pre-trained language models for open-domain MMSS, and 2) lacking the explicit critical information modeling. To address these limitations, we propose a BART-MMSS framework, where BART is adopted as the backbone. To be specific, we propose a prompt-guided image encoding module to extract the source image feature. It leverages several soft to-be-learned prompts for image patch embedding, which facilitates the visual content injection to BART for open-domain MMSS tasks. Thereafter, we devise an explicit source critical token learning module to directly capture the critical tokens of the source sentence with the reference of the source image, where we incorporate explicit supervision to improve performance. Extensive experiments on a public dataset fully validate the superiority of our proposed method. In addition, the predicted tokens by the vision-guided key-token highlighting module can be easily understood by humans and hence improve the interpretability of our model.
        </div> </ul> <br>



        <label for="Panel19">
        <strong> SciMine: An Efficient Systematic Prioritization Model Based on Richer Semantic Information </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fang+Guo">Fang Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yun+Luo">Yun Luo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linyi+Yang">Linyi Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Zhang">Yue Zhang</a> (1) </u>  <br>
        1:  Westlake University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591764">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SciMine: An Efficient Systematic Prioritization Model Based on Richer Semantic Information">Google Scholar</a></div>
        (19)
        <br>
        <b>概要:　</b> 全件レビューは、さまざまな研究分野の学者によって広く使われている重要な手法です。しかし、論文の候補から関連する科学文献を選別することは非常に時間のかかるプロセスであり、人間の作業負担を軽減するために選別の優先順位付けが確立されました。これに対処するため、人間のループを含むさまざまな方法が、語彙的特徴を使用して提案されています。これらの方法は、BERTのような高度な特徴ベースのモデルよりも優れた性能を達成していますが、豊富で本質的な意味情報を省略してしまうため、特徴バイアスに悩まされています。本研究では、新しいフレームワークSciMineを提案し、背景とコーパスの両方から意味的特徴表現を捉えることで、この選別プロセスを加速させます。特に、事前訓練された言語モデルから学習された文脈的表現に基づいて、我々のアプローチはオートエンコーダーベースの分類器と特徴依存の分類モジュールを利用して、一般的な文書レベルとフレーズレベルの情報を抽出します。次に、これらの2つの補完的な情報を組み合わせるためにランキングエンセブル戦略が使用されます。5つの実世界のデータセットでの実験により、SciMineが最先端の性能を達成し、さらに包括的な分析により、SciMineの特徴バイアス解決の有効性が示されました。
        </label>
        <input type="checkbox" id="Panel19" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Systematic review is a crucial method that has been widely used. by scholars from different research domains. However, screening for relevant scientific literature from paper candidates remains an extremely time-consuming process so the task of screening prioritization has been established to reduce the human workload. Various methods under the human-in-the-loop fashion are proposed to solve this task by using lexical features. These methods, even though achieving better performance than more sophisticated feature-based models such as BERT, omit rich and essential semantic information, therefore suffered from feature bias. In this study, we propose a novel framework SciMine to accelerate this screening process by capturing semantic feature representations from both background and the corpus. In particular, based on contextual representation learned from the pre-trained language models, our approach utilizes an autoencoder-based classifier and a feature-dependent classification module to extract general document-level and phrase-level information. Then a ranking ensemble strategy is used to combine these two complementary pieces of information. Experiments on five real-world datasets demonstrate that SciMine achieves state-of-the-art performance and comprehensive analysis further shows the efficacy of SciMine to solve feature bias.
        </div> </ul> <br>



        <label for="Panel20">
        <strong> Distilling Semantic Concept Embeddings from Contrastively Fine-Tuned Language Models </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Na+Li">Na Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hanane+Kteich">Hanane Kteich</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zied+Bouraoui">Zied Bouraoui</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Steven+Schockaert">Steven Schockaert</a> (3) </u>  <br>
        1:  University of Shanghai for Science and Technology, 2:  CRIL CNRS & University of Artois, 3:  Cardiff University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591667">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Distilling Semantic Concept Embeddings from Contrastively Fine-Tuned Language Models">Google Scholar</a></div>
        (20)
        <br>
        <b>概要:　</b> 概念の意味を捉えるベクトルを学習することは依然として基本的な課題である。予想外かもしれないが、事前学習された言語モデルは、これまでのところ、そのような概念埋め込みの品質向上にはわずかな改善しかもたらしていない。現在の言語モデルの使用戦略では、通常、コーパス内の言及の文脈化された表現を平均化することで概念を表す。しかし、これには少なくとも二つの理由から最適でない可能性がある。第一に、文脈化された単語ベクトルには異常な形状があり、これが下流のタスクを妨げる。第二に、概念埋め込みは概念の意味的特性を捉えるべきであるのに対し、文脈化された単語ベクトルは他の要素の影響も受ける。これらの問題に対処するために、我々は二つのコントラスト学習戦略を提案する。これは、二つの文が類似の特性を示す場合、それに対応する文脈化ベクトルも類似すべきだという見解に基づく。一つの戦略は完全に教師なしであり、文脈化単語埋め込みの近接構造から文が表現する特性を推定する。もう一つの戦略は、ConceptNetからの遠距離教師信号に依存する。我々の実験結果は、得られたベクトルが既存の概念埋め込みを大幅に上回り、概念の意味的特性を予測するのに優れていることを示している。特に、ConceptNetベースの戦略が最良の結果を達成している。これらの知見はさらに、クラスタリングタスクと下流タスクであるオントロジー補完においても確認されている。
        </label>
        <input type="checkbox" id="Panel20" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Learning vectors that capture the meaning of concepts remains a fundamental challenge. Somewhat surprisingly, perhaps, pre-trained language models have thus far only enabled modest improvements to the quality of such concept embeddings. Current strategies for using language models typically represent a concept by averaging the contextualised representations of its mentions in some corpus. This is potentially sub-optimal for at least two reasons. First, contextualised word vectors have an unusual geometry, which hampers downstream tasks. Second, concept embeddings should capture the semantic properties of concepts, whereas contextualised word vectors are also affected by other factors. To address these issues, we propose two contrastive learning strategies, based on the view that whenever two sentences reveal similar properties, the corresponding contextualised vectors should also be similar. One strategy is fully unsupervised, estimating the properties which are expressed in a sentence from the neighbourhood structure of the contextualised word embeddings. The second strategy instead relies on a distant supervision signal from ConceptNet. Our experimental results show that the resulting vectors substantially outperform existing concept embeddings in predicting the semantic properties of concepts, with the ConceptNet-based strategy achieving the best results. These findings are furthermore confirmed in a clustering task and in the downstream task of ontology completion.
        </div> </ul> <br>



        <label for="Panel21">
        <strong> Prompt Learning for News Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zizhuo+Zhang">Zizhuo Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bang+Wang">Bang Wang</a> (1) </u>  <br>
        1:  Huazhong University of Science and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591752">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Prompt Learning for News Recommendation">Google Scholar</a></div>
        (21)
        <br>
        <b>概要:　</b> 最近のニュース推薦（NR）手法では、事前学習済み言語モデル（PLM）を導入し、慎重に設計された推薦特化型ニューラルネットワークと目的関数を用いて、従来の事前学習と微調整のパラダイムに基づいてニュース表現をエンコードしています。しかし、タスクの目的がPLMと一致しないため、これらのモデリングパラダイムは事前学習プロセスに埋め込まれた豊富な意味情報と言語知識を十分に活用できていないと考えられます。最近では、事前学習、プロンプト、予測のパラダイム、すなわちプロンプト学習が自然言語処理分野で多くの成功を収めています。本研究では、この新しいパラダイムを初めてニュース推薦に応用し、ニュース推薦のためのプロンプト学習（Prompt4NR）フレームワークを開発します。このフレームワークは、ユーザーが候補となるニュースをクリックするかどうかを予測するタスクをクローズ形式のマスク予測タスクに変換します。具体的には、離散的、連続的、およびハイブリッドのプロンプトテンプレートを設計し、それに対応する解答空間を構築して、提案するPrompt4NRフレームワークを検証します。さらに、複数のプロンプトテンプレートからの予測を統合するためにプロンプトアンサンブリングを使用します。MINDデータセットを用いた広範な実験により、Prompt4NRの有効性が新しいベンチマーク結果とともに検証されました。
        </label>
        <input type="checkbox" id="Panel21" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Some recent news recommendation (NR) methods introduce a Pre-trained Language Model (PLM) to encode news representation by following the vanilla pre-train and fine-tune paradigm with carefully-designed recommendation-specific neural networks and objective functions. Due to the inconsistent task objective with that of PLM, we argue that their modeling paradigm has not well exploited the abundant semantic information and linguistic knowledge embedded in the pre-training process. Recently, the pre-train, prompt, and predict paradigm, called prompt learning, has achieved many successes in natural language processing domain. In this paper, we make the first trial of this new paradigm to develop a Prompt Learning for News Recommendation (Prompt4NR) framework, which transforms the task of predicting whether a user would click a candidate news as a cloze-style mask-prediction task. Specifically, we design a series of prompt templates, including discrete, continuous, and hybrid templates, and construct their corresponding answer spaces to examine the proposed Prompt4NR framework. Furthermore, we use the prompt ensembling to integrate predictions from multiple prompt templates. Extensive experiments on the MIND dataset validate the effectiveness of our Prompt4NR with a set of new benchmark results.
        </div> </ul> <br>



        <label for="Panel22">
        <strong> Alleviating Matthew Effect of Offline Reinforcement Learning in Interactive Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chongming+Gao">Chongming Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kexin+Huang">Kexin Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiawei+Chen">Jiawei Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuan+Zhang">Yuan Zhang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Biao+Li">Biao Li</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peng+Jiang">Peng Jiang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shiqi+Wang">Shiqi Wang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhong+Zhang">Zhong Zhang</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangnan+He">Xiangnan He</a> (1) </u>  <br>
        1:  University of Science and Technology of China, 2:  Zhejiang University, 3:  Kuaishou Technology Co., 4:  Chongqing University, 5:  University of Electronic Science and Technology of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591636">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Alleviating Matthew Effect of Offline Reinforcement Learning in Interactive Recommendation">Google Scholar</a></div>
        (22)
        <br>
        <b>概要:　</b> オフライン強化学習 (RL) は、オンライン環境と相互作用することなく、ログデータからポリシーをオフラインで学習する技術であり、インタラクティブなレコメンデーションなどの意思決定プロセスにおいて好まれる選択肢となっています。しかし、オフラインRLは価値推定の過大評価問題に直面します。この問題に対処するため、既存の方法は学習されたポリシーを振る舞いポリシーに近づけることや、ほとんど訪れられない状態-アクション対を罰するなどの保守性を採用しています。しかし、このようなオフラインRLをレコメンデーションに適用すると、人気アイテムやカテゴリを押し上げ、あまり人気のないものを抑制することで、深刻なマシュー効果（富める者はますます富み、貧しい者はますます貧しくなる）が生じます。これは、実際のレコメンダーシステムにおいて対処が必要な悪名高い問題です。本論文では、オフラインRLベースのレコメンデーションにおけるマシュー効果を軽減することを目指しています。理論的分析を通じて、既存の方法の保守性がユーザーの長期的な満足を追求する点で失敗していることを発見しました。これに触発され、高エントロピーのログポリシー状態に対する悲観性を緩和する罰則項を追加し、間接的に多様性の低い状態に至るアクションを罰することを提案します。これが本研究の主要な技術的貢献である「偏り補正モデルベースのオフラインRL (DORL)」方法です。実験結果は、DORLがユーザーの興味を良好に捕捉し、マシュー効果を軽減することを示しています。実装は https://github.com/chongminggao/DORL-codes で利用可能です。
        </label>
        <input type="checkbox" id="Panel22" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Offline reinforcement learning (RL), a technology that offline learns a policy from logged data without the need to interact with online environments, has become a favorable choice in decision-making processes like interactive recommendation. Offline RL faces the value overestimation problem. To address it, existing methods employ conservatism, e.g., by constraining the learned policy to be close to behavior policies or punishing the rarely visited state-action pairs. However, when applying such offline RL to recommendation, it will cause a severe Matthew effect, i.e., the rich get richer and the poor get poorer, by promoting popular items or categories while suppressing the less popular ones. It is a notorious issue that needs to be addressed in practical recommender systems. In this paper, we aim to alleviate the Matthew effect in offline RL-based recommendation. Through theoretical analyses, we find that the conservatism of existing methods fails in pursuing users' long-term satisfaction. It inspires us to add a penalty term to relax the pessimism on states with high entropy of the logging policy and indirectly penalizes actions leading to less diverse states. This leads to the main technical contribution of the work: Debiased model-based Offline RL (DORL) method. Experiments show that DORL not only captures user interests well but also alleviates the Matthew effect. The implementation is available via https://github.com/chongminggao/DORL-codes
        </div> </ul> <br>



        <label for="Panel23">
        <strong> Safe Deployment for Counterfactual Learning to Rank with Exposure-Based Risk Minimization </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shashank+Gupta">Shashank Gupta</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Harrie+Oosterhuis">Harrie Oosterhuis</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (1) </u>  <br>
        1:  University of Amsterdam, 2:  Radboud Universiteit <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591760">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Safe Deployment for Counterfactual Learning to Rank with Exposure-Based Risk Minimization">Google Scholar</a></div>
        (23)
        <br>
        <b>概要:　</b> 反実格ランキング学習（Counterfactual Learning to Rank, CLTR）は、位置バイアスを修正するために、ランク学習（Learning to Rank, LTR）に特化した逆傾向スコアリング（Inverse Propensity Scoring, IPS）に依存しています。IPSは偏りのない一貫した推定を提供できる一方で、多くの場合、高い分散に悩まされます。特にクリックデータが少ない場合、この分散はCLTRに最適でないランキング行動を学習させる原因となります。その結果、既存のCLTR手法は、モデルを無造作に展開することによる非常に否定的なユーザー体験のリスクを伴います。我々は、安全な展開のための理論的保証を備えた新しいリスク対応型CLTR手法を導入します。我々は、リスク正則化の新しい概念をIPS推定に適用し、LTRのための新しい露出ベースのリスク正則化を行います。我々のリスク正則化は、学習モデルのランキング行動と既存の安全なモデルとの間のミスマッチをペナルティ化します。これにより、IPS推定において高い不確実性がある場合に、学習されたランキングモデルが信頼されたモデルに近い状態を保つことができ、展開時のリスクが大幅に軽減されます。我々の実験結果は、新提案手法の有効性を示しており、データが少ない初期段階における不良性能を回避しつつ、収束時には高い性能を維持することができます。CLTR分野において、我々の新しい露出ベースのリスク最小化手法は、従来の方法に付随する多くのリスクを軽減し、CLTR手法をより安全に採用することを可能にします。
        </label>
        <input type="checkbox" id="Panel23" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Counterfactual learning to rank (CLTR) relies on exposure-based inverse propensity scoring (IPS), a LTR-specific adaptation of IPS to correct for position bias. While IPS can provide unbiased and consistent estimates, it often suffers from high variance. Especially when little click data is available, this variance can cause CLTR to learn sub-optimal ranking behavior. Consequently, existing CLTR methods bring significant risks with them, as naively deploying their models can result in very negative user experiences. We introduce a novel risk-aware CLTR method with theoretical guarantees for safe deployment. We apply a novel exposure-based concept of risk regularization to IPS estimation for LTR. Our risk regularization penalizes the mismatch between the ranking behavior of a learned model and a given safe model. Thereby, it ensures that learned ranking models stay close to a trusted model, when there is high uncertainty in IPS estimation, which greatly reduces the risks during deployment. Our experimental results demonstrate the efficacy of our proposed method, which is effective at avoiding initial periods of bad performance when little date is available, while also maintaining high performance at convergence. For the CLTR field, our novel exposure-based risk minimization method enables practitioners to adopt CLTR methods in a safer manner that mitigates many of the risks attached to previous methods.
        </div> </ul> <br>



        <label for="Panel24">
        <strong> HDNR: A Hyperbolic-Based Debiased Approach for Personalized News Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shicheng+Wang">Shicheng Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shu+Guo">Shu Guo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lihong+Wang">Lihong Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tingwen+Liu">Tingwen Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongbo+Xu">Hongbo Xu</a> (1) </u>  <br>
        1:  Institute of Information Engineering, 2:  National Computer Network Emergency Response Technical Team/Coordination Center <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591693">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=HDNR: A Hyperbolic-Based Debiased Approach for Personalized News Recommendation">Google Scholar</a></div>
        (24)
        <br>
        <b>概要:　</b> パーソナライズドニュース推薦は、クリックされたニュース履歴に基づいて対象ユーザーに候補ニュースを推薦することを目指しています。ユーザーとニュースの相互作用データはべき法則分布を示しますが、既存の研究は通常ユークリッド空間での表現学習を行い、データ空間と埋め込み空間の容量が不整合となり、重大な表現歪みの問題が発生します。その上、べき法則分布の潜在原因である同調バイアスの存在がユーザー表現の学習に偏りを導入する可能性があります。本論文では、上記の問題に対処するために、双曲空間に基づいた新しいデバイアス手法であるHDNRを提案します。具体的には、まず、ユーザーとニュースのモデリングを行うために、指数的成長容量を持つ双曲面モデルを採用し、空間容量の不整合問題を解決し、低歪み表現を取得します。次に、クリックされたニュースのコンテクスト履歴における局所的な重要性とその全体的な人気度を同時に考慮することにより、データ分布における同調バイアスをさらに軽減する再重み付けアグリゲーションモジュールを設計します。最後に、対象ユーザーと候補ニュースの表現間の関連性スコアを計算します。2つの実世界のニュース推薦データセットMIND-Large、MIND-Smallを用いた実験を行い、複数の視点から我々の手法の有効性を実証しました。
        </label>
        <input type="checkbox" id="Panel24" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Personalized news recommendation aims to recommend candidate news to the target user, according to the clicked news history. The user-news interaction data exhibits power-law distribution, however, existing works usually learn representations in Euclidean space which makes inconsistent capacities between data space and embedding space, leading to severe representation distortion problem. Besides, the existence of conformity bias, a potential cause of power-law distribution, may introduce biased guidance to learn user representations. In this paper, we propose a novel debiased method based on hyperbolic space, named HDNR, to tackle the above problems. Specifically, first, we employ hyperboloid model with exponential growth capacity to conduct user and news modeling, in order to solve inconsistent space capacities problem and obtain low distortion representations. Second, we design a re-weighting aggregation module to further mitigate conformity bias in data distribution, through considering local importance of the clicked news among contextual history and its global popularity degree simultaneously. Finally, we calculate the relevance score between target user and candidate news representations. We conduct experiments on two real-world news recommendation datasets MIND-Large, MIND-Small and empirical results demonstrate the effectiveness of our approach from multiple perspectives.
        </div> </ul> <br>



        <label for="Panel25">
        <strong> Measuring Item Global Residual Value for Fair Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiayin+Wang">Jiayin Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weizhi+Ma">Weizhi Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chumeng+Jiang">Chumeng Jiang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Min+Zhang">Min Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuan+Zhang">Yuan Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Biao+Li">Biao Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peng+Jiang">Peng Jiang</a> (2) </u>  <br>
        1:  Tsinghua University, 2:  Kuaishou Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591724">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Measuring Item Global Residual Value for Fair Recommendation">Google Scholar</a></div>
        (25)
        <br>
        <b>概要:　</b> 情報爆発の時代において、特にフィードシナリオでは毎日数多くのアイテムが出現します。システム表示枠とユーザーの閲覧注意が限定されているため、さまざまなレコメンデーションシステムがユーザーの個別の情報ニーズを満たすだけでなく、アイテムの露出を割り当てるためにも設計されています。しかし、最近のレコメンデーション研究は、満足のいく結果を提示し、ユーザーのインタラクションを最大化するために主にユーザーの嗜好をモデル化することに焦点を当てており、合理的な情報配信のためのアイテム側の公平な露出メカニズムの開発にはほとんど注意が払われていません。これにより、雪だるま効果などのアイテム側の深刻な資源配分問題が発生する可能性があります。さらに、不公平な露出メカニズムはレコメンデーションのパフォーマンスにも悪影響を及ぼす可能性があります。本論文では、ユーザーの嗜好をモデル化することからアイテムの公平な露出メカニズムの開発へと注意を向けることを提案します。まず、異なるアップロード時間を持つアイテム間の露出問題を探るためのフィードシナリオの実証分析を行います。これにより、時間要因によって引き起こされる不公平な露出が雪だるま効果の主要な原因であることが示されます。次に、公平な資源配分のためにアイテムレベルでカスタマイズされたタイムリーな分布、グローバル残存価値（GRV）を明示的にモデル化することを提案します。このGRVモジュールは、設計された時間意識型公平レコメンデーションフレームワーク（TaFR）とともにレコメンデーションに導入されます。2つのデータセットに対する広範な実験により、TaFRがさまざまなバックボーンレコメンデーションモデルに対して一貫した改善を達成することが示されました。アイテム側のカスタマイズされたグローバル残存価値をモデル化することで、公平な資源配分を実現し、同時にレコメンデーションパフォーマンスの向上を達成しました。
        </label>
        <input type="checkbox" id="Panel25" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In the era of information explosion, numerous items emerge every day, especially in feed scenarios. Due to the limited system display slots and user browsing attention, various recommendation systems are designed not only to satisfy users' personalized information needs but also to allocate items' exposure. However, recent recommendation studies mainly focus on modeling user preferences to present satisfying results and maximize user interactions, while paying little attention to developing item-side fair exposure mechanisms for rational information delivery. This may lead to serious resource allocation problems on the item side, such as the Snowball Effect. Furthermore, unfair exposure mechanisms may hurt recommendation performance. In this paper, we call for a shift of attention from modeling user preferences to developing fair exposure mechanisms for items. We first conduct empirical analyses of feed scenarios to explore exposure problems between items with distinct uploaded times. This points out that unfair exposure caused by the time factor may be the major cause of the Snowball Effect. Then, we propose to explicitly model item-level customized timeliness distribution, Global Residual Value (GRV), for fair resource allocation. This GRV module is introduced into recommendations with the designed Timeliness-aware Fair Recommendation Framework (TaFR). Extensive experiments on two datasets demonstrate that TaFR achieves consistent improvements with various backbone recommendation models. By modeling item-side customized Global Residual Value, we achieve a fairer distribution of resources and, at the same time, improve recommendation performance.
        </div> </ul> <br>



        <label for="Panel26">
        <strong> Distributionally Robust Sequential Recommnedation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rui+Zhou">Rui Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xian+Wu">Xian Wu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaopeng+Qiu">Zhaopeng Qiu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yefeng+Zheng">Yefeng Zheng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xu+Chen">Xu Chen</a> (1) </u>  <br>
        1:  Renmin University of China, 2:  Tencent Jarvis Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591668">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Distributionally Robust Sequential Recommnedation">Google Scholar</a></div>
        (26)
        <br>
        <b>概要:　</b> ユーザーの時系列行動をモデル化することは、レコメンデーションの性能向上に効果的であることが示されています。これまでの研究は顕著な成果を上げていますが、多くの場合、訓練とテストの分布が一致していると仮定しており、これはユーザーの多様で複雑な嗜好と矛盾し、実際のシナリオでのレコメンデーション性能を制限する可能性があります。この問題を軽減するために、本論文では、訓練セットとテストセットの間の潜在的な分布変動を克服するために、ロバストな時系列レコメンダーフレームワークを提案します。具体的には、まずサンプルの重み付けを通じて異なる訓練分布をシミュレートします。次に、これらの分布によって引き起こされる最大の損失を最小化し、モデルのロバスト性を向上させるために「最悪のケース」の損失を最適化します。サンプルの重みが多すぎて最適化が困難になる可能性を考慮し、硬軟両方の戦略に基づいて訓練サンプルをクラスタリングし、各クラスタに統一された重みを割り当てます。最後に、上記のミニマックス目的の一般化誤差境界を提示することで、理論的観点から提案されたフレームワークをよりよく理解するための分析を行います。３つの実世界のデータセットを基にした広範な実験を行い、提案されたフレームワークの有効性を実証します。我々の実験を再現し、この研究分野を推進するために、プロジェクトをhttps://anonymousrsr.github.io/RSR/に公開しました。
        </label>
        <input type="checkbox" id="Panel26" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Modeling user sequential behaviors have been demonstrated to be effective in promoting the recommendation performance. While previous work has achieved remarkable successes, they mostly assume that the training and testing distributions are consistent, which may contradict with the diverse and complex user preferences, and limit the recommendation performance in real-world scenarios. To alleviate this problem, in this paper, we propose a robust sequential recommender framework to overcome the potential distribution shift between the training and testing sets. In specific, we firstly simulate different training distributions via sample reweighting. Then, we minimize the largest loss induced by these distributions to optimize the 'worst-case' loss for improving the model robustness. Considering that there can be too many sample weights, which may introduce too much flexibility and be hard to optimize, we cluster the training samples based on both hard and soft strategies, and assign each cluster with a unified weight. At last, we analyze our framework by presenting the generalization error bound of the above minimax objective, which help us to better understand the proposed framework from the theoretical perspective. We conduct extensive experiments based on three real-world datasets to demonstrate the effectiveness of our proposed framework. To reproduce our experiments and promote this research direction, we have released our project at https://anonymousrsr.github.io/RSR/.
        </div> </ul> <br>



        <label for="Panel27">
        <strong> LinRec: Linear Attention Mechanism for Long-term Sequential Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Langming+Liu">Langming Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liu+Cai">Liu Cai</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chi+Zhang">Chi Zhang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyu+Zhao">Xiangyu Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingtong+Gao">Jingtong Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wanyu+Wang">Wanyu Wang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yifu+Lv">Yifu Lv</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenqi+Fan">Wenqi Fan</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiqi+Wang">Yiqi Wang</a> (6), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ming+He">Ming He</a> (7), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zitao+Liu">Zitao Liu</a> (8), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qing+Li">Qing Li</a> (5) </u>  <br>
        1:  City University of Hong Kong, 2:  Ant Group, 3:  Harbin Engineering University, 4:  City University of Hong Kong, 5:  The Hong Kong Polytechnic University, 6:  National University of Defense Technology, 7:  AI Lab, 8:  Guangdong Institute of Smart Education <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591717">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=LinRec: Linear Attention Mechanism for Long-term Sequential Recommender Systems">Google Scholar</a></div>
        (27)
        <br>
        <b>概要:　</b> トランスフォーマーモデルは順序推薦システム（SRS）において顕著な成功を収めています。しかし、従来のドットプロダクトアテンションメカニズムにおけるアテンションマトリックスの計算は、系列の長さに対して二次の複雑さを持ち、長期的な順序推薦に対して高い計算コストを引き起こします。この観察に基づき、効率を理論的に向上させつつ、従来のドットプロダクトアテンションの学習能力を保持するために、新しいL2正規化線形アテンションをトランスフォーマーベースの順序推薦システム（LinRec）に提案します。具体的には、効率的なアテンションメカニズムの等価条件を綿密に調査することで、LinRecが線形の複雑さを持ちながらアテンションメカニズムの特性を保持していることを示します。さらに、統計的な視点から提案されたLinRecメカニズムを解釈することで、その潜在的な効率特性を明らかにします。2つの公開ベンチマークデータセットに基づいて広範な実験を行い、LinRecとトランスフォーマーモデルの組み合わせが最新のトランスフォーマーベースSRSモデルに匹敵するか、あるいはそれを凌駕する性能を達成しながら、時間およびメモリ効率を大幅に改善することを示しています。実装コードはhttps://github.com/Applied-Machine-Learning-Lab/LinRecでオンラインで利用可能です。
        </label>
        <input type="checkbox" id="Panel27" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Transformer models have achieved remarkable success in sequential recommender systems (SRSs). However, computing the attention matrix in traditional dot-product attention mechanisms results in a quadratic complexity with sequence lengths, leading to high computational costs for long-term sequential recommendation. Motivated by the above observation, we propose a novel L2-Normalized Linear Attention for the Transformer-based Sequential Recommender Systems (LinRec), which theoretically improves efficiency while preserving the learning capabilities of the traditional dot-product attention. Specifically, by thoroughly examining the equivalence conditions of efficient attention mechanisms, we show that LinRec possesses linear complexity while preserving the property of attention mechanisms. In addition, we reveal its latent efficiency properties by interpreting the proposed LinRec mechanism through a statistical lens. Extensive experiments are conducted based on two public benchmark datasets, demonstrating that the combination of LinRec and Transformer models achieves comparable or even superior performance than state-of-the-art Transformer-based SRS models while significantly improving time and memory efficiency. The implementation code is available online at https://github.com/Applied-Machine-Learning-Lab/LinRec.>
        </div> </ul> <br>



        <label for="Panel28">
        <strong> Poisoning Self-supervised Learning Based Sequential Recommendations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanling+Wang">Yanling Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuchen+Liu">Yuchen Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qian+Wang">Qian Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cong+Wang">Cong Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenliang+Li">Chenliang Li</a> (2) </u>  <br>
        1:  Wuhan University & City University of Hong Kong, 2:  Wuhan University, 3:  City University of Hong Kong <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591751">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Poisoning Self-supervised Learning Based Sequential Recommendations">Google Scholar</a></div>
        (28)
        <br>
        <b>概要:　</b> 自己教師あり学習（Self-Supervised Learning, SSL）は、シーケンシャルレコメンダーシステムに高品質なユーザ表現を提供するために最近適用されてきました。しかし、学習プロセスを促進する一方で、SSLにはセキュリティの脅威も存在します。巧妙に作成された入力は、SSLによって駆動される事前学習済みモデルをポイズニングし、下流のレコメンデーションモデルの有効性を低下させる可能性があります。本研究は事前学習段階に対するポイズニング攻撃がシーケンシャルレコメンダーシステムにとって脅威となりえることを示します。モデルのアーキテクチャやパラメータについての事前知識やAPIクエリを一切持たず、我々の戦略は主流のSSLベースのレコメンダースキームおよび一般的に使用されるデータセットに対するポイズニング攻撃の実行可能性を証明します。ごく少量の偽ユーザーを注入することで、目標とするアイテムが実際のユーザーに以前よりも数千回多く推薦されることを確認し、レコメンダーシステムがSSLにより新たな攻撃面を持つことを示します。さらに、我々の攻撃がレコメンデーションプラットフォームにとって検出および防御が困難であることも示します。本研究は自己教師あり学習を基盤とするレコメンダーシステムの脆弱性を浮き彫りにし、研究者がこのセキュリティ脅威に注意を払う必要性を強調します。ソースコードはhttps://github.com/CongGroup/Poisoning-SSL-based-RSにて公開しています。
        </label>
        <input type="checkbox" id="Panel28" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Self-supervised learning (SSL) has been recently applied to sequential recommender systems to provide high-quality user representations. However, while facilitating the learning process recommender systems, SSL is not without security threats: carefully crafted inputs can poison the pre-trained models driven by SSL, thus reducing the effectiveness of the downstream recommendation model. This work shows that poisoning attacks against the pre-training stage threaten sequential recommender systems. Without any background knowledge of the model architecture and parameters, nor any API queries, our strategy proves the feasibility of poisoning attacks on mainstream SSL-based recommender schemes as well as on commonly used datasets. By injecting only a tiny amount of fake users, we get the target item recommended to real users more than thousands of times as before, demonstrating that recommender systems have a new attack surface due to SSL. We further show our attack is challenging for recommendation platforms to detect and defend. Our work highlights the weakness of self-supervised recommender systems and shows the necessity for researchers to be aware of this security threat. Our source code is available at https://github.com/CongGroup/Poisoning-SSL-based-RS.
        </div> </ul> <br>



        <label for="Panel29">
        <strong> Towards Multi-Interest Pre-training with Sparse Capsule Network </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zuoli+Tang">Zuoli Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lin+Wang">Lin Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lixin+Zou">Lixin Zou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaolu+Zhang">Xiaolu Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenliang+Li">Chenliang Li</a> (1) </u>  <br>
        1:  Wuhan University, 2:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591778">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Towards Multi-Interest Pre-training with Sparse Capsule Network">Google Scholar</a></div>
        (29)
        <br>
        <b>概要:　</b> 多くの分野で新しい事実上の標準となりつつある前学習パラダイム、つまり広範な領域にわたる普遍的な知識を学習する手法は、新しいドメインに移行するために特に重要です。最近の進展には、推薦システムのための普遍的な前学習ソリューションが含まれます。しかし、マスク付き言語モデルや対照学習による単純なデータ増強を利用する一般的な方法では、推薦システムの前学習には不十分であると考えます。ユーザーの意図は次の単語やアイテムを予測するよりも複雑であるためです。より直感的には、普遍的なユーザー理解のために、複数の関心に基づく前学習フレームワークを考案することです。とはいえ、リコメンダーシステムの前学習において、ユーザーの関心が動的で、文脈に依存し、一時的であるために、複数の関心モデリングを取り入れることは容易ではありません。特に異なるドメインからのユーザーについてです。この分野での限られた努力は、依然として未解決の問題となっています。本論文では、新しい「スパースカプセルを用いたマルチインタレスト前学習」（Miracle）フレームワークを提案します。Miracleはスパースカプセルネットワークと関心認識前学習タスクを使用して、普遍的な複数の関心モデリングを行います。具体的には、情景に適応したアイテム表現をモデル化するために、MoEアダプタと詳細なコンテクストエンコードコンポーネントを含むテキスト認識アイテム埋め込みモジュールを利用します。次に、アダプティブな関心抽出のために位置認識カプセルネットワークと組み合わせたスパース関心活性化メカニズムを提案します。さらに、スパースカプセルネットワークが普遍的な関心を正確に学習するために、関心レベルの対照前学習タスクを導入します。11の実世界のデータセットと8つのベースラインにおいて広範な実験を行いました。その結果、これらのベンチマークデータセットにおいて、我々の手法が一連のSOTAを大幅に上回ることを示しました。コードはhttps://github.com/WHUIR/Miracleで入手可能です。
        </label>
        <input type="checkbox" id="Panel29" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The pre-training paradigm, i.e., learning universal knowledge across a wide spectrum of domains, has increasingly become a new de-facto practice in many fields, especially for transferring to new domains. The recent progress includes universal pre-training solutions for recommendation. However, we argue that the common treatment utilizing the masked language modeling or simple data augmentation via contrastive learning is not sufficient for pre-training a recommender system, since a user's intent could be more complex than predicting the next word or item. It is more intuitive to go a step further by devising the multi-interest driven pre-training framework for universal user understanding. Nevertheless, incorporating multi-interest modeling in recommender system pre-training is non-trivial due to the dynamic, contextual, and temporary nature of the user interests, particularly when the users are from different domains. The limited effort on this line has greatly rendered it as an open question. In this paper, we propose a novel Multi-Interest Pre-training with Sparse Capsule framework (named Miracle). Miracle performs a universal multi-interest modeling with a sparse capsule network and an interest-aware pre-training task. Specifically, we utilize a text-aware item embedding module, including an MoE adaptor and a deeply-contextual encoding component, to model contextual and transferable item representations. Then, we propose a sparse interest activation mechanism coupled with a position-aware capsule network for adaptive interest extraction. Furthermore, an interest-level contrastive pre-training task is introduced to guide the sparse capsule network to learn universal interests precisely. We conduct extensive experiments on eleven real-world datasets and eight baselines. The results show that our method significantly outperforms a series of SOTA on these benchmark datasets. The code is available at https://github.com/WHUIR/Miracle.
        </div> </ul> <br>



        <label for="Panel30">
        <strong> Graph Masked Autoencoder for Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yaowen+Ye">Yaowen Ye</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lianghao+Xia">Lianghao Xia</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chao+Huang">Chao Huang</a> (1) </u>  <br>
        1:  University of Hong Kong <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591692">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Graph Masked Autoencoder for Sequential Recommendation">Google Scholar</a></div>
        (30)
        <br>
        <b>概要:　</b> 強力なニューラルネットワークアーキテクチャ（例：Transformer、グラフニューラルネットワーク）は、高次のアイテム依存性モデリングによってシーケンシャルレコメンデーションのパフォーマンスを向上させましたが、ラベルが不足しているシナリオでは表現能力が低下する可能性があります。このラベルの不足を解決するために、コントラスト学習（Contrastive Learning, CL）が注目されており、埋め込み対立による自己教師ありデータ拡張を行います。しかし、既存のCL強化モデルは手工芸的な対立ビュー生成戦略のために、i) 多様なシーケンシャルレコメンデーションタスクで一貫したパフォーマンスを発揮するのが難しい、ii) ユーザ行動データのノイズに免疫がない可能性があります。これを踏まえ、自己教師あり拡張のためにグローバルなアイテム遷移情報を適応的かつ動的に抽出する、シンプルかつ効果的なグラフマスク付きオートエンコーダーを強化したシーケンシャルレコメンデーションシステム（MAERec）を提案します。これは、質の高い埋め込み対立ビューの構築に大きく依存する問題を自然に回避します。代わりに、情報豊かな拡張を行うために、適応的なデータ再構築パラダイムが長距離のアイテム依存性モデリングと統合されるように設計されています。広範な実験により、我々の手法が最先端のベースラインモデルを大幅に上回り、データのノイズや疎性に対してより正確な表現を学習できることが示されました。我々の実装モデルのコードはhttps://github.com/HKUDS/MAERecにあります。
        </label>
        <input type="checkbox" id="Panel30" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> While some powerful neural network architectures (e.g., Transformer, Graph Neural Networks) have achieved improved performance in sequential recommendation with high-order item dependency modeling, they may suffer from poor representation capability in label scarcity scenarios. To address the issue of insufficient labels, Contrastive Learning (CL) has attracted much attention in recent methods to perform data augmentation through embedding contrasting for self-supervision. However, due to the hand-crafted property of their contrastive view generation strategies, existing CL-enhanced models i) can hardly yield consistent performance on diverse sequential recommendation tasks; ii) may not be immune to user behavior data noise. In light of this, we propose a simple yet effective Graph Masked AutoEncoder-enhanced sequential Recommender system (MAERec) that adaptively and dynamically distills global item transitional information for self-supervised augmentation. It naturally avoids the above issue of heavy reliance on constructing high-quality embedding contrastive views. Instead, an adaptive data reconstruction paradigm is designed to be integrated with the long-range item dependency modeling, for informative augmentation in sequential recommendation. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baseline models and can learn more accurate representations against data noise and sparsity. Our implemented model code is available at https://github.com/HKUDS/MAERec.
        </div> </ul> <br>



        <label for="Panel31">
        <strong> A Generic Learning Framework for Sequential Recommendation with Distribution Shifts </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhengyi+Yang">Zhengyi Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangnan+He">Xiangnan He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jizhi+Zhang">Jizhi Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiancan+Wu">Jiancan Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Xin">Xin Xin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiawei+Chen">Jiawei Chen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Wang">Xiang Wang</a> (1) </u>  <br>
        1:  University of Science and Technology of China, 2:  Shandong University, 3:  Zhejiang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591624">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Generic Learning Framework for Sequential Recommendation with Distribution Shifts">Google Scholar</a></div>
        (31)
        <br>
        <b>概要:　</b> 最先端のシーケンシャル推薦（SeqRec）モデルは、学習フレームワークとして経験的リスク最小化（ERM）を採用しています。この方法では、トレーニングデータ（過去のインタラクションシーケンス）とテストデータ（将来のインタラクション）が同じ分布からサンプリングされているという前提が暗黙の了解とされています。しかし、オンライン提供とレコメンダーシステムの動的な性質により、このi.i.d.仮定は実際にはほとんど成り立ちません。例えば、新しいデータのストリーミングによってアイテムの人気度分布が変わり、ユーザーの嗜好も消費したアイテムによって進化することがあります。このような分布の変動はERMフレームワークを揺るがし、モデルの将来のオンライン提供に対する一般化能力を損なう可能性があります。本研究では、動的な環境でレコメンダーの一般化を強化するための汎用学習フレームワークを開発することを目的としています。具体的には、ERMに加えて、シーケンシャル推薦に対する分布ロバスト最適化メカニズム（DROS）を考案しました。DROSの核心は、データ分布のダイナミクスを考慮し、トレーニングとテストの間の分布シフトを探求する慎重に設計された分布適応パラダイムです。これにより、バックボーンのレコメンダーに対してより優れた一般化能力を持たせることができます。DROSは、一般的な推薦シナリオに適用可能な効果的なモデル非依存学習フレームワークです。理論的な分析により、DROSがバックボーンのレコメンダーに対して将来のテストデータにおけるロバストなパフォーマンスを達成させることが示されています。実証研究もDROSの動的分布シフトに対する有効性を確認しています。コードはhttps://github.com/YangZhengyi98/DROSで匿名で公開されています。
        </label>
        <input type="checkbox" id="Panel31" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Leading sequential recommendation (SeqRec) models adopt empirical risk minimization (ERM) as the learning framework, which inherently assumes that the training data (historical interaction sequences) and the testing data (future interactions) are drawn from the same distribution. However, such i.i.d. assumption hardly holds in practice, due to the online serving and dynamic nature of recommender system.For example, with the streaming of new data, the item popularity distribution would change, and the user preference would evolve after consuming some items. Such distribution shifts could undermine the ERM framework, hurting the model's generalization ability for future online serving. In this work, we aim to develop a generic learning framework to enhance the generalization of recommenders in the dynamic environment. Specifically, on top of ERM, we devise a Distributionally Robust Optimization mechanism for SeqRec (DROS). At its core is our carefully-designed distribution adaption paradigm, which considers the dynamics of data distribution and explores possible distribution shifts between training and testing. Through this way, we can endow the backbone recommenders with better generalization ability.It is worth mentioning that DROS is an effective model-agnostic learning framework, which is applicable to general recommendation scenarios.Theoretical analyses show that DROS enables the backbone recommenders to achieve robust performance in future testing data.Empirical studies verify the effectiveness against dynamic distribution shifts of DROS. Codes are anonymously open-sourced at https://github.com/YangZhengyi98/DROS.
        </div> </ul> <br>



        <label for="Panel32">
        <strong> Single-shot Feature Selection for Multi-task Recommendations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yejing+Wang">Yejing Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaocheng+Du">Zhaocheng Du</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyu+Zhao">Xiangyu Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Chen">Bo Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huifeng+Guo">Huifeng Guo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruiming+Tang">Ruiming Tang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenhua+Dong">Zhenhua Dong</a> (2) </u>  <br>
        1:  City University of Hong Kong, 2:  Huawei Noah's Ark Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591767">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Single-shot Feature Selection for Multi-task Recommendations">Google Scholar</a></div>
        (32)
        <br>
        <b>概要:　</b> マルチタスクレコメンダーシステム（MTRS）は、その優れた訓練効率と推薦品質により、さまざまな実世界のアプリケーションでますます普及しています。しかし、従来のMTRSは、すべてのタスクに対してすべての関連する特徴フィールドを区別せずに入力するため、混乱やパフォーマンスの低下を引き起こす可能性があります。また、既存の特徴選択方法は、タスク間の関係を無視するか、マルチタスク設定でのモデル訓練時に多大な計算を必要とすることがあります。これを解決するために、本論文では、タスク関係を考慮しながら各タスクの特徴フィールドを単発で選択できる新しい単発特徴選択フレームワーク「MultiSFS」を提案します。具体的には、まずMultiSFSは単一のフォワード・バックワードパスを通じてタスク固有の特徴重要度を効率的に取得します。次に、データタスク二部グラフを構築し、フィールドレベルのタスク関係を学習します。その後、特徴重要度をタスク関係に従って統合し、異なるタスクの特徴フィールドを選択します。MultiSFSの有効性と特性を示すために、代表的なMTRSモデルと統合し、3つの実世界のデータセットで評価を行いました。再現性を容易にするため、実装コードはオンラインで公開しています。
        </label>
        <input type="checkbox" id="Panel32" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multi-task Recommender Systems (MTRSs) has become increasingly prevalent in a variety of real-world applications due to their exceptional training efficiency and recommendation quality. However, conventional MTRSs often input all relevant feature fields without distinguishing their contributions to different tasks, which can lead to confusion and a decline in performance. Existing feature selection methods may neglect task relations or require significant computation during model training in multi-task setting. To this end, this paper proposes a novel Single-shot Feature Selection framework for MTRSs, referred to as MultiSFS, which is capable of selecting feature fields for each task while considering task relations in a single-shot manner. Specifically, MultiSFS first efficiently obtains task-specific feature importance through a single forward-backward pass. Then, a data-task bipartite graph is constructed to learn field-level task relations. Subsequently, MultiSFS merges the feature importance according to task relations and selects feature fields for different tasks. To demonstrate the effectiveness and properties of MultiSFS, we integrate it with representative MTRS models and evaluate on three real-world datasets. The implementation code is available online to ease reproducibility.
        </div> </ul> <br>



        <label for="Panel33">
        <strong> Knowledge-enhanced Multi-View Graph Neural Networks for Session-based Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qian+Chen">Qian Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Guo">Zhiqiang Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianjun+Li">Jianjun Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guohui+Li">Guohui Li</a> (1) </u>  <br>
        1:  Huazhong University of Science and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591706">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Knowledge-enhanced Multi-View Graph Neural Networks for Session-based Recommendation">Google Scholar</a></div>
        (33)
        <br>
        <b>概要:　</b> セッションベースの推薦（SBR）は、グローバルおよびローカルなアイテム間関係を抽出および統合することで次のアイテムを予測するために、ますます重要視されています。しかしながら、これらの2種類の関係を把握する際には依然としていくつかの欠点があります。グローバルなアイテム間関係の場合、ほとんどのSBRによって構築されるグローバルグラフは擬似的なグローバルグラフであり、これによりシーケンス関係の冗長なマイニングが引き起こされる可能性があります。ローカルなアイテム間関係の場合、従来のSBRは特徴パターンを無視してシーケンスパターンのみをマイニングするため、ユーザーの興味を学習する際にノイズが入る可能性があります。これらの問題に対処するために、我々は知識ビュー、セッションビュー、およびペアワイズビューという3つのビューを構築することによって、斬新な知識強化マルチビューブグラフニューラルネットワーク（KMVG）を提案します。具体的には、知識グラフ（KG）に含まれる豊富なセマンティック情報を活用して、KGに基づいてシーケンスと無関係な真のグローバルグラフを構築し、知識ビューにおけるグローバルなアイテム間関係をマイニングします。次に、セッションビューはローカルなアイテム間関係のシーケンスパターンとしてアイテム間のコンテキスト遷移を把握し、ペアワイズビューはローカルなアイテム間関係の特徴パターンとしてセッション内の特徴共通性を探ります。3つの実世界の公開データセットを用いた大規模な実験により、KMVGの優位性が示され、最先端のベースラインを上回ることが分かりました。さらに、複数のビューでアイテム間関係を活用するKMVGの効果も明らかになりました。
        </label>
        <input type="checkbox" id="Panel33" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Session-based recommendation (SBR) has received increasing attention to predict the next item via extracting and integrating both global and local item-item relationships. However, there still exist some deficiencies in current works when capturing these two kinds of relationships. For global item-item relationships, the global graph constructed by most SBR is a pseudo-global graph, which may cause redundant mining of sequence relationships. For local item-item relationships, conventional SBR only mines the sequence patterns while ignoring the feature patterns, which may introduce noise when learning users' interests. To address these problems, we propose a novel Knowledge-enhanced Multi-View Graph Neural Network (KMVG) by constructing three views, namely knowledge view, session view, and pairwise view. Specifically, benefiting from the rich semantic information in the knowledge graph (KG), we build a genuine global graph that is sequence-independent based on KG to mine the global item-item relationships in the knowledge view. Then, a session view is utilized to capture the contextual transitions among items as the sequence patterns of local item-item relationships, and a pairwise view is used to explore the feature commonality within a session as the feature patterns of the local item-item relationships. Extensive experiments on three real-world public datasets demonstrate the superiority of KMVG, showing that it outperforms the state-of-the-art baselines. Further analysis also reveals the effectiveness of KMVG in exploiting the item-item relationships under multiple views.
        </div> </ul> <br>



        <label for="Panel34">
        <strong> Knowledge-refined Denoising Network for Robust Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinjun+Zhu">Xinjun Zhu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuntao+Du">Yuntao Du</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuren+Mao">Yuren Mao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lu+Chen">Lu Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yujia+Hu">Yujia Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunjun+Gao">Yunjun Gao</a> (1) </u>  <br>
        1:  Zhejiang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591707">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Knowledge-refined Denoising Network for Robust Recommendation">Google Scholar</a></div>
        (34)
        <br>
        <b>概要:　</b> 豊富な補助情報を含む知識グラフ（KG）は、推薦のパフォーマンスを向上させ、その説明可能性を高めるために不可欠な部分となっています。しかし、既存の知識認識推薦方法は、KGとユーザー・アイテムの二部グラフに直接情報伝播を行うため、タスクに関連しない知識の伝播とインタラクションノイズの影響を無視しており、それがパフォーマンスを制限しています。これらの問題を解決するために、タスクに関連しない知識の関連性とノイズの多い暗黙のフィードバックを同時に整理する堅牢な知識認識推薦フレームワーク、Knowledge-refined Denoising Network (KRDN)を提案します。KRDNは適応的な知識精製戦略と対比的なデノイジングメカニズムで構成されており、それぞれ高品質なKGトリプレットを自動で抽出して集約し、ノイズの多い暗黙のフィードバックを整理することが可能です。また、自己適応型損失関数およびグラディエント推定器を設計し、モデルの最適化を図ります。3つのベンチマークデータセットにおける実験結果から、KRDNがKGIN、MCCLK、KGCLなどの最新の知識認識方法およびSGL、SimGCLなどの堅牢な推薦モデルを上回る効果と堅牢性を示すことが確認されました。実装はhttps://github.com/xj-zhu98/KRDNにて利用可能です。
        </label>
        <input type="checkbox" id="Panel34" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge graph (KG), which contains rich side information, becomes an essential part to boost the recommendation performance and improve its explainability. However, existing knowledge-aware recommendation methods directly perform information propagation on KG and user-item bipartite graph, ignoring the impacts of task-irrelevant knowledge propagation and vulnerability to interaction noise, which limits their performance. To solve these issues, we propose a robust knowledge-aware recommendation framework, called Knowledge-refined Denoising Network (KRDN), to prune the task-irrelevant knowledge associations and noisy implicit feedback simultaneously. KRDN consists of an adaptive knowledge refining strategy and a contrastive denoising mechanism, which are able to automatically distill high-quality KG triplets for aggregation and prune noisy implicit feedback respectively. Besides, we also design the self-adapted loss function and the gradient estimator for model optimization. The experimental results on three benchmark datasets demonstrate the effectiveness and robustness of KRDN over the state-of-the-art knowledge-aware methods like KGIN, MCCLK, and KGCL, and also outperform robust recommendation models like SGL and SimGCL. The implementations are available at https://github.com/xj-zhu98/KRDN.
        </div> </ul> <br>



        <label for="Panel35">
        <strong> Mixed-Curvature Manifolds Interaction Learning for Knowledge Graph-aware Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jihu+Wang">Jihu Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuliang+Shi">Yuliang Shi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Han+Yu">Han Yu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinjun+Wang">Xinjun Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhongmin+Yan">Zhongmin Yan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fanyu+Kong">Fanyu Kong</a> (1) </u>  <br>
        1:  Shandong University, 2:  Shandong University & Dareway Software Co., 3:  Nanyang Technological University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591730">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Mixed-Curvature Manifolds Interaction Learning for Knowledge Graph-aware Recommendation">Google Scholar</a></div>
        (35)
        <br>
        <b>概要:　</b> 知識グラフ（KG）のトリプルがもつエンティティの結びつきや関係の意味性は、推薦システムにおけるデータのスパース性やコールドスタート問題の解消に寄与する。従って、多くの研究がユーザーとアイテムの表現をユークリッド空間内のグラフ構造データの情報統合を通じて取得することを検討している。しかし、スケールフリーグラフ（例えばKG）は本質的に非ユークリッド幾何学的トポロジー、例えば木構造や円形構造を示す。単一の埋め込み空間内に構築された既存の推薦モデルは多様な幾何学的パターンに対応する能力が不足しており、その結果パフォーマンスが最適化されていない。この制約に対処するために、混合曲率マニホールド相互作用学習を用いたKG対応推薦モデル、すなわちCurvRecを提案する。一方で、混合曲率マニホールド空間をバックボーンとしてKG内の多様なグローバル幾何学的構造を維持することを目指す。他方では、リッチ曲率をグラフ畳み込みネットワーク（GCN）に統合し、隣接ノードを集約する際に局所的な幾何学的構造特性を捕捉する。さらに、KGにおける表現力豊かな空間特性を活用するために、曲率を取り入れた測地距離指標を採用し、ユークリッド空間と非ユークリッド空間間の相互情報を最大化することで幾何学的メッセージ伝達を保証する。広範な実験を通じて、提案したCurvRecが最先端のベースラインを上回ることを示す。
        </label>
        <input type="checkbox" id="Panel35" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> As auxiliary collaborative signals, the entity connectivity and relation semanticity beneath knowledge graph (KG) triples can alleviate the data sparsity and cold-start issues of recommendation tasks. Thus many works consider obtaining user and item representations via information aggregation on graph-structured data within Euclidean space. However, the scale-free graphs (e.g., KGs) inherently exhibit non-Euclidean geometric topologies, such as tree-like and circle-like structures. The existing recommendation models built in a single type of embedding space do not have enough capacity to embrace various geometric patterns, consequently, resulting in suboptimal performance. To address this limitation, we propose a KG-aware recommendation model with mixed-curvature manifolds interaction learning, namely CurvRec. On the one hand, it aims to preserve various global geometric structures in KG with mixed-curvature manifold spaces as the backbone. On the other hand, we integrate Ricci curvature into graph convolutional networks (GCNs) to capture local geometric structural properties when aggregating neighbor nodes. Besides, to exploit the expressive spatial features in KG, we incorporate interaction learning to ensure the geometric message passing between curved manifolds. Specifically, we adopt curvature-aware geodesic distance metrics to maximize the mutual information between Euclidean space and non-Euclidean spaces. Through extensive experiments, we demonstrate that the proposed CurvRec outperforms state-of-the-art baselines.
        </div> </ul> <br>



        <label for="Panel36">
        <strong> EEDN: Enhanced Encoder-Decoder Network with Local and Global Context Learning for POI Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinfeng+Wang">Xinfeng Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fumiyo+Fukumoto">Fumiyo Fukumoto</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jin+Cui">Jin Cui</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yoshimi+Suzuki">Yoshimi Suzuki</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiyi+Li">Jiyi Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongjin+Yu">Dongjin Yu</a> (2) </u>  <br>
        1:  University of Yamanashi, 2:  Hangzhou Dianzi University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591678">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=EEDN: Enhanced Encoder-Decoder Network with Local and Global Context Learning for POI Recommendation">Google Scholar</a></div>
        (36)
        <br>
        <b>概要:　</b> ポイント・オブ・インタレスト（POI）推薦は、ユーザーが関心を持ちそうな目的地を予測するもので、位置情報基盤のソーシャルネットワーク（LBSN）の主要なアプリケーションの一つとして注目を集めています。グラフベースのニューラルネットワーク（GNN）や行列分解ベース（MF）のアプローチに関する最近の研究は、ユーザーとPOIのより良い表現を得ることで、ユーザーの潜在的な好みを予測する結果を出しています。しかし、これらのアプローチはチェックインデータの暗黙のフィードバックとコールドスタート問題に悩まされており、ユーザー（またはPOI）の局所的および大域的なグラフベースの関係を同時に捉えることができず、コールドスタート隣接者がGNNのグラフ畳み込み中に適切に処理されません。本論文では、POI推薦のためにユーザー、POI、およびそれらの相互作用間の豊富な潜在特徴を活用するための強化エンコーダ・デコーダネットワーク（EEDN）を提案します。EEDNのエンコーダはハイブリッドハイパーグラフ畳み込みを利用して、各グラフ畳み込みステップの集約能力を強化し、コールドスタート対応のユーザー表現をより堅牢に導き出すことを学習します。一方、デコーダはグラフベースおよびシーケンシャルベースのパターンによって、局所および大域的な相互作用を掘り下げ、特に露出バイアスを軽減するために暗黙のフィードバックをモデル化します。3つの公開された実世界のデータセットにおける広範な実験により、EEDNが最先端の手法を上回る性能を示すことが実証されました。ソースコードとデータはhttps://github.com/WangXFng/EEDNで公開されています。
        </label>
        <input type="checkbox" id="Panel36" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The point-of-interest (POI) recommendation predicts users' destinations, which might be of interest to users and has attracted considerable attention as one of the major applications in location-based social networks (LBSNs). Recent work on graph-based neural networks (GNN) or matrix factorization-based (MF) approaches has resulted in better representations of users and POIs to forecast users' latent preferences. However, they still suffer from the implicit feedback and cold-start problems of check-in data, as they cannot capture both local and global graph-based relations among users (or POIs) simultaneously, and the cold-start neighbors are not handled properly during graph convolution in GNN. In this paper, we propose an enhanced encoder-decoder network (EEDN) to exploit rich latent features between users, POIs, and interactions between users and POIs for POI recommendation. The encoder of EEDN utilizes a hybrid hypergraph convolution to enhance the aggregation ability of each graph convolution step and learns to derive more robust cold-start-aware user representations. In contrast, the decoder mines local and global interactions by both graph- and sequential-based patterns for modeling implicit feedback, especially to alleviate exposure bias. Extensive experiments in three public real-world datasets demonstrate that EEDN outperforms state-of-the-art methods. Our source codes and data are released at https://github.com/WangXFng/EEDN
        </div> </ul> <br>



        <label for="Panel37">
        <strong> Adaptive Graph Representation Learning for Next POI Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaobo+Wang">Zhaobo Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanmin+Zhu">Yanmin Zhu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chunyang+Wang">Chunyang Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenze+Ma">Wenze Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Li">Bo Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiadi+Yu">Jiadi Yu</a> (1) </u>  <br>
        1:  Shanghai Jiao Tong University, 2:  Hong Kong University of Science and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591634">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Adaptive Graph Representation Learning for Next POI Recommendation">Google Scholar</a></div>
        (37)
        <br>
        <b>概要:　</b> 次のポイント・オブ・インタレスト（POI）の推薦は、位置情報ベースのアプリケーションの急速な発展において重要な役割を果たしています。ユーザーの要求は、最近のチェックイン行動だけでなく、POI間の地理的依存性の重大な影響によっても決定されます。既存の手法は、事前に定義されたPOIグラフを用いてグラフニューラルネットワークを活用し、ユーザーの嗜好をモデル化するための不可欠な相関関係を捉えるものですが、適切な地理的依存性があらかじめ決められることが前提となっています。しかし、事前定義されたグラフ構造は、ノイズや適応性の問題により、常に最適なグラフトポロジーから遠く、学習されたPOI表現の表現力とユーザー嗜好のモデル化の信頼性が低下する可能性があります。本論文では、次のPOI推薦のための新しい適応型グラフ表現強化注意ネットワーク（AGRAN）を提案します。これは、より表現力のあるPOI表現を学習するために、事前定義された静的グラフを置き換えるグラフ構造学習の利用を探ります。具体的には、適応型POIグラフ行列を開発し、POI埋め込みと類似性学習を通じて学習し、表現学習のための潜在的な地理的依存性を自動的に捉える方法を採用します。その後、学習されたPOI表現と個別の時空間情報を組み込み、動的なユーザー嗜好を捉えるために自己注意メカニズムを拡張します。二つの実世界データセットを用いた広範な実験によって、我々の提案手法が最先端のベースラインを上回る優れた性能を持つことが検証されました。
        </label>
        <input type="checkbox" id="Panel37" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Next Point-of-Interest (POI) recommendation is an essential part of the flourishing location-based applications, where the demands of users are not only conditioned by their recent check-in behaviors but also by the critical influence stemming from geographical dependencies among POIs. Existing methods leverage Graph Neural Networks with the aid of pre-defined POI graphs to capture such indispensable correlations for modeling user preferences, assuming that the appropriate geographical dependencies among POIs could be pre-determined. However, the pre-defined graph structures are always far from the optimal graph topology due to noise and adaptability issues, which may decrease the expressivity of learned POI representations as well as the credibility of modeling user preferences. In this paper, we propose a novel Adaptive Graph Representation-enhanced Attention Network (AGRAN) for next POI recommendation, which explores the utilization of graph structure learning to replace the pre-defined static graphs for learning more expressive representations of POIs. In particular, we develop an adaptive POI graph matrix and learn it via similarity learning with POI embeddings, automatically capturing the underlying geographical dependencies for representation learning. Afterward, we incorporate the learned representations of POIs and personalized spatial-temporal information with an extension to the self-attention mechanism for capturing dynamic user preferences. Extensive experiments conducted on two real-world datasets validate the superior performance of our proposed method over state-of-the-art baselines.
        </div> </ul> <br>



        <label for="Panel38">
        <strong> Spatio-Temporal Hypergraph Learning for Next POI Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaodong+Yan">Xiaodong Yan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tengwei+Song">Tengwei Song</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yifeng+Jiao">Yifeng Jiao</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianshan+He">Jianshan He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiaotuan+Wang">Jiaotuan Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruopeng+Li">Ruopeng Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Chu">Wei Chu</a> (3) </u>  <br>
        1:  Ant Group, 2:  Ant Group & Beihang University, 3:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591770">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Spatio-Temporal Hypergraph Learning for Next POI Recommendation">Google Scholar</a></div>
        (38)
        <br>
        <b>概要:　</b> 次の訪問地点（Next Point-of-Interest, POI）の推薦タスクは、ユーザーが次に訪れる可能性の高い場所を予測し、魅力的な位置情報アドバイスを提供することに焦点を当てています。この観点から、グラフニューラルネットワーク（GNN）に基づくモデルは、そのグローバルなユーザーの嗜好を学習し、コールドスタート問題を緩和する能力により、このタスクにおいて画期的な手法として台頭しています。しかしながら、既存の多くの手法はPOI間の関係にのみ注目し、ユーザーの軌跡や軌跡間の協調関係といった高次情報を無視している点が多く見受けられます。本論文では、Spatio-Temporal HyperGraph Convolutional Network（STHGCN）を提案します。このモデルは、ハイパーグラフを活用して軌跡レベルの情報を捉え、ユーザーの歴史的な軌跡（ユーザー内）だけでなく、他のユーザーの協調的な軌跡（ユーザー間）から学習します。さらに、ハイパーグラフ構造のエンコーディングと時空間情報を効果的に組み合わせるため、新しいハイパーグラフトランスフォーマーを導入します。実世界のデータセットを用いた広範な実験により、我々のモデルが既存の最先端の手法を上回る性能を発揮することが示され、さらに解析によって、コールドスタート問題の緩和と短距離および長距離軌跡における性能向上の有効性が確認されました。
        </label>
        <input type="checkbox" id="Panel38" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Next Point-of-Interest (POI) recommendation task focuses on predicting the immediate next position a user would visit, thus providing appealing location advice. In light of this, graph neural networks (GNNs) based models have recently been emerging as breakthroughs for this task due to their ability to learn global user preferences and alleviate cold-start challenges. Nevertheless, most existing methods merely focus on the relations between POIs, neglecting the higher-order information including user trajectories and the collaborative relations among trajectories. In this paper, we propose the Spatio-Temporal HyperGraph Convolutional Network (STHGCN). This model leverages a hypergraph to capture the trajectory-grain information and learn from user's historical trajectories (intra-user) as well as collaborative trajectories from other users (inter-user). Furthermore, a novel hypergraph transformer is introduced to effectively combine the hypergraph structure encoding with spatio-temporal information. Extensive experiments on real-world datasets demonstrate that our model outperforms the existing state-of-the-art methods and further analysis confirms the effectiveness in alleviating cold-start issues and achieving improved performance for both short and long trajectories.
        </div> </ul> <br>



        <label for="Panel39">
        <strong> Fine-Grained Preference-Aware Personalized Federated POI Recommendation with Data Sparsity </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Zhang">Xiao Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ziming+Ye">Ziming Ye</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianfeng+Lu">Jianfeng Lu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuzhen+Zhuang">Fuzhen Zhuang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanwei+Zheng">Yanwei Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongxiao+Yu">Dongxiao Yu</a> (1) </u>  <br>
        1:  Shandong University, 2:  Wuhan University of Science and Technology, 3:  Beihang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591688">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Fine-Grained Preference-Aware Personalized Federated POI Recommendation with Data Sparsity">Google Scholar</a></div>
        (39)
        <br>
        <b>概要:　</b> プライバシー問題の増加と厳格なデータ規制に伴い、連携学習パラダイムであるフェデレーテッドラーニングは、センシティブなPOIデータを共有せずにレコメンデーションモデルを構築するための注目すべき手法となりました。しかしながら、時間依存性、異質性、および限定されたPOI記録が、フェデレーテッドPOIレコメンデーションの開発を大きく制約しています。そこで本論文では、これらの課題を解決するために、極めてスパースな履歴軌跡の下で詳細な嗜好意識のあるパーソナライズされたフェデレーテッドPOIレコメンデーションフレームワーク、PrefFedPOIを設計しました。具体的には、PrefFedPOIは各ローカルクライアント内で過去の最近の嗜好と周期的嗜好を組み合わせることで、現在の時間スロットの詳細な嗜好を抽出します。特定の時間スロットでのPOIデータの極端な不足に対応するために、データ量に応じた選択的アップロード戦略を設計しました。さらに、強化学習を用いたパフォーマンス強化クラスタリングメカニズムを提案し、全クライアント間の嗜好の関連性を捉え、ポジティブな知識共有を促進します。また、クラスタリングの指導により効率を向上させるクラスタリングティーチャーネットワークを設計しました。二つの多様な実世界のデータセットで広範な実験を行い、提案されたPrefFedPOIの有効性を最新技術と比較して実証しました。特に、パーソナライズされたPrefFedPOIは、データ不足クライアントにおいて平均7%の精度向上を達成しました。
        </label>
        <input type="checkbox" id="Panel39" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> With the raised privacy concerns and rigorous data regulations, federated learning has become a hot collaborative learning paradigm for the recommendation model without sharing the highly sensitive POI data. However, the time-sensitive, heterogeneous, and limited POI records seriously restrict the development of federated POI recommendation. To this end, in this paper, we design the fine-grained preference-aware personalized federated POI recommendation framework, namely PrefFedPOI, under extremely sparse historical trajectories to address the above challenges. In details, PrefFedPOI extracts the fine-grained preference of current time slot by combining historical recent preferences and periodic preferences within each local client. Due to the extreme lack of POI data in some time slots, a data amount aware selective strategy is designed for model parameters uploading. Moreover, a performance enhanced clustering mechanism with reinforcement learning is proposed to capture the preference relatedness among all clients to encourage the positive knowledge sharing. Furthermore, a clustering teacher network is designed for improving efficiency by clustering guidance. Extensive experiments are conducted on two diverse real-world datasets to demonstrate the effectiveness of proposed PrefFedPOI comparing with state-of-the-arts. In particular, personalized PrefFedPOI can achieve 7% accuracy improvement on average among data-sparsity clients.
        </div> </ul> <br>



        <label for="Panel40">
        <strong> Model-Agnostic Decentralized Collaborative Learning for On-Device POI Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jing+Long">Jing Long</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tong+Chen">Tong Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Quoc+Viet+Hung+Nguyen">Quoc Viet Hung Nguyen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guandong+Xu">Guandong Xu</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kai+Zheng">Kai Zheng</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongzhi+Yin">Hongzhi Yin</a> (1) </u>  <br>
        1:  The University of Queensland, 2:  The University of Queensland, 3:  Griffith University, 4:  University of Technology Sydney, 5:  University of Electronic Science and Technology of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591733">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Model-Agnostic Decentralized Collaborative Learning for On-Device POI Recommendation">Google Scholar</a></div>
        (40)
        <br>
        <b>概要:　</b> 位置情報ソーシャルネットワーク（LBSN）における重要な個別サービスとして、次の訪問先（POI）推薦は、人々が魅力的で興味深い場所を見つけるのを助けることを目的としています。現在、ほとんどのPOI推薦システムは、集中的なクラウドパラダイムに基づいており、大量のユーザーのセンシティブなチェックインデータを収集し、クラウドでモデルをトレーニングしています。近年、堅牢でプライバシー保護に配慮したオンデバイスフレームワークが研究されていますが、それらは常にパラメータや勾配の集約と協調においてモデルの均質性を前提としています。しかし、実際のユーザーのモバイルデバイスは様々なハードウェア構成（例：計算資源）を持ち、異なるアーキテクチャやサイズの異質なオンデバイスモデルを持つことになります。これに対処するために、ユーザーが自身のモデル構造（例：次元や隠れ層の数）をカスタマイズできる、新しいオンデバイスPOI推薦フレームワーク、すなわちModel-Agnostic Collaborative learning for on-device POI recommendation（MAC）を提案します。オンデバイスユーザーデータの希少性を克服するために、物理的距離、カテゴリレベルの好み、ソーシャルネットワークに基づいて協力する隣接ユーザーを事前に選定することを提案します。選定された隣接ユーザーから効率的かつ安全に知識を得るために、相互情報の最大化を用いた知識蒸留フレームワークを採用しています。センシティブなモデルや勾配を共有する代わりに、MACのクライアントは、事前にロードされたリファレンスデータセットに対するソフトな意思決定を共有するだけです。低品質の隣接ユーザーを除外するために、パフォーマンストリガーサンプリングと類似性ベースサンプリングという二つのサンプリング戦略を提案し、トレーニングプロセスを高速化し最適な推薦システムを取得します。さらに、ユーザーのプライバシーを保護しながら、より効果的なリファレンスデータセットを生成するための二つの新しいアプローチを設計しました。二つのデータセットに対する広範な実験により、MACが先進的なベースラインを上回る優位性を持つことが示されました。
        </label>
        <input type="checkbox" id="Panel40" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> As an indispensable personalized service in Location-based Social Networks (LBSNs), the next Point-of-Interest (POI) recommendation aims to help people discover attractive and interesting places. Currently, most POI recommenders are based on the conventional centralized paradigm that heavily relies on the cloud to train the recommendation models with large volumes of collected users' sensitive check-in data. Although a few recent works have explored on-device frameworks for resilient and privacy-preserving POI recommendations, they invariably hold the assumption of model homogeneity for parameters/gradients aggregation and collaboration. However, users' mobile devices in the real world have various hardware configurations (e.g., compute resources), leading to heterogeneous on-device models with different architectures and sizes. In light of this, We propose a novel on-device POI recommendation framework, namely Model-Agnostic Collaborative learning for on-device POI recommendation (MAC), allowing users to customize their own model structures (e.g., dimension & number of hidden layers). To counteract the sparsity of on-device user data, we propose to pre-select neighbors for collaboration based on physical distances, category-level preferences, and social networks. To assimilate knowledge from the above-selected neighbors in an efficient and secure way, we adopt the knowledge distillation framework with mutual information maximization. Instead of sharing sensitive models/gradients, clients in MAC only share their soft decisions on a preloaded reference dataset. To filter out low-quality neighbors, we propose two sampling strategies, performance-triggered sampling and similarity-based sampling, to speed up the training process and obtain optimal recommenders. In addition, we design two novel approaches to generate more effective reference datasets while protecting users' privacy. Extensive experiments on two datasets have shown the superiority of MAC over advanced baselines.
        </div> </ul> <br>



        <label for="Panel41">
        <strong> Learning Fine-grained User Interests for Micro-video Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yu+Shang">Yu Shang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chen+Gao">Chen Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiansheng+Chen">Jiansheng Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Depeng+Jin">Depeng Jin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Meng+Wang">Meng Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yong+Li">Yong Li</a> (1) </u>  <br>
        1:  Tsinghua University, 2:  University of Science and Technology Beijing, 3:  Hefei University of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591713">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Learning Fine-grained User Interests for Micro-video Recommendation">Google Scholar</a></div>
        (41)
        <br>
        <b>概要:　</b> 近年、オンラインのマイクロビデオプラットフォームが急速に発展しており、レコメンダーシステムは情報過多の問題を克服し、ユーザーにパーソナライズされたコンテンツを提供する上で重要な役割を果たしています。マイクロビデオ推薦システムに関しては一定の進展が見られるものの、依然としてユーザーの興味やビデオの特徴を表現する上でいくつかの制約があります。具体的には、既存の研究ではユーザーモデリングが粗粒度（ビデオレベル）で行われています。しかし、マイクロビデオ推薦において、ユーザーのフィードバックは連続的な形式であり（例：各フレームでビデオをスキップすることが可能）、これが微細なユーザーの嗜好を示します。本研究では、微細なユーザー嗜好を学習する問題に取り組むため、まず2つの実世界データセットを収集しました。嗜好のモデリングと弱い監督信号の課題に対処するために、FRAME（Fine-gRAined preference-modeling for Micro-video rEcommendation）と呼ばれる解決策を提案します。具体的には、まず視覚的特徴の抽出と変換を行い、微細なビデオ埋め込みを維持します。次に、複雑で微細なユーザーとクリップの関係からユーザーの嗜好を学習するためにグラフ畳み込み層を提案し、監督信号を強化するためのハイブリッド監督目的を設定します。収集した2つの実世界データセットでの実験結果は、提案モデルの有効性を示しています。我々はデータセットとコードをhttps://github.com/tsinghua-fib-lab/FRAME にて公開しており、これがコミュニティに貢献できると信じています。
        </label>
        <input type="checkbox" id="Panel41" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recent years have witnessed the rapid development of online micro-video platforms, in which the recommender system plays an essential role in overcoming the information overloading problem and providing personalized content for users. Although some progress has been achieved in the micro-video recommendation, there are still some limitations in learning the representations of user interests and video features. Specifically, the user modeling in existing works is performed at a coarse-grained level, i.e., video level. However, in micro-video recommendation, the user feedback is at a continuous form---users can skip over a video at each frame---which reveals fine-grained user preferences. In this work, we approach the problem of learning fine-grained user preferences for micro-video recommendation by first collecting two real-world datasets. To address the challenges of preference modeling and weak supervision signal, we propose a solution named FRAME (short for Fine-gRAined preference-modeling for Micro-video rEcommendation). Specifically, we first adopt visual feature extraction and transformation to maintain the fine-grained video embeddings. We then propose graph convolution layers to learn the user preference from complex and fine-grained user-clip relations, and hybrid-supervision objectives for enhancing the supervision signal. The experimental results on two collected real-world datasets demonstrate the effectiveness of our proposed model. We release the datasets and codes in https://github.com/tsinghua-fib-lab/FRAME, which we believe can benefit the community.
        </div> </ul> <br>



        <label for="Panel42">
        <strong> Mining Stable Preferences: Adaptive Modality Decorrelation for Multimedia Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinghao+Zhang">Jinghao Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiang+Liu">Qiang Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shu+Wu">Shu Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liang+Wang">Liang Wang</a> (1) </u>  <br>
        1:  Institute of Automation <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591729">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Mining Stable Preferences: Adaptive Modality Decorrelation for Multimedia Recommendation">Google Scholar</a></div>
        (42)
        <br>
        <b>概要:　</b> 現代のウェブ時代において、マルチメディアコンテンツは重要な役割を果たしています。さまざまな推奨モデルが提案され、多様なモダリティで表現されたアイテムとのユーザーインタラクションを調査してきました。実際のシナリオでは、異なるモダリティはアイテム属性の異なる側面を示し、通常、ユーザーの購入決定に異なる重要性を持っています。しかし、異なるモダリティ間には強い統計的相関が存在するため、モデルがユーザーの真の好みを見極めるのは困難です。さらには、この強い統計的相関が、重要でないモダリティへの誤った好みをモデルに学習させる可能性もあります。その結果、データ（モダリティの特徴量）の分布がシフトすると、学習された誤った好みが訓練セット上での推論と同じように有効であるとは限りません。この問題の主な原因が異なるモダリティ間の統計的相関であることを踏まえ、我々はユーザーの安定した好みを学習するための新しいMOdality DEcorrelating STable learningフレームワーク、略してMODESTを提案します。サンプルの重み付け技術に触発され、提案手法は各アイテムに重みを推定し、重み付けされた分布における異なるモダリティの特徴が非相関となるようにします。我々は、二次元および非線形変数間の相関度を評価する能力を持つカーネルベースの手法であるHilbert Schmidt Independence Criterion（HSIC）を独立性検定手段として採用します。さらに、適応的な勾配マスクを利用することで、HSICにタスク関連の相関を測定する能力を付与します。全体として、トレーニングフェーズでは、（1）重み付けされたベイズ型パーソナライズドランキング（BPR）損失を最小化することでモデルパラメータを最適化し、（2）重み付けされた分布内のモダリティの相関（HSIC損失を通じて定量化）を最小化することでサンプルの重みを最適化します。推論フェーズでは、訓練されたマルチメディア推薦モデルを直接使用して推奨を行うことができます。我々の手法は既存のマルチメディア推薦システムのバックボーンにプレイアンドプラグモジュールとして利用できる可能性があります。公開されている4つのデータセットと4つの最先端のマルチメディア推薦バックボーンに対する広範な実験により、提案された手法がパフォーマンスを大幅に改善できることが明確に示されています。
        </label>
        <input type="checkbox" id="Panel42" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multimedia content is of predominance in the modern Web era. Many recommender models have been proposed to investigate how users interact with items which are represented in diverse modalities. In real scenarios, different modalities reveal different aspects of item attributes and usually possess different importance to user purchase decisions. However, it is difficult for models to figure out users' true preference towards different modalities since there exists strong statistical correlation between different modalities. Even worse, the strong statistical correlation might mislead models to learn the spurious preference towards inconsequential modalities. As a result, when data (modal features) distribution shifts, the learned spurious preference might not guarantee to be as effective on inference as on the training set. Given that the statistical correlation between different modalities is a major cause of this problem, we propose a novel MOdality DEcorrelating STable learning framework, MODEST for brevity, to learn users' stable preference. Inspired by sample re-weighting techniques, the proposed method aims to estimate a weight for each item, such that the features from different modalities in the weighted distribution are decorrelated. We adopt Hilbert Schmidt Independence Criterion (HSIC) as independence testing measure which is a kernel-based method capable of evaluating the correlation degree between two multi-dimensional and non-linear variables. Moreover, by utilizing adaptive gradient mask, we empower HSIC with the ability to measure task-relevant correlation. Overall, in the training phase, we alternately optimize (1) model parameters via minimizing weighted Bayesian Personalized Ranking (BPR) loss and (2) sample weights via minimizing modal correlation in the weighted distribution (quantified through HSIC loss). In the inference phase, we can directly use the the trained multimedia recommendation models to make recommendations. Our method could be served as a play-and-plug module for existing multimedia recommendation backbones. Extensive experiments on four public datasets and four state-of-the-art multimedia recommendation backbones unequivocally show that our proposed method can improve the performances by a large margin.
        </div> </ul> <br>



        <label for="Panel43">
        <strong> DisCover: Disentangled Music Representation Learning for Cover Song Identification </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiahao+Xun">Jiahao Xun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shengyu+Zhang">Shengyu Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanting+Yang">Yanting Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jieming+Zhu">Jieming Zhu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liqun+Deng">Liqun Deng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhou+Zhao">Zhou Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenhua+Dong">Zhenhua Dong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruiqi+Li">Ruiqi Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lichao+Zhang">Lichao Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Wu">Fei Wu</a> (1) </u>  <br>
        1:  Zhejiang University, 2:  Huawei Noah's Ark Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591664">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=DisCover: Disentangled Music Representation Learning for Cover Song Identification">Google Scholar</a></div>
        (43)
        <br>
        <b>概要:　</b> 音楽情報検索 (MIR) の分野において、カバーソング識別 (CSI) は、あるクエリ曲のカバー バージョンを大量の楽曲コレクションから識別するという難しい課題です。既存の研究では、バージョン固有の要素とバージョン不変の要素が絡み合っているため、曲内のバラつきや曲間の相関が高いという問題が残っています。本研究では、バージョン固有の要素とバージョン不変の要素を分離することを目標とし、未見のクエリ曲に対して不変な音楽表現をモデルが学習しやすくすることを目指します。分離の観点から因果グラフ技術を用いて CSI タスクを分析し、不変学習にバイアスをかけるバージョン内およびバージョン間の効果を特定します。これらの効果をブロックするために、CSI 用の分離音楽表現学習フレームワーク (DisCover) を提案します。DisCover は、以下の 2 つの重要なコンポーネントで構成されています。 (1) 知識に基づく分離モジュール (KDM) と (2) 勾配に基づく敵対的分離モジュール (GADM)、それぞれがバージョン内およびバージョン間のバイアス効果をブロックします。KDM は、事前のドメイン知識を使用して特定されたバージョン可変の要素と学習された表現の相互情報量を最小化します。GADM は、曲内バージョン間の表現変遷をシミュレートしてバージョン可変の要素を特定し、効果をブロックするために敵対的蒸留を利用します。最先端の手法との広範な比較および詳細な分析により、DisCover の有効性と CSI における分離の必要性が実証されました。
        </label>
        <input type="checkbox" id="Panel43" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In the field of music information retrieval (MIR), cover song identification (CSI) is a challenging task that aims to identify cover versions of a query song from a massive collection. Existing works still suffer from high intra-song variances and inter-song correlations, due to the entangled nature of version-specific and version-invariant factors in their modeling. In this work, we set the goal of disentangling version-specific and version-invariant factors, which could make it easier for the model to learn invariant music representations for unseen query songs. We analyze the CSI task in a disentanglement view with the causal graph technique, and identify the intra-version and inter-version effects biasing the invariant learning. To block these effects, we propose the disentangled music representation learning framework (DisCover) for CSI. DisCover consists of two critical components: (1) Knowledge-guided Disentanglement Module (KDM) and (2) Gradient-based Adversarial Disentanglement Module (GADM), which block intra-version and inter-version biased effects, respectively. KDM minimizes the mutual information between the learned representations and version-variant factors that are identified with prior domain knowledge. GADM identifies version-variant factors by simulating the representation transitions between intra-song versions, and exploits adversarial distillation for effect blocking. Extensive comparisons with best-performing methods and in-depth analysis demonstrate the effectiveness of DisCover and the and necessity of disentanglement for CSI.
        </div> </ul> <br>



        <label for="Panel44">
        <strong> A Scalable Framework for Automatic Playlist Continuation on Music Streaming Services </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Walid+Bendada">Walid Bendada</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guillaume+Salha-Galvan">Guillaume Salha-Galvan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Thomas+Bouabça">Thomas Bouabça</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tristan+Cazenave">Tristan Cazenave</a> (3) </u>  <br>
        1:  Deezer Research & Université Paris Dauphine - PSL, 2:  Deezer Research, 3:  Université Paris Dauphine & PSL <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591628">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Scalable Framework for Automatic Playlist Continuation on Music Streaming Services">Google Scholar</a></div>
        (44)
        <br>
        <b>概要:　</b> 音楽ストリーミングサービスは、しばしばユーザーがこれらのサービスで作成したプレイリストを拡張するために、曲を推薦しようとします。しかし、プレイリストの音楽的特徴を保持しつつユーザーの好みに合致させるためにプレイリストを拡張することは、自動プレイリスト継続（Automatic Playlist Continuation, APC）と呼ばれる難題です。さらに、これらのサービスは大量の候補曲からリアルタイムで最適な曲を推奨する必要がある一方で、最近のAPCに関する研究は、スケーラビリティ保証が少なく、比較的小規模なデータセットで評価されたモデルに主に焦点を当てています。本論文では、大規模アプリケーション向けにスケーラブルかつ効果的なAPCモデルを構築するための一般的なフレームワークを紹介します。Represent-then-aggregate戦略に基づき、幅広い表現学習とシーケンスモデリング技術（Transformersに基づくものなど）を取り入れる柔軟性を保ちながら、設計上のスケーラビリティを確保します。我々は、SpotifyのMillion Playlist Dataset（MPD）, APC用の最大の公開データセットに対する詳細な実験的検証を通じて、このフレームワークの有効性を実証します。また、2022年にこのフレームワークを活用して、Deezerの生産環境におけるAPCの改善に成功した方法についても説明します。このサービスでの大規模なオンラインA/Bテストの結果を報告し、実世界のアプリケーションにおける我々のアプローチの実際的な影響を強調します。
        </label>
        <input type="checkbox" id="Panel44" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Music streaming services often aim to recommend songs for users to extend the playlists they have created on these services. However, extending playlists while preserving their musical characteristics and matching user preferences remains a challenging task, commonly referred to as Automatic Playlist Continuation (APC). Besides, while these services often need to select the best songs to recommend in real-time and among large catalogs with millions of candidates, recent research on APC mainly focused on models with few scalability guarantees and evaluated on relatively small datasets. In this paper, we introduce a general framework to build scalable yet effective APC models for large-scale applications. Based on a represent-then-aggregate strategy, it ensures scalability by design while remaining flexible enough to incorporate a wide range of representation learning and sequence modeling techniques, e.g., based on Transformers. We demonstrate the relevance of this framework through in-depth experimental validation on Spotify's Million Playlist Dataset (MPD), the largest public dataset for APC. We also describe how, in 2022, we successfully leveraged this framework to improve APC in production on Deezer. We report results from a large-scale online A/B test on this service, emphasizing the practical impact of our approach in such a real-world application.
        </div> </ul> <br>



        <label for="Panel45">
        <strong> MEME: Multi-Encoder Multi-Expert Framework with Data Augmentation for Video Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Seong-Min+Kang">Seong-Min Kang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yoon-Sik+Cho">Yoon-Sik Cho</a> (1) </u>  <br>
        1:  Chung-Ang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591726">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MEME: Multi-Encoder Multi-Expert Framework with Data Augmentation for Video Retrieval">Google Scholar</a></div>
        (45)
        <br>
        <b>概要:　</b> :<br>テキストからビデオ（T2V）への検索は、テキストクエリに関連するビデオを見つけることを目的としています。最近導入されたContrastive Language Image Pretraining (CLIP)は、大規模な画像とキャプションのペアでトレーニングされた事前学習済みの言語ビジョンモデルで、このタスクにおいて広く研究されています。既存のT2Vタスクに関する研究は、主にCLIPの知識を転用し、細粒度の表現学習を通じて検索性能の向上を目指しています。細粒度の対照学習では驚くべき成果が得られていますが、粗粒度の対照学習にはあまり注意が払われていません。そこで、我々は「Graph Patch Spreading (GPS)」という手法を提案し、粗粒度レベルでフレーム間のパッチを集約します。我々の提案するMulti-Encoder Multi-Expert (MEME)フレームワークにGPSを適用しました。我々の提案する手法は、既存のCLIPベースのビデオテキスト検索モデルに対して広範に適用可能です。MSR-VTT、MSVD、LSMDCなどのベンチマークデータセット上で、既存モデルに対する我々の手法の有効性を実証しました。コードはhttps://github.com/kang7734/MEME__にて公開しています。
        </label>
        <input type="checkbox" id="Panel45" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Text-to-video(T2V) retrieval aims to find relevant videos from text queries. The recently introduced Contrastive Language Image Pretraining (CLIP), a pretrained language-vision model trained on large-scale image and caption pairs, has been extensively studied in the literature for this task. Existing studies on T2V task have aimed to transfer the CLIP knowledge and focus on enhancing retrieval performance through fine-grained representation learning. While fine-grained contrast has achieved some remarkable results, less attention has been paid to coarse-grained contrasts. To this end, we propose a method called Graph Patch Spreading (GPS) to aggregate patches across frames at the coarse-grained level. We apply GPS to our proposed framework called Multi-Encoder Multi-Expert (MEME) framework. Our proposed scheme is general enough to be applied to any existing CLIP-based video-text retrieval models. We demonstrate the effectiveness of our method on existing models over the benchmark datasets MSR-VTT, MSVD, and LSMDC datasets. Our code can be found at https://github.com/kang7734/MEME__.
        </div> </ul> <br>



        <label for="Panel46">
        <strong> BotMoE: Twitter Bot Detection with Community-Aware Mixtures of Modal-Specific Experts </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuhan+Liu">Yuhan Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaoxuan+Tan">Zhaoxuan Tan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Heng+Wang">Heng Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shangbin+Feng">Shangbin Feng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qinghua+Zheng">Qinghua Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Minnan+Luo">Minnan Luo</a> (1) </u>  <br>
        1:  Xi'an Jiaotong University, 2:  University of Washington <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591646">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=BotMoE: Twitter Bot Detection with Community-Aware Mixtures of Modal-Specific Experts">Google Scholar</a></div>
        (46)
        <br>
        <b>概要:　</b> Twitterボットの検出は、オンライン上の誤情報の対策、選挙干渉の軽減、悪意あるプロパガンダの抑制において重要な課題となっています。しかし、高度なTwitterボットは特徴操作を通じて本物のユーザーの特性を模倣し、多様なユーザーコミュニティに溶け込むように偽装するため、既存のボット検出モデルにとって困難な課題を提供します。この問題に対応するため、我々はBotMoEというTwitterボット検出フレームワークを提案します。これは、複数のユーザー情報のモダリティ（メタデータ、テキストコンテンツ、ネットワーク構造）を共同利用して、欺瞞的なボットの検出を改善するものです。さらに、BotMoEはコミュニティ対応の専門家混合（MoE）層を組み込むことで、ドメイン一般化を改善し、異なるTwitterコミュニティに適応します。具体的には、BotMoEはメタデータ特徴、テキストコンテンツ、およびグラフ構造のためのモーダル固有のエンコーダーを構築し、これらが三つのモーダル固有の視点からTwitterユーザーを共同でモデル化します。その後、コミュニティ対応のMoE層を使用して、ユーザーを自動的に異なるコミュニティに割り当て、対応する専門家ネットワークを活用します。最後に、メタデータ、テキスト、グラフの各視点からのユーザー表現を専門家融合層で融合し、すべてのモダリティを組み合わせながらユーザー情報の一貫性を測定します。広範な実験により、BotMoEは、三つのTwitterボット検出ベンチマークにおいて最先端技術を大幅に進展させることが示されています。また、BotMoEは高度で回避的なボットを捉え、トレーニングデータへの依存を軽減し、新規およびこれまで見たことのないユーザーコミュニティへの適応性を向上させることも確認されています。
        </label>
        <input type="checkbox" id="Panel46" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Twitter bot detection has become a crucial task in efforts to combat online misinformation, mitigate election interference, and curb malicious propaganda. However, advanced Twitter bots often attempt to mimic the characteristics of genuine users through feature manipulation and disguise themselves to fit in diverse user communities, posing challenges for existing Twitter bot detection models. To this end, we propose BotMoE, a Twitter bot detection framework that jointly utilizes multiple user information modalities (metadata, textual content, network structure) to improve the detection of deceptive bots. Furthermore, BotMoE incorporates a community-aware Mixture-of-Experts (MoE) layer to improve domain generalization and adapt to different Twitter communities. Specifically, BotMoE constructs modal-specific encoders for metadata features, textual content, and graph structure, which jointly model Twitter users from three modal-specific perspectives. We then employ a community-aware MoE layer to automatically assign users to different communities and leverage the corresponding expert networks. Finally, user representations from metadata, text, and graph perspectives are fused with an expert fusion layer, combining all three modalities while measuring the consistency of user information. Extensive experiments demonstrate that BotMoE significantly advances the state-of-the-art on three Twitter bot detection benchmarks. Studies also confirm that BotMoE captures advanced and evasive bots, alleviates the reliance on training data, and better generalizes to new and previously unseen user communities.
        </div> </ul> <br>



        <label for="Panel47">
        <strong> Multi-behavior Self-supervised Learning for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingcao+Xu">Jingcao Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaokun+Wang">Chaokun Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cheng+Wu">Cheng Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Song">Yang Song</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kai+Zheng">Kai Zheng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaowei+Wang">Xiaowei Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Changping+Wang">Changping Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guorui+Zhou">Guorui Zhou</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kun+Gai">Kun Gai</a> (3) </u>  <br>
        1:  Tsinghua University, 2:  Kuaishou Inc., 3:  Unaffiliated <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591734">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multi-behavior Self-supervised Learning for Recommendation">Google Scholar</a></div>
        (47)
        <br>
        <b>概要:　</b> 現代の推薦システムは、クリックや転送、購入など、様々なユーザーインタラクションを処理する必要があり、そのためには基盤となる推薦エンジンがユーザーからの多様な行動データを完全に理解し、活用することが求められます。これまでの研究では、異質なデータの利用が進められてきたにもかかわらず、多重行動推薦は依然として大きな課題に直面しています。第一に、ターゲット信号のスパース性とノイズの多い補助的なインタラクションが依然として問題となっています。第二に、データのスパース性に対処するために自己教師あり学習（Self-Supervised Learning, SSL）を利用する既存の手法は、SSLタスクとターゲットタスクの間の深刻な最適化バランスの不均衡を見落としています。このため、本研究では多重行動自己教師あり学習（Multi-Behavior Self-Supervised Learning, MBSSL）フレームワークと適応的な最適化手法を提案します。具体的には、行動の多様性と依存関係を捉えるために、自己注意メカニズムを組み込んだ行動対応グラフニューラルネットワークを設計しました。ターゲット行動におけるデータのスパース性と補助行動からのノイズの多いインタラクションに対するロバスト性を高めるために、行動間および行動内の両レベルでノードの自己識別を行う、新しい自己教師あり学習パラダイムを提案します。さらに、ハイブリッドな勾配操作を通じたカスタマイズされた最適化戦略を開発し、自己教師あり学習タスクとメインの教師あり推薦タスクを適応的にバランスさせます。5つの実世界データセットにおける広範な実験により、MBSSLが10の最先端（State-Of-The-Art, SOTA）ベースラインに対して一貫した改良を達成することが示されました。私たちのモデル実装を以下で公開しています: https://github.com/Scofield666/MBSSL.git.
        </label>
        <input type="checkbox" id="Panel47" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Modern recommender systems often deal with a variety of user interactions, e.g., click, forward, purchase, etc., which requires the underlying recommender engines to fully understand and leverage multi-behavior data from users. Despite recent efforts towards making use of heterogeneous data, multi-behavior recommendation still faces great challenges. Firstly, sparse target signals and noisy auxiliary interactions remain an issue. Secondly, existing methods utilizing self-supervised learning (SSL) to tackle the data sparsity neglect the serious optimization imbalance between the SSL task and the target task. Hence, we propose a Multi-Behavior Self-Supervised Learning (MBSSL) framework together with an adaptive optimization method. Specifically, we devise a behavior-aware graph neural network incorporating the self-attention mechanism to capture behavior multiplicity and dependencies. To increase the robustness to data sparsity under the target behavior and noisy interactions from auxiliary behaviors, we propose a novel self-supervised learning paradigm to conduct node self-discrimination at both inter-behavior and intra-behavior levels. In addition, we develop a customized optimization strategy through hybrid manipulation on gradients to adaptively balance the self-supervised learning task and the main supervised recommendation task. Extensive experiments on five real-world datasets demonstrate the consistent improvements obtained by MBSSL over ten state-of-the-art (SOTA) baselines. We release our model implementation at: https://github.com/Scofield666/MBSSL.git.
        </div> </ul> <br>



        <label for="Panel48">
        <strong> Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhihao+Wen">Zhihao Wen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuan+Fang">Yuan Fang</a> (1) </u>  <br>
        1:  Singapore Management University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591641">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting">Google Scholar</a></div>
        (48)
        <br>
        <b>概要:　</b> テキスト分類は、オンライン記事のトピック予測やeコマース商品の説明カテゴリ予測など、多くの実世界のアプリケーションを持つ情報検索の基本的な問題です。しかし、ラベル付きサンプルが少ないまたはない低リソーステキスト分類は、教師あり学習にとって深刻な問題となります。同時に、多くのテキストデータは、オンライン記事のハイパーリンク/引用ネットワークやeコマース商品のユーザー-アイテム購入ネットワークなど、ネットワーク構造に基づいています。これらのグラフ構造は豊富なセマンティック関係を捉え、低リソーステキスト分類を強化する可能性があります。本論文では、低リソーステキスト分類に対処するために、Graph-Grounded Pre-training and Prompting（G2P2）という新しいモデルを提案します。プレトレーニング時には、グラフ-テキストモデルを共同でプレトレーニングするために、3つのグラフ相互作用に基づくコントラスト戦略を提案します。ダウンストリーム分類では、共同プレトレーニングされたモデルに対するプロンプティングを探索し、低リソース分類を達成します。4つの実世界データセットに関する広範な実験により、G2P2がゼロショットおよび数ショットの低リソーステキスト分類タスクにおいて優れた性能を発揮することが示されました。
        </label>
        <input type="checkbox" id="Panel48" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Text classification is a fundamental problem in information retrieval with many real-world applications, such as predicting the topics of online articles and the categories of e-commerce product descriptions. However, low-resource text classification, with few or no labeled samples, poses a serious concern for supervised learning. Meanwhile, many text data are inherently grounded on a network structure, such as a hyperlink/citation network for online articles, and a user-item purchase network for e-commerce products. These graph structures capture rich semantic relationships, which can potentially augment low-resource text classification. In this paper, we propose a novel model called Graph-Grounded Pre-training and Prompting (G2P2) to address low-resource text classification in a two-pronged approach. During pre-training, we propose three graph interaction-based contrastive strategies to jointly pre-train a graph-text model; during downstream classification, we explore prompting for the jointly pre-trained model to achieve low-resource classification. Extensive experiments on four real-world datasets demonstrate the strength of G2P2 in zero- and few-shot low-resource text classification tasks
        </div> </ul> <br>



        <label for="Panel49">
        <strong> Multi-Scenario Ranking with Adaptive Feature Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yu+Tian">Yu Tian</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bofang+Li">Bofang Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Si+Chen">Si Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xubin+Li">Xubin Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongbo+Deng">Hongbo Deng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jian+Xu">Jian Xu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Zheng">Bo Zheng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qian+Wang">Qian Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenliang+Li">Chenliang Li</a> (1) </u>  <br>
        1:  Wuhan University, 2:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591736">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multi-Scenario Ranking with Adaptive Feature Learning">Google Scholar</a></div>
        (49)
        <br>
        <b>概要:　</b> 近年、マルチシナリオ学習（Multi-Scenario Learning, MSL）は、異なるシナリオからの転移学習を促進し、データの希薄化を軽減し、維持コストを削減するため、産業界の推薦および検索システムで広く利用されています。これらの取り組みにより、最適なネットワーク構造を探索することで、補助ネットワーク、エキスパートネットワーク、マルチタワーネットワークなど、異なるMSLのパラダイムが生み出されました。直感的には、異なるシナリオがそれぞれの特徴を持ち、ユーザーの意図を異なる形で活性化させることが考えられます。言い換えれば、異なる補助特徴は、異なるシナリオの下で重要性に差が生じる可能性があります。シナリオに応じた形でより識別的な特徴表現を洗練することで、最適なネットワーク構造を高価な検索を経ずに簡単に得られるランク付け性能が向上するでしょう。残念ながら、このシンプルなアイデアは主に見過ごされていますが、実際のシステムでは非常に望まれています。このため、本論文では適応特徴学習を用いたマルチシナリオランク付けフレームワーク（MARIA）を提案します。具体的には、MARIAはネットワークの下部にシナリオのセマンティクスを導入し、より識別的な特徴表現を導き出すように設計されています。この目的のために、MARIAには特徴スケーリング、特徴精錬、および特徴相関モデリングの3つのコンポーネントが設計されています。特徴スケーリングの目的は、シナリオ関連フィールドを強調し、関連性の低いフィールドを抑制することです。次に、特徴精錬では、各フィールドに対して自動的なリファイナー選択サブネットワークを利用し、シナリオに関連する高レベルのセマンティクスを最適なエキスパートにより抽出できるようにします。その後、他のシグナルとして補完的なフィールド間の特徴相関を明示的に導き出します。得られた表現は、最終予測のために追加のシナリオ共有タワーを備えたシンプルなMoE構造に入力されます。2つの大規模な実世界のデータセットでの実験により、製品検索および推薦の両方で、いくつかの最新のベースラインと比較してMARIAの優位性が実証されました。さらに、マルチシナリオのスキームの下での適応特徴学習の合理性も検証されました。また、Alibabaの検索広告プラットフォームでのA/Bテスト結果も、MARIAが実際のプロダクション環境で優れていることを示しています。
        </label>
        <input type="checkbox" id="Panel49" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recently, Multi-Scenario Learning (MSL) is widely used in recommendation and retrieval systems in the industry because it facilitates transfer learning from different scenarios, mitigating data sparsity and reducing maintenance cost. These efforts produce different MSL paradigms by searching more optimal network structure, such as Auxiliary Network, Expert Network, and Multi-Tower Network. It is intuitive that different scenarios could hold their specific characteristics, activating the user's intents quite differently. In other words, different kinds of auxiliary features would bear varying importance under different scenarios. With more discriminative feature representations refined in a scenario-aware manner, better ranking performance could be easily obtained without expensive search for the optimal network structure. Unfortunately, this simple idea is mainly overlooked but much desired in real-world systems. To this end, in this paper, we propose a multi-scenario ranking framework with adaptive feature learning (named MARIA). Specifically, MARIA is devised to inject the scenario semantics in the bottom part of the network to derive more discriminative feature representations. There are three components designed in MARIA for this purpose: feature scaling, feature refinement, and feature correlation modeling. The purpose of feature scaling is to highlight the scenario-relevant fields and also suppress the irrelevant ones. Then, the feature refinement utilizes an automatic refiner selection subnetwork for each feature field, such that the high-level semantics with respect to the scenario can be extracted with the optimal expert. Afterwards, we further explicitly derive the feature correlations across fields as complementary signals. The resultant representations are then fed into a simple MoE structure with an additional scenario-shared tower for final prediction. Experiments on two large-scale real-world datasets demonstrate the superiority of MARIA against several state-of-the-art baselines for both product search and recommendation. Further analysis also validates the rationality of adaptive feature learning under a multi-scenario scheme. Moreover, our A/B test results on the Alibaba search advertising platform also demonstrate that MARIA is superior in production environments.
        </div> </ul> <br>



        <label for="Panel50">
        <strong> LOAM: Improving Long-tail Session-based Recommendation via Niche Walk Augmentation and Tail Session Mixup </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Heeyoon+Yang">Heeyoon Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=YunSeok+Choi">YunSeok Choi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gahyung+Kim">Gahyung Kim</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jee-Hyong+Lee">Jee-Hyong Lee</a> (1) </u>  <br>
        1:  Sungkyunkwan University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591718">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=LOAM: Improving Long-tail Session-based Recommendation via Niche Walk Augmentation and Tail Session Mixup">Google Scholar</a></div>
        (50)
        <br>
        <b>概要:　</b> セッションベースのレコメンデーションは、付随情報を使用せずに匿名セッションに基づいてユーザーの次のアクションを予測することを目的としています。実際のセッションデータセットのほとんどは希薄で、アイテムの分布はロングテールです。ロングテールアイテムの推薦はユーザー満足度を向上させる上で重要な役割を果たしますが、これを考慮に入れた手法はほとんど提案されていません。データの希薄性問題への対応は、主に自己教師あり学習技術とヒューリスティックな拡張に限られており、これによりセッションデータセットの元々の特徴、特にシーケンシャル構造や同時発生の特性が損なわれ、アイテムを削除したりシーケンスを切り取ったりすることによってノイズの多い短いセッションが生成されてしまいます。我々は、ロングテールセッションベースのレコメンデーションを改善するための新しい手法であるLOAM（ニッチウォーク拡張およびテイルセッションミックスアップ）を提案し、人気バイアスを軽減し、ロングテール推薦のパフォーマンスを向上させます。LOAMは、ニッチウォーク拡張（NWA）とテイルセッションミックスアップ（TSM）の二つのモジュールから構成されています。NWAは、前のヒューリスティック手法とは異なり、ロングテール分布を考慮した合成セッションを生成し、元のデータセット内で見られる可能性があるさまざまなアイテムの遷移をレコメンデーションモデルに提示します。これにより、推薦のアイテムカバレッジが向上します。TSMは、表現レベルでセッションを補間することにより、モデルをより一般化し、堅牢にします。これにより、レコメンデーションシステムがニッチアイテムをより多様かつ関連性の高い形で予測することが奨励されます。四つの実世界データセットを用いた大規模な実験を行い、我々の手法が全体のバランスを保ちながらロングテールのパフォーマンスを大幅に向上させることを確認しました。
        </label>
        <input type="checkbox" id="Panel50" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Session-based recommendation aims to predict the user's next action based on anonymous sessions without using side information. Most of the real-world session datasets are sparse and have long-tail item distribution. Although long-tail item recommendation plays a crucial role in improving user satisfaction, only a few methods have been proposed to take the long-tail session recommendation into consideration. Previous works in handling data sparsity problems are mostly limited to self-supervised learning techniques with heuristic augmentation which can ruin the original characteristic of session datasets, sequential and co-occurrences, and make noisier short sessions by dropping items and cropping sequences. We propose a novel method, LOAM, improving LOng-tail session-based recommendation via niche walk Augmentation and tail session Mixup, that alleviates popularity bias and enhances long-tail recommendation performance. LOAM consists of two modules, Niche Walk Augmentation (NWA) and Tail Session Mixup (TSM). NWA can generate synthetic sessions considering long-tail distribution which are likely to be found in original datasets, unlike previous heuristic methods, and expose a recommender model to various item transitions with global information. This improves the item coverage of recommendations. TSM makes the model more generalized and robust by interpolating sessions at the representation level. It encourages the recommender system to predict niche items with more diversity and relevance. We conduct extensive experiments with four real-world datasets and verify that our methods greatly improve tail performance while balancing overall performance.
        </div> </ul> <br>



        <label for="Panel51">
        <strong> Curse of "Low" Dimensionality in Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Naoto+Ohsaka">Naoto Ohsaka</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Riku+Togashi">Riku Togashi</a> (1) </u>  <br>
        1:  CyberAgent <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591659">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Curse of "Low" Dimensionality in Recommender Systems">Google Scholar</a></div>
        (51)
        <br>
        <b>概要:　</b> リコメンダーシステムの品質には、多様性、公平性、堅牢性など、精度を超えたさまざまな側面があります。我々は、リコメンダーシステムにおける多くの一般的な問題が、ユーザーとアイテムの埋め込みの次元数の低さ、特に行列分解などのドットプロダクトモデルを使用する場合に一部起因していると主張します。本研究では、ユーザー/アイテムの埋め込みに十分な次元が必要であることを示唆する実証的証拠を紹介し、多様性、公平性、堅牢性のある推薦を達成します。続いて、ドットプロダクトモデルの表現力に関する理論的解析を提示します。我々の理論的結果は、ドットプロダクトモデルの下で表現可能なランキングの数がアイテム要因の次元によって指数関数的に制約されていることを示しています。実証的には、次元数の低さが人気バイアスに寄与し、人気アイテムとロングテールアイテムのランク位置のギャップを広げることも発見し、この現象に対する理論的な正当性を示しています。
        </label>
        <input type="checkbox" id="Panel51" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Beyond accuracy, there are a variety of aspects to the quality of recommender systems, such as diversity, fairness, and robustness. We argue that many of the prevalent problems in recommender systems are partly due to low-dimensionality of user and item embeddings, particularly when dot-product models, such as matrix factorization, are used. In this study, we showcase empirical evidence suggesting the necessity of sufficient dimensionality for user/item embeddings to achieve diverse, fair, and robust recommendation. We then present theoretical analyses of the expressive power of dot-product models. Our theoretical results demonstrate that the number of possible rankings expressible under dot-product models is exponentially bounded by the dimension of item factors. We empirically found that the low-dimensionality contributes to a popularity bias, widening the gap between the rank positions of popular and long-tail items; we also give a theoretical justification for this phenomenon.
        </div> </ul> <br>



        <label for="Panel52">
        <strong> Beyond Two-Tower Matching: Learning Sparse Retrievable Cross-Interactions for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liangcai+Su">Liangcai Su</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fan+Yan">Fan Yan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jieming+Zhu">Jieming Zhu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xi+Xiao">Xi Xiao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haoyi+Duan">Haoyi Duan</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhou+Zhao">Zhou Zhao</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenhua+Dong">Zhenhua Dong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruiming+Tang">Ruiming Tang</a> (2) </u>  <br>
        1:  Shenzhen International Graduate School, 2:  Huawei Noah's Ark Lab, 3:  Zhejiang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591643">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Beyond Two-Tower Matching: Learning Sparse Retrievable Cross-Interactions for Recommendation">Google Scholar</a></div>
        (52)
        <br>
        <b>概要:　</b> 二塔モデルは推奨のための一般的なマッチングフレームワークであり、工業用途で広く展開されています。二塔マッチングの成功は、多数のアイテムの中から効率的に検索できる点にあります。これは、アイテムタワーが事前に計算され、高速な近似最近傍（ANN）検索に使用されるためです。しかし、二塔モデルには二つの主な課題があります。ひとつは特徴量の相互作用能力が限定されていること、もうひとつはオンラインサービングにおいて精度が低下することです。既存のアプローチは、新しい後期相互作用を設計しようとしますが、依然として複雑な特徴量の相互作用をサポートできないか、検索効率を損ないます。これらの課題に対処するために、複雑な特徴量の相互作用と効率的な検索の両方をサポートする新しいマッチングパラダイム「SparCode」を提案します。具体的には、細粒度のクエリ-アイテム相互作用をモデル化するための全対全相互作用モジュールを導入します。加えて、効果的かつ効率的なモデル推論を実現するために、モデルと共同でトレーニングされた離散コードベースのスパース反転索引を設計しました。公開されているベンチマークデータセットを用いた多くの実験で、このフレームワークの優位性を示しました。その結果、SparCodeは候補アイテムのマッチング精度を大幅に向上させる一方で、二塔モデルと同じレベルの検索効率を維持できることが明らかになりました。
        </label>
        <input type="checkbox" id="Panel52" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Two-tower models are a prevalent matching framework for recommendation, which have been widely deployed in industrial applications. The success of two-tower matching attributes to its efficiency in retrieval among a large number of items, since the item tower can be precomputed and used for fast Approximate Nearest Neighbor (ANN) search. However, it suffers two main challenges, including limited feature interaction capability and reduced accuracy in online serving. Existing approaches attempt to design novel late interactions instead of dot products, but they still fail to support complex feature interactions or lose retrieval efficiency. To address these challenges, we propose a new matching paradigm named SparCode, which supports not only sophisticated feature interactions but also efficient retrieval. Specifically, SparCode introduces an all-to-all interaction module to model fine-grained query-item interactions. Besides, we design a discrete code-based sparse inverted index jointly trained with the model to achieve effective and efficient model inference. Extensive experiments have been conducted on open benchmark datasets to demonstrate the superiority of our framework. The results show that SparCode significantly improves the accuracy of candidate item matching while retaining the same level of retrieval efficiency with two-tower models.
        </div> </ul> <br>



        <label for="Panel53">
        <strong> An Offline Metric for the Debiasedness of Click Models </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Romain+Deffayet">Romain Deffayet</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philipp+Hager">Philipp Hager</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jean-Michel+Renders">Jean-Michel Renders</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (4) </u>  <br>
        1:  Naver Labs Europe & University of Amsterdam, 2:  University of Amsterdam & Booking.com, 3:  Naver Labs Europe, 4:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591639">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=An Offline Metric for the Debiasedness of Click Models">Google Scholar</a></div>
        (53)
        <br>
        <b>概要:　</b> ユーザーのクリックから学習する際のよく知られた問題として、データに内在するバイアス（位置バイアスや信頼性バイアス）が挙げられます。クリックモデルは、例えばウェブ検索におけるドキュメントの関連性を抽出したり、カウンターファクトラル・ランク学習や広告配置、公平なランキングなどの下流アプリケーションのためにクリックバイアスを推定するための一般的な手法です。最近の研究では、コミュニティ内での現在の評価手法が、ランキング分布が訓練分布と異なる（すなわち、共変量シフト下での）下流タスクに対してうまく一般化できるかどうかを保証できないことが示されています。本研究では、共変量シフトに対する頑健性の欠如を検出するための条件付き独立性検定に基づく評価指標を提案します。また、偏り補正の概念とそれを測定するための指標を導入します。偏り補正が、偏りのない一貫した関連性スコアの回復と、共変量シフト下でのクリック予測の不変性を確保するための必要条件であることを証明します。広範な半合成実験において、提案する評価指標が共変量シフト下でのクリックモデルの下流パフォーマンスを予測するのに役立ち、オフポリシーモデル選択の設定において有用であることを示します。
        </label>
        <input type="checkbox" id="Panel53" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> A well-known problem when learning from user clicks are inherent biases prevalent in the data, such as position or trust bias. Click models are a common method for extracting information from user clicks, such as document relevance in web search, or to estimate click biases for downstream applications such as counterfactual learning-to-rank, ad placement, or fair ranking. Recent work shows that the current evaluation practices in the community fail to guarantee that a well-performing click model generalizes well to downstream tasks in which the ranking distribution differs from the training distribution, i.e., under covariate shift. In this work, we propose an evaluation metric based on conditional independence testing to detect a lack of robustness to covariate shift in click models. We introduce the concept of debiasedness and a metric for measuring it. We prove that debiasedness is a necessary condition for recovering unbiased and consistent relevance scores and for the invariance of click prediction under covariate shift. In extensive semi-synthetic experiments, we show that our proposed metric helps to predict the downstream performance of click models under covariate shift and is useful in an off-policy model selection setting.
        </div> </ul> <br>



        <label for="Panel54">
        <strong> Do-GOOD: Towards Distribution Shift Evaluation for Pre-Trained Visual Document Understanding Models </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiabang+He">Jiabang He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Hu">Yi Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Wang">Lei Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xing+Xu">Xing Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ning+Liu">Ning Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hui+Liu">Hui Liu</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Heng+Tao+Shen">Heng Tao Shen</a> (5) </u>  <br>
        1:  University of Electronic Science and Technology of China, 2:  Singapore Management University, 3:  Beijing Forestry University, 4:  Beijing Rongda Technology Co., 5:  University of Electronic Science and Technology of China & Peng Cheng Laboratory <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591670">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Do-GOOD: Towards Distribution Shift Evaluation for Pre-Trained Visual Document Understanding Models">Google Scholar</a></div>
        (54)
        <br>
        <b>概要:　</b> 最近、視覚文書理解（VDU）のための多数の事前学習技術が、さまざまな文書タスクにおいて大幅な性能向上を示しています。しかし、これらの事前学習されたVDUモデルは、テストデータの分布がトレーニングデータの分布と異なる場合において、継続的な成功を保証することはできません。本研究では、既存の事前学習VDUモデルがさまざまな分布シフトに対してどの程度ロバストであるかを調査するために、まず、文書画像関連タスクに特化した詳細な分析のためのOOD（分布外）ベンチマーク「Do-GOOD」を開発しました。Do-GOODベンチマークは、異なる分布シフトを引き起こす基本メカニズムを定義しており、文書情報抽出、分類、質疑応答など、3つのVDU関連タスクをカバーする9つのOODデータセットを含んでいます。次に、最新の5つの事前学習VDUモデルおよび2つの典型的なOOD一般化アルゴリズムをこれらのOODデータセットで評価し、詳細な分析を行いました。実験結果は、文書画像においてID（分布内）設定とOOD（分布外）設定の間に顕著な性能ギャップが存在し、分布シフトの詳細な分析が既存の事前学習VDUモデルおよびOOD一般化アルゴリズムの脆弱性を明らかにすることを示しています。私たちのDo-GOODベンチマークのコードとデータセットは、https://github.com/MAEHCM/Do-GOOD で入手できます。
        </label>
        <input type="checkbox" id="Panel54" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Numerous pre-training techniques for visual document understanding (VDU) have recently shown substantial improvements in performance across a wide range of document tasks. However, these pre-trained VDU models cannot guarantee continued success when the distribution of test data differs from the distribution of training data. In this paper, to investigate how robust existing pre-trained VDU models are to various distribution shifts, we first develop an out-of-distribution (OOD) benchmark termed Do-GOOD for the fine-Grained analysis on Document image-related tasks specifically. The Do-GOOD benchmark defines the underlying mechanisms that result in different distribution shifts and contains 9 OOD datasets covering 3 VDU related tasks, e.g., document information extraction, classification and question answering. We then evaluate the robustness and perform a fine-grained analysis of 5 latest VDU pre-trained models and 2 typical OOD generalization algorithms on these OOD datasets. Results from the experiments demonstrate that there is a significant performance gap between the in-distribution (ID) and OOD settings for document images, and that fine-grained analysis of distribution shifts can reveal the brittle nature of existing pre-trained VDU models and OOD generalization algorithms. The code and datasets for our Do-GOOD benchmark can be found at https://github.com/MAEHCM/Do-GOOD.
        </div> </ul> <br>



        <label for="Panel55">
        <strong> Smooth Operators for Effective Systematic Review Queries </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Harrisen+Scells">Harrisen Scells</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ferdinand+Schlatt">Ferdinand Schlatt</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Martin+Potthast">Martin Potthast</a> (3) </u>  <br>
        1:  Leipzig University, 2:  Friedrich-Schiller-Universität, 3:  Leipzig University & ScaDS.AI <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591768">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Smooth Operators for Effective Systematic Review Queries">Google Scholar</a></div>
        (55)
        <br>
        <b>概要:　</b> 効果的な検索クエリは、メディカルシステマティックレビューの時間とコストを最小限に抑えるために非常に重要です。回収されたすべての文書は関連性について評価される必要があります。エキスパートの司書によって作成されたブールクエリは、システマティックレビューの標準です。これらは再現性と検証可能な回収を保証し、フリーテキストクエリよりも多くのコントロールを提供します。しかし、ブールクエリの結果セットはランキングされておらず、厳密なブール演算子のために制御が難しいです。私たちは、これらの問題に対処するために、既存のブール演算子と互換性があり、さらに拡張する一連のスムーズ演算子を定式化することで単一の統一検索モデルを提案します。私たちのスムーズ演算子は、ブール検索モデルの以前の拡張のいくつかの欠点を克服します。特に、私たちの演算子は基礎となるランク付け関数に依存しないため、完全一致のランカーと大規模な言語モデルランカーを同じクエリ内で組み合わせることができます。ブール演算子を同等または類似のスムーズ演算子に置き換えると、クエリの有効性が向上することがよくあります。これらの演算子の特性により、精度または再現率に応じてクエリを調整することが直感的になり、文書の回収方法に関してより多くのコントロールが可能になります。この追加のコントロールにより、クエリがより効果的になり、システマティックレビューのコストが削減されます。
        </label>
        <input type="checkbox" id="Panel55" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Effective queries are crucial to minimising the time and cost of medical systematic reviews, as all retrieved documents must be judged for relevance. Boolean queries, developed by expert librarians, are the standard for systematic reviews. They guarantee reproducible and verifiable retrieval and more control than free-text queries. However, the result sets of Boolean queries are unranked and difficult to control due to the strict Boolean operators. We address these problems in a single unified retrieval model by formulating a class of smooth operators that are compatible with and extend existing Boolean operators. Our smooth operators overcome several shortcomings of previous extensions of the Boolean retrieval model. In particular, our operators are independent of the underlying ranking function, so that exact-match and large language model rankers can be combined in the same query. We found that replacing Boolean operators with equivalent or similar smooth operators often improves the effectiveness of queries. Their properties make tuning a query to precision or recall intuitive and allow greater control over how documents are retrieved. This additional control leads to more effective queries and reduces the cost of systematic reviews.
        </div> </ul> <br>



        <label for="Panel56">
        <strong> Decoupled Hyperbolic Graph Attention Network for Cross-domain Named Entity Recognition </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingyun+Xu">Jingyun Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Cai">Yi Cai</a> (1) </u>  <br>
        1:  South China University of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591662">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Decoupled Hyperbolic Graph Attention Network for Cross-domain Named Entity Recognition">Google Scholar</a></div>
        (56)
        <br>
        <b>概要:　</b> 大規模なラベル付きデータの不足に対処するため、クロスドメイン固有表現認識（クロスドメインNER）が注目を集めています。最近の研究では、NERを2つの別個のタスク（すなわち、エンティティスパン検出とエンティティタイプ分類）に分解することで、クロスドメイン転送の複雑さを減少させることに焦点を当てています。有望な結果が得られているものの、改善の余地はまだ存在します。特に、エンティティスパン検出とエンティティタイプ分類にそれぞれ重要な、豊富なドメイン共有の構文情報と意味情報がまだ十分に活用されていません。これらの課題に対処するために、我々はこの2種類の情報をエンコードするためにグラフアテンションネットワーク（GATs）を適用することを提案します。さらに、GATsは主にユークリッド空間で動作するため、高品質な単語表現を学習する際に単語間の隠れた階層関係を捉えられない可能性があることを踏まえ、単語を双曲空間に埋め込むことを提案します。最後に、クロスドメインNERのための分離双曲グラフアテンションネットワーク（DH-GAT）を導入します。10のドメインペアでの実証結果は、DH-GATがいくつかの標準的な指標で最先端の性能を達成することを示しており、各コンポーネントの有効性をよりよく理解するための追加分析も行われています。
        </label>
        <input type="checkbox" id="Panel56" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> To address the scarcity of massive labeled data, cross-domain named entity recognition (cross-domain NER) attracts increasing attention. Recent studies focus on decomposing NER into two separate tasks (i.e., entity span detection and entity type classification) to reduce the complexity of the cross-domain transfer. Despite the promising results, there still exists room for improvement. In particular, the rich domain-shared syntactic and semantic information, which are respectively important for entity span detection and entity type classification, are still underutilized. In light of these two challenges, we propose applying graph attention networks (GATs) to encode the above two kinds of information. Moreover, considering that GATs mainly operate in the Euclidean space, which may fail to capture the latent hierarchical relations among words for learning high-quality word representations, we further propose to embed words into Hyperbolic spaces. Finally, a decouple hyperbolic graph attention network (DH-GAT) is introduced for cross-domain NER. Empirical results on 10 domain pairs show that DH-GAT achieves state-of-the-art performance on several standard metrics, and further analyses are presented to better understand each component's effectiveness.
        </div> </ul> <br>



        <label for="Panel57">
        <strong> Continual Learning on Dynamic Graphs via Parameter Isolation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peiyan+Zhang">Peiyan Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuchen+Yan">Yuchen Yan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaozhuo+Li">Chaozhuo Li</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Senzhang+Wang">Senzhang Wang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xing+Xie">Xing Xie</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guojie+Song">Guojie Song</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sunghun+Kim">Sunghun Kim</a> (5) </u>  <br>
        1:  Hong Kong University of Science and Technology, 2:  School of Intelligence Science and Technology, 3:  Microsoft Research Asia, 4:  School of Computer Science and Engineering, 5:  Hong Kong University of Science and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591652">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Continual Learning on Dynamic Graphs via Parameter Isolation">Google Scholar</a></div>
        (57)
        <br>
        <b>概要:　</b> 多くの現実世界のグラフ学習タスクでは、新しいノードやエッジが出現する動的グラフを扱う必要があります。動的グラフ学習法は、新しいグラフの更新によって以前の知識が上書きされる「カタストロフィックフォーゲッティング」問題に直面することがよくあります。この問題を軽減するために、継続的なグラフ学習法が提案されています。しかし、既存の継続的グラフ学習法は、同じサイズの固定されたパラメータセットを用いて新しいパターンを学習し、古いパターンを維持することを目指しているため、両者の目的の間で根本的なトレードオフに直面します。本研究では、このトレードオフをパラメータの分離と拡張によって回避する、動的グラフにおける継続学習のための「パラメータ分離GNN（PI-GNN）」を提案します。我々の動機は、異なるパラメータが異なるグラフパターンの学習に寄与するという点にあります。この考えに基づき、我々は新たに出現するグラフパターンを継続的に学習するためにモデルパラメータを拡張します。一方で、影響を受けないパターンに対する知識を効果的に保存するために、最適化を通じてそれらに対応するパラメータを見つけ、上書きされないように固定します。8つの現実世界のデータセットに対する実験により、最先端のベースラインと比較してPI-GNNの有効性が裏付けられました。
        </label>
        <input type="checkbox" id="Panel57" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Many real-world graph learning tasks require handling dynamic graphs where new nodes and edges emerge. Dynamic graph learning methods commonly suffer from the catastrophic forgetting problem, where knowledge learned for previous graphs is overwritten by updates for new graphs. To alleviate the problem, continual graph learning methods are proposed. However, existing continual graph learning methods aim to learn new patterns and maintain old ones with the same set of parameters of fixed size, and thus face a fundamental tradeoff between both goals. In this paper, we propose Parameter Isolation GNN (PI-GNN) for continual learning on dynamic graphs that circumvents the tradeoff via parameter isolation and expansion. Our motivation lies in that different parameters contribute to learning different graph patterns. Based on the idea, we expand model parameters to continually learn emerging graph patterns. Meanwhile, to effectively preserve knowledge for unaffected patterns, we find parameters that correspond to them via optimization and freeze them to prevent them from being rewritten. Experiments on eight real-world datasets corroborate the effectiveness of PI-GNN compared to state-of-the-art baselines.
        </div> </ul> <br>



        <label for="Panel58">
        <strong> Subgraph Search over Neural-Symbolic Graphs </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ye+Yuan">Ye Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Delong+Ma">Delong Ma</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anbiao+Wu">Anbiao Wu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianbin+Qin">Jianbin Qin</a> (3) </u>  <br>
        1:  Beijing Institute of Technology, 2:  Northeastern University, 3:  Shenzhen University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591773">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Subgraph Search over Neural-Symbolic Graphs">Google Scholar</a></div>
        (58)
        <br>
        <b>概要:　</b> 本論文では、各ノードにコンテンツ及び構造埋め込みを追加することで、従来のグラフデータを拡張するニューラル-シンボリックグラフデータベース（NSGD）を提案します。コンテンツ埋め込みは非構造化データ（例: 画像、動画、テキストなど）を表現でき、構造埋め込みは不完全なグラフに対処するために用いることができます。非構造化データとグラフノードをこれらの埋め込みに変換するために、機械学習モデル（例: ディープラーニング）を活用することが可能です。NSGDは、ソーシャルメディアネットワークやマルチモーダル知識グラフなどにおけるオンライン推薦や自然言語質問応答など、幅広い応用をサポートします。典型的なグラフ検索として、大規模なNSGDにおける神経-シンボリックサブグラフマッチング（NSMatch）と呼ばれる新しいランキング検索機能を含むサブグラフ検索を研究します。具体的には、NSMatchを効率的に処理するための一般的なアルゴリズムフレームワークを開発しました。実際のマルチモーダルグラフを用いて、NSMatchの有効性、スケーラビリティ、および効率性を実験的に検証しました。
        </label>
        <input type="checkbox" id="Panel58" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this paper, we propose neural-symbolic graph databases (NSGDs) that extends traditional graph data with content and structural embeddings in every node. The content embeddings can represent unstructured data (e.g., images, videos, and texts), while structural embeddings can be used to deal with incomplete graphs. We can advocate machine learning models (e.g., deep learning) to transform unstructured data and graph nodes to these embeddings. NSGDs can support a wide range of applications (e.g., online recommendation and natural language question answering) in social-media networks, multi-modal knowledge graphs and etc. As a typical search over graphs, we study subgraph search over a large NSGD, called neural-symbolic subgraph matching (NSMatch) that includes a novel ranking search function. Specifically, we develop a general algorithmic framework to process NSMatch efficiently. Using real-life multi-modal graphs, we experimentally verify the effectiveness, scalability and efficiency of NSMatch.
        </div> </ul> <br>



        <label for="Panel59">
        <strong> StreamE: Learning to Update Representations for Temporal Knowledge Graphs in Streaming Scenarios </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiasheng+Zhang">Jiasheng Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jie+Shao">Jie Shao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bin+Cui">Bin Cui</a> (3) </u>  <br>
        1:  University of Electronic Science and Technology of China, 2:  Shenzhen Institute for Advanced Study, 3:  Peking University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591772">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=StreamE: Learning to Update Representations for Temporal Knowledge Graphs in Streaming Scenarios">Google Scholar</a></div>
        (59)
        <br>
        <b>概要:　</b> 時系列知識グラフ (TKGs) のための表現学習は基本的な課題です。既存のほとんどの方法は、TKGを静的なスナップショットのシーケンスと見なし、前のスナップショットをたどることで表現を学習しています。しかし、新しい知識はストリームとしてTKGに継続的に加わることができます。これらの方法は新しいエンティティの処理ができなかったり、リアルタイムで表現を更新できなかったりするため、ストリーミングシナリオに適応できません。本論文では、ストリーミングシナリオでのTKG表現の効率的な生成を目指した軽量フレームワークであるStreamEを提案します。パラメータサイズを減少させるために、StreamEではエンティティ表現がモデルのトレーニングから切り離され、エンティティの過去情報を保存するメモリモジュールとして機能します。効率的な更新と生成を達成するために、表現生成プロセスはStreamEで二つの関数として分離されます。更新関数は新たに到着した知識に基づいてエンティティ表現を漸進的に更新するよう学習され、読み取り関数はエンティティ表現の将来の意味を予測するように学習されます。更新関数は再帰的なモデリングパラダイムを避け、効率を高め、読み取り関数は複数の意味変化特性を考慮します。また、二つの時間的正則化を用いた共同トレーニング戦略を提案し、フレームワークを効果的に最適化します。実験結果は、StreamEが基準方法よりも100倍高速な推論、25倍高速なトレーニング、そしてパラメータサイズが1/5でより良い性能を達成することを示し、その優位性を裏付けています。コードはhttps://github.com/zjs123/StreamEで入手可能です。
        </label>
        <input type="checkbox" id="Panel59" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Learning representations for temporal knowledge graphs (TKGs) is a fundamental task. Most existing methods regard TKG as a sequence of static snapshots and recurrently learn representations by retracing the previous snapshots. However, new knowledge can be continuously accrued to TKGs as streams. These methods either cannot handle new entities or fail to update representations in real time, making them unfeasible to adapt to the streaming scenarios. In this paper, we propose a lightweight framework called StreamE towards the efficient generation of TKG representations in streaming scenarios. To reduce the parameter size, entity representations in StreamE are decoupled from the model training to serve as the memory module to store the historical information of entities. To achieve efficient update and generation, the process of generating representations is decoupled as two functions in StreamE. An update function is learned to incrementally update entity representations based on the newly-arrived knowledge and a read function is learned to predict the future semantics of entity representations. The update function avoids the recurrent modeling paradigm and thus gains high efficiency while the read function considers multiple semantic change properties. We further propose a joint training strategy with two temporal regularizations to effectively optimize the framework. Experimental results show that StreamE can achieve better performance than baseline methods with 100x faster in inference, 25x faster in training, and only 1/5 parameter size, which demonstrates its superiority. Code is available at https://github.com/zjs123/StreamE.
        </div> </ul> <br>



        <label for="Panel60">
        <strong> Exploiting Simulated User Feedback for Conversational Search: Ranking, Rewriting, and Beyond </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Paul+Owoicho">Paul Owoicho</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ivan+Sekulic">Ivan Sekulic</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mohammad+Aliannejadi">Mohammad Aliannejadi</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jeffrey+Dalton">Jeffrey Dalton</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fabio+Crestani">Fabio Crestani</a> (2) </u>  <br>
        1:  University of Glasgow, 2:  Università della Svizzera italiana, 3:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591683">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Exploiting Simulated User Feedback for Conversational Search: Ranking, Rewriting, and Beyond">Google Scholar</a></div>
        (60)
        <br>
        <b>概要:　</b> 本研究は、混合イニシアチブ会話型検索（CS）システムにおけるユーザーのフィードバックを評価するためのさまざまな方法を探ることを目的としています。CSシステムは多方面にわたり著しい進歩を享受していますが、最近の研究ではユーザーからのフィードバックをうまく取り入れることに失敗しています。その主な理由の一つは、システムとユーザーの対話データの欠如です。この問題に対処するために、さまざまな混合イニシアチブCSシステムとの多ターンインタラクションのためのユーザーシミュレータベースのフレームワークを提案します。具体的には、情報ニーズの記述で初期化された後、システムの応答にフィードバックを提供し、また潜在的な明確化質問に答える能力を持つユーザーシミュレータ「ConvSim」を開発しました。最先端のパッセージ検索やニューラル再ランキングモデルを対象とした多様な実験では、ユーザーフィードバックの効果的な利用がnDCG@3において16％の検索性能向上に繋がることを示しました。さらに、フィードバックラウンドの数が増えるごとに一貫した改善が見られ、3ラウンド後のnDCG@3において35％の相対的な改善が見られました。これは、特定のフィードバック処理モジュールの開発における研究のギャップを示しており、CSの大きな進歩の可能性を開きます。さらに、このテーマにおける研究をサポートするために、確立されたCSデータセットに基づいたシステム-シミュレータインタラクションの3万以上のトランスクリプトを公開します。
        </label>
        <input type="checkbox" id="Panel60" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This research aims to explore various methods for assessing user feedback in mixed-initiative conversational search (CS ) systems. While CS systems enjoy profuse advancements across multiple aspects, recent research fails to successfully incorporate feedback from the users. One of the main reasons for that is the lack of system-user conversational interaction data. To this end, we propose a user simulator-based framework for multi-turn interactions with a variety of mixed-initiative CS systems. Specifically, we develop a user simulator, dubbed ConvSim, that, once initialized with an information need description, is capable of providing feedback to system's responses, as well as answering potential clarifying questions. Our experiments on a wide variety of state-of-the-art passage retrieval and neural re-ranking models show that effective utilization of user feedback can lead to 16% retrieval performance increase in terms of nDCG@3. Moreover, we observe consistent improvements as the number of feedback rounds increases (35% relative improvement in terms of nDCG@3 after three rounds). This points to a research gap in the development of specific feedback processing modules and opens a potential for significant advancements in CS. To support further research in the topic, we release over 30 000 transcripts of system-simulator interactions based on well-established CS datasets.
        </div> </ul> <br>



        <label for="Panel61">
        <strong> Explainable Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philipp+Christmann">Philipp Christmann</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rishiraj+Saha+Roy">Rishiraj Saha Roy</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gerhard+Weikum">Gerhard Weikum</a> (1) </u>  <br>
        1:  Max Planck Institute for Informatics <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591682">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Explainable Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks">Google Scholar</a></div>
        (61)
        <br>
        <b>概要:　</b> 対話型質問応答において、ユーザーは不完全な文脈を含む一連の発話を通じて情報ニーズを表現します。通常の対話型質問応答（ConvQA）手法は、知識ベース（KB）、テキストコーパス、または表のセットといった単一の情報源のみに依存するため、複数の情報源から得られる回答の網羅性や冗長性を享受できません。私たちの手法EXPLAIGNNは、ユーザーに理解しやすい回答の説明を提供しつつ、複数の情報源からの情報を統合することで、これらの制約を克服します。この手法では、知識ベース、テキストコーパス、ウェブテーブル、インフォボックスから取得したエンティティと証拠スニペットを用いて異種グラフを構築します。この大規模なグラフは、質問レベルのアテンションを組み込んだグラフニューラルネットワークを通じて反復的に縮小され、最良の回答とその説明が抽出されます。実験により、EXPLAIGNNが最新のベースラインよりも性能を向上させることが示されました。またユーザー調査により、導出された回答がエンドユーザーに理解可能であることが実証されました。
        </label>
        <input type="checkbox" id="Panel61" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In conversational question answering, users express their information needs through a series of utterances with incomplete context. Typical ConvQA methods rely on a single source (a knowledge base (KB), or a text corpus, or a set of tables), thus being unable to benefit from increased answer coverage and redundancy of multiple sources. Our method EXPLAIGNN overcomes these limitations by integrating information from a mixture of sources with user-comprehensible explanations for answers. It constructs a heterogeneous graph from entities and evidence snippets retrieved from a KB, a text corpus, web tables, and infoboxes. This large graph is then iteratively reduced via graph neural networks that incorporate question-level attention, until the best answers and their explanations are distilled. Experiments show that EXPLAIGNN improves performance over state-of-the-art baselines. A user study demonstrates that derived answers are understandable by end users.
        </div> </ul> <br>



        <label for="Panel62">
        <strong> Multi-view Hypergraph Contrastive Policy Learning for Conversational Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sen+Zhao">Sen Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Wei">Wei Wei</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xian-Ling+Mao">Xian-Ling Mao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuai+Zhu">Shuai Zhu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Minghui+Yang">Minghui Yang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zujie+Wen">Zujie Wen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dangyang+Chen">Dangyang Chen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Feida+Zhu">Feida Zhu</a> (4) </u>  <br>
        1:  Huazhong University of Science and Technology, 2:  Beijing Institute of Technology, 3:  Ant Group, 4:  Singapore Management University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591737">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multi-view Hypergraph Contrastive Policy Learning for Conversational Recommendation">Google Scholar</a></div>
        (62)
        <br>
        <b>概要:　</b> 会話型レコメンデーションシステム（CRS）は、ユーザーの好みを対話的に取得し、それに応じてアイテムを推薦することを目的としています。CRSにおいて、動的なユーザーの好みを正確に学習することは極めて重要です。これまでの研究では、対話とアイテム知識からユーザーの好みをペアワイズで学習する一方で、CRSにおける関係性の要素が多様であることを大きく無視していました。具体的には、ユーザーは特定の属性を満たすアイテムを好む/嫌う（Like/Dislikeビュー）ということです。さらに、社会的影響もユーザーのアイテムに対する好みに影響を与える重要な要素ですが（Socialビュー）、これもまたこれまでのCRSの研究ではほとんど無視されていました。これら三つのビューから得られるユーザーの好みは、本質的に異なるが全体として相関しています。同じビューからのユーザーの好みは、異なるビューからの好みよりも類似しているべきです。具体的には、Likeビューの好みはSocialビューと類似しており、Dislikeビューとは異なるべきです。これを踏まえ、我々は新しいモデル「Multi-view Hypergraph Contrastive Policy Learning（MHCPL）」を提案します。具体的には、MHCPLは対話履歴に応じて有用な社会的情報を適時に選択し、異なるビューからの三種類の多重関係で動的ハイパーグラフを構築します。各ビュー内の多重関係は、対話の生成順序に従って連続的に接続されます。階層型ハイパーグラフニューラルネットワークを提案し、動的ハイパーグラフのグラフィカルおよび時系列構造の情報を統合してユーザーの好みを学習します。また、クロスビューコントラスト学習モジュールを提案し、異なるビューからのユーザーの好みの固有の特性と相関を維持します。ベンチマークデータセットで実施された大規模な実験により、MHCPLが最先端の手法を上回る性能を示すことが確認されました。
        </label>
        <input type="checkbox" id="Panel62" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Conversational recommendation systems (CRS) aim to interactively acquire user preferences and accordingly recommend items to users. Accurately learning the dynamic user preferences is of crucial importance for CRS. Previous works learn the user preferences with pairwise relations from the interactive conversation and item knowledge, while largely ignoring the fact that factors for a relationship in CRS are multiplex. Specifically, the user likes/dislikes the items that satisfy some attributes (Like/Dislike view). Moreover social influence is another important factor that affects user preference towards the item (Social view), while is largely ignored by previous works in CRS. The user preferences from these three views are inherently different but also correlated as a whole. The user preferences from the same views should be more similar than that from different views. The user preferences from Like View should be similar to Social View while different from Dislike View. To this end, we propose a novel model, namely Multi-view Hypergraph Contrastive Policy Learning (MHCPL). Specifically, MHCPL timely chooses useful social information according to the interactive history and builds a dynamic hypergraph with three types of multiplex relations from different views. The multiplex relations in each view are successively connected according to their generation order in the interactive conversation. A hierarchical hypergraph neural network is proposed to learn user preferences by integrating information of the graphical and sequential structure from the dynamic hypergraph. A cross-view contrastive learning module is proposed to maintain the inherent characteristics and the correlations of user preferences from different views. Extensive experiments conducted on benchmark datasets demonstrate that MHCPL outperforms the state-of-the-art methods.
        </div> </ul> <br>



        <label for="Panel63">
        <strong> An Effective, Efficient, and Scalable Confidence-based Instance Selection Framework for Transformer-Based Text Classification </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Washington+Cunha">Washington Cunha</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Celso+França">Celso França</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guilherme+Fonseca">Guilherme Fonseca</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Leonardo+Rocha">Leonardo Rocha</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Marcos+André+Gonçalves">Marcos André Gonçalves</a> (1) </u>  <br>
        1:  Federal University of Minas Gerais, 2:  Federal University of São João del Rei <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591638">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=An Effective, Efficient, and Scalable Confidence-based Instance Selection Framework for Transformer-Based Text Classification">Google Scholar</a></div>
        (63)
        <br>
        <b>概要:　</b> Transformerベースのディープラーニングは、多くの自然言語処理（NLP）および情報検索（IR）タスクにおいて最先端の技術となっています。しかし、特定のタスクに対してこれらのTransformerをファインチューニングすることは、特にデータ量が増え続けるシナリオでは、再トレーニングの必要性や予算の制約もあり、計算コストおよび財政的コストがかかり、さらにエネルギー消費も大きくなります。本論文では、インスタンス選択（IS）に注目します。これは、トレーニング用の最も代表的な文書を選択することに焦点を当てた一連の手法であり、分類の効果を維持（または向上させ）つつ、トレーニング（またはファインチューニング）時間の総量を削減することを目指しています。私たちはE2SC-IS（Effective, Efficient, and Scalable Confidence-Based IS）を提案します。これは二段階のフレームワークで、特にTransformerと大規模データに焦点を当てています。E2SC-ISは、スケーラブルで高速、かつキャリブレーションされた弱い分類器に基づいて、各インスタンスがトレーニングセットから削除される確率を推定します。また、E2SC-ISは反復的なヒューリスティクスを活用して、ほぼ最適な削減率を推定します。我々のソリューションは、全てのデータセットにおいて効果を維持しつつ、トレーニングセットを平均29％削減し、最大で70％の高速化を達成し、非常に大規模なデータセットに対してもスケーリング可能です（これはベースライン手法にはできないことです）。
        </label>
        <input type="checkbox" id="Panel63" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Transformer-based deep learning is currently the state-of-the-art in many NLP and IR tasks. However, fine-tuning such Transformers for specific tasks, especially in scenarios of ever-expanding volumes of data with constant re-training requirements and budget constraints, is costly (computationally and financially) and energy-consuming. In this paper, we focus on Instance Selection (IS) - a set of methods focused on selecting the most representative documents for training, aimed at maintaining (or improving) classification effectiveness while reducing total time for training (or fine-tuning). We propose E2SC-IS -- Effective, Efficient, and Scalable Confidence-Based IS -- a two-step framework with a particular focus on Transformers and large datasets. E2SC-IS estimates the probability of each instance being removed from the training set based on scalable, fast, and calibrated weak classifiers. E2SC-IS also exploits iterative heuristics to estimate a near-optimal reduction rate. Our solution can reduce the training sets by 29% on average while maintaining the effectiveness in all datasets, with speedup gains up to 70%, scaling for very large datasets (something that the baselines cannot do).
        </div> </ul> <br>



        <label for="Panel64">
        <strong> EDIndex: Enabling Fast Data Queries in Edge Storage Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiang+He">Qiang He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siyu+Tan">Siyu Tan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Feifei+Chen">Feifei Chen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaolong+Xu">Xiaolong Xu</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lianyong+Qi">Lianyong Qi</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinhong+Hei">Xinhong Hei</a> (6), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hai+Jin">Hai Jin</a> (7), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yun+Yang">Yun Yang</a> (8) </u>  <br>
        1:  Huazhong University of Science and Technology & Swinburne University of Technology, 2:  Southeast University, 3:  Deakin University, 4:  Nanjing University of Information Science and Technology, 5:  China University of Petroleum, 6:  Xi'an University of Technology, 7:  Huazhong University of Science and Technology, 8:  Swinburne University of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591676">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=EDIndex: Enabling Fast Data Queries in Edge Storage Systems">Google Scholar</a></div>
        (64)
        <br>
        <b>概要:　</b> エッジストレージシステムでは、人気のあるデータをエッジサーバーに保存することで、近隣のユーザーが低遅延でデータを取得することができます。しかし、ストレージ容量が限られているため、エッジサーバーはユーザーのデータ要求を協調して処理する必要があります。データを取得するためには、システム内のどのエッジサーバーが要求されたデータを持っているかを特定することが不可欠です。本論文では、このエッジデータクエリ（EDQ）問題を初めて研究し、高速なデータクエリを可能にする分散エッジデータインデックスシステムであるEDIndexを提案します。まず、エッジデータクエリを容易にするための新しいインデックス構造であるカウントブルームフィルタ（CBF）ツリーを導入します。次に、クエリパフォーマンスを向上させるために、EDIndexを階層型カウントブルームフィルタ（HCBF）ツリーという新しいインデックス構造で強化します。EDIndexでは、各エッジサーバーが近隣のエッジサーバーに保存されているデータをインデックス化するHCBFツリーを維持し、エッジ間でのデータ取得を促進します。90台のエッジサーバーで構成されるエッジストレージシステムで行った大規模な実験の結果、EDIndexは1)最先端のエッジインデックスシステムと比較してエッジデータクエリにかかる時間を最大8.8倍短縮し、2)高いクエリ精度で低コストの初期化およびメンテナンスオーバーヘッドで実際に実装可能であることが示されました。
        </label>
        <input type="checkbox" id="Panel64" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In an edge storage system, popular data can be stored on edge servers to enable low-latency data retrieval for nearby users. Suffering from constrained storage capacities, edge servers must process users' data requests collaboratively. For sourcing data, it is essential to find out which edge servers in the system have the requested data. In this paper, we make the first attempt to study this edge data query (EDQ) problem and present EDIndex, a distributed Edge Data Indexing system to enable fast data queries at the edge. First, we introduce a new index structure named Counting Bloom Filter (CBF) tree for facilitating edge data queries. Then, to improve query performance, we enhance EDIndex with a novel index structure named hierarchical Counting Bloom Filter (HCBF) tree. In EDIndex, each edge server maintains an HCBF tree that indexes the data stored on nearby edge servers to facilitate data sourcing between edge servers at the edge. The results of extensive experiments conducted on an edge storage system comprised of 90 edge servers demonstrate that EDIndex 1) takes up to 8.8x less time to answer edge data queries compared with state-of-the-art edge indexing systems; and 2) can be implemented in practice with a high query accuracy at low initialization and maintenance overheads.
        </div> </ul> <br>



        <label for="Panel65">
        <strong> Data-Aware Proxy Hashing for Cross-modal Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rong-Cheng+Tu">Rong-Cheng Tu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xian-Ling+Mao">Xian-Ling Mao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenjin+Ji">Wenjin Ji</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Wei">Wei Wei</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Heyan+Huang">Heyan Huang</a> (1) </u>  <br>
        1:  Beijing Institute of Technology, 2:  Beijing Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591660">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Data-Aware Proxy Hashing for Cross-modal Retrieval">Google Scholar</a></div>
        (65)
        <br>
        <b>概要:　</b> 近年、データのラベル情報を活用してハッシュモデルの訓練を監督する多くのプロキシハッシュコードベースの手法が提案されました。これらの手法は著しい進展を遂げているものの、そのプロキシハッシュコードの生成プロセスは、データセットのクラス情報やデータのラベルに基づくだけで、データ自体を考慮していません。そのため、これらの手法は不適切なプロキシハッシュコードを生成し、ハッシュモデルの検索性能を損なう可能性があります。この問題を解決するために、我々はクロスモーダル検索のための新たなデータ認識型プロキシハッシング（DAPH）を提案します。具体的には、提案手法はまず、データポイント、データのラベルベクトル、データセットのクラスベクトルを入力として使用し、クラスベースのデータ認識型プロキシハッシュコード、ラベル融合型画像認識プロキシハッシュコード、およびラベル融合型テキスト認識プロキシハッシュコードを生成するデータ認識型プロキシネットワークを訓練します。その後、これらの三種類のデータ認識型プロキシハッシュコードを利用してモダリティ固有のハッシングネットワークの訓練を監督する新たなハッシュ損失を提案します。訓練後、DAPHはセマンティック情報を十分に保持した区別可能なハッシュコードを生成できます。三つのベンチマークデータセットにおける広範な実験により、提案するDAPHがクロスモーダル検索タスクにおいて最先端のベースラインを上回る性能を示しました。
        </label>
        <input type="checkbox" id="Panel65" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recently, numerous proxy hash code based methods, which sufficiently exploit the label information of data to supervise the training of hashing models, have been proposed. Although these methods have made impressive progress, their generating processes of proxy hash codes are based only on the class information of the dataset or labels of data but do not take the data themselves into account. Therefore, these methods will probably generate some inappropriate proxy hash codes, thus damaging the retrieval performance of the hash models. To solve the aforementioned problem, we propose a novel Data-Aware Proxy Hashing for cross-modal retrieval, called DAPH. Specifically, our proposed method first train a data-aware proxy network that takes the data points, label vectors of data, and the class vectors of the dataset as inputs to generate class-based data-aware proxy hash codes, label-fused image-aware proxy hash codes and label-fused text-aware proxy hash codes. Then, we propose a novel hash loss that exploits the three types of data-aware proxy hash codes to supervise the training of modality-specific hashing networks. After training, DAPH is able to generate discriminate hash codes with the semantic information preserved adequately. Extensive experiments on three benchmark datasets show that the proposed DAPH outperforms the state-of-the-art baselines in cross-modal retrieval tasks.
        </div> </ul> <br>



        <label for="Panel66">
        <strong> Asymmetric Hashing for Fast Ranking via Neural Network Measures </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Khoa+D.+Doan">Khoa D. Doan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shulong+Tan">Shulong Tan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weijie+Zhao">Weijie Zhao</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ping+Li">Ping Li</a> (4) </u>  <br>
        1:  VinUniversity, 2:  Coupang, 3:  Rochester Institute of Technology, 4:  Linkedin Ads <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591640">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Asymmetric Hashing for Fast Ranking via Neural Network Measures">Google Scholar</a></div>
        (66)
        <br>
        <b>概要:　</b> 推薦システムにおける高速なアイテムランキングは重要な課題です。従来の研究では、グラフベースの近似最近傍（ANN）アプローチが、一般的な検索/マッチング指標（ニューラルネットワークの指標などの複雑な指標を含む）を用いたアイテムランキングタスクで優れた性能を示してきました。しかし、これらのANNアプローチはランキング中にニューラル指標を複数回使用しなければならないため、ニューラル指標が大規模なネットワークである場合、計算量が現実的ではありません。一方、Locality Sensitive Hashing（LSH）などの既存のハッシングベースのアプローチを用いた高速なアイテムランキングは、コサイン距離やユークリッド距離などの限られた指標でしか機能せず、ニューラルネットワークのような一般的な検索指標には対応していません。任意の検索指標に対して、以前の学習型ハッシングアプローチも、この問題において多くの可能性のあるトレーニングペアのために、ハッシュ関数を検索指標に近似するには大量の時間と計算を要するため、高速なアイテムランキング問題を解決するには不適です。しかし、ハッシングアプローチは、候補アイテムを迅速かつ効率的に取得する基本原理を提供するため、魅力的です。本論文では、ニューラルネットワークの指標を含む任意のタイプの指標を効率的に近似するための、簡単で効果的な学習型ハッシングアプローチを提案します。具体的には、非対称ハッシングフレームワークに基づいた離散内積フィッティングを利用してこの問題を解決します。我々は、ユーザとアイテムなど、異種オブジェクトを共通の離散空間にマッピングする関連するハッシュ関数のペアを学習します。この空間では、それらのバイナリコードの内積が元の検索指標によって定義された真の類似性を明らかにします。この非対称ハッシングスキームを介して、高速ランキング問題をANN検索に帰着させます。その上で、関連性のある対照的なサンプルを効率的に選択してハッシングモデルをトレーニングするためのサンプリング戦略を提案します。様々な非線形検索関数と著名なデータセットの組み合わせにおいて、既存の最先端の高速アイテムランキング手法に対して、提案手法を実証的に検証しました。
        </label>
        <input type="checkbox" id="Panel66" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Fast item ranking is an important task in recommender systems. In previous works, graph-based Approximate Nearest Neighbor (ANN) approaches have demonstrated good performance on item ranking tasks with generic searching/matching measures (including complex measures such as neural network measures). However, since these ANN approaches must go through the neural measures several times during ranking, the computation is not practical if the neural measure is a large network. On the other hand, fast item ranking using existing hashing-based approaches, such as Locality Sensitive Hashing (LSH), only works with a limited set of measures, such as cosine and Euclidean distance, but not with general search measures such as neural networks. Given an arbitrary searching measure, previous learning-to-hash approaches are also not suitable to solve the fast item ranking problem since they can take a significant amount of time and computation to train the hash functions to approximate the searching measure due to a large number of possible training pairs in this problem. Hashing approaches, however, are attractive because they provide a principal and efficient way to retrieve candidate items. In this paper, we propose a simple and effective learning-to-hash approach for the fast item ranking problem that can be used to efficiently approximate any type of measure, including neural network measures. Specifically, we solve this problem with an asymmetric hashing framework based on discrete inner product fitting. We learn a pair of related hash functions that map heterogeneous objects (e.g., users and items) into a common discrete space where the inner product of their binary codes reveals their true similarity defined via the original searching measure. The fast ranking problem is reduced to an ANN search via this asymmetric hashing scheme. Then, we propose a sampling strategy to efficiently select relevant and contrastive samples to train the hashing model. We empirically validate the proposed method against the existing state-of-the-art fast item ranking methods in several combinations of non-linear searching functions and prominent datasets.
        </div> </ul> <br>



        <label for="Panel67">
        <strong> Continuous Input Embedding Size Search For Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunke+Qu">Yunke Qu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tong+Chen">Tong Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyu+Zhao">Xiangyu Zhao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lizhen+Cui">Lizhen Cui</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kai+Zheng">Kai Zheng</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongzhi+Yin">Hongzhi Yin</a> (1) </u>  <br>
        1:  The University of Queensland, 2:  City University of Hong Kong, 3:  Shandong University, 4:  University of Electronic Science and Technology of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591653">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Continuous Input Embedding Size Search For Recommender Systems">Google Scholar</a></div>
        (67)
        <br>
        <b>概要:　</b> ラテントファクターモデルは、その優れたパフォーマンスにより、今日のレコメンダーシステムの最も人気のある基盤です。ラテントファクターモデルは、ユーザーとアイテムをペアワイズな類似度計算のために実数値の埋め込みベクトルとして表現しますが、全ての埋め込みベクトルは伝統的に均一で比較的大きなサイズ（例：256次元）に制限されています。現代のeコマースにおけるユーザーベースとアイテムカタログの指数関数的な拡大に伴い、この設計は確かにメモリー効率が低くなっています。軽量な推薦を実現するために、最近では強化学習（RL）が異なるユーザーやアイテムに対して可変の埋め込みサイズを特定する可能性を開いています。しかし、検索効率と最適なRLポリシーの学習に挑戦されるため、既存のRLベースの方法は高度に離散的で事前定義された埋め込みサイズの選択に制限されています。これにより、与えられたメモリ予算の下でより良い推薦効果を得るための埋め込みサイズに細かい粒度を導入する潜在力がほとんど見過ごされています。本論文では、任意の埋め込みサイズから選択できる連続的な検索空間で動作する新しいRLベースの方法、連続入力埋め込みサイズ検索（CIESS）を提案します。CIESSではさらに、RLポリシーがより多くの候補埋め込みサイズを効率的に探索し、より良い決定に収束するための革新的なランダムウォークベースの探索戦略を提案します。CIESSはまた、モデルに依存しないため、さまざまなラテントファクターレコメンダーシステム（RS）に対して汎用的に適用可能です。実際の2つのデータセットでの実験では、異なるメモリ予算の下で、人気のある3つの推薦モデルと組み合わせた場合でも、CIESSが最先端のパフォーマンスを示しました。
        </label>
        <input type="checkbox" id="Panel67" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a given memory budget. In this paper, we propose continuous input embedding size search (CIESS), a novel RL-based method that operates on a continuous search space with arbitrary embedding sizes to choose from. In CIESS, we further present an innovative random walk-based exploration strategy to allow the RL policy to efficiently explore more candidate embedding sizes and converge to a better decision. CIESS is also model-agnostic and hence generalizable to a variety of latent factor RSs, whilst experiments on two real-world datasets have shown state-of-the-art performance of CIESS under different memory budgets when paired with three popular recommendation models.
        </div> </ul> <br>



        <label for="Panel68">
        <strong> Hear Me Out: A Study on the Use of the Voice Modality for Crowdsourced Relevance Assessments </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nirmal+Roy">Nirmal Roy</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Agathe+Balayn">Agathe Balayn</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=David+Maxwell">David Maxwell</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Claudia+Hauff">Claudia Hauff</a> (2) </u>  <br>
        1:  Delft University of Technology, 2:  Spotify & Delft University of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591694">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Hear Me Out: A Study on the Use of the Voice Modality for Crowdsourced Relevance Assessments">Google Scholar</a></div>
        (68)
        <br>
        <b>概要:　</b> 人間の評価者（現在では多くの場合クラウドワーカー）が行う関連性評価の作成は、IRテストコレクションを構築する際に重要なステップです。先行研究では、評価者の質と行動、および評価者を支援するツールに関する調査が行われてきました。しかし、文書の提示モダリティが評価者の効率と効果に与える影響についての洞察はほとんどありません。音声ベースのインターフェースの普及に伴い、評価者が音声ベースのインターフェースを通じてテキスト文書の関連性を判断することが可能かどうかを調査しました。TRECディープラーニングコーパスからサンプルされた短文および長文の関連性を評価するために、クラウドソーシングプラットフォームでユーザースタディ（n = 49）を実施しました。文書はテキストモダリティまたは音声モダリティのいずれかで提示されました。その結果、以下の点が明らかになりました：(i) 参加者はテキストモダリティと音声モダリティの両方で同等の正確さで判断を下すことができる；(ii) 文書の長さが増すにつれて、音声条件では評価にかかる時間が大幅に長くなる（120語を超える文書ではほぼ2倍の時間がかかる）；および(iii) 対象外の刺激を無視する能力（すなわち抑制）が音声モダリティでの評価品質に影響を与え、抑制力が高い評価者は低い評価者よりも有意に正確である。これらの結果は、音声モダリティを効果的に利用してクラウドワーカーから関連性ラベルを信頼性高く収集できることを示しています。
        </label>
        <input type="checkbox" id="Panel68" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The creation of relevance assessments by human assessors (often nowadays crowdworkers) is a vital step when building IR test collections. Prior works have investigated assessor quality & behaviour, and tooling to support assessors in their task. We have few insights though into the impact of a document's presentation modality on assessor efficiency and effectiveness. Given the rise of voice-based interfaces, we investigate whether it is feasible for assessors to judge the relevance of text documents via a voice-based interface. We ran a user study (n = 49) on a crowdsourcing platform where participants judged the relevance of short and long documents- sampled from the TREC Deep Learning corpus-presented to them either in the text or voice modality. We found that: (i) participants are equally accurate in their judgements across both the text and voice modality; (ii) with increased document length it takes partic- ipants significantly longer (for documents of length > 120 words it takes almost twice as much time) to make relevance judgements in the voice condition; and (iii) the ability of assessors to ignore stimuli that are not relevant (i.e., inhibition) impacts the assessment quality in the voice modality-assessors with higher inhibition are significantly more accurate than those with lower inhibition. Our results indicate that we can reliably leverage the voice modality as a means to effectively collect relevance labels from crowdworkers.
        </div> </ul> <br>



        <label for="Panel69">
        <strong> Extending Label Aggregation Models with a Gaussian Process to Denoise Crowdsourcing Labels </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dan+Li">Dan Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (2) </u>  <br>
        1:  University of Amsterdam & Elsevier, 2:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591685">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Extending Label Aggregation Models with a Gaussian Process to Denoise Crowdsourcing Labels">Google Scholar</a></div>
        (69)
        <br>
        <b>概要:　</b> ラベル集約（Label Aggregation, LA）は、人間のアノテータやモデルの予測から生成された複数のノイズの多いラベルから高品質なラベルを推定するタスクです。従来のLAに関する研究では、ラベル生成プロセスを仮定し、観測されたクラウドソースラベルから潜在的な真のラベルを学習するために確率的グラフィカルモデル（Probabilistic Graphical Model, PGM）を設計しています。しかし、PGMベースのLAモデルの性能はクラウドソースラベルのノイズに影響されやすいです。このため、LAモデルの性能は異なるデータセットで異なり、全てのデータセットにおいて他を凌駕する単一のLAモデルは存在しません。我々は、真のラベルにガウス過程（Gaussian Process, GP）事前分布を取り入れることで、PGMベースのLAモデルを拡張しました。GP事前分布を取り入れたLAモデルの利点は、クラウドソースラベル、サンプルの特徴、および既存の事前学習済みラベル予測モデルを入力として利用し、真のラベルを推定できる点です。オリジナルのLAではクラウドソースラベルのみを利用可能です。合成データおよび実データセットの実験結果は、GP事前分布と適切な平均関数を組み込んだLAモデルが、元のLAモデルよりも優れた性能を達成することを示しており、GP事前分布の効果を実証しています。
        </label>
        <input type="checkbox" id="Panel69" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Label aggregation (LA) is the task of inferring a high-quality label for an example from multiple noisy labels generated by either human annotators or model predictions. Existing work on LA assumes a label generation process and designs a probabilistic graphical model (PGM) to learn latent true labels from observed crowd labels. However, the performance of PGM-based LA models is easily affected by the noise of the crowd labels. As a consequence, the performance of LA models differs on different datasets and no single LA model outperforms the rest on all datasets. We extend PGM-based LA models by integrating a GP prior on the true labels. The advantage of LA models extended with a GP prior is that they can take as input crowd labels, example features, and existing pre-trained label prediction models to infer the true labels, while the original LA can only leverage crowd labels. Experimental results on both synthetic and real datasets show that any LA models extended with a GP prior and a suitable mean function achieves better performance than the underlying LA models, demonstrating the effectiveness of using a GP prior.
        </div> </ul> <br>



        <label for="Panel70">
        <strong> Wisdom of Crowds and Fine-Grained Learning for Serendipity Recommendations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhe+Fu">Zhe Fu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xi+Niu">Xi Niu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Li+Yu">Li Yu</a> (2) </u>  <br>
        1:  University of North Carolina at Charlotte, 2:  Renmin University of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591787">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Wisdom of Crowds and Fine-Grained Learning for Serendipity Recommendations">Google Scholar</a></div>
        (70)
        <br>
        <b>概要:　</b> セレンディピティとは、予期しないが価値のある発見を意味する概念です。その捉えどころのない主観的な性質ゆえに、今日の機械学習やディープラーニング技術が進んでも、セレンディピティの研究は難しいです。特に、基底真実データ収集とモデル開発はオープンな研究課題となっています。本論文は、レコメンダーシステムにおけるセレンディピティの特定に対するデータとモデルの両方の課題に取り組みます。基底真実データ収集に関しては、ユーザー生成レビューとクラウドソーシング手法の併用による新しくスケーラブルなアプローチを提案します。この結果、大規模なセレンディピティに関する基底真実データが得られます。モデル開発に関しては、セレンディピティの詳細な側面を学習するための自己強化モジュールを設計し、セレンディピティ基底真実データセットに内在するデータの希薄性問題を軽減します。この自己強化モジュールは、多くの基本のディープラーニングモデルに適用可能な汎用性を持っています。一連の実験を行った結果、我々が収集した基底真実データと自己強化モジュールを使用して訓練された基本ディープラーニングモデルは、セレンディピティの予測において最先端のベースラインモデルを上回る性能を示しました。
        </label>
        <input type="checkbox" id="Panel70" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Serendipity is a notion that means an unexpected but valuable discovery. Due to its elusive and subjective nature, serendipity is difficult to study even with today's advances in machine learning and deep learning techniques. Both ground truth data collecting and model developing are the open research questions. This paper addresses both the data and the model challenges for identifying serendipity in recommender systems. For the ground truth data collecting, it proposes a new and scalable approach by using both user generated reviews and a crowd sourcing method. The result is a large-scale ground truth data on serendipity. For model developing, it designed a self-enhanced module to learn the fine-grained facets of serendipity in order to mitigate the inherent data sparsity problem in any serendipity ground truth dataset. The self-enhanced module is general enough to be applied with many base deep learning models for serendipity. A series of experiments have been conducted. As the result, a base deep learning model trained on our collected ground truth data, as well as with the help of the self-enhanced module, outperforms the state-of-the-art baseline models in predicting serendipity.
        </div> </ul> <br>



        <label for="Panel71">
        <strong> Dataset Preparation for Arbitrary Object Detection: An Automatic Approach based on Web Information in English </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shucheng+Li">Shucheng Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Boyu+Chang">Boyu Chang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Yang">Bo Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Wu">Hao Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sheng+Zhong">Sheng Zhong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fengyuan+Xu">Fengyuan Xu</a> (1) </u>  <br>
        1:  National Key Lab for Novel Software Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591661">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Dataset Preparation for Arbitrary Object Detection: An Automatic Approach based on Web Information in English">Google Scholar</a></div>
        (71)
        <br>
        <b>概要:　</b> 自動データセット準備は、ユーザーが時間と費用がかかる手動のデータアノテーションを避けるのに役立ちます。物体検出のための高品質なデータセットを準備する際の難しさは、関連性、自然性、およびバランスの3つの重要な側面に関係していますが、既存の研究ではこれらに対応していません。本論文では、ウェブ情報を活用し、人間によるアノテーションを一切必要としない完全自動のデータセット準備メカニズムを提案し、ターゲットオブジェクトを説明する英語のテキスト用語を使用して物体検出タスクのための高品質なトレーニングデータセットを自動的に準備します。このメカニズムには、キーワード展開、データノイズ除去、およびデータバランシングの3つの重要な設計が含まれています。我々の実験は、自動的に準備されたデータで訓練された物体検出器が、ベンチマークデータセットで訓練されたものと同等であり、他のベースラインを上回ることを示しています。また、ベンチマークデータセットに含まれない、より挑戦的な現実世界の物体カテゴリにおいても、本手法の有効性を実証しています。
        </label>
        <input type="checkbox" id="Panel71" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Automatic dataset preparation can help users avoid labor-intensive and costly manual data annotations. The difficulty in preparing a high-quality dataset for object detection involves three key aspects: relevance, naturality, and balance, which are not addressed by existing works. In this paper, we leverage information from the web, and propose a fully-automatic dataset preparation mechanism without any human annotation, which can automatically prepare a high-quality training dataset for the detection task with English text terms describing target objects. It contains three key designs, i.e., keyword expansion, data de-noising, and data balancing. Our experiments demonstrate that the object detectors trained with auto-prepared data are comparable to those trained with benchmark datasets and outperform other baselines. We also demonstrate the effectiveness of our approach in several more challenging real-world object categories that are not included in the benchmark datasets.
        </div> </ul> <br>



        <label for="Panel72">
        <strong> InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siddhant+Kharbanda">Siddhant Kharbanda</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Atmadeep+Banerjee">Atmadeep Banerjee</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Devaansh+Gupta">Devaansh Gupta</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Akash+Palrecha">Akash Palrecha</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rohit+Babbar">Rohit Babbar</a> (4) </u>  <br>
        1:  Aalto University & Microsoft Corporation, 2:  Aalto University, 3:  Aalto University & BITS Pilani, 4:  Aalto University & University of Bath <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591699">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification">Google Scholar</a></div>
        (72)
        <br>
        <b>概要:　</b> 短文データを多数のターゲットラベルに自動で注釈を付ける技術、短文極端分類（Short Text Extreme Classification: XTC）は、関連検索の予測や商品推薦など、多くの応用分野で活用されています。本論文では、軽量ながら強力で、検索や推薦時に遭遇する短文クエリの単語順序の欠如に対しても頑健な畳み込みアーキテクチャ「InceptionXML」を提案します。従来のテキスト分類で用いられるCNNが単語次元に沿って適用される操作を、埋め込み次元に沿って再構築することで、畳み込みの有効性を実証しました。さらに、数百万のラベルが含まれるデータセットに対するモデルのスケーリングに向け、ラベルの短縮選定における動的ハードネガティブマイニング技術の欠点を改善する「SyncXMLパイプライン」を提案し、ラベル短縮選定器と極端分類器の同期化を図りました。SyncXMLは推論時間を半減させるだけでなく、モデルサイズの点で最先端のAstecよりも桁違いに小さいです。包括的な実証比較を通じて、InceptionXMLが既存のアプローチやトランスフォーマーベースラインを上回る性能を発揮し、必要なFLOPsがわずか2%であることを示しています。InceptionXMLのコードは、https://github.com/xmc-aaltoで利用可能です。
        </label>
        <input type="checkbox" id="Panel72" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Automatic annotation of short-text data to a large number of target labels, referred to as Short Text Extreme Classification, has found numerous applications including prediction of related searches and product recommendation. In this paper, we propose a convolutional architecture InceptionXML which is light-weight, yet powerful, and robust to the inherent lack of word-order in short-text queries encountered in search and recommendation. We demonstrate the efficacy of applying convolutions by recasting the operation along the embedding dimension instead of the word dimension as applied in conventional CNNs for text classification. Towards scaling our model to datasets with millions of labels, we also propose SyncXML pipeline which improves upon the shortcomings of the recently proposed dynamic hard-negative mining technique for label shortlisting by synchronizing the label-shortlister and extreme classifier. SyncXML not only reduces the inference time to half but is also an order of magnitude smaller than state-of-the-art Astec in terms of model size. Through a comprehensive empirical comparison, we show that not only can InceptionXML outperform existing approaches on benchmark datasets but also the transformer baselines requiring only 2% FLOPs. The code for InceptionXML is available at https://github.com/xmc-aalto.
        </div> </ul> <br>



        <label for="Panel73">
        <strong> An Effective Framework for Enhancing Query Answering in a Heterogeneous Data Lake </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qin+Yuan">Qin Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ye+Yuan">Ye Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenyu+Wen">Zhenyu Wen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=He+Wang">He Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shiyuan+Tang">Shiyuan Tang</a> (1) </u>  <br>
        1:  Beijing Institute of Technology, 2:  Beijing Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591637">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=An Effective Framework for Enhancing Query Answering in a Heterogeneous Data Lake">Google Scholar</a></div>
        (73)
        <br>
        <b>概要:　</b> 近年、豊富な知識を得るためにクロスソース検索への関心が高まっています。データレイクは、異なるデータスキーマとクエリインタフェースを持つ大量の未処理で異質なデータを収集します。多くの実生活アプリケーションでは、eコマース、バイオインフォマティクス、ヘルスケアなど、異質なデータレイクに対するクエリ応答が求められます。本論文では、データレイクの異質なデータスキーマを意味的に統合し、クエリ応答の意味を強化するためのLakeAnsを提案します。この目的のために、効率的かつ効果的にクロスソース検索を行うための新しいフレームワークを提案します。このフレームワークは、強化学習法を活用してデータスキーマを意味的に統合し、さらに異質なデータのグローバルリレーショナルスキーマを作成します。次に、グローバルスキーマに基づくクエリ応答アルゴリズムを実行し、複数のデータソースから回答を見つけます。我々は、実生活データを用いた広範な実験的評価を行い、本手法が既存のソリューションに比べて効果と効率の両面で優れていることを確認しました。
        </label>
        <input type="checkbox" id="Panel73" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> There has been a growing interest in cross-source searching to gain rich knowledge in recent years. A data lake collects massive raw and heterogeneous data with different data schemas and query interfaces. Many real-life applications require query answering over the heterogeneous data lake, such as e-commerce, bioinformatics and healthcare. In this paper, we propose LakeAns that semantically integrates heterogeneous data schemas of the lake to enhance the semantics of query answers. To this end, we propose a novel framework to efficiently and effectively perform the cross-source searching. The framework exploits a reinforcement learning method to semantically integrate the data schemas and further create a global relational schema for the heterogeneous data. It then performs a query answering algorithm based on the global schema to find answers across multiple data sources. We conduct extensive experimental evaluations using real-life data to verify that our approach outperforms existing solutions in terms of effectiveness and efficiency.
        </div> </ul> <br>



        <label for="Panel74">
        <strong> BeamQA: Multi-hop Knowledge Graph Question Answering with Sequence-to-Sequence Prediction and Beam Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Farah+Atif">Farah Atif</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ola+El+Khatib">Ola El Khatib</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Djellel+Difallah">Djellel Difallah</a> (1) </u>  <br>
        1:  NYU Abu Dhabi <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591698">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=BeamQA: Multi-hop Knowledge Graph Question Answering with Sequence-to-Sequence Prediction and Beam Search">Google Scholar</a></div>
        (74)
        <br>
        <b>概要:　</b> 知識グラフ質問応答（KGQA）は、自然言語のクエリに対し、知識グラフから事実を抽出して答えるタスクです。現在の最先端技術は、グラフのエンティティや関係ラベル、および外部のテキストコーパスからのテキスト情報に依存しています。グラフ内の複数のエッジを推論することで、これらは最も関連性の高いエンティティを正確にランク付けして返すことができます。しかし、これらの手法の一つの限界は、現実世界の知識グラフの本質的な不完全性を扱えないため、エッジの欠落によって不正確な答えを導く可能性があることです。この問題に対処するため、最近のグラフ表現学習の進歩により、欠落エッジを確率的に扱うリンク予測技術を使用して不完全な情報を推論できるシステムが開発されました。しかし、こうした技術を使用する既存のKGQAフレームワークは、クエリ表現からグラフ埋め込み空間への変換を学習する必要があり、大規模なトレーニングデータセットへのアクセスが求められることが多いです。我々はこれらの制約を克服するために、シーケンス・トゥ・シーケンス予測モデルとビーム検索実行を埋め込み空間で組み合わせたアプローチであるBeamQAを提案します。我々のモデルは、事前学習された大規模言語モデルと合成質問生成を使用します。我々の実験では、BeamQAが2つの知識グラフ質問応答データセットにおいて他のKGQA手法と比較して有効であることを示しています。
        </label>
        <input type="checkbox" id="Panel74" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge Graph Question Answering (KGQA) is a task that aims to answer natural language queries by extracting facts from a knowledge graph. Current state-of-the-art techniques for KGQA rely on text-based information from graph entity and relations labels, as well as external textual corpora. By reasoning over multiple edges in the graph, these can accurately rank and return the most relevant entities. However, one of the limitations of these methods is that they cannot handle the inherent incompleteness of real-world knowledge graphs and may lead to inaccurate answers due to missing edges. To address this issue, recent advances in graph representation learning have led to the development of systems that can use link prediction techniques to handle missing edges probabilistically, allowing the system to reason with incomplete information. However, existing KGQA frameworks that use such techniques often depend on learning a transformation from the query representation to the graph embedding space, which requires access to a large training dataset. We present BeamQA, an approach that overcomes these limitations by combining a sequence-to-sequence prediction model with beam search execution in the embedding space. Our model uses a pre-trained large language model and synthetic question generation. Our experiments demonstrate the effectiveness of BeamQA when compared to other KGQA methods on two knowledge graph question-answering datasets.
        </div> </ul> <br>



        <label for="Panel75">
        <strong> Leader-Generator Net: Dividing Skill and Implicitness for Conquering FairytaleQA </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Peng">Wei Peng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wanshui+Li">Wanshui Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Hu">Yue Hu</a> (1) </u>  <br>
        1:  Institute of Information Engineering, 2:  University College London <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591710">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Leader-Generator Net: Dividing Skill and Implicitness for Conquering FairytaleQA">Google Scholar</a></div>
        (75)
        <br>
        <b>概要:　</b> 機械読解理解（Machine Reading Comprehension）は、システムが与えられた文章を理解し、質問に答える能力を求めます。従来の方法は主に質問と文章の相互作用に焦点を当てていました。しかし、それらは質問の背後にある認知要素、例えば詳細な読解スキル（本論文では物語理解スキルに焦点を当てます）や質問の暗示性や明示性（回答が文章内で見つかるかどうか）を深く探求することを怠っていました。読み取り理解に関する先行文献に基づくと、質問の理解は複雑なプロセスであり、人間は質問の意味を理解し、異なる質問に対して異なる読解スキルを使用し、次いで質問の暗示性を判断する必要があります。この目的のために、シンプルで効果的なLeader-Generatorネットワークが提案されており、詳細な読解スキルと質問の暗示性や明示性を明示的に分離および抽出します。具体的には、提案されるスキルリーダーは対照学習を用いて詳細な読解スキルの意味表現を正確に捉えます。そして、暗示性対応のポインタジェネレーターは、質問の暗示性や明示性に基づいて適応的に回答を抽出または生成します。さらに、この方法論の汎用性を検証するために、NarrativeQA 1.1という新しいデータセットを注釈付けしました。FairytaleQAおよびNarrativeQA 1.1の実験では、提案されたモデルが質問応答タスクで最新技術の性能（Rouge-Lで約5％の向上）を達成したことが示されました。私たちの注釈付きデータとコードは、https://github.com/pengwei-iie/Leader-Generator-Netで利用可能です。
        </label>
        <input type="checkbox" id="Panel75" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Machine reading comprehension requires systems to understand the given passage and answer questions. Previous methods mainly focus on the interaction between the question and passage. However, they ignore the deep exploration of cognitive elements behind questions, such as fine-grained reading skills (this paper focuses on narrative comprehension skills) and implicitness or explicitness of the question (whether the answer can be found in the passage). Grounded in prior literature on reading comprehension, the understanding of a question is a complex process where human beings need to understand the semantics of the question, use different reading skills for different questions, and then judge the implicitness of the question. To this end, a simple but effective Leader-Generator Network is proposed to explicitly separate and extract fine-grained reading skills and the implicitness or explicitness of the question. Specifically, the proposed skill leader accurately captures the semantic representation of fine-grained reading skills with contrastive learning. And the implicitness-aware pointer-generator adaptively extracts or generates the answer based on the implicitness or explicitness of the question. Furthermore, to validate the generalizability of the methodology, we annotate a new dataset named NarrativeQA 1.1. Experiments on the FairytaleQA and NarrativeQA 1.1 show that the proposed model achieves the state-of-the-art performance (about 5% gain on Rouge-L) on the question answering task. Our annotated data and code are available at https://github.com/pengwei-iie/Leader-Generator-Net.
        </div> </ul> <br>



        <label for="Panel76">
        <strong> Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Susik+Yoon">Susik Yoon</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongha+Lee">Dongha Lee</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunyi+Zhang">Yunyi Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiawei+Han">Jiawei Han</a> (1) </u>  <br>
        1:  UIUC, 2:  Yonsei University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591782">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding">Google Scholar</a></div>
        (76)
        <br>
        <b>概要:　</b> リアルタイムで相関するニュース記事を通じて物語を無監督に発見することは、高価な人的注釈を必要とせずに大量のニュースストリームを消化するのに役立ちます。既存研究における無監督のオンライン物語発見の一般的なアプローチは、ニュース記事を象徴的またはグラフベースの埋め込みとして表現し、それらを増分的に物語にクラスタリングすることです。最近の大規模言語モデルはこの埋め込みをさらに向上させると期待されていますが、記事内の全情報を無差別にエンコードするというモデルの直接的な採用は、テキストが豊富で進化するニュースストリームに対処するには効果的ではありません。本研究では、共有される時間的テーマを考慮して記事と物語を動的に表現するための、新しいテーマ別埋め込みをオフ・ザ・シェルフの事前訓練された文エンコーダを使用して提案します。無監督のオンライン物語発見の実現に向けて、2つの主要な技術、テーマ及び時間を考慮した動的埋め込みと新規性を考慮した適応クラスタリングを搭載し、軽量な物語のを活用するスケーラブルなフレームワーク「USTORY」を導入しました。実際のニュースデータセットを用いた徹底的な評価により、USTORYはベースラインと比較して高い物語発見性能を達成し、さまざまなストリーミング設定に対しても堅牢でスケーラブルであることが示されました。
        </label>
        <input type="checkbox" id="Panel76" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Unsupervised discovery of stories with correlated news articles in real-time helps people digest massive news streams without expensive human annotations. A common approach of the existing studies for unsupervised online story discovery is to represent news articles with symbolic- or graph-based embedding and incrementally cluster them into stories. Recent large language models are expected to improve the embedding further, but a straightforward adoption of the models by indiscriminately encoding all information in articles is ineffective to deal with text-rich and evolving news streams. In this work, we propose a novel thematic embedding with an off-the-shelf pretrained sentence encoder to dynamically represent articles and stories by considering their shared temporal themes. To realize the idea for unsupervised online story discovery, a scalable framework USTORY is introduced with two main techniques, theme- and time-aware dynamic embedding and novelty-aware adaptive clustering, fueled by lightweight story summaries. A thorough evaluation with real news data sets demonstrates that USTORY achieves higher story discovery performances than baselines while being robust and scalable to various streaming settings.
        </div> </ul> <br>



        <label for="Panel77">
        <strong> BiTimeBERT: Extending Pre-Trained Language Representations with Bi-Temporal Information </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiexin+Wang">Jiexin Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Adam+Jatowt">Adam Jatowt</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Masatoshi+Yoshikawa">Masatoshi Yoshikawa</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Cai">Yi Cai</a> (1) </u>  <br>
        1:  South China University of Technology, 2:  University of Innsbruck, 3:  Kyoto University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591686">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=BiTimeBERT: Extending Pre-Trained Language Representations with Bi-Temporal Information">Google Scholar</a></div>
        (77)
        <br>
        <b>概要:　</b> 時間は文書の重要な側面であり、多くのNLP（自然言語処理）およびIR（情報検索）タスクに利用されます。本研究では、時間に関連するタスクの性能をさらに向上させるために、事前学習中に時間情報を取り入れる手法を調査します。本研究では、BERTのような一般的な事前学習済み言語モデルが同期的な文書コレクション（例：BookCorpusやWikipedia）をトレーニングコーパスとして利用するのに対し、長期間にわたるニュース記事コレクションを使用して単語表現を構築します。我々は、ニュース記事の時間的コレクションを用いた二つの新しい事前学習タスクによって訓練された、新しい言語表現モデル「BiTimeBERT」を紹介します。このモデルは、二つの異なる時間信号を活用して時間認識言語表現を構築します。実験結果は、BiTimeBERTがBERTおよびその他の既存の事前学習済みモデルに比べて、時間が重要なさまざまな下流NLPタスクとアプリケーションにおいて一貫して優れた性能を発揮することを示しています（例：イベント時間推定タスクにおいて、BERTに対する精度向上は155%です）。
        </label>
        <input type="checkbox" id="Panel77" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Time is an important aspect of documents and is used in a range of NLP and IR tasks. In this work, we investigate methods for incorporating temporal information during pre-training to further improve the performance on time-related tasks. Compared with common pre-trained language models like BERT which utilize synchronic document collections (e.g., BookCorpus and Wikipedia) as the training corpora, we use long-span temporal news article collection for building word representations. We introduce BiTimeBERT, a novel language representation model trained on a temporal collection of news articles via two new pre-training tasks, which harnesses two distinct temporal signals to construct time-aware language representations. The experimental results show that BiTimeBERT consistently outperforms BERT and other existing pre-trained models with substantial gains on different downstream NLP tasks and applications for which time is of importance (e.g., the accuracy improvement over BERT is 155% on the event time estimation task).
        </div> </ul> <br>



        <label for="Panel78">
        <strong> Time-interval Aware Share Recommendation via Bi-directional Continuous Time Dynamic Graphs </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ziwei+Zhao">Ziwei Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xi+Zhu">Xi Zhu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tong+Xu">Tong Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Aakas+Lizhiyu">Aakas Lizhiyu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yu+Yu">Yu Yu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xueying+Li">Xueying Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zikai+Yin">Zikai Yin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Enhong+Chen">Enhong Chen</a> (1) </u>  <br>
        1:  University of Science and Technology of China, 2:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591775">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Time-interval Aware Share Recommendation via Bi-directional Continuous Time Dynamic Graphs">Google Scholar</a></div>
        (78)
        <br>
        <b>概要:　</b> 特定のタイムスタンプにおいて、特定のアイテムを共有したい友人を推薦することを目的とする動的シェア推薦は、ソーシャル志向のeコマースプラットフォームにおける新たなタスクとして浮上しています。伝統的なグラフベースの推薦タスクとは異なり、過去のシェア記録からの相互接続された社会的インタラクションや細かい粒度の時系列情報を統合することで、この新しいタスクは一つの独自の課題に直面する可能性があります。それは、動的な社会的接続と非対称的なシェアインタラクションにどう対処するかということです。さらに悪いことに、ユーザーは特定の期間中に非アクティブな状態となる可能性があり、個別のプロフィールの更新が困難になります。これらの課題に対処するために、本論文ではDynShareと呼ばれる動的グラフシェア推薦モデルを提案します。具体的には、まず各ユーザーの埋め込みを2つの部分、すなわち招待埋め込みと票埋め込みに分け、それぞれ送信と受信の傾向を示します。次に、双方向の連続時間動的グラフ（CTDGs）に基づく時系列グラフアテンションネットワーク（TGATs）を活用して、異なる方向からの時系列近傍情報をエンコードします。その後、最後のインタラクション後の時間間隔を異なるユーザーがどのように知覚するかを推定するために、時系列ポイントプロセス（TPPs）を基盤とした時間間隔認識パーソナライズド射影演算子をさらに設計し、次回のシェア予測のためにユーザー埋め込みを射影します。実世界のeコマースシェアデータセットに対する広範な実験によって、提案されたDynShareが最新のベースライン手法と比較してより良い結果を達成できることが示されました。また、コードはプロジェクトのウェブサイトで入手可能です：https://github.com/meteor-gif/DynShare。
        </label>
        <input type="checkbox" id="Panel78" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Dynamic share recommendation, which aims at recommending a friend who would like to share a particular item at a certain timestamp, has emerged as a novel task for social-oriented e-commerce platforms. Different from traditional graph-based recommendation tasks, with integrating the interconnected social interactions and fine-grained temporal information from historical share records, this novel task may encounter one unique challenge, i.e., how to deal with the dynamic social connections and asymmetric share interactions. Even worse, users may keep inactive during some periods, which results in difficulties in updating personalized profiles. To address the above challenges, in this paper, we propose a dynamic graph share recommendation model called DynShare. Specifically, we first divide each user embedding into two parts, namely the invitation embedding and vote embedding to show the tendencies of sending and receiving items, respectively. Then, temporal graph attention networks (TGATs) based on bi-directional continuous time dynamic graphs (CTDGs) are leveraged to encode temporal neighbor information from different directions. Afterward, to estimate how different users perceive the time intervals after the last interaction, we further design a time-interval aware personalized projection operator on the foundation of temporal point processes (TPPs) to project user embedding for the next-time share prediction. Extensive experiments on a real-world e-commerce share dataset have demonstrated that our proposed DynShare can achieve better results compared with state-of-the-art baseline methods. And our code is available on the project website: https://github.com/meteor-gif/DynShare.
        </div> </ul> <br>



        <label for="Panel79">
        <strong> Diffusion Recommender Model </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenjie+Wang">Wenjie Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiyan+Xu">Yiyan Xu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuli+Feng">Fuli Feng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinyu+Lin">Xinyu Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangnan+He">Xiangnan He</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tat-Seng+Chua">Tat-Seng Chua</a> (1) </u>  <br>
        1:  National University of Singapore, 2:  University of Science and Technology of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591663">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Diffusion Recommender Model">Google Scholar</a></div>
        (79)
        <br>
        <b>概要:　</b> 生成モデルであるGenerative Adversarial Networks（GANs）やVariational Auto-Encoders（VAEs）は、幅広くユーザーインタラクションの生成プロセスをモデリングするために利用されています。しかし、GANの不安定さやVAEsの表現力の制約といった内在的な限界により、複雑なユーザーインタラクション生成の正確なモデリングが妨げられます。例えば、様々な干渉要因によりノイズの多いインタラクションが発生することがその一例です。これに対し、画像生成における従来の生成モデルに比べて高い利点を持つDiffusion Models（DMs）に注目し、ノイズ除去の手法で生成プロセスを学習する新しいDiffusion Recommender Model（DiffRec）を提案します。ユーザーインタラクションにおけるパーソナライズされた情報を保持するために、DiffRecは追加されるノイズを減少させ、画像生成のように純粋なノイズに変換することを避けます。さらに、推奨システムにおける固有の課題（大規模なアイテム予測のための高いリソースコストおよびユーザー嗜好の時間的変動）に対処するために、従来のDMsを拡張します。具体的には、DiffRecの2つの拡張版を提案します：L-DiffRecはアイテムをクラスタリングして次元圧縮を行い、潜在空間で拡散プロセスを実行します。一方、T-DiffRecはインタラクションのタイムスタンプに基づいてユーザーインタラクションに重み付けを行い、時間的情報をエンコードします。3つのデータセットを用いた多様な設定（例：クリーントレーニング、ノイズトレーニング、時間的トレーニング）の下で広範な実験を行い、競合ベースラインに対するDiffRecとその2つの拡張版の優位性を実証しました。
        </label>
        <input type="checkbox" id="Panel79" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Generative models such as Generative Adversarial Networks (GANs) and Variational Auto-Encoders (VAEs) are widely utilized to model the generative process of user interactions. However, they suffer from intrinsic limitations such as the instability of GANs and the restricted representation ability of VAEs. Such limitations hinder the accurate modeling of the complex user interaction generation procedure, such as noisy interactions caused by various interference factors. In light of the impressive advantages of Diffusion Models (DMs) over traditional generative models in image synthesis, we propose a novel Diffusion Recommender Model (named DiffRec) to learn the generative process in a denoising manner. To retain personalized information in user interactions, DiffRec reduces the added noises and avoids corrupting users' interactions into pure noises like in image synthesis. In addition, we extend traditional DMs to tackle the unique challenges in recommendation: high resource costs for large-scale item prediction and temporal shifts of user preference. To this end, we propose two extensions of DiffRec: L-DiffRec clusters items for dimension compression and conducts the diffusion processes in the latent space; and T-DiffRec reweights user interactions based on the interaction timestamps to encode temporal information. We conduct extensive experiments on three datasets under multiple settings (e.g., clean training, noisy training, and temporal training). The empirical results validate the superiority of DiffRec with two extensions over competitive baselines.
        </div> </ul> <br>



        <label for="Panel80">
        <strong> Understand the Dynamic World: An End-to-End Knowledge Informed Framework for Open Domain Entity State Tracking </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mingchen+Li">Mingchen Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lifu+Huang">Lifu Huang</a> (2) </u>  <br>
        1:  Georgia State University, 2:  Virginia Tech <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591781">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Understand the Dynamic World: An End-to-End Knowledge Informed Framework for Open Domain Entity State Tracking">Google Scholar</a></div>
        (80)
        <br>
        <b>概要:　</b> オープンドメインのエンティティ状態追跡は、アクションの記述をもとにエンティティの妥当な状態変化（例：[エンティティ]の[属性]が、[以前の状態]から[後の状態]へ変化した）を予測することを目的としています。これは、日常生活における人間の多様な推論タスクを支援するために重要です。しかし、このタスクは、モデルがアクションによって引き起こされる任意の数のエンティティ状態変化を予測する必要があるため、困難です。特に、ほとんどのエンティティはアクションに暗黙的に関連しており、その属性や状態はオープンボキャブラリーから取られます。これらの課題に対処するために、我々はオープンドメインエンティティ状態追跡のための新しいエンドツーエンドの知識活用フレームワーク、すなわちKIEST（Knowledge Informed Entity State Tracking）を提案します。このフレームワークは、外部の知識グラフ（例：ConceptNet）から関連するエンティティと属性を明示的に取得し、それらを取り入れて、新しい動的知識粒度エンコーダ・デコーダフレームワークによりすべてのエンティティ状態変化を自動回帰的に生成します。予測されたエンティティ、属性、および状態間の論理的一貫性を強化するために、新しい制約デコーディング戦略を設計し、一貫性の報酬を用いてデコーディングプロセスを改善します。実験結果は、提案するKIESTフレームワークが公開ベンチマークデータセットであるOpenPIにおいて、強力なベースラインを大幅に上回る成果を示していることを示しています。
        </label>
        <input type="checkbox" id="Panel80" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Open domain entity state tracking aims to predict reasonable state changes of entities (i.e., [attribute] of [entity] was [before_state] and [after_state] afterwards) given the action descriptions. It's important to many reasoning tasks to support human everyday activities. However, it's challenging as the model needs to predict an arbitrary number of entity state changes caused by the action while most of the entities are implicitly relevant to the actions and their attributes as well as states are from open vocabularies. To tackle these challenges, we propose a novel end-to-end Knowledge Informed framework for open domain Entity State Tracking, namely KIEST, which explicitly retrieves the relevant entities and attributes from external knowledge graph (i.e., ConceptNet) and incorporates them to autoregressively generate all the entity state changes with a novel dynamic knowledge grained encoder-decoder framework. To enforce the logical coherence among the predicted entities, attributes, and states, we design a new constraint decoding strategy and employ a coherence reward to improve the decoding process. Experimental results show that our proposed KIEST framework significantly outperforms the strong baselines on the public benchmark dataset - OpenPI
        </div> </ul> <br>



        <label for="Panel81">
        <strong> Weighted Knowledge Graph Embedding </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhao+Zhang">Zhao Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhanpeng+Guan">Zhanpeng Guan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuwei+Zhang">Fuwei Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuzhen+Zhuang">Fuzhen Zhuang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhulin+An">Zhulin An</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Wang">Fei Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongjun+Xu">Yongjun Xu</a> (1) </u>  <br>
        1:  Institute of Computing Technology, 2:  Institute of Computing Technology, 3:  Institute of Artificial Intelligence <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591784">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Weighted Knowledge Graph Embedding">Google Scholar</a></div>
        (81)
        <br>
        <b>概要:　</b> ナレッジグラフ埋め込み（Knowledge Graph Embedding, KGE）は、ナレッジグラフ（Knowledge Graph, KG）内のエンティティとリレーションを低次元ベクトルに射影することを目的としています。実際、既存のKGはデータの不均衡問題に直面しています。すなわち、エンティティとリレーションはロングテール分布に従い、ごく一部のエンティティとリレーションが頻繁に出現する一方で、大多数のエンティティとリレーションはほとんど訓練サンプルを持ちません。既存のKGE手法は、訓練プロセス中に各エンティティやリレーションに均等な重みを割り当てます。この設定では、ロングテールのエンティティとリレーションが充分に訓練されず、信頼できる表現が得られません。この論文では、異なるエンティティとリレーションに差別的に注意を向けるWeightEを提案します。具体的には、WeightEは頻出するエンティティとリレーションには低い重みを、少ないものには高い重みを付与することができます。このようにして、WeightEはロングテールのエンティティとリレーションの重みを増加させ、それらのより良い表現を学習することが可能です。特に、WeightEはKGEタスクのためにバイレベル最適化を調整しており、内側のレベルでは信頼性のあるエンティティおよびリレーション埋め込みを学習し、外側のレベルでは各エンティティとリレーションに適切な重みを割り当てようとします。さらに、異なるエンティティとリレーションに重みを適用するという我々の技術は汎用性が高く柔軟であり、既存の多くのKGEモデルにも適用可能です。最後に、様々な最先端のベースラインに対するWeightEの優位性を広範に検証しました。
        </label>
        <input type="checkbox" id="Panel81" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge graph embedding (KGE) aims to project both entities and relations in a knowledge graph (KG) into low-dimensional vectors. Indeed, existing KGs suffer from the data imbalance issue, i.e., entities and relations conform to a long-tail distribution, only a small portion of entities and relations occur frequently, while the vast majority of entities and relations only have a few training samples. Existing KGE methods assign equal weights to each entity and relation during the training process. Under this setting, long-tail entities and relations are not fully trained during training, leading to unreliable representations. In this paper, we propose WeightE, which attends differentially to different entities and relations. Specifically, WeightE is able to endow lower weights to frequent entities and relations, and higher weights to infrequent ones. In such manner, WeightE is capable of increasing the weights of long-tail entities and relations, and learning better representations for them. In particular, WeightE tailors bilevel optimization for the KGE task, where the inner level aims to learn reliable entity and relation embeddings, and the outer level attempts to assign appropriate weights for each entity and relation. Moreover, it is worth noting that our technique of applying weights to different entities and relations is general and flexible, which can be applied to a number of existing KGE models. Finally, we extensively validate the superiority of WeightE against various state-of-the-art baselines.
        </div> </ul> <br>



        <label for="Panel82">
        <strong> Relation-Aware Multi-Positive Contrastive Knowledge Graph Completion with Embedding Dimension Scaling </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bin+Shang">Bin Shang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yinliang+Zhao">Yinliang Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Di+Wang">Di Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Liu">Jun Liu</a> (1) </u>  <br>
        1:  Xi'an Jiaotong University, 2:  Xi'dian University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591756">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Relation-Aware Multi-Positive Contrastive Knowledge Graph Completion with Embedding Dimension Scaling">Google Scholar</a></div>
        (82)
        <br>
        <b>概要:　</b> 近年、既知の事実を元に推論し、欠けているリンクを推測する知識グラフ完成（KGC）に関する多くの研究が行われてきました。同時に、コントラスト学習がKGCタスクに適用され、エンティティおよびリレーションの表現の質を向上させることができます。しかし、既存のKGCアプローチは高次元の埋め込みと複雑なモデルでパフォーマンスを向上させる傾向があり、その結果、大量のストレージ空間と高い訓練コストを伴います。さらに、単一の正サンプルを用いたコントラスト損失では、複雑なリレーションタイプのために知識グラフ内の構造および意味情報を十分に学習できません。これらの課題に対処するために、埋め込み次元スケーリングとリレーションアウェアな複数正サンプルコントラスト損失を備えた新しい知識グラフ完成モデル「ConKGC」を提案します。空間消費の削減とモデル性能の向上を同時に達成するために、新しいスコアリング関数を提案し、エンティティおよびリレーションの低次元の埋め込みを高次元の埋め込み空間にマッピングし、高次元の埋め込みの潜在的な意味情報を使用して低次元のテールエンティティを予測します。さらに、ConKGCは、異なるリレーションタイプに基づく複数の弱い正サンプルを持つコントラスト損失を設計し、アライメントと統一性という2つの重要な訓練目標を維持します。この損失関数と少ないモデルパラメータにより、ConKGCは最適なパフォーマンスを発揮し、素早い収束速度を実現します。3つの標準データセットでの広範な実験により、我々の革新の有効性が確認され、ConKGCのパフォーマンスは最先端の方法と比較して大幅に向上しました。
        </label>
        <input type="checkbox" id="Panel82" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recently, a large amount of work has emerged for knowledge graph completion (KGC), which aims to reason over known facts and to infer the missing links. Meanwhile, contrastive learning has been applied to the KGC tasks, which can improve the representation quality of entities and relations. However, existing KGC approaches tend to improve their performance with high-dimensional embeddings and complex models, which make them suffer from large storage space and high training costs. Furthermore, contrastive loss with single positive sample learns little structural and semantic information in knowledge graphs due to the complex relation types. To address these challenges, we propose a novel knowledge graph completion model named ConKGC with the embedding dimension scaling and a relation-aware multi-positive contrastive loss. In order to achieve both space consumption reduction and model performance improvement, a new scoring function is proposed to map the raw low-dimensional embeddings of entities and relations to high-dimensional embedding space, and predict low-dimensional tail entities with latent semantic information of high-dimensional embeddings. In addition, ConKGC designs a multiple weak positive samples based contrastive loss under different relation types to maintain two important training targets, Alignment and Uniformity. This loss function and few parameters of the model ensure that ConKGC performs best and has fast convergence speed. Extensive experiments on three standard datasets confirm the effectiveness of our innovations, and the performance of ConKGC is significantly improved compared to the state-of-the-art methods.
        </div> </ul> <br>



        <label for="Panel83">
        <strong> Incorporating Structured Sentences with Time-enhanced BERT for Fully-inductive Temporal Relation Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhongwu+Chen">Zhongwu Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chengjin+Xu">Chengjin Xu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fenglong+Su">Fenglong Su</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhen+Huang">Zhen Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yong+Dou">Yong Dou</a> (1) </u>  <br>
        1:  National University of Defense Technology, 2:  International Digital Economy Academy <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591700">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Incorporating Structured Sentences with Time-enhanced BERT for Fully-inductive Temporal Relation Prediction">Google Scholar</a></div>
        (83)
        <br>
        <b>概要:　</b> 不完全な時間知識グラフ（TKG）における時間的関係の予測は、推論的および導出的な設定の両方で人気のある時間知識グラフ補完（TKGC）の問題です。従来の埋め込みベースのTKGCモデル（TKGE）は構造化された接続に依存しており、固定されたエンティティセット、つまり推論的設定のみを扱えます。テストTKGに新たなエンティティが含まれる導出的設定では、最新の手法はシンボルルールや事前学習された言語モデル（PLM）に基づいています。しかし、これらの手法はそれぞれ柔軟性の欠如と時間特異性の欠如という欠点があります。本研究では、トレーニングセットとテストセットのエンティティが完全に異なる「完全導出的設定」をTKGに拡張し、より柔軟で時間特異的な時間関係予測手法SST-BERT（Structured Sentences with Time-enhanced BERT）の開発に一歩進みました。我々のモデルは、構造化された文をエンコードすることでエンティティの履歴を取得し、意味空間内でルールを暗黙的に学習するため、柔軟性の問題を解決します。TKGに特化して生成された時間トークンに富むコーパスでBERTを事前学習するために、時間マスキングMLMタスクを使用することを提案し、SST-BERTの時間特異性を強化します。ターゲットの四重項の発生確率を計算するために、時間的および意味的な観点からすべての構造化文をスコアに統合します。推論的データセットと新たに生成された完全導出的ベンチマークでの実験は、SST-BERTが最新のベースラインを大幅に改善することを示しています。
        </label>
        <input type="checkbox" id="Panel83" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Temporal relation prediction in incomplete temporal knowledge graphs (TKGs) is a popular temporal knowledge graph completion (TKGC) problem in both transductive and inductive settings. Traditional embedding-based TKGC models (TKGE) rely on structured connections and can only handle a fixed set of entities, i.e., the transductive setting. In the inductive setting where test TKGs contain emerging entities, the latest methods are based on symbolic rules or pre-trained language models (PLMs). However, they suffer from being inflexible and not time-specific, respectively. In this work, we extend the fully-inductive setting, where entities in the training and test sets are totally disjoint, into TKGs and take a further step towards a more flexible and time-sensitive temporal relation prediction approach SST-BERT,incorporating Structured Sentences with Time-enhanced BERT. Our model can obtain the entity history and implicitly learn rules in the semantic space by encoding structured sentences, solving the problem of inflexibility. We propose to use a time masking MLM task to pre-train BERT in a corpus rich in temporal tokens specially generated for TKGs, enhancing the time sensitivity of SST-BERT. To compute the probability of occurrence of a target quadruple, we aggregate all its structured sentences from both temporal and semantic perspectives into a score. Experiments on the transductive datasets and newly generated fully-inductive benchmarks show that SST-BERT successfully improves over state-of-the-art baselines.
        </div> </ul> <br>



        <label for="Panel84">
        <strong> Normalizing Flow-based Neural Process for Few-Shot Knowledge Graph Completion </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linhao+Luo">Linhao Luo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuan-Fang+Li">Yuan-Fang Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gholamreza+Haffari">Gholamreza Haffari</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shirui+Pan">Shirui Pan</a> (2) </u>  <br>
        1:  Monash University, 2:  Griffith University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591743">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Normalizing Flow-based Neural Process for Few-Shot Knowledge Graph Completion">Google Scholar</a></div>
        (84)
        <br>
        <b>概要:　</b> 知識グラフ（KG）は、知識表現の構造化形式として、現実世界で広く応用されています。近年、新たに登場した関係に対する欠落事実を数少ない関連事実から予測することを目的とするFew-Shot知識グラフ完了（FKGC）が、実務者や研究者の間で注目を集めています。しかし、既存のFKGC手法はメトリック学習やメタ学習に基づいており、これらは分布外問題や過学習の問題にしばしば悩まされます。同時に、少数ショット設定ではモデルの予測が非常に不確実なため、予測の不確実性を評価する能力が不足しています。さらに、ほとんどの手法が複雑な関係の処理ができず、KG内のパス情報を無視してしまうため、その性能が大幅に制限されます。本論文では、Few-Shot知識グラフ完了のための正規化フローに基づくニューラルプロセス（NP-FKGC）を提案します。具体的には、正規化フローとニューラルプロセスを統合し、KG完了関数の複雑な分布をモデル化します。これにより、不確実性を見積もりつつ、数少ない関係に対する事実を予測する新しい方法を提供します。次に、ニューラルプロセスを組み込んで数少ないショット設定における複雑な関係を処理するために、確率的ManifoldEデコーダを提案します。さらにパフォーマンスを向上させるために、KG内のパス情報をキャプチャするための注意力を持つ関係パスベースのグラフニューラルネットワークを導入します。3つの公開データセットでの広範な実験により、我々の手法が既存のFKGC手法を大幅に上回り、最先端の性能を達成することを示しました。コードはhttps://github.com/RManLuo/NP-FKGC.gitで利用可能です。
        </label>
        <input type="checkbox" id="Panel84" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge graphs (KGs), as a structured form of knowledge representation, have been widely applied in the real world. Recently, few-shot knowledge graph completion (FKGC), which aims to predict missing facts for unseen relations with few-shot associated facts, has attracted increasing attention from practitioners and researchers. However, existing FKGC methods are based on metric learning or meta-learning, which often suffer from the out-of-distribution and overfitting problems. Meanwhile, they are incompetent at estimating uncertainties in predictions, which is critically important as model predictions could be very unreliable in few-shot settings. Furthermore, most of them cannot handle complex relations and ignore path information in KGs, which largely limits their performance. In this paper, we propose a normalizing flow-based neural process for few-shot knowledge graph completion (NP-FKGC). Specifically, we unify normalizing flows and neural processes to model a complex distribution of KG completion functions. This offers a novel way to predict facts for few-shot relations while estimating the uncertainty. Then, we propose a stochastic ManifoldE decoder to incorporate the neural process and handle complex relations in few-shot settings. To further improve performance, we introduce an attentive relation path-based graph neural network to capture path information in KGs. Extensive experiments on three public datasets demonstrate that our method significantly outperforms the existing FKGC methods and achieves state-of-the-art performance. Code is available at https://github.com/RManLuo/NP-FKGC.git.
        </div> </ul> <br>



        <label for="Panel85">
        <strong> Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunzhi+Yao">Yunzhi Yao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shengyu+Mao">Shengyu Mao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ningyu+Zhang">Ningyu Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Chen">Xiang Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shumin+Deng">Shumin Deng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xi+Chen">Xi Chen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huajun+Chen">Huajun Chen</a> (1) </u>  <br>
        1:  Zhejiang University, 2:  National University of Singapore, 3:  Tencent <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591763">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction">Google Scholar</a></div>
        (85)
        <br>
        <b>概要:　</b> 事前学習された言語モデルの発展に伴い、効率的な知識グラフ構築のためのプロンプトベースのアプローチが多く提案され、顕著な成果を上げています。しかし、知識グラフ構築のための既存のプロンプトベースの学習方法には、いくつかの潜在的な制約が残っています。（i）自然言語と事前に定義されたスキーマを持つ構造化された知識との間の意味的ギャップ。このため、モデルは制限されたテンプレートで意味知識を十分に活用できません。（ii）局所的な個々のインスタンスでの表現学習は、不十分な特徴が与えられた状態での性能を制限し、事前学習された言語モデルの潜在的な類推能力を引き出せないことがあります。これらの観察結果を受けて、私たちはリトリーバル強化型アプローチを提案しました。このアプローチは、スキーマ認識を持つリファレンス・アズ・プロンプト（RAP）をリトリーブし、効率的な知識グラフ構築に利用します。RAPは、人手でアノテートされたデータや弱教師ありデータから継承されたスキーマや知識をプロンプトとして各サンプルに動的に活用でき、モデルに依存せず、広く既存のアプローチに統合可能です。実験結果は、RAPを統合した従来の方法が、リソースの少ない環境での関係トリプル抽出と知識グラフ構築のためのイベント抽出の五つのデータセットで顕著な性能向上を達成できることを示しています。コードはhttps://github.com/zjunlp/RAPで入手可能です。
        </label>
        <input type="checkbox" id="Panel85" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> With the development of pre-trained language models, many prompt-based approaches to data-efficient knowledge graph construction have been proposed and achieved impressive performance. However, existing prompt-based learning methods for knowledge graph construction are still susceptible to several potential limitations: (i) semantic gap between natural language and output structured knowledge with pre-defined schema, which means model cannot fully exploit semantic knowledge with the constrained templates; (ii) representation learning with locally individual instances limits the performance given the insufficient features, which are unable to unleash the potential analogical capability of pre-trained language models. Motivated by these observations, we propose a retrieval-augmented approach, which retrieves schema-aware Reference As Prompt (RAP), for data-efficient knowledge graph construction. It can dynamically leverage schema and knowledge inherited from human-annotated and weak-supervised data as a prompt for each sample, which is model-agnostic and can be plugged into widespread existing approaches. Experimental results demonstrate that previous methods integrated with RAP can achieve impressive performance gains in low-resource settings on five datasets of relational triple extraction and event extraction for knowledge graph construction Code is available in https://github.com/zjunlp/RAP.
        </div> </ul> <br>



        <label for="Panel86">
        <strong> Contrastive State Augmentations for Reinforcement Learning-Based Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaochun+Ren">Zhaochun Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Na+Huang">Na Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yidan+Wang">Yidan Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pengjie+Ren">Pengjie Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Ma">Jun Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiahuan+Lei">Jiahuan Lei</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinlei+Shi">Xinlei Shi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hengliang+Luo">Hengliang Luo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Joemon+Jose">Joemon Jose</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Xin">Xin Xin</a> (1) </u>  <br>
        1:  Shandong University, 2:  Meituan, 3:  University of Glasgow <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591656">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Contrastive State Augmentations for Reinforcement Learning-Based Recommender Systems">Google Scholar</a></div>
        (86)
        <br>
        <b>概要:　</b> 履歴的なユーザーアイテム間インタラクションシーケンスから強化学習（RL）に基づくレコメンダーを学習することは、高報酬の推奨を生成し、長期的な累積利益を向上させるために不可欠です。しかし、既存のRLレコメンデーション手法は、(i) オフライントレーニングデータに含まれていない状態の価値関数を推定すること、および、(ii) コントラスト信号の欠如によりユーザーの暗黙的なフィードバックから効果的な状態表現を学習することに困難を抱えています。本研究では、RLベースのレコメンダーシステムのトレーニングに対するコントラスト的な状態増強（CSA）を提案します。第一の問題に対処するために、オフラインデータの状態空間を拡大するための4つの状態増強戦略を提案します。提案手法は、RLエージェントが局所的な状態領域を訪れるようにし、元の状態と増強された状態間で学習された価値関数が類似することを保証することで、レコメンダーの一般化能力を向上させます。第二の問題に対しては、増強された状態と他のセッションからランダムにサンプリングされた状態との間にコントラスト信号を導入することを提案し、状態表現の学習をさらに改善します。提案するCSAの有効性を検証するために、2つの公開データセットおよび実際のeコマースプラットフォームから収集された1つのデータセットで広範な実験を行いました。また、オンライン評価設定としてシミュレートされた環境でも実験を行いました。実験結果は、CSAがレコメンデーション性能を効果的に向上させることを示しています。
        </label>
        <input type="checkbox" id="Panel86" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Learning reinforcement learning (RL)-based recommenders from historical user-item interaction sequences is vital to generate high-reward recommendations and improve long-term cumulative benefits. However, existing RL recommendation methods encounter difficulties (i) to estimate the value functions for states which are not contained in the offline training data, and (ii) to learn effective state representations from user implicit feedback due to the lack of contrastive signals. In this work, we propose contrastive state augmentations (CSA) for the training of RL-based recommender systems. To tackle the first issue, we propose four state augmentation strategies to enlarge the state space of the offline data. The proposed method improves the generalization capability of the recommender by making the RL agent visit the local state regions and ensuring the learned value functions are similar between the original and augmented states. For the second issue, we propose introducing contrastive signals between augmented states and the state randomly sampled from other sessions to improve the state representation learning further. To verify the effectiveness of the proposed CSA, we conduct extensive experiments on two publicly accessible datasets and one dataset collected from a real-life e-commerce platform. We also conduct experiments on a simulated environment as the online evaluation setting. Experimental results demonstrate that CSA can effectively improve recommendation performance.
        </div> </ul> <br>



        <label for="Panel87">
        <strong> Improving Implicit Feedback-Based Recommendation through Multi-Behavior Alignment </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Xin">Xin Xin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyuan+Liu">Xiangyuan Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hanbing+Wang">Hanbing Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pengjie+Ren">Pengjie Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhumin+Chen">Zhumin Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiahuan+Lei">Jiahuan Lei</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinlei+Shi">Xinlei Shi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hengliang+Luo">Hengliang Luo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Joemon+M.+Jose">Joemon M. Jose</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaochun+Ren">Zhaochun Ren</a> (1) </u>  <br>
        1:  Shandong University, 2:  Meituan, 3:  University of Glasgow, 4:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591697">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Improving Implicit Feedback-Based Recommendation through Multi-Behavior Alignment">Google Scholar</a></div>
        (87)
        <br>
        <b>概要:　</b> 暗黙的なフィードバックから学習するレコメンダシステムは、多くの場合、クリックのような単一種の暗黙的なユーザーフィードバックを利用し、購入などの希少なターゲット行動の予測を強化します。複数種類の暗黙的なユーザーフィードバックを用いてターゲット行動を予測することは依然として未解決の問題です。複数種類のユーザー行動から学習しようとする既存の研究は、多くの場合次の課題に直面します: (i) 異なる行動データ分布から普遍的かつ正確なユーザーの好みを学習することができないこと、(ii) 観察された暗黙的なユーザーフィードバックにおけるノイズやバイアスを克服することができないこと。これらの問題に対処するために、我々は新しいレコメンデーションフレームワークであるマルチビヘイビアアライメント（MBA）を提案します。このフレームワークは複数種類の行動データを用いて暗黙的フィードバックから学習します。我々は、同一ユーザーの複数種類の行動（例：クリックや購入）がそのユーザーの類似した好みを反映すると推測します。この目的のため、我々は根底にある普遍的なユーザーの好みを潜在変数として見なし、その変数を複数の観察された行動データ分布の尤度を最大化し、同時に補助行動（クリックや閲覧など）とターゲット行動から学習したユーザーモデル間のカルバック?ライブラー発散（KL発散）を最小化することによって推定します。MBAは、複数の行動データから普遍的なユーザーの好みを推定し、データのノイズ除去を行い効果的な知識の伝達を可能にします。3つのデータセットを用いた実験を実施し、その中には実際のeコマースプラットフォームから収集したデータセットも含まれています。実験結果は、ターゲット行動の予測を強化するために複数種類の行動データを利用する我々の提案手法の有効性を実証しています。
        </label>
        <input type="checkbox" id="Panel87" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recommender systems that learn from implicit feedback often use large volumes of a single type of implicit user feedback, such as clicks, to enhance the prediction of sparse target behavior such as purchases. Using multiple types of implicit user feedback for such target behavior prediction purposes is still an open question. Existing studies that attempted to learn from multiple types of user behavior often fail to: (i) learn universal and accurate user preferences from different behavioral data distributions, and (ii) overcome the noise and bias in observed implicit user feedback. To address the above problems, we propose multi-behavior alignment (MBA), a novel recommendation framework that learns from implicit feedback by using multiple types of behavioral data. We conjecture that multiple types of behavior from the same user (e.g., clicks and purchases) should reflect similar preferences of that user. To this end, we regard the underlying universal user preferences as a latent variable. The variable is inferred by maximizing the likelihood of multiple observed behavioral data distributions and, at the same time, minimizing the Kullback?Leibler divergence (KL-divergence) between user models learned from auxiliary behavior (such as clicks or views) and the target behavior separately. MBA infers universal user preferences from multi-behavior data and performs data denoising to enable effective knowledge transfer. We conduct experiments on three datasets, including a dataset collected from an operational e-commerce platform. Empirical results demonstrate the effectiveness of our proposed method in utilizing multiple types of behavioral data to enhance the prediction of the target behavior.
        </div> </ul> <br>



        <label for="Panel88">
        <strong> When Newer is Not Better: Does Deep Learning Really Benefit Recommendation From Implicit Feedback? </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yushun+Dong">Yushun Dong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jundong+Li">Jundong Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tobias+Schnabel">Tobias Schnabel</a> (2) </u>  <br>
        1:  University of Virginia, 2:  Microsoft <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591785">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=When Newer is Not Better: Does Deep Learning Really Benefit Recommendation From Implicit Feedback?">Google Scholar</a></div>
        (88)
        <br>
        <b>概要:　</b> 近年、ニューラルモデルはレコメンデーションにおいて最先端の性能を示すと繰り返し宣伝されています。しかしながら、最近の複数の研究により、多くのニューラルレコメンデーションモデルの報告された最先端の結果が信頼性をもって再現できないことが明らかになっています。主な理由は、既存の評価が様々な一貫性のないプロトコルの下で実施されていることです。この再現性の問題により、実際にこれらのニューラルモデルからどれだけの利益を得られるのかを理解するのが難しくなっています。そのため、伝統的なモデルとニューラルモデルの公平かつ包括的な性能比較が必要となります。これらの問題に動機づけられ、インプリシットデータからのトップNレコメンデーションにおいて、最近のニューラルレコメンデーションモデルと伝統的なモデルを比較する大規模な体系的研究を行います。我々は、レコメンデーションモデルの記憶性能、一般化性能、およびサブグループ特定の性能を測定するための評価戦略を提案します。9つの一般的に使用されるデータセットに対し、2つのニューラルモデルと11の伝統的モデルを含む13の人気のあるレコメンデーションモデルで広範な実験を行いました。我々の実験は、広範なハイパーパラメータ探索を行っても、ニューラルモデルは平均HitRateの観点では伝統的モデルをすべての面で上回るわけではないことを示しています。また、ニューラルモデルが非ニューラルモデルよりも優れていると思われる分野があり、例えばレコメンデーション多様性や異なるユーザーやアイテムのサブグループ間でのロバスト性などです。我々の研究は、レコメンデーションにおけるニューラルモデルの相対的な利点と欠点を明らかにし、より良いレコメンダーシステムの構築に向けた重要な一歩となります。
        </label>
        <input type="checkbox" id="Panel88" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In recent years, neural models have been repeatedly touted to exhibit state-of-the-art performance in recommendation. Nevertheless, multiple recent studies have revealed that the reported state-of-the-art results of many neural recommendation models cannot be reliably replicated. A primary reason is that existing evaluations are performed under various inconsistent protocols. Correspondingly, these replicability issues make it difficult to understand how much benefit we can actually gain from these neural models. It then becomes clear that a fair and comprehensive performance comparison between traditional and neural models is needed. Motivated by these issues, we perform a large-scale, systematic study to compare recent neural recommendation models against traditional ones in top-n recommendation from implicit data. We propose a set of evaluation strategies for measuring memorization performance, generalization performance, and subgroup-specific performance of recommendation models. We conduct extensive experiments with 13 popular recommendation models (including two neural models and 11 traditional ones as baselines) on nine commonly used datasets. Our experiments demonstrate that even with extensive hyper-parameter searches, neural models do not dominate traditional models in all aspects, e.g., they fare worse in terms of average HitRate. We further find that there are areas where neural models seem to outperform non-neural models, for example, in recommendation diversity and robustness between different subgroups of users and items. Our work illuminates the relative advantages and disadvantages of neural models in recommendation and is therefore an important step towards building better recommender systems.
        </div> </ul> <br>



        <label for="Panel89">
        <strong> Session Search with Pre-trained Graph Classification Model </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shengjie+Ma">Shengjie Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chong+Chen">Chong Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiaxin+Mao">Jiaxin Mao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Tian">Qi Tian</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuhui+Jiang">Xuhui Jiang</a> (4) </u>  <br>
        1:  Renmin University of China, 2:  Huawei Cloud BU, 3:  Huawei Cloud BU, 4:  Institute of Computing Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591766">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Session Search with Pre-trained Graph Classification Model">Google Scholar</a></div>
        (89)
        <br>
        <b>概要:　</b> タイトル: セッション検索を用いたグラフ分類モデル（SSGC）の提案:<br>セッション検索は、ユーザの情報ニーズをよりよく理解し、関連性の高いランキング結果を提供するために、検索セッションの完全なインタラクション履歴を活用する広く採用されている技術です。既存のほとんどの方法は、検索セッションをクエリとクリックされたドキュメントのシーケンスとしてモデル化します。しかし、単純に検索セッションをシーケンスとして表現すると、元の検索セッション内のトポロジカル情報が失われてしまいます。以前に発行されたクエリ、クリックされたドキュメント、及びそれらに現れた用語やエンティティ間のセッション内相互作用や複雑な構造パターンをモデル化することは容易ではありません。この問題を解決するために、本論文では、新しいアプローチとしてグラフ分類モデルを用いたセッション検索（SSGC）を提案します。SSGCは、各セッションの検索履歴を表す異種グラフ上でのグラフ分類タスクとしてセッション検索を捉えます。グラフ分類の性能向上のために、我々は提案するGNNベースの分類モデルに対して特定の事前トレーニング戦略を設計しました。2つの公開セッション検索データセットに対する広範な実験により、セッション検索タスクにおける我々のモデルの有効性が実証されました。
        </label>
        <input type="checkbox" id="Panel89" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Session search is a widely adopted technique in search engines that seeks to leverage the complete interaction history of a search session to better understand the information needs of users and provide more relevant ranking results. The vast majority of existing methods model a search session as a sequence of queries and previously clicked documents. However, if we simply represent a search session as a sequence we will lose the topological information in the original search session. It is non-trivial to model the intra-session interactions and complicated structural patterns among the previously issued queries, clicked documents, as well as the terms or entities that appeared in them. To solve this problem, in this paper, we propose a novel Session Search with Graph Classification Model (SSGC), which regards session search as a graph classification task on a heterogeneous graph that represents the search history in each session. To improve the performance of the graph classification, we design a specific pre-training strategy for our proposed GNN-based classification model. Extensive experiments on two public session search datasets demonstrate the effectiveness of our model in the session search task.
        </div> </ul> <br>



        <label for="Panel90">
        <strong> Multi-order Matched Neighborhood Consistent Graph Alignment in a Union Vector Space </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Tang">Wei Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haifeng+Sun">Haifeng Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingyu+Wang">Jingyu Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Qi">Qi Qi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jing+Wang">Jing Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Yang">Hao Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shimin+Tao">Shimin Tao</a> (2) </u>  <br>
        1:  Beijing University of Posts and Telecommunications, 2:  Huawei <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591735">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multi-order Matched Neighborhood Consistent Graph Alignment in a Union Vector Space">Google Scholar</a></div>
        (90)
        <br>
        <b>概要:　</b> 本研究では付帯情報なしで2つのグラフ間のノード対応を見つけることを目的とした、教師なしプレイングラフアラインメント（UPGA）問題を検討します。これまでの大部分の研究は構造情報に基づいてUPGAに対処しており、これは必然的に部分グラフ同型写像問題を引き起こします。すなわち、未整列ノードが類似の局所構造情報を持ちうるのです。この問題を軽減するために、限られた数の擬似整列シードのみを用いて学習されたノード埋め込みを整合させることでノードを整列させることを試みる、多階層一致近傍整合（MMNC）を提案します。特に、一致近傍整合（MNC）をベクトル空間に拡張し、埋め込みベースのMNC（EMNC）をさらに開発しました。EMNCベースの損失関数を最小化することで、限られた擬似整列シードを利用して、2つのノード埋め込みグループ間の直交変換行列を高効率かつ高精度で近似することができます。公的ベンチマークでの広範な実験を通じて、提案手法が複数のデータセットにわたり、既存の手法に比べてアラインメント精度と速度のバランスが良好であることを示しています。
        </label>
        <input type="checkbox" id="Panel90" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this paper, we study the unsupervised plain graph alignment problem, which aims to find node correspondences across two graphs without any side information. The majority of previous works addressed UPGA based on structural information, which will inevitably lead to subgraph isomorphism issues. That is, unaligned nodes could take similar local structural information. To mitigate this issue, we present the Multi-order Matched Neighborhood Consistent (MMNC) which tries to match nodes by aligning the learned node embeddings with only a small number of pseudo alignment seeds. In particular, we extend matched neighborhood consistency (MNC) to vector space and further develop embedding-based MNC (EMNC). By minimizing the EMNC-based loss function, we can utilize the limited pseudo alignment seeds to approximate the orthogonal transformation matrix between two groups of node embeddings with high efficiency and accuracy. Through extensive experiments on public benchmarks, we show that the proposed methods achieve a good balance between alignment accuracy and speed over multiple datasets compared with existing methods.
        </div> </ul> <br>



        <label for="Panel91">
        <strong> Personalized Federated Relation Classification over Heterogeneous Texts </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ning+Pang">Ning Pang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Zhao">Xiang Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weixin+Zeng">Weixin Zeng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ji+Wang">Ji Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weidong+Xiao">Weidong Xiao</a> (1) </u>  <br>
        1:  National University of Defense Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591748">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Personalized Federated Relation Classification over Heterogeneous Texts">Google Scholar</a></div>
        (91)
        <br>
        <b>概要:　</b> 関係分類は、テキスト中の二つの注釈付けされたエンティティ間のセマンティックな関係を検出するものであり、知識の構造化に有用なツールです。最近では、分散環境で関係分類モデルをトレーニングするためにフェデレーテッドラーニングが導入されました。現在の方法では、クライアントのテキストに直接アクセスすることなくサーバーでモデルをトレーニングしつつ、それらを活用することで強力なサーバーモデルを目指しています。しかし、クライアントが異質なテキスト（すなわち、多様に偏った関係の分布を持つテキスト）を持っている事実を見過ごしているため、既存の方法は実用性に欠けています。本論文では、クライアント自身のデータに適合した強力なクライアントモデルが求められるパーソナライズドフェデレーテッド関係分類を検討することを提案します。異質なテキストによる課題に対応するために、我々はpf-RCと呼ばれる新しいフレームワークをいくつかの最適化されたデザインと共に提案します。これは、関係ごとの重み付け機構を活用する知識集約方法と、プロトタイプを利用して長い尾の関係のインスタンスの表現を適応的に強化する特徴増強方法を特徴としています。我々は様々な設定で競合するベースラインに対するpf-RCの優位性を実験的に検証し、その結果、カスタマイズされた技術が課題を軽減することを示唆しています。
        </label>
        <input type="checkbox" id="Panel91" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Relation classification detects the semantic relation between two annotated entities from a piece of text, which is a useful tool for structurization of knowledge. Recently, federated learning has been introduced to train relation classification models in decentralized settings. Current methods strive for a strong server model by decoupling the model training at server from direct access to texts at clients while taking advantage of them. Nevertheless, they overlook the fact that clients have heterogeneous texts (i.e., texts with diversely skewed distribution of relations), which renders existing methods less practical. In this paper, we propose to investigate personalized federated relation classification, in which strong client models adapted to their own data are desired. To further meet the challenges brought by heterogeneous texts, we present a novel framework, namely pf-RC, with several optimized designs. It features a knowledge aggregation method that exploits a relation-wise weighting mechanism, and a feature augmentation method that leverages prototypes to adaptively enhance the representations of instances of long-tail relations. We experimentally validate the superiority of pf-RC against competing baselines in various settings, and the results suggest that the tailored techniques mitigate the challenges.
        </div> </ul> <br>



        <label for="Panel92">
        <strong> Leveraging Transferable Knowledge Concept Graph Embedding for Cold-Start Cognitive Diagnosis </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weibo+Gao">Weibo Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Wang">Hao Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Liu">Qi Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Wang">Fei Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Lin">Xin Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linan+Yue">Linan Yue</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zheng+Zhang">Zheng Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rui+Lv">Rui Lv</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shijin+Wang">Shijin Wang</a> (2) </u>  <br>
        1:  University of Science and Technology of China, 2:  iFLYTEK CO. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591774">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Leveraging Transferable Knowledge Concept Graph Embedding for Cold-Start Cognitive Diagnosis">Google Scholar</a></div>
        (92)
        <br>
        <b>概要:　</b> 認知診断（CD）とは、特定の知識概念に関する学生の熟練度やテスト問題の特徴（例えば、難易度）を明らかにすることを目的としています。パーソナライズされた学習指導を支援することで、インテリジェント教育システムにおいて重要な役割を果たします。しかし、最近のCDの発展は主に診断結果の精度向上に集中しており、重要で実践的な課題である領域レベルのゼロショット認知診断（DZCD）を見落としがちです。DZCDの主な課題は、ターゲット領域における学生行動データの欠如であり、これは学生とテスト問題のインタラクションの欠如や訓練用の記録の不在によるものです。このコールドスタート問題に対処するために、我々はTechCD（認知診断のための知識概念グラフ埋め込みフレームワーク）という二段階の解決策を提案します。基本的な概念は、教育的な知識概念グラフ（KCG）を媒介として異なる領域を結び付け、確立された領域からゼロショットのコールドスタート領域に学生の認知信号を伝達することです。具体的には、転送可能な学生の認知状態および領域固有の問題特徴を学習するために、KCGに対してナイーブですが効果的なグラフ畳み込みネットワーク（GCN）とボトムレイヤーの排除操作を初期に導入します。さらに、一般的なTechCDフレームワークの典型的な認知診断ソリューションに従った3つの実装を示します。最後に、実際のデータセットに関する広範な実験は、TechCDがゼロショット診断を効果的に行えることを証明するだけでなく、問題の推薦といった一般的な応用も示します。
        </label>
        <input type="checkbox" id="Panel92" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Cognitive diagnosis (CD) aims to reveal the proficiency of students on specific knowledge concepts and traits of test exercises (e.g., difficulty). It plays a critical role in intelligent education systems by supporting personalized learning guidance. However, recent developments in CD mostly concentrate on improving the accuracy of diagnostic results and often overlook the important and practical task: domain-level zero-shot cognitive diagnosis (DZCD). The primary challenge of DZCD is the deficiency of student behavior data in the target domain due to the absence of student-exercise interactions or unavailability of exercising records for training purposes. To tackle the cold-start issue, we propose a two-stage solution named TechCD (Transferable knowledgE Concept grapH embedding framework for Cognitive Diagnosis). The fundamental notion involves utilizing a pedagogical knowledge concept graph (KCG) as a mediator to connect disparate domains, allowing the transmission of student cognitive signals from established domains to the zero-shot cold-start domain. Specifically, a naive yet effective graph convolutional network (GCN) with the bottom-layer discarding operation is initially employed over the KCG to learn transferable student cognitive states and domain-specific exercise traits. Moreover, we give three implementations of the general TechCD framework following the typical cognitive diagnosis solutions. Finally, extensive experiments on real-world datasets not only prove that Tech can effectively perform zero-shot diagnosis, but also give some popular applications such as exercise recommendation.
        </div> </ul> <br>



        <label for="Panel93">
        <strong> Editable User Profiles for Controllable Text Recommendations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sheshera+Mysore">Sheshera Mysore</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mahmood+Jasim">Mahmood Jasim</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrew+Mccallum">Andrew Mccallum</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hamed+Zamani">Hamed Zamani</a> (1) </u>  <br>
        1:  University of Massachusetts Amherst <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591677">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Editable User Profiles for Controllable Text Recommendations">Google Scholar</a></div>
        (93)
        <br>
        <b>概要:　</b> 高品質なレコメンデーションを行うための手法は、しばしばインタラクションデータから潜在表現を学習することに依存しています。これらの手法はパフォーマンスは高いものの、利用者が受け取るレコメンデーションを制御するための即時のメカニズムを提供していません。本研究では、制御可能なテキストレコメンデーションのための新しい概念値ボトルネックモデルであるLACEを提案します。LACEは、ユーザーがインタラクトしたドキュメントからの検索を通じて各ユーザーを人間が読解可能な概念の簡潔なセットで表し、ユーザードキュメントに基づいて概念の個別化された表現を学習します。この概念に基づくユーザープロフィールを利用してレコメンデーションを行います。私たちのモデルの設計は、透明なユーザープロフィールとの直感的なインタラクションを通じてレコメンデーションの制御を可能にします。初めに、LACEによって得られたレコメンデーションの品質を、6つのデータセットを用いたウォームスタート、コールドスタート、およびゼロショット設問での3つのレコメンデーションタスクでのオフライン評価によって確立します。次に、LACEの制御可能性をシミュレートされたユーザーインタラクションの下で検証します。最後に、LACEを実際のインタラクティブな制御可能レコメンダーシステムに実装し、編集可能なユーザープロフィールを通じたインタラクションによってユーザーが受け取るレコメンデーションの質を向上させられることを実証するユーザースタディを行います。
        </label>
        <input type="checkbox" id="Panel93" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Methods for making high-quality recommendations often rely on learning latent representations from interaction data. These methods, while performant, do not provide ready mechanisms for users to control the recommendation they receive. Our work tackles this problem by proposing LACE, a novel concept value bottleneck model for controllable text recommendations. LACE represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents and learns personalized representations of the concepts based on user documents. This concept based user profile is then leveraged to make recommendations. The design of our model affords control over the recommendations through a number of intuitive interactions with a transparent user profile. We first establish the quality of recommendations obtained from LACE in an offline evaluation on three recommendation tasks spanning six datasets in warm-start, cold-start, and zero-shot setups. Next, we validate the controllability of LACE under simulated user interactions. Finally, we implement LACE in an interactive controllable recommender system and conduct a user study to demonstrate that users are able to improve the quality of recommendations they receive through interactions with an editable user profile.
        </div> </ul> <br>



        <label for="Panel94">
        <strong> Intent-aware Ranking Ensemble for Personalized Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiayu+Li">Jiayu Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peijie+Sun">Peijie Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhefan+Wang">Zhefan Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weizhi+Ma">Weizhi Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yangkun+Li">Yangkun Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Min+Zhang">Min Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhoutian+Feng">Zhoutian Feng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daiyue+Xue">Daiyue Xue</a> (2) </u>  <br>
        1:  Tsinghua University, 2:  Meituan Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591702">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Intent-aware Ranking Ensemble for Personalized Recommendation">Google Scholar</a></div>
        (94)
        <br>
        <b>概要:　</b> ランク集合は、実際のレコメンダシステムにおいて重要な要素です。ユーザーがプラットフォームにアクセスすると、システムは複数のアイテムリストを用意します。これらのリストは、一般に単一の行動目的の推薦モデルから生成されます。クリックすることと特定のアイテムカテゴリーを購入することなど、複数の行動意図がユーザー訪問時に並行して存在することが多いため、複数の単一目的ランクリストを1つに統合する必要があります。しかし、従来のランク集約の研究は、同じ目的でランキングされた同種のアイテムリストの統合に重点を置いており、さまざまなユーザー意図で異なる目的でランキングされた異種のリストの集約を無視していました。本研究では、ユーザーの可能な行動と潜在的なインタラクティブなアイテムカテゴリーをユーザーの意図とみなし、ユーザーの意図を考慮して異なる目的から生成された候補アイテムリストをどのように統合するかを研究することを目的としています。この課題に対処するために、複数の単一目的アイテムリストをさまざまなユーザーの意図と共に統合するIntent-aware ranking Ensemble Learning (IntEL)モデルを提案し、アイテムごとのパーソナライズされた重みを学習します。さらに、ポイントワイズ、ペアワイズ、リストワイズ損失関数を通じてエラー-曖昧さ分解によってIntELの有効性を理論的に証明します。2つの大規模な実世界データセットでの実験でも、従来のランク集合モデルと比較して、IntELが複数の行動目的に対して同時に有意な改善を示しました。
        </label>
        <input type="checkbox" id="Panel94" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Ranking ensemble is a critical component in real recommender systems. When a user visits a platform, the system will prepare several item lists, each of which is generally from a single behavior objective recommendation model. As multiple behavior intents, e.g., both clicking and buying some specific item category, are commonly concurrent in a user visit, it is necessary to integrate multiple single-objective ranking lists into one. However, previous work on rank aggregation mainly focused on fusing homogeneous item lists with the same objective while ignoring ensemble of heterogeneous lists ranked with different objectives with various user intents. In this paper, we treat a user's possible behaviors and the potential interacting item categories as the user's intent. And we aim to study how to fuse candidate item lists generated from different objectives aware of user intents. To address such a task, we propose an Intent-aware ranking Ensemble Learning (IntEL) model to fuse multiple single-objective item lists with various user intents, in which item-level personalized weights are learned. Furthermore, we theoretically prove the effectiveness of IntEL with point-wise, pair-wise, and list-wise loss functions via error-ambiguity decomposition. Experiments on two large-scale real-world datasets also show significant improvements of IntEL on multiple behavior objectives simultaneously compared to previous ranking ensemble models.
        </div> </ul> <br>



        <label for="Panel95">
        <strong> Personalized Retrieval over Millions of Items </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hemanth+Vemuri">Hemanth Vemuri</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sheshansh+Agrawal">Sheshansh Agrawal</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shivam+Mittal">Shivam Mittal</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Deepak+Saini">Deepak Saini</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Akshay+Soni">Akshay Soni</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Abhinav+V.+Sambasivan">Abhinav V. Sambasivan</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenhao+Lu">Wenhao Lu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yajun+Wang">Yajun Wang</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mehul+Parsana">Mehul Parsana</a> (6), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Purushottam+Kar">Purushottam Kar</a> (7), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Manik+Varma">Manik Varma</a> (3) </u>  <br>
        1:  Microsoft, 2:  Microsoft, 3:  Microsoft Research, 4:  Microsoft, 5:  LinkedIn Corporation, 6:  Google, 7:  IIT Kanpur <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591749">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Personalized Retrieval over Millions of Items">Google Scholar</a></div>
        (95)
        <br>
        <b>概要:　</b> パーソナライズド検索は、ユーザーのイベント（例えば、ページ訪問やクエリ）に関連するアイテムをユーザーの個別の好みに合わせて検索することを目的としています。例えば、同じ商品ページを訪問したり、同じクエリを行ったりする二人のユーザーが、それぞれの嗜好に適応した異なる推薦を受ける可能性があります。多数のアイテムがあるカタログに対してパーソナライズド検索を行うのは稀です。なぜなら、既存のパーソナライズ手法のコストは候補アイテム数に比例して増加するからです。例えば、イベントとアイテムの両方の埋め込みをユーザーごとにパーソナライズする「両面パーソナライズド検索」を行うと、ストレージや計算コストが非常に高くなります。そのため、まず非パーソナライズド検索を用いて小さなアイテムのリストを取得し、その上でパーソナライズド再ランキングを迅速に行うのが一般的です。しかし、この方法は、非パーソナライズド検索時に選ばれなかったユーザー固有の関連アイテムが失われるリスクを伴います。本論文は、XPERTアルゴリズムを開発することによってこのギャップを埋めます。このアルゴリズムは、数百万のアイテムと数億のユーザーに対してスケーラブルに実装できる両面パーソナライズド検索の一形態を特定します。パーソナライズド検索の計算上の課題を克服する鍵は、任意のエンコーダーアーキテクチャで使用でき、両面パーソナライズの大きなメモリオーバーヘッドを完全に回避し、ミリ秒単位の推論を提供し、複数の意図に対する検索を可能にするモーフオペレータの新しい概念です。複数の公開データセットおよび専用データセットにおいて、XPERTは最新技術と比べて最大5%の上回るリコールとAUCを提供しました。XPERTのコードは https://github.com/personalizedretrieval/xpert で利用可能です。
        </label>
        <input type="checkbox" id="Panel95" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Personalized retrieval seeks to retrieve items relevant to a user event (e.g. a page visit or a query) that are adapted to the user's personal preferences. For example, two users who happen to perform the same event such as visiting the same product page or asking the same query should receive potentially distinct recommendations adapted to their individual tastes. Personalization is seldom attempted over catalogs of millions of items since the cost of existing personalization routines scale linearly in the number of candidate items. For example, performing two-sided personalized retrieval (with both event and item embeddings personalized to the user) incurs prohibitive storage and compute costs. Instead, it is common to use non-personalized retrieval to obtain a small shortlist of items over which personalized re-ranking can be done quickly. Despite being scalable, this strategy risks losing items uniquely relevant to a user that fail to get shortlisted during non-personalized retrieval. This paper bridges this gap by developing the XPERT algorithm that identifies a form of two-sided personalization that can be scalably implemented over millions of items and hundreds of millions of users. Key to overcoming the computational challenges of personalized retrieval is a novel concept of morph operators that can be used with arbitrary encoder architectures, completely avoids the steep memory overheads of two-sided personalization, provides millisecond-time inference and offers multi-intent retrieval. On multiple public and proprietary datasets, XPERT offered upto 5% superior recall and AUC than state-of-the-art techniques. Code for XPERT is available at https://github.com/personalizedretrieval/xpert.
        </div> </ul> <br>



        <label for="Panel96">
        <strong> ML-LJP: Multi-Law Aware Legal Judgment Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yifei+Liu">Yifei Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiquan+Wu">Yiquan Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yating+Zhang">Yating Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Changlong+Sun">Changlong Sun</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weiming+Lu">Weiming Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Wu">Fei Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kun+Kuang">Kun Kuang</a> (1) </u>  <br>
        1:  Zhejiang University, 2:  Alibaba Group, 3:  Alibaba Group & Zhejiang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591731">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=ML-LJP: Multi-Law Aware Legal Judgment Prediction">Google Scholar</a></div>
        (96)
        <br>
        <b>概要:　</b> 法律判決予測（LJP）は、裁判官を支援し、事件の事実記述に基づいて判決結果を決定することを目的とした法的インテリジェンスにおける重要なタスクです。判決結果は、法令記事、罪状、および刑期から成り立っています。法令記事は罪状および刑期の根拠となり、これはそれぞれ罪状関連法令記事と刑期関連法令記事の2種類に分けられます。最近では、多くの方法が提案され、LJPにおいて大きな進展を遂げています。しかし、既存の方法は罪状関連法令記事の予測にのみ焦点を当てており、刑期関連法令記事（例えば、寛大な処遇に関する法律）を無視しているため、刑期予測のパフォーマンスが制限されています。本論文では、実際の法的プロセスに従い、法令記事予測を罪状関連法令記事と刑期関連法令記事を含むマルチラベル分類タスクとして拡張し、LJPのパフォーマンスを向上させるために、新しいマルチ法令対応LJP（ML-LJP）手法を提案します。事件の事実記述を考慮し、まず、法典におけるラベル（例えば、法令記事および罪状）の定義を用いて、事実の表現を複数のラベル固有の表現に変換し、法令記事と罪状の予測を行います。異なるラベル定義の類似した内容を区別するために、トレーニングでは対照学習を実施します。次に、グラフアテンションネットワーク（GAT）を適用して、複数の法令記事間の相互作用を学習し、刑期の予測を行います。LJPにおいて数値（例えば、窃盗の額やドラッグの重量）が重要であるが、従来のエンコーダーではしばしば無視されているため、これらの有効な数値を位置付けてより良く表現するための対応する数値表現方法を設計します。実世界のデータセットにおける広範な実験により、我々の方法が最先端モデルと比べて最良の結果を達成し、特に刑期予測のタスクではML-LJPがベストベースラインより10.07%の相対的な改善を達成したことが示されました。
        </label>
        <input type="checkbox" id="Panel96" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Legal judgment prediction (LJP) is a significant task in legal intelligence, which aims to assist the judges and determine the judgment result based on the case's fact description. The judgment result consists of law articles, charge, and prison term. The law articles serve as the basis for the charge and the prison term, which can be divided into two types, named as charge-related law article and term-related law article, respectively. Recently, many methods have been proposed and made tremendous progress in LJP. However, the existing methods only focus on the prediction of the charge-related law articles, ignoring the term-related law articles (e.g., laws about lenient treatment), which limits the performance in the prison term prediction. In this paper, following the actual legal process, we expand the law article prediction as a multi-label classification task that includes both the charge-related law articles and term-related law articles and propose a novel multi-law aware LJP (ML-LJP) method to improve the performance of LJP. Given the case's fact description, firstly, the label (e.g., law article and charge) definitions in the Code of Law are used to transform the representation of the fact into several label-specific representations and make the prediction of the law articles and the charge. To distinguish the similar content of different label definitions, contrastive learning is conducted in the training. Then, a graph attention network (GAT) is applied to learn the interactions among the multiple law articles for the prediction of the prison term. Since numbers (e.g., amount of theft and weight of drugs) are important for LJP but often ignored by conventional encoders, we design a corresponding number representation method to locate and better represent these effective numbers. Extensive experiments on real-world dataset show that our method achieves the best results compared to the state-of-the-art models, especially in the task of prison term prediction where ML-LJP achieves a 10.07% relative improvement over the best baseline.
        </div> </ul> <br>



        <label for="Panel97">
        <strong> SAILER: Structure-aware Pre-trained Language Model for Legal Case Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haitao+Li">Haitao Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qingyao+Ai">Qingyao Ai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jia+Chen">Jia Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qian+Dong">Qian Dong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yueyue+Wu">Yueyue Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiqun+Liu">Yiqun Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chong+Chen">Chong Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Tian">Qi Tian</a> (2) </u>  <br>
        1:  Tsinghua University, 2:  Huawei Cloud BU <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591761">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SAILER: Structure-aware Pre-trained Language Model for Legal Case Retrieval">Google Scholar</a></div>
        (97)
        <br>
        <b>概要:　</b> 法的ケース検索は、クエリケースに関連するケースを見つけることを目的としており、インテリジェントな法的システムにおいて中核的な役割を果たします。アドホック検索タスクにおいて事前学習が成功を収めているにもかかわらず、法的ケース検索に対する効果的な事前学習戦略はまだ十分に探求されていません。一般的な文書と比較して、法的ケース文書は通常、内在する論理構造を持つ長文のテキストシーケンスです。しかし、既存の多くの言語モデルは、異なる構造間の長距離依存関係を理解するのが困難です。さらに、一般的な検索とは対照的に、法的分野における関連性は、重要な法的要素に非常に敏感です。法的要素における微妙な違いでも、関連性の判断に大きな影響を与える可能性があります。しかし、一般目的で設計された既存の事前学習言語モデルは、法的要素に対処する準備ができていないことが多いです。<br><br>これらの問題に対処するために、本論文ではSAILER（Structure-Aware pre-traIned language model for LEgal case Retrieval）という新しいモデルを提案します。SAILERは以下の3つの側面で注目されています。(1) SAILERは法的ケース文書に含まれる構造情報を最大限に活用し、法律専門家が法的ケース文書を閲覧するのと同様に、重要な法的要素により多くの注意を払います。(2) SAILERは非対称なエンコーダーデコーダーアーキテクチャを採用して、いくつかの異なる事前学習の目的を統合しています。このようにして、タスク間の豊富なセマンティック情報が密なベクトルにエンコードされます。(3) SAILERは、法的アノテーションデータなしでも強力な識別能力を持ち、異なる罪状を持つ法的ケースを正確に区別できます。公に利用可能な法的ベンチマークに対する広範な実験により、我々のアプローチが法的ケース検索において、従来の最先端手法を大幅に上回ることが実証されています。
        </label>
        <input type="checkbox" id="Panel97" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Legal case retrieval, which aims to find relevant cases for a query case, plays a core role in the intelligent legal system. Despite the success that pre-training has achieved in ad-hoc retrieval tasks, effective pre-training strategies for legal case retrieval remain to be explored. Compared with general documents, legal case documents are typically long text sequences with intrinsic logical structures. However, most existing language models have difficulty understanding the long-distance dependencies between different structures. Moreover, in contrast to the general retrieval, the relevance in the legal domain is sensitive to key legal elements. Even subtle differences in key legal elements can significantly affect the judgement of relevance. However, existing pre-trained language models designed for general purposes have not been equipped to handle legal elements. To address these issues, in this paper, we propose SAILER, a new Structure-Aware pre-traIned language model for LEgal case Retrieval. It is highlighted in the following three aspects: (1) SAILER fully utilizes the structural information contained in legal case documents and pays more attention to key legal elements, similar to how legal experts browse legal case documents. (2) SAILER employs an asymmetric encoder-decoder architecture to integrate several different pre-training objectives. In this way, rich semantic information across tasks is encoded into dense vectors. (3) SAILER has powerful discriminative ability, even without any legal annotation data. It can distinguish legal cases with different charges accurately. Extensive experiments over publicly available legal benchmarks demonstrate that our approach can significantly outperform previous state-of-the-art methods in legal case retrieval.
        </div> </ul> <br>



        <label for="Panel98">
        <strong> Creating a Silver Standard for Patent Simplification </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Silvia+Casola">Silvia Casola</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alberto+Lavelli">Alberto Lavelli</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Horacio+Saggion">Horacio Saggion</a> (3) </u>  <br>
        1:  University of Padua & Fondazione Bruno Kessler, 2:  Fondazione Bruno Kessler, 3:  Universitat Pompeu Fabra <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591657">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Creating a Silver Standard for Patent Simplification">Google Scholar</a></div>
        (98)
        <br>
        <b>概要:　</b> 特許は、一方で発明を保護し、他方で技術知識を循環させることを目的とした法的文書です。その複雑なスタイル――法的、技術的、そして極めて曖昧な言語のミックス――は、人間と機械の両方にとってその内容を理解しにくくし、情報検索コミュニティに対して重大な課題を提供します。本論文では、言い換えを通して特許文書を自動的に簡素化するアプローチを提案します。ドメイン内の並列簡素化データが存在しないため、大規模なシルバースタンダードの特許文を自動生成する方法を提案します。候補を得るために、一般ドメインのパラフレージングシステムを使用しますが、このプロセスはエラーが発生しやすく制御が困難です。したがって、適切なフィルターと組み合わせてクリーンなコーパスを構築し、簡素化システムの訓練に成功裏に使用できるようにします。合成されたシルバーコーパスの人間による評価では、文法的であると考えられ、適切であり、単純な文が含まれていることが示されました。
        </label>
        <input type="checkbox" id="Panel98" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Patents are legal documents that aim at protecting inventions on the one hand and at making technical knowledge circulate on the other. Their complex style -- a mix of legal, technical, and extremely vague language -- makes their content hard to access for humans and machines and poses substantial challenges to the information retrieval community. This paper proposes an approach to automatically simplify patent text through rephrasing. Since no in-domain parallel simplification data exist, we propose a method to automatically generate a large-scale silver standard for patent sentences. To obtain candidates, we use a general-domain paraphrasing system; however, the process is error-prone and difficult to control. Thus, we pair it with proper filters and construct a cleaner corpus that can successfully be used to train a simplification system. Human evaluation of the synthetic silver corpus shows that it is considered grammatical, adequate, and contains simple sentences.
        </div> </ul> <br>



        <label for="Panel99">
        <strong> Not Just Skipping: Understanding the Effect of Sponsored Content on Users' Decision-Making in Online Health Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anat+Hashavit">Anat Hashavit</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongning+Wang">Hongning Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tamar+Stern">Tamar Stern</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sarit+Kraus">Sarit Kraus</a> (3) </u>  <br>
        1:  Bar-Ilan University, 2:  University of Virgina, 3:  Bar-Ilan University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591744">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Not Just Skipping: Understanding the Effect of Sponsored Content on Users' Decision-Making in Online Health Search">Google Scholar</a></div>
        (99)
        <br>
        <b>概要:　</b> 検索エンジンのビジネスモデルにおいて、広告（ads）は本質的な部分を占めています。販売促進のため、広告主は自社のコンテンツを検索結果ページ（SERP）の目立つ位置に表示するために、検索エンジンに対価を支払う意欲があります。これにより、検索エンジン操作効果（SEME）に関する懸念が生じます。すなわち、ユーザーの意見が検索結果の表示方法によって影響を受ける可能性があるのです。本研究では、保健領域におけるSEMEとスポンサー付コンテンツとの関連性を調査します。参加者がさまざまな医療条件に対する非処方箋の自然療法の効果を評価する一連のユーザースタディを実施します。参加者には特定の視点に対して意図的なバイアスを持たせたSERPsを、スポンサー付きコンテンツの有無で提示し、提示された情報に基づいて治療効果を評価するよう依頼しました。スポンサー付きコンテンツは二種類を調査します：1) 製品の効果には言及せず直接的に販売を行う広告。また、2) クエリに関連する条件に対する製品の効果を明言して推奨する広告。結果として、これら二種類の広告がユーザーに与える影響には有意差があることが明らかになりました。ユーザーは主に直接的な広告を飛ばしがちですが、これが意思決定を傾けることもあります。一方、間接的な広告はユーザーの調査行動と治療の効果に対する認識の両方に影響を及ぼします。さらに、間接的な広告と自然検索結果における視点のコントラストが、ユーザーの意思決定に重要な役割を果たすことを発見しました。コントラストが高い場合、ユーザーは否定的な視点を強く支持し、コントラストが低いか無い場合、ユーザーはより肯定的な視点を支持する傾向にあります。
        </label>
        <input type="checkbox" id="Panel99" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Advertisements (ads) are an innate part of search engine business models. To promote sales, advertisers are willing to pay search engines to promote their content to a prominent position in the search result page (SERP). This raises concerns about the search engine manipulation effect (SEME): the opinions of users can be influenced by the way search results are presented In this work, we investigate the connection between SEME and sponsored content in the health domain. We conduct a series of user studies in which participants need to evaluate the effectiveness of different non-prescription natural remedies for various medical conditions. We present participants SERPs with different intentionally created biases towards certain viewpoints, with or without sponsored content, and ask them to evaluate the effectiveness of the treatment solely based on the information presented to them. We investigate two types of sponsored content: 1). Direct marketing ads that directly market the product without expressing an opinion about its effectiveness; and 2). Indirect marketing ads that explicitly advocate the product's effectiveness on the condition in the query. Our results reveal a significant difference between the influence on users from these two types of ads. Though users mostly skip direct marketing ads, they do sometimes tilt users' decision-making. Indirect marketing ads affect both the users' examination behavior and their perception of the treatment's effectiveness. We further discover that the contrast between the indirect marketing ads and the viewpoint presented in the organic search results plays an important role in users' decision-making. When the contrast is high, users exhibit a strong preference towards a negative viewpoint, and when the contrast is low or none, users exhibit a preference toward a more positive viewpoint.
        </div> </ul> <br>



        <label for="Panel100">
        <strong> Cone: Unsupervised Contrastive Opinion Extraction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Runcong+Zhao">Runcong Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lin+Gui">Lin Gui</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yulan+He">Yulan He</a> (1) </u>  <br>
        1:  King's College London <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591650">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Cone: Unsupervised Contrastive Opinion Extraction">Google Scholar</a></div>
        (100)
        <br>
        <b>概要:　</b> 対照的な意見抽出は、特定の側面やトピックに対する肯定的および否定的な視点として整理された構造化されたまたは重要なポイントを抽出することを目的としています。最新の無監督キーポイント抽出の多くは、テキストに表現された意見の人気度に基づいて、文クラスタリングや意見に依存しています。しかし、これらの方法は、非連続な文、相反する視点、冗長な側面を含むクラスタを生成する傾向があります。これらの問題を解決するために、擬似的な側面と感情のラベルを使用し、コントラスト学習と反復的な側面/感情クラスタリングの精緻化を組み合わせることにより、分離された潜在的な側面と感情の表現を学習する新しい無監督の対照的意見抽出モデル「Cone」を提案します。このモデルは、対照的な意見を抽出できるだけでなく、側面の相対的な人気とそれに関連する感情分布を定量化することもできます。ホテルレビューのデータセットとCOVIDワクチンに関するTwitterデータセットの両方で評価を行った結果、ラベルの監督や側面を示すシードワードを使用せずに、Coneは対照的意見抽出において多くの競争力のあるベースラインを上回ることが示されました。Coneの結果は、オンラインでの製品やサービスの推薦を改善するために使用できます。
        </label>
        <input type="checkbox" id="Panel100" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Contrastive opinion extraction aims to extract a structured summary or key points organised as positive and negative viewpoints towards a common aspect or topic. Most recent works for unsupervised key point extraction is largely built on sentence clustering or opinion summarisation based on the popularity of opinions expressed in text. However, these methods tend to generate aspect clusters with incoherent sentences, conflicting viewpoints, redundant aspects. To address these problems, we propose a novel unsupervised Contrastive OpinioN Extraction model, called Cone, which learns disentangled latent aspect and sentiment representations based on pseudo aspect and sentiment labels by combining contrastive learning with iterative aspect/sentiment clustering refinement. Apart from being able to extract contrastive opinions, it is also able to quantify the relative popularity of aspects and their associated sentiment distributions. The model has been evaluated on both a hotel review dataset and a Twitter dataset about COVID vaccines. The results show that despite using no label supervision or aspect-denoted seed words, Cone outperforms a number of competitive baselines on contrastive opinion extraction. The results of Cone can be used to offer a better recommendation of products and services online.
        </div> </ul> <br>



        <label for="Panel101">
        <strong> AdaMCL: Adaptive Fusion Multi-View Contrastive Learning for Collaborative Filtering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guanghui+Zhu">Guanghui Zhu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wang+Lu">Wang Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chunfeng+Yuan">Chunfeng Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yihua+Huang">Yihua Huang</a> (1) </u>  <br>
        1:  Nanjing University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591632">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=AdaMCL: Adaptive Fusion Multi-View Contrastive Learning for Collaborative Filtering">Google Scholar</a></div>
        (101)
        <br>
        <b>概要:　</b> グラフ協調フィルタリングは、ユーザーのアイテムに対する嗜好をキャプチャする上で大きな成功を収めています。しかし、その有効性にもかかわらず、グラフニューラルネットワーク（GNN）ベースの手法は、実際のシナリオにおけるデータのスパース性に悩まされています。最近では、このデータスパース性の問題を解決するためにコントラスト学習（CL）が使用されています。しかし、ほとんどのCLベースの手法は、CLタスクを構築する際にユーザーとアイテムの相互作用グラフだけを活用しており、高次情報（ユーザー間およびアイテム間の関係）の明示的な利用には欠けています。さらに、高次情報を使用するCLベースの手法においても、その受信領域は固定されており、ノード間の違いを考慮していません。本論文では、グラフ協調フィルタリングのための新しい適応型マルチビュー融合コントラスト学習フレームワークであるAdaMCLを提案します。高次情報をより正確に活用するために、ユーザーアイテムおよびユーザー間グラフから学習した埋め込みを融合する適応的な融合戦略を提案します。さらに、効果的なCLタスクを構築するためのマルチビュー融合コントラスト学習パラダイムを提案します。加えて、高次近傍の集約に伴うノイズ情報を軽減するために、レイヤーレベルのCLタスクを導入します。広範な実験結果により、AdaMCLが効果的であり、既存の協調フィルタリングモデルを大幅に上回ることが明らかになりました。
        </label>
        <input type="checkbox" id="Panel101" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Graph collaborative filtering has achieved great success in capturing users' preferences over items. Despite effectiveness, graph neural network (GNN)-based methods suffer from data sparsity in real scenarios. Recently, contrastive learning (CL) has been used to address the problem of data sparsity. However, most CL-based methods only leverage the original user-item interaction graph to construct the CL task, lacking the explicit exploitation of the higher-order information (i.e., user-user and item-item relationships). Even for the CL-based method that uses the higher-order information, the reception field of the higher-order information is fixed and regardless of the difference between nodes. In this paper, we propose a novel adaptive multi-view fusion contrastive learning framework, named AdaMCL, for graph collaborative filtering. To exploit the higher-order information more accurately, we propose an adaptive fusion strategy to fuse the embeddings learned from the user-item and user-user graphs. Moreover, we propose a multi-view fusion contrastive learning paradigm to construct effective CL tasks. Besides, to alleviate the noisy information caused by aggregating higher-order neighbors, we propose a layer-level CL task. Extensive experimental results reveal that AdaMCL is effective and outperforms existing collaborative filtering models significantly.
        </div> </ul> <br>



        <label for="Panel102">
        <strong> Triple Structural Information Modelling for Accurate, Explainable and Interactive Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiahao+Liu">Jiahao Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongsheng+Li">Dongsheng Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hansu+Gu">Hansu Gu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tun+Lu">Tun Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peng+Zhang">Peng Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Li+Shang">Li Shang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ning+Gu">Ning Gu</a> (1) </u>  <br>
        1:  Fudan University, 2:  Independent <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591779">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Triple Structural Information Modelling for Accurate, Explainable and Interactive Recommendation">Google Scholar</a></div>
        (102)
        <br>
        <b>概要:　</b> 動的相互作用グラフにおいて、ユーザーとアイテムの相互作用は通常、ユーザーとアイテムの同時発生、ユーザー相互作用の時系列情報、アイテムペアの遷移確率といった異なる構造情報によって異質なパターンに従います。しかし、既存の方法ではこれら三つの構造情報を同時に活用することができず、最適でないパフォーマンスをもたらします。これを解決するために、動的相互作用グラフ上で正確かつ説明可能でインタラクティブな推薦を行うための三重構造情報モデリング方法であるØursを提案します。具体的には、Øursは以下の要素から構成されます：1) インクリメンタル特異値分解（SVD）を用いた動的理想ローパスグラフフィルタによって、ユーザーとアイテムの相互作用の同時発生情報を動的に抽出する、2) パラメータフリーのアテンションモジュールによってユーザー相互作用の時系列情報を効率的かつ効果的に捕捉する、3) アイテムペアの遷移確率を格納するアイテム遷移行列。これら三重の構造情報源からの予測を融合し、最終的な推薦結果を得ます。SVDベースの協調フィルタリング方法と最近注目されているグラフ信号処理（GSP）ベースの方法との関係を分析することで、SVDの本質が理想的なローパスグラフフィルタであることを確認し、その結果、Øursにおける興味ベクトル空間を拡張し、説明可能でインタラクティブな推薦を実現します。これにより、ユーザーが情報のコクーンを積極的に突破することが可能になります。六つの公開データセットで行った実験で、Øursの正確性、説明可能性、およびインタラクティブ性における有効性が実証されました。
        </label>
        <input type="checkbox" id="Panel102" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In dynamic interaction graphs, user-item interactions usually follow heterogeneous patterns, represented by different structural information, such as user-item co-occurrence, sequential information of user interactions and the transition probabilities of item pairs. However, the existing methods cannot simultaneously leverage all three structural information, resulting in suboptimal performance. To this end, we propose øurs, a triple structural information modeling method for accurate, explainable and interactive recommendation on dynamic interaction graphs. Specifically, øurs consists of 1) a dynamic ideal low-pass graph filter to dynamically mine co-occurrence information in user-item interactions, which is implemented by incremental singular value ecomposition (SVD); 2) a parameter-free attention module to capture sequential information of user interactions effectively and efficiently; and 3) an item transition matrix to store the transition probabilities of item pairs. Then, we fuse the predictions from the triple structural information sources to obtain the final recommendation results. By analyzing the relationship between the SVD-based and the recently emerging graph signal processing (GSP)-based collaborative filtering methods, we find that the essence of SVD is an ideal low-pass graph filter, so that the interest vector space in øurs can be extended to achieve explainable and interactive recommendation, making it possible for users to actively break through the information cocoons. Experiments on six public datasets demonstrated the effectiveness of øurs in accuracy, explainability and interactivity.
        </div> </ul> <br>



        <label for="Panel103">
        <strong> Blurring-Sharpening Process Models for Collaborative Filtering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jeongwhan+Choi">Jeongwhan Choi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Seoyoung+Hong">Seoyoung Hong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Noseong+Park">Noseong Park</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sung-Bae+Cho">Sung-Bae Cho</a> (1) </u>  <br>
        1:  Yonsei University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591645">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Blurring-Sharpening Process Models for Collaborative Filtering">Google Scholar</a></div>
        (103)
        <br>
        <b>概要:　</b> コラボレーティブ・フィルタリングはレコメンダーシステムの中で最も基本的なトピックの一つです。マトリックス分解からグラフ畳み込み法まで、様々な手法が提案されています。最近のグラフフィルタリングベースの手法やスコアベースの生成モデル（SGM）の成功に触発され、私たちは新しい概念であるブラーフィルタリングとシャープフィルタリングプロセスモデル（BSPM）を提案します。SGMとBSPMは、もとの情報をまず攪乱し、その後元の形に回復させることで新しい情報を発見するという、同じ処理哲学を共有しています（例えば、SGMの場合は新しい画像が生成されます）。しかし、SGMと私たちのBSPMは異なる種類の情報を扱っており、その最適な攪乱と回復プロセスには根本的な違いがあります。したがって、BSPMはSGMとは異なる形式を持っています。さらに、私たちの概念は、多くの既存のコラボレーティブ・フィルタリングモデルを理論的に包含するだけでなく、3つのベンチマークデータセット（Gowalla、Yelp2018、Amazon-book）において、RecallとNDCGの点でそれらを上回っています。また、私たちの手法の処理時間は他の高速なベースラインとも比較可能です。今後、私たちの提案する概念は、本論文で使用したものよりも良いブラーリング（すなわち攪乱）およびシャープニング（すなわち回復）プロセスを設計することでさらに強化される可能性があります。私たちのコードはhttps://github.com/jeongwhanchoi/BSPMで入手可能です。
        </label>
        <input type="checkbox" id="Panel103" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Collaborative filtering is one of the most fundamental topics for recommender systems. Various methods have been proposed for collaborative filtering, ranging from matrix factorization to graph convolutional methods. Being inspired by recent successes of graph filtering-based methods and score-based generative models (SGMs), we present a novel concept of blurring-sharpening process model (BSPM). SGMs and BSPMs share the same processing philosophy that new information can be discovered (e.g., new images are generated in the case of SGMs) while original information is first perturbed and then recovered to its original form. However, SGMs and our BSPMs deal with different types of information, and their optimal perturbation and recovery processes have fundamental discrepancies. Therefore, our BSPMs have different forms from SGMs. In addition, our concept not only theoretically subsumes many existing collaborative filtering models but also outperforms them in terms of Recall and NDCG in the three benchmark datasets, Gowalla, Yelp2018, and Amazon-book. In addition, the processing time of our method is comparable to other fast baselines. Our proposed concept has much potential in the future to be enhanced by designing better blurring (i.e., perturbation) and sharpening (i.e., recovery) processes than what we use in this paper. Our code is available at https://github.com/jeongwhanchoi/BSPM.
        </div> </ul> <br>



        <label for="Panel104">
        <strong> Collaborative Residual Metric Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tianjun+Wei">Tianjun Wei</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianghong+Ma">Jianghong Ma</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tommy+W.S.+Chow">Tommy W.S. Chow</a> (1) </u>  <br>
        1:  City University of Hong Kong, 2:  City University of Hong Kong <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591649">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Collaborative Residual Metric Learning">Google Scholar</a></div>
        (104)
        <br>
        <b>概要:　</b> 協調フィルタリングにおいて、距離計量学習は行列分解の手法に対して有望な結果をもたらしています。しかし、行列分解は協力的な情報を捉える能力に欠けており、これは最近の研究で指摘され、ユーザーの相互作用を信号として解釈することで改善されてきました。本論文は、距離計量学習がこれらの信号ベースのモデルとどのように結びつくかを解明することを目的としています。一般化された距離計量を採用することで、信号ベースのモデルにおいては、距離そのものを推定するよりも、ユーザーからターゲット項目や他の項目への距離の差である距離の残差を推定する方が容易であることを発見しました。さらに分析を進めると、相互作用信号の正規化の強さと推薦の新規性との関連性が明らかになり、これは既存の研究で見逃されていました。上記の発見に基づき、距離の残差をモデル化することによって相互作用信号におけるユーザーの好みを捉える、一般化されたユーザー項目距離計量を学習するための新しいモデルを提案します。提案するCoRMLモデルは、新たに導入された近似ランク重み付けによりトレーニング効率がさらに向上しました。4つの公開データセットで行われた広範な実験により、CoRMLは協調フィルタリングにおいて最先端のベースラインモデルと比較して優れた性能を示し、高い効率性と新規性を促進する推薦を提供する能力も持っていることが実証され、計量学習ベースの推薦システムの研究に新たな視点をもたらします。
        </label>
        <input type="checkbox" id="Panel104" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In collaborative filtering, distance metric learning has been applied to matrix factorization techniques with promising results. However, matrix factorization lacks the ability of capturing collaborative information, which has been remarked by recent works and improved by interpreting user interactions as signals. This paper aims to find out how metric learning connect to these signal-based models. By adopting a generalized distance metric, we discovered that in signal-based models, it is easier to estimate the residual of distances, which refers to the difference between the distances from a user to a target item and another item, rather than estimating the distances themselves. Further analysis also uncovers a link between the normalization strength of interaction signals and the novelty of recommendation, which has been overlooked by existing studies. Based on the above findings, we propose a novel model to learn a generalized distance user-item distance metric to capture user preference in interaction signals by modeling the residuals of distance. The proposed CoRML model is then further improved in training efficiency by a newly introduced approximated ranking weight. Extensive experiments conducted on 4 public datasets demonstrate the superior performance of CoRML compared to the state-of-the-art baselines in collaborative filtering, along with high efficiency and the ability of providing novelty-promoted recommendations, shedding new light on the study of metric learning-based recommender systems.
        </div> </ul> <br>



        <label for="Panel105">
        <strong> Generative-Contrastive Graph Learning for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yonghui+Yang">Yonghui Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhengwei+Wu">Zhengwei Wu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Le+Wu">Le Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kun+Zhang">Kun Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Richang+Hong">Richang Hong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Zhang">Zhiqiang Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Meng+Wang">Meng Wang</a> (1) </u>  <br>
        1:  Hefei University of Technology, 2:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591691">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Generative-Contrastive Graph Learning for Recommendation">Google Scholar</a></div>
        (105)
        <br>
        <b>概要:　</b> ユーザーのインタラクションをユーザーアイテムグラフとして扱うことにより、グラフ学習モデルは主にCollaborative Filtering~(CF)に基づくレコメンデーションに広く利用されてきました。 最近、研究者たちはスパースなスーパービジョンの問題を軽減するために、Graph Contrastive Learning~(GCL)技術をCFに導入しました。GCLでは、まずデータ拡張によって対比ビューを構築し、その後、対比ビュー間の相互情報量を最大化することで自己教師信号を提供します。 しかし、その効果にもかかわらず、現在のGCLベースのレコメンデーションモデルにはいくつかの制約があると考えます。具体的には、現在のデータ拡張手法では、構造拡張または特徴拡張のいずれかを選択します。まず、構造拡張はノードやエッジをランダムにドロップアウトするため、ユーザーアイテムグラフの本質的性質を損なう可能性があります。次に、特徴拡張は各ノードに同じスケールのノイズ拡張を施すため、グラフ上のノードの固有特性を無視しています。これらの制約に対処するために、新しいVariational Graph Generative-Contrastive Learning (VGCL)フレームワークを提案します。具体的には、変分グラフ再構成を利用して各ノードのガウス分布を推定し、推定された分布から複数のサンプリングを行うことで複数の対比ビューを生成し、生成学習と対比学習の橋渡しをします。生成された対比ビューは情報の歪みなく入力グラフを再構成できます。さらに、推定された分散は各ノードに合わせて調整され、最適化の際に各ノードの対比損失のスケールを調整します。推定された分布の類似性を考慮し、各ノードの対比ビューの一貫性を促進するノードレベルと、クラスタ内のノードの一貫性を促進するクラスタレベルのクラスタ対応二重対比学習を提案します。最後に、3つの公開データセットで行った広範な実験結果により、提案されたモデルの有効性が明確に示されました。
        </label>
        <input type="checkbox" id="Panel105" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> By treating users' interactions as a user-item graph, graph learning models have been widely deployed in Collaborative Filtering~(CF) based recommendation. Recently, researchers have introduced Graph Contrastive Learning~(GCL) techniques into CF to alleviate the sparse supervision issue, which first constructs contrastive views by data augmentations and then provides self-supervised signals by maximizing the mutual information between contrastive views. Despite the effectiveness, we argue that current GCL-based recommendation models are still limited as current data augmentation techniques, either structure augmentation or feature augmentation. First, structure augmentation randomly dropout nodes or edges, which is easy to destroy the intrinsic nature of the user-item graph. Second, feature augmentation imposes the same scale noise augmentation on each node, which neglects the unique characteristics of nodes on the graph. To tackle the above limitations, we propose a novel Variational Graph Generative-Contrastive Learning (VGCL) framework for recommendation. Specifically, we leverage variational graph reconstruction to estimate a Gaussian distribution of each node, then generate multiple contrastive views through multiple samplings from the estimated distributions, which builds a bridge between generative and contrastive learning. The generated contrastive views can well reconstruct the input graph without information distortion. Besides, the estimated variances are tailored to each node, which regulates the scale of contrastive loss for each node on optimization. Considering the similarity of the estimated distributions, we propose a cluster-aware twofold contrastive learning, a node-level to encourage consistency of a node's contrastive views and a cluster-level to encourage consistency of nodes in a cluster. Finally, extensive experimental results on three public datasets clearly demonstrate the effectiveness of the proposed model.
        </div> </ul> <br>



        <label for="Panel106">
        <strong> Hydrus: Improving Personalized Quality of Experience in Short-form Video Services </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiyu+Yuan">Zhiyu Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kai+Ren">Kai Ren</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gang+Wang">Gang Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Miao">Xin Miao</a> (3) </u>  <br>
        1:  Tsinghua University & Kuaishou, 2:  Kuaishou, 3:  Tsinghua University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591696">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Hydrus: Improving Personalized Quality of Experience in Short-form Video Services">Google Scholar</a></div>
        (106)
        <br>
        <b>概要:　</b> 従来のユーザー体験（QoE）向上策は、サーバー側の応答遅延を最小限に抑えることに焦点を当てていました。しかし、1,500万人のユーザーを分析したところ、ショートフォーム動画アプリでは、ユーザー体験は応答遅延と推薦精度の両方に依存することが分かりました。この観察結果は、サービスプロバイダーにとってのジレンマとなります。高精度な推薦を実現するためには、複雑な戦略の採用が求められ、それが大幅な応答遅延を引き起こすためです。我々のモチベーションは、ユーザーの応答遅延と推薦精度に対する感受性が大きく異なることに基づいています。言い換えれば、あるユーザーは高品質な動画を楽しむために20ミリ秒の遅延を受け入れる一方で、他のユーザーは遅延の最小化を最優先にします。これに着想を得て、我々はHydrusという新しいリソース配分システムを提案します。Hydrusは、応答遅延と推薦精度のトレードオフを行うことで、最適な個別化されたQoEを提供します。具体的には、リソース配分問題を効用最大化問題として定式化し、Hydrusは数ミリ秒以内に問題を解決することが保証されています。我々は、オフラインシミュレーションと、世界中に数億人のユーザーを持つ非常に人気のある動画アプリ「Kuaishou」でのオンライン実験を通して、Hydrusの有効性を実証しました。結果は、Hydrusが同じ遅延でQoEを35.6%向上させるか、同じQoEで遅延を10.1%削減できることを示しています。さらに、HydrusはQoEを低下させることなく、スループットを54.5%向上させることが可能です。オンラインのA/Bテストでも、Hydrusはクリック率（CTR）と視聴時間を有意に改善し、QoEを犠牲にせずにシステムリソースコストを削減することができます。
        </label>
        <input type="checkbox" id="Panel106" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Traditional approaches to improving users' quality of experience (QoE) focus on minimizing the latency on the server side. Through an analysis of 15 million users, however, we find that for short-form video apps, user experience depends on both response latency and recommendation accuracy. This observation brings a dilemma to service providers since improving recommendation accuracy requires adopting complex strategies that demand heavy computation, which substantially increases response latency. Our motivation is that users' sensitivity to response latency and recommendation accuracy varies greatly. In other words, some users would accept a 20ms increase in latency to enjoy higher-quality videos, while others prioritize minimizing lag above all else. Inspired by this, we present Hydrus, a novel resource allocation system that delivers the best possible personalized QoE by making tradeoffs between response latency and recommendation accuracy. Specifically, we formulate the resource allocation problem as a utility maximization problem, and Hydrus is guaranteed to solve the problem within a few milliseconds. We demonstrate the effectiveness of Hydrus through offline simulation and online experiments in Kuaishou, a massively popular video app with hundreds of millions of users worldwide. The results show that Hydrus can increase QoE by 35.6% with the same latency or reduce the latency by 10.1% with the same QoE. Furthermore, Hydrus can achieve 54.5% higher throughput without a decrease in QoE. In online A/B testing, Hydrus significantly improves click-through rate (CTR) and watch time; it can also reduce system resource costs without sacrificing QoE.
        </div> </ul> <br>



        <label for="Panel107">
        <strong> Disentangled Contrastive Collaborative Filtering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xubin+Ren">Xubin Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lianghao+Xia">Lianghao Xia</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiashu+Zhao">Jiashu Zhao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dawei+Yin">Dawei Yin</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chao+Huang">Chao Huang</a> (4) </u>  <br>
        1:  University of Hong Kong, 2:  Wilfrid Laurier University, 3:  Baidu Inc, 4:  University of Hong Kong <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591665">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Disentangled Contrastive Collaborative Filtering">Google Scholar</a></div>
        (107)
        <br>
        <b>概要:　</b> 最近の研究では、グラフニューラルネットワーク（GNN）が協調フィルタリング（CF）における高次関係をモデル化するために広く利用されていることが示されています。この研究ラインに向けて、グラフ対照学習（GCL）は、ユーザーおよびアイテムの表現を補強することによって、監督ラベル不足の問題を解決する強力な性能を発揮しています。多くの研究がその有効性を示している一方で、未解決の重要な2つの課題が残っています。i) 既存の多くのGCLベースのCFモデルは、ユーザーとアイテムの相互作用が多様な潜在的意図要因（例：家族のパーティーの買い物、好みの色やブランド）によって駆動される事実を無視している点で依然として制約されています。ii) 紹介された非適応的な増強技術はノイズの多い情報に対して脆弱であり、モデルのロバスト性や誤った自己教師あり信号を取り込むリスクについて懸念されます。これらの制限を踏まえ、自己教師あり増強を適応的に実現するための意図解離のための分離対照協調フィルタリングフレームワーク（DCCF）を提案します。学習されたグローバルコンテキストを持つ分離表現により、DCCFは絡み合った自己監督信号からより細かな潜在要因を抽出するだけでなく、増強によるノイズも軽減します。最後に、パラメータ化された相互作用マスク生成器を使用して、適応的な増強を可能にするクロスビュー対照学習タスクを導入します。様々な公共データセットにおける実験により、既存のソリューションと比較して本手法の優越性が実証されました。我々のモデル実装は、リンクhttps://github.com/HKUDS/DCCFで公開されています。
        </label>
        <input type="checkbox" id="Panel107" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recent studies show that graph neural networks (GNNs) are prevalent to model high-order relationships for collaborative filtering (CF). Towards this research line, graph contrastive learning (GCL) has exhibited powerful performance in addressing the supervision label shortage issue by learning augmented user and item representations. While many of them show their effectiveness, two key questions still remain unexplored: i) Most existing GCL-based CF models are still limited by ignoring the fact that user-item interaction behaviors are often driven by diverse latent intent factors (e.g., shopping for family party, preferred color or brand of products); ii) Their introduced non-adaptive augmentation techniques are vulnerable to noisy information, which raises concerns about the model's robustness and the risk of incorporating misleading self-supervised signals. In light of these limitations, we propose a Disentangled Contrastive Collaborative Filtering framework (DCCF) to realize intent disentanglement with self-supervised augmentation in an adaptive fashion. With the learned disentangled representations with global context, our DCCF is able to not only distill finer-grained latent factors from the entangled self-supervision signals but also alleviate the augmentation-induced noise. Finally, the cross-view contrastive learning task is introduced to enable adaptive augmentation with our parameterized interaction mask generator. Experiments on various public datasets demonstrate the superiority of our method compared to existing solutions. Our model implementation is released at the link https://github.com/HKUDS/DCCF.
        </div> </ul> <br>



        <label for="Panel108">
        <strong> Aligning Distillation For Cold-start Item Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Feiran+Huang">Feiran Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zefan+Wang">Zefan Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Huang">Xiao Huang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yufeng+Qian">Yufeng Qian</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhetao+Li">Zhetao Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Chen">Hao Chen</a> (2) </u>  <br>
        1:  Jinan University, 2:  The Hong Kong Polytechnic University, 3:  Georgia Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591732">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Aligning Distillation For Cold-start Item Recommendation">Google Scholar</a></div>
        (108)
        <br>
        <b>概要:　</b> レコメンデーションシステムにおいて、コールドアイテムの推薦は、ユーザ行動に基づいて推薦されるウォームアイテムとは異なるため、長年の課題となっています。この問題を解決するために、生成モデルはコンテンツ特徴から合成埋め込みを生成し、ドロップアウトモデルは行動埋め込みをランダムにドロップアウトすることで推薦システムのロバスト性を向上させます。しかし、これらのモデルは主にコールドアイテムの推薦を扱うことに焦点を当てており、ウォームアイテムとコールドアイテムの推薦の違いを効果的に対処していません。その結果、生成モデルはウォームアイテムかコールドアイテムのどちらか一方に偏って推薦し、他方を無視する可能性があり、ドロップアウトモデルはウォームアイテムの推薦に悪影響を及ぼす可能性があります。この問題に対処するために、我々はAligning Distillation (ALDI)フレームワークを提案します。ALDIはウォームアイテムを「教師」として利用し、その行動情報をコールドアイテム（「生徒」）に転移させます。ALDIは特定のレーティング分布の整合、ランキングの整合、識別の整合といった損失を用いて、推薦特性の差を比較し、生徒と教師を整合させます。さらに、ALDIは信頼性の低い教師から不正確な情報を学習することを防ぐために、教師の資格を評価する重みづけ構造を取り入れています。3つのデータセットを用いた実験では、我々のアプローチが最先端のベースラインを上回り、全体的な性能、ウォームアイテムの性能、およびコールドアイテムの性能のいずれにおいても、3つの異なる推薦バックボーンで優れた結果を示しました。
        </label>
        <input type="checkbox" id="Panel108" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recommending cold items in recommendation systems is a longstanding challenge due to the inherent differences between warm items, which are recommended based on user behavior, and cold items, which are recommended based on content features. To tackle this, generative models generate synthetic embeddings from content features, while dropout models enhance the robustness of the recommendation system by randomly dropping behavioral embeddings during training. However, these models primarily focus on handling the recommendation of cold items, but do not effectively address the differences between warm and cold recommendations. As a result, generative models may over-recommend either warm or cold items, neglecting the other type, and dropout models may negatively impact warm item recommendations. To address this, we propose the Aligning Distillation (ALDI) framework, which leverages warm items as "teachers" to transfer their behavioral information to cold items, referred to as "students". ALDI aligns the students with the teachers by comparing the differences in their recommendation characters, using tailored rating distribution aligning, ranking aligning, and identification aligning losses to narrow these differences. Furthermore, ALDI incorporates a teacher-qualifying weighting structure to prevent students from learning inaccurate information from unreliable teachers. Experiments on three datasets show that our approach outperforms state-of-the-art baselines in terms of overall, warm, and cold recommendation performance with three different recommendation backbones.
        </div> </ul> <br>



        <label for="Panel109">
        <strong> M2EU: Meta Learning for Cold-start Recommendation via Enhancing User Preference Estimation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenchao+Wu">Zhenchao Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Zhou">Xiao Zhou</a> (1) </u>  <br>
        1:  Renmin University of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591719">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=M2EU: Meta Learning for Cold-start Recommendation via Enhancing User Preference Estimation">Google Scholar</a></div>
        (109)
        <br>
        <b>概要:　</b> コールドスタート問題は、限られたインタラクション情報しか持たないユーザーやアイテムに推奨を提供する際にレコメンダーシステムでよく遭遇する課題であり、システムの性能に深刻な影響を与えることがあります。この問題を克服するために、近年、メタラーニングに基づくアプローチが注目されてきました。これにより、モデルは事前トレーニング段階でユーザーの好みをグローバルに学習し、ターゲットユーザーに対しては少数のインタラクションでローカルなファインチューニングを行います。しかし、この方法で学習されたユーザー表現は、コールドスタートシナリオでは自身のインタラクションだけでは不十分であり、ユーザーの好みを十分に捕捉できない可能性があると考えます。この問題に対処するために、M2EUと名付けた新しいメタラーニング手法を提案します。これは、内在する属性と過去のインタラクションの類似性に基づいて特定された他の類似ユーザーからの情報を取り入れることで、コールドスタートユーザーの表現を豊かにします。さらに、類似ユーザーの埋め込み情報を集約する際に、評価値の分散に基づいたアテンションメカニズムを設計しました。ユーザーの嗜好モデリングの能力をさらに強化するために、異なるニューラルレイヤーでユーザーやアイテムの埋め込みを評価レベルで生成し、重み共有戦略を利用してメタラーニングアプローチにおけるニューラルレイヤーのパラメータを十分に学習させます。ミニバッチによるメタトレーニングでは、すべてのタスクに対して一般化されたパラメータセットを学習するためにインクリメンタル学習方式を採用しています。公開ベンチマークデータセットでの実験結果は、さまざまなコールドスタートシナリオにおいてM2EUが最先端の手法を凌駕することを、広範な定量評価を通じて示しています。
        </label>
        <input type="checkbox" id="Panel109" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The cold-start problem is commonly encountered in recommender systems when delivering recommendations to users or items with limited interaction information and can seriously harm the performance of the system. To cope with this issue, meta-learning-based approaches have come to the rescue in recent years by enabling models to learn user preferences globally in the pre-training stage followed by local fine-tuning for a target user with only a few interactions. However, we argue that the user representation learned in this way may be inadequate to capture user preference well since solely utilizing his/her own interactions may be far from enough in cold-start scenarios. To tackle this problem, we propose a novel meta-learning method named M2EU to enrich the representations of cold-start users by incorporating the information from other similar users who are identified based on the similarity of both inherent attributes and historical interactions. In addition, we design an attention mechanism according to the variances of ratings in the aggregation of similar user embeddings. To further enhance the capability of user preference modeling, we devise different neural layers to generate user or item embeddings at the rating level and utilize the weight-sharing strategy to guarantee adequate parameters learning of neural layers in our meta-learning approach. In meta-training with mini-batching, we adopt an incremental learning scheme to learn a set of generalized parameters for all tasks. Experimental results on the public benchmark datasets demonstrate that M2EU outperforms state-of-the-art methods through extensive quantitative evaluations in various cold-start scenarios.
        </div> </ul> <br>



        <label for="Panel110">
        <strong> A Preference Learning Decoupling Framework for User Cold-Start Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chunyang+Wang">Chunyang Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanmin+Zhu">Yanmin Zhu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Aixin+Sun">Aixin Sun</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaobo+Wang">Zhaobo Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ke+Wang">Ke Wang</a> (1) </u>  <br>
        1:  Shanghai Jiao Tong University, 2:  Nanyang Technological University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591627">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Preference Learning Decoupling Framework for User Cold-Start Recommendation">Google Scholar</a></div>
        (110)
        <br>
        <b>概要:　</b> 新しいユーザーのインタラクションが少ないため、ユーザーのコールドスタート問題は推薦システムにとって依然として大きな課題です。近年、メタラーニングに基づいた研究では、それぞれのコールドスタートユーザーをユーザー固有の少数ショットタスクとみなし、学習ユーザー全体で迅速なモデル適応のためのメタ知識を導出しています。しかし、既存の解決策はほとんどの場合、新しいユーザーの概念と新たな嗜好の概念を明確に区別しておらず、結果として新たなパターンに対するメタラーニングベースの適応性に過度に依存しています。加えて、既存のメタトレーニングタスクの構築は、本質的に記憶過剰適合の問題に悩まされており、新しいユーザーへのメタ一般化を妨げています。このような問題に対処するために、私たちはメタ増強（PDMA）を強化した嗜好学習分離フレームワークを提案し、ユーザーのコールドスタート推薦を行います。一般的なパターンへの不必要な適応からメタラーニングを救うために、私たちのフレームワークは、コールドスタートユーザーの嗜好学習を2つの補完的な側面、すなわち共通の嗜好転送と新しい嗜好適応に分離します。記憶過剰適合問題に対処するため、属性ベースのノイズを注入してメタトレーニングユーザーを増強し、互いに排他的なタスクを実現することを提案します。ベンチマークデータセットを用いた広範な実験により、私たちのフレームワークが最先端の方法と比較して優れた性能改善を達成することが示されました。また、提案したフレームワークが記憶過剰適合を軽減する効果的な手法であることも示されています。
        </label>
        <input type="checkbox" id="Panel110" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The issue of user cold-start poses a long-standing challenge to recommendation systems, due to the scarce interactions of new users. Recently, meta-learning based studies treat each cold-start user as a user-specific few-shot task and then derive meta-knowledge about fast model adaptation across training users. However, existing solutions mostly do not clearly distinguish the concept of new users and the concept of novel preferences, leading to over-reliance on meta-learning based adaptability to novel patterns. In addition, we also argue that the existing meta-training task construction inherently suffers from the memorization overfitting issue, which inevitably hinders meta-generalization to new users. In response to the aforementioned issues, we propose a preference learning decoupling framework, which is enhanced with meta-augmentation (PDMA), for user cold-start recommendation. To rescue the meta-learning from unnecessary adaptation to common patterns, our framework decouples preference learning for a cold-start user into two complementary aspects: common preference transfer, and novel preference adaptation. To handle the memorization overfitting issue, we further propose to augment meta-training users by injecting attribute-based noises, to achieve mutually-exclusive tasks. Extensive experiments on benchmark datasets demonstrate that our framework achieves superior performance improvements against state-of-the-art methods. We also show that our proposed framework is effective in alleviating memorization overfitting.
        </div> </ul> <br>



        <label for="Panel111">
        <strong> Exploring Scenarios of Uncertainty about the Users' Preferences in Interactive Recommendation Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nícollas+Silva">Nícollas Silva</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Thiago+Silva">Thiago Silva</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Henrique+Hott">Henrique Hott</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yan+Ribeiro">Yan Ribeiro</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Adriano+Pereira">Adriano Pereira</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Leonardo+Rocha">Leonardo Rocha</a> (2) </u>  <br>
        1:  Universidade Federal de Minas Gerais, 2:  Federal University of São João Del Rei <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591684">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Exploring Scenarios of Uncertainty about the Users' Preferences in Interactive Recommendation Systems">Google Scholar</a></div>
        (111)
        <br>
        <b>概要:　</b> 対話型リコメンダーシステムは、様々なエンターテイメント分野で文脈バンディットモデルを通じて重要な役割を果たしてきました。しかし、現在の進歩にもかかわらず、そのパーソナライズのレベルは依然としてユーザーに関する事前の情報に直接関連しています。とはいえ、ユーザーの好みに関して少なくとも二つの不確実なシナリオがあります：（1）ユーザーが初めて参加する場合、および（2）システムが以前の誤った仮定に基づいて継続的に間違った推薦を行う場合です。本研究では、このようなシナリオの影響を軽減するためにアクティブラーニング理論の概念を導入します。我々は、ユーザー情報をより多く取得する可能性が高いアイテムを推薦するように三つの伝統的なバンディットを修正し、不確実なシナリオが観察された場合でもモデルの精度を低下させないようにしました。我々の実験結果は、修正されたモデルが長期的には累積報酬を増加させ、すべてのベースラインを上回ることを示しています。さらに、反事実評価によって、これらの改善が単にオフラインデータセットのバイアスによって達成されたのではないことが確認されました。
        </label>
        <input type="checkbox" id="Panel111" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Interactive Recommender Systems have played a crucial role in distinct entertainment domains through a Contextual Bandit model. Despite the current advances, their personalisation level is still directly related to the information previously available about the users. However, there are at least two scenarios of uncertainty about the users' preferences over their journey: (1) when the user joins for the first time and (2) when the system continually makes wrong recommendations because of prior misleading assumptions. In this work, we introduce concepts from the Active Learning theory to mitigate the impact of such scenarios. We modify three traditional bandits to recommend items with a higher potential to get more user information without decreasing the model's accuracy when an uncertain scenario is observed. Our experiments show that the modified models outperform all baselines by increasing the cumulative reward in the long run. Moreover, a counterfactual evaluation validates that such improvements were not simply achieved due to the bias of offline datasets.
        </div> </ul> <br>



        <label for="Panel112">
        <strong> Topic-enhanced Graph Neural Networks for Extraction-based Explainable Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jie+Shuai">Jie Shuai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Le+Wu">Le Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kun+Zhang">Kun Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peijie+Sun">Peijie Sun</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Richang+Hong">Richang Hong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Meng+Wang">Meng Wang</a> (1) </u>  <br>
        1:  Hefei University of Technology, 2:  Tsinghua University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591776">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Topic-enhanced Graph Neural Networks for Extraction-based Explainable Recommendation">Google Scholar</a></div>
        (112)
        <br>
        <b>概要:　</b> レビュー情報は説明可能なレコメンデーションにおいて有益であることが示されています。これは生成ベースの手法における訓練コーパスや、抽出ベースのモデルにおける知識ベースとして扱うことができます。しかし、生成ベースの手法では、ユーザ生成レビューのスパース性と生成言語モデルの高い複雑性のために、パーソナライズ化と適応性に欠ける問題があります。抽出ベースの手法では関連属性にのみ焦点を当てるため、明示的な属性語がない状況では有効ではなく、抽出ベースのモデルの可能性が制限されます。この問題に対処するため、本研究ではレビュー情報の明示的および暗黙的な分析に注目し、新たにトピック強化型グラフニューラルネットワーク（TGNN）を提案し、より良い説明可能なレコメンデーションを実現します。具体的には、まず事前学習済みのトピックモデルを用いてトピックレベルでレビューを分析し、トピックをユーザとアイテムの間の中間ノードとしてモデル化する文強化型トピックグラフを設計します。対応する文はエッジ特徴量として機能します。これにより、明示的な属性語の必要性が軽減されます。同時に、レビューをエッジ特徴量として考慮するレビュー強化型評価グラフを活用し、精細なユーザ-アイテムのインタラクションをモデル化します。次に、2つのグラフから得られたユーザとアイテムの表現を最終的なレーティング予測と説明抽出に使用します。3つの実世界データセットにおける広範な実験により、当提案のTGNNの推薦精度と説明品質の両方における優位性が実証されました。
        </label>
        <input type="checkbox" id="Panel112" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Review information has been demonstrated beneficial for the explainable recommendation. It can be treated as training corpora for generation-based methods or knowledge bases for extraction-based models. However, for generation-based methods, the sparsity of user-generated reviews and the high complexity of generative language models lead to a lack of personalization and adaptability. For extraction-based methods, focusing only on relevant attributes makes them invalid in situations where explicit attribute words are absent, limiting the potential of extraction-based models. To this end, in this paper, we focus on the explicit and implicit analysis of review information simultaneously and propose novel a Topic-enhanced Graph Neural Networks (TGNN) to fully explore review information for better explainable recommendations. To be specific, we first use a pre-trained topic model to analyze reviews at the topic level, and design a sentence-enhanced topic graph to model user preference explicitly, where topics are intermediate nodes between users and items. Corresponding sentences serve as edge features. Thus, the requirement of explicit attribute words can be mitigated. Meanwhile, we leverage a review-enhanced rating graph to model user preference implicitly, where reviews are also considered as edge features for fine-grained user-item interaction modeling. Next, user and item representations from two graphs are used for final rating prediction and explanation extraction. Extensive experiments on three real-world datasets demonstrate the superiority of our proposed TGNN with both recommendation accuracy and explanation quality.
        </div> </ul> <br>



        <label for="Panel113">
        <strong> Strategy-aware Bundle Recommender System </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yinwei+Wei">Yinwei Wei</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaohao+Liu">Xiaohao Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunshan+Ma">Yunshan Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Wang">Xiang Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liqiang+Nie">Liqiang Nie</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tat-Seng+Chua">Tat-Seng Chua</a> (1) </u>  <br>
        1:  National University of Singapore, 2:  University of Chinese Academy of Sciences, 3:  University of Science and Technology of China, 4:  Harbin Institute of Technology (Shenzhen) <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591771">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Strategy-aware Bundle Recommender System">Google Scholar</a></div>
        (113)
        <br>
        <b>概要:　</b> バンドルとは、ユーザーに向上したサービスを提供し、売り手にとって利益を増加させるアイテムのグループです。しかし、ユーザーの好みに合ったバンドルを見つけ出すことは、データのスパース性の問題により依然として困難です。既存のアプローチは顕著な成果を上げていますが、バンドル内のアイテムがどのように関連付けられているか（バンドル戦略）を考慮することは稀であり、その結果、ユーザーとバンドルの表現がサブ最適な状態での予測に繋がっていると主張します。そこで、本研究では、バンドル推奨のための戦略を考慮したユーザーとバンドルの表現をモデル化することを提案します。この目的のために、新しいバンドル推奨モデルであるBundle Graph Transformer（BundleGT）を開発しました。このモデルは、トークン埋め込みレイヤー、階層的グラフトランスフォーマー（HGT）レイヤー、および予測レイヤーで構成されています。具体的には、トークン埋め込みレイヤーでバンドル内のアイテムをトークンとして扱い、ユーザーとアイテムの相互作用から学習したアイテムID埋め込みで表現します。入力トークンを持つことで、HGTレイヤーは戦略を考慮したバンドルおよびユーザーの表現を同時にモデル化できます。バンドル戦略の事前知識を良く設計されたバンドルからエンコードし、それをトークンの埋め込みに組み込むことで、戦略を考慮したバンドルの表現を学習します。一方、同じユーザーによって消費されるバンドル間の相関を考慮し、バンドル戦略に対するユーザーの嗜好をさらに学習します。これをアイテムコンテンツに対するユーザーの嗜好と合わせて考慮することで、ユーザーとバンドルの相互作用予測のための戦略を考慮したユーザー表現を学ぶことができます。Youshu、ifashion、およびNeteaseのデータセットで広範な実験を行い、提案モデルが最先端のベースライン（例えば、BundleNet [7]、BGCN [3]、およびCrossCBR [22]）を上回る性能を発揮することを示し、提案モデルの有効性を正当化しました。さらに、HGTレイヤー内で考案された軽量なセルフアテンションブロックは、BundleGTの精度性能だけでなく効率も向上させることができます。コードは以下で公開されています：https://github.com/Xiaohao-Liu/BundleGT。
        </label>
        <input type="checkbox" id="Panel113" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> A bundle is a group of items that provides improved services to users and increased profits for sellers. However, locating the desired bundles that match the users' tastes still challenges us, due to the sparsity issue. Despite the remarkable performance of existing approaches, we argue that they seldom consider the bundling strategy (i.e., how the items within a bundle are associated with each other) in the bundle recommendation, resulting in the suboptimal user and bundle representations for their interaction prediction. Therefore, we propose to model the strategy-aware user and bundle representations for the bundle recommendation. Towards this end, we develop a new model for bundle recommendation, termed Bundle Graph Transformer (BundleGT), which consists of the token embedding layer, hierarchical graph transformer (HGT) layer, and prediction layer. Specifically, in the token embedding layer, we take the items within bundles as tokens and represent them with items' id embedding learned from user-item interactions. Having the input tokens, the HGT layer can simultaneously model the strategy-aware bundle and user representations. Therein, we encode the prior knowledge of bundling strategy from the well-designed bundles and incorporate it with tokens' embeddings to model the bundling strategy and learn the strategy-aware bundle representations. Meanwhile, upon the correlation between bundles consumed by the same user, we further learn the user preference on bundling strategy. Jointly considering it with the user preference on the item content, we can learn the strategy-aware user representation for user-bundle interaction prediction. Conducting extensive experiments on Youshu, ifashion, and Netease datasets, we demonstrate that our proposed model outperforms the state-of-the-art baselines (e.g., BundelNet [7] Net, BGCN [3] BGCN, and CrossCBR [22]), justifying the effectiveness of our proposed model. Moreover, in HGT layer, our devised light self-attention block improves not only the accuracy performance but efficiency of BundleGT. Our code is publicly available at: https://github.com/Xiaohao-Liu/BundleGT.
        </div> </ul> <br>



        <label for="Panel114">
        <strong> Soft Prompt Decoding for Multilingual Dense Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqi+Huang">Zhiqi Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hansi+Zeng">Hansi Zeng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hamed+Zamani">Hamed Zamani</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=James+Allan">James Allan</a> (1) </u>  <br>
        1:  University of Massachusetts Amherst <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591769">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Soft Prompt Decoding for Multilingual Dense Retrieval">Google Scholar</a></div>
        (114)
        <br>
        <b>概要:　</b> 本研究では、複数言語の文書を含むコレクションに対して、マルチリンガル情報検索（MLIR）タスクを探求します。クロスリンガル情報検索のために開発された最先端のアプローチをMLIRタスクに適用すると、最適ではないパフォーマンスになることを示します。これは、マルチリンガルコレクションの異質性と不均衡性によるもので、一部の言語はコレクション内でより良く表現されており、大規模なトレーニングデータから恩恵を受けているからです。この問題に対処するために、KD-SPDというMLIRのための新しいソフトプロンプトデコーディングアプローチを提案します。これは異なる言語の文書の表現を同じ埋め込み空間に暗黙的に「翻訳」します。データの不足と不均衡の課題に対処するために、ナレッジディスティレーション戦略を導入します。教師モデルは豊富な英語の検索データで訓練され、バイテキストデータを活用することで、この蒸留フレームワークはその検索知識をマルチリンガル文書エンコーダーに転送します。したがって、我々のアプローチはマルチリンガルな検索トレーニングデータを必要としません。合計15の言語から成る3つのMLIRデータセットに関する広範な実験により、KD-SPDがすべてのケースで競争力のあるベースラインを大幅に上回ることを示します。我々の手法が言語バイアスを軽減し、新しい言語に対するゼロショット転送能力を向上させることを示す広範な分析も行っています。
        </label>
        <input type="checkbox" id="Panel114" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this work, we explore a Multilingual Information Retrieval (MLIR) task, where the collection includes documents in multiple languages. We demonstrate that applying state-of-the-art approaches developed for cross-lingual information retrieval to MLIR tasks leads to sub-optimal performance. This is due to the heterogeneous and imbalanced nature of multilingual collections -- some languages are better represented in the collection and some benefit from large-scale training data. To address this issue, we present KD-SPD, a novel soft prompt decoding approach for MLIR that implicitly "translates'' the representation of documents in different languages into the same embedding space. To address the challenges of data scarcity and imbalance, we introduce a knowledge distillation strategy. The teacher model is trained on rich English retrieval data, and by leveraging bi-text data, our distillation framework transfers its retrieval knowledge to the multilingual document encoder. Therefore, our approach does not require any multilingual retrieval training data. Extensive experiments on three MLIR datasets with a total of 15 languages demonstrate that KD-SPD significantly outperforms competitive baselines in all cases. We conduct extensive analyses to show that our method has less language bias and better zero-shot transfer ability towards new languages.
        </div> </ul> <br>



        <label for="Panel115">
        <strong> BLADE: Combining Vocabulary Pruning and Intermediate Pretraining for Scaleable Neural CLIR </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Suraj+Nair">Suraj Nair</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Eugene+Yang">Eugene Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dawn+Lawrie">Dawn Lawrie</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=James+Mayfield">James Mayfield</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Douglas+W.+Oard">Douglas W. Oard</a> (1) </u>  <br>
        1:  University of Maryland, 2:  Johns Hopkins University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591644">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=BLADE: Combining Vocabulary Pruning and Intermediate Pretraining for Scaleable Neural CLIR">Google Scholar</a></div>
        (115)
        <br>
        <b>概要:　</b> :<br>事前学習された言語モデルを用いてスパース表現を学習することは、単言語ランキングの有効性を高めることができます。このような表現は、文書の語彙から投影された言語モデルの語彙内にあるスパースベクトルです。多言語の事前学習された言語モデルを用いて、これらのアプローチをクロスランゲージ情報検索（CLIR）に拡張することには、二つの課題があります。第一に、多言語モデルの大きな語彙は、訓練と推論の両方の効率に影響を与えます。第二に、異なる言語の同義語の表現が十分に類似していない可能性があります。これらの問題に対処するために、語彙の削減とクロスランゲージの監督に基づく中間事前訓練を組み合わせた、学習されたスパース表現モデルであるBLADEを提案します。我々の実験結果は、機械翻訳された文書に対して単言語のモデルであるSPLADEと比較して、BLADEがインデックス作成時間を大幅に短縮し、他の効率的なCLIR手法の利点を補強するランキングを生成することを明らかにしました。
        </label>
        <input type="checkbox" id="Panel115" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Learning sparse representations using pretrained language models enhances the monolingual ranking effectiveness. Such representations are sparse vectors in the vocabulary of a language model projected from document terms. Extending such approaches to Cross-Language Information Retrieval (CLIR) using multilingual pretrained language models poses two challenges. First, the larger vocabularies of multilingual models affect both training and inference efficiency. Second, the representations of terms from different languages with similar meanings might not be sufficiently similar. To address these issues, we propose a learned sparse representation model, BLADE, combining vocabulary pruning with intermediate pre-training based on cross-language supervision. Our experiments reveal BLADE significantly reduces indexing time compared to its monolingual counterpart, SPLADE, on machine-translated documents, and it generates rankings with strengths complementary to those of other efficient CLIR methods.
        </div> </ul> <br>



        <label for="Panel116">
        <strong> Representation and Labeling Gap Bridging for Cross-lingual Named Entity Recognition </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinghua+Zhang">Xinghua Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bowen+Yu">Bowen Yu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiangxia+Cao">Jiangxia Cao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Quangang+Li">Quangang Li</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuebin+Wang">Xuebin Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tingwen+Liu">Tingwen Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongbo+Xu">Hongbo Xu</a> (3) </u>  <br>
        1:  Institute of Information Engineering, 2:  DAMO Academy, 3:  Institute of Information Engineering <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591757">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Representation and Labeling Gap Bridging for Cross-lingual Named Entity Recognition">Google Scholar</a></div>
        (116)
        <br>
        <b>概要:　</b> クロスリンガル固有表現認識（NER）は、リソースが少ない言語におけるデータ不足の課題を、高リソース言語からの知識を活用することで解決することを目指しています。現在の多くの研究は、テキストを表現するために一般的な多言語モデルに依存し、その後、古典的な結合タグ付け（例：B-ORG）を使用してエンティティを注釈付けします。しかし、このアプローチは言語モデルにおけるエンティティ表現のクロスリンガルな整合性の欠如を無視しており、また、エンティティのスパンとタイプが転移可能性の観点から異なるレベルのラベリングの難易度を持つことも無視しています。これらの課題に対処するために、表現とラベリングの問題を同時に解決する新しいフレームワーク「DLBri」を提案します。具体的には、提案されたフレームワークは、ターゲット向けの文ペアに対する進行的なコントラスト学習を利用して言語モデルを事前にファインチューニングし、クロスリンガルなエンティティに対する認識力を向上させます。さらに、エンティティのスパンとタイプを分解してそれぞれ転移し、その情報を結合する「分解-結合」手法を提案し、クロスリンガルなエンティティラベリングの難易度を低減します。13の多様な言語ペアに関する広範な実験により、DLBriの有効性が確認されました。
        </label>
        <input type="checkbox" id="Panel116" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Cross-lingual Named Entity Recognition (NER) aims to address the challenge of data scarcity in low-resource languages by leveraging knowledge from high-resource languages. Most current work relies on general multilingual language models to represent text, and then uses classic combined tagging (e.g., B-ORG) to annotate entities; However, this approach neglects the lack of cross-lingual alignment of entity representations in language models, and also ignores the fact that entity spans and types have varying levels of labeling difficulty in terms of transferability. To address these challenges, we propose a novel framework, referred to as DLBri, which addresses the issues of representation and labeling simultaneously. Specifically, the proposed framework utilizes progressive contrastive learning with source-to-target oriented sentence pairs to pre-finetune the language model, resulting in improved cross-lingual entity-aware representations. Additionally, a decomposition-then-combination procedure is proposed, which separately transfers entity span and type, and then combines their information, to reduce the difficulty of cross-lingual entity labeling. Extensive experiments on 13 diverse language pairs confirm the effectiveness of DLBri.
        </div> </ul> <br>



        <label for="Panel117">
        <strong> Rethinking Benchmarks for Cross-modal Image-text Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weijing+Chen">Weijing Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linli+Yao">Linli Yao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qin+Jin">Qin Jin</a> (1) </u>  <br>
        1:  Renmin University of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591758">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Rethinking Benchmarks for Cross-modal Image-text Retrieval">Google Scholar</a></div>
        (117)
        <br>
        <b>概要:　</b> 画像とテキストの検索は、情報検索の重要な分野として、広範な研究の注目を集めています。このタスクの主な課題は、クロスモーダルなセマンティックの理解と一致です。近年の研究では、より詳細なクロスモーダルセマンティックマッチングに焦点が当てられています。大規模なマルチモーダル事前学習モデルの普及に伴い、いくつかの最先端モデル（例: X-VLM）が、広く使用されている画像とテキストの検索ベンチマーク（MSCOCO-Test-5KやFlickr30K-Test-1K）でほぼ完璧な性能を達成しています。本論文では、これらの一般的なベンチマークを再評価し、これらが詳細なクロスモーダルセマンティックマッチングの真の能力を評価するには不十分であることを観察しました。その理由は、ベンチマーク内の多くの画像とテキストが粗粒度であるためです。この観察に基づき、旧ベンチマークの粗粒度の画像とテキストを改良し、改良版のベンチマークであるMSCOCO-FGとFlickr30K-FGを作成しました。具体的には、画像側ではより多くの類似画像を採用することで元の画像プールを拡大しました。テキスト側では、独自の半自動改良アプローチを提案し、最低限の人間の労力で粗粒度の文を詳細な文に改良しました。さらに、新しいベンチマークで代表的な画像とテキストの検索モデルを評価し、我々の手法の有効性を示しました。詳細なセマンティック理解におけるモデルの能力を、広範な実験を通じて分析しました。その結果、最先端のモデルでも、特に画像内の近接オブジェクトの属性を区別する能力において、多くの改善の余地があることが分かりました。我々のコードと改良されたベンチマークデータセットは公開されており、クロスモーダル検索に関するさらなる深入り研究への動機となることを望んでいます。
        </label>
        <input type="checkbox" id="Panel117" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Image-text retrieval, as a fundamental and important branch of information retrieval, has attracted extensive research attentions. The main challenge of this task is cross-modal semantic understanding and matching. Some recent works focus more on fine-grained cross-modal semantic matching. With the prevalence of large scale multimodal pretraining models, several state-of-the-art models (e.g. X-VLM) have achieved near-perfect performance on widely-used image-text retrieval benchmarks, i.e. MSCOCO-Test-5K and Flickr30K-Test-1K. In this paper, we review the two common benchmarks and observe that they are insufficient to assess the true capability of models on fine-grained cross-modal semantic matching. The reason is that a large amount of images and texts in the benchmarks are coarse-grained. Based on the observation, we renovate the coarse-grained images and texts in the old benchmarks and establish the improved benchmarks called MSCOCO-FG and Flickr30K-FG. Specifically, on the image side, we enlarge the original image pool by adopting more similar images. On the text side, we propose a novel semi-automatic renovation approach to refine coarse-grained sentences into finer-grained ones with little human effort. Furthermore, we evaluate representative image-text retrieval models on our new benchmarks to demonstrate the effectiveness of our method. We also analyze the capability of models on fine-grained semantic comprehension through extensive experiments. The results show that even the state-of-the-art models have much room for improvement in fine-grained semantic understanding, especially in distinguishing attributes of close objects in images. Our code and improved benchmark datasets are publicly available1 which we hope will inspire further in-depth research on cross-modal retrieval.
        </div> </ul> <br>



        <label for="Panel118">
        <strong> Learnable Pillar-based Re-ranking for Image-Text Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Leigang+Qu">Leigang Qu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Meng+Liu">Meng Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenjie+Wang">Wenjie Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhedong+Zheng">Zhedong Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liqiang+Nie">Liqiang Nie</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tat-Seng+Chua">Tat-Seng Chua</a> (1) </u>  <br>
        1:  National University of Singapore, 2:  Shandong Jianzhu University, 3:  Harbin Institute of Technology (Shenzhen) <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591712">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Learnable Pillar-based Re-ranking for Image-Text Retrieval">Google Scholar</a></div>
        (118)
        <br>
        <b>概要:　</b> 画像とテキストの検索は、モダリティのギャップを埋め、意味的な類似性に基づいてクロスモーダルなコンテンツを検索することを目的としています。これまでの研究は通常、ペアごとの関係（つまり、あるデータサンプルが他のサンプルと一致するかどうか）に注目していましたが、複数のデータサンプル間における一致構造（つまり、高次の近隣関係）を無視していました。再ランキングは、人気のある事後処理手法であり、単一モダリティの検索タスクにおいては近隣関係を捉える優位性を示しています。しかし、既存の再ランキングアルゴリズムを画像とテキストの検索に直接拡張することは効果的ではありません。本研究では、これを汎用性、柔軟性、スパース性、非対称性の四つの観点から分析し、新たに学習可能なピラー（柱）ベースの再ランキングパラダイムを提案します。具体的には、まずトップランクのイントラモダリティおよびインターモダリティの近隣を柱として選択し、その柱との近隣関係を用いてデータサンプルを再構築します。この方法により、各サンプルは類似性のみを使用してマルチモーダルな柱空間にマッピングされ、汎用性が確保されます。その後、近隣関係に基づくグラフ推論モジュールを設計し、近隣内のスパースな正の項目を柔軟に利用します。また、クロスモーダルなコラボレーションを促進し、非対称なモダリティを整合させるための構造整合制約を提示します。さまざまなベースバックボーンの上に、Flickr30KおよびMS-COCOという二つのベンチマークデータセットで広範な実験を行い、提案する再ランキングパラダイムの効果、優位性、汎用性、および転移可能性を実証しました。
        </label>
        <input type="checkbox" id="Panel118" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Image-text retrieval aims to bridge the modality gap and retrieve cross-modal content based on semantic similarities. Prior work usually focuses on the pairwise relations (i.e., whether a data sample matches another) but ignores the higher-order neighbor relations (i.e., a matching structure among multiple data samples). Re-ranking, a popular post-processing practice, has revealed the superiority of capturing neighbor relations in single-modality retrieval tasks. However, it is ineffective to directly extend existing re-ranking algorithms to image-text retrieval. In this paper, we analyze the reason from four perspectives, i.e., generalization, flexibility, sparsity, and asymmetry, and propose a novel learnable pillar-based re-ranking paradigm. Concretely, we first select top-ranked intra- and intermodal neighbors as pillars, and then reconstruct data samples with the neighbor relations between them and the pillars. In this way, each sample can be mapped into a multimodal pillar space only using similarities, ensuring generalization. After that, we design a neighbor-aware graph reasoning module to flexibly exploit the relations and excavate the sparse positive items within a neighborhood. We also present a structure alignment constraint to promote crossmodal collaboration and align the asymmetric modalities. On top of various base backbones, we carry out extensive experiments on two benchmark datasets, i.e., Flickr30K and MS-COCO, demonstrating the effectiveness, superiority, generalization, and transferability of our proposed re-ranking paradigm.
        </div> </ul> <br>



        <label for="Panel119">
        <strong> Keyword-Based Diverse Image Retrieval by Semantics-aware Contrastive Learning and Transformer </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Minyi+Zhao">Minyi Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinpeng+Wang">Jinpeng Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongliang+Liao">Dongliang Liao</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiru+Wang">Yiru Wang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huanzhong+Duan">Huanzhong Duan</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuigeng+Zhou">Shuigeng Zhou</a> (1) </u>  <br>
        1:  Fudan University, 2:  Tsinghua University, 3:  Tencent Inc., 4:  Tencent Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591705">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Keyword-Based Diverse Image Retrieval by Semantics-aware Contrastive Learning and Transformer">Google Scholar</a></div>
        (119)
        <br>
        <b>概要:　</b> 関連性に加えて、多様性もクロスモーダル画像検索システムの重要なパフォーマンス指標ですが、これはユーザー体験にとって非常に重要であるにもかかわらず、あまり研究が進んでいません。多様性対応の画像検索に対する既存のソリューションは、標準検索システムからの生データの検索結果を明示的に後処理するか、画像の多様なセマンティクスを表現するためにマルチベクトル表現を学習しようとします。しかし、どちらの方法も、関連性と多様性をバランス良く保つには十分ではありません。一方で、標準検索システムは通常、一般的なセマンティクスに偏りがあり、トレーニングにおいて多様性対応の正則化を利用することは稀であり、そのため後処理で多様性を促進するのは困難です。他方で、マルチベクトル表現法は、頑健な複数の射影を学習することが保証されていません。その結果、関係のない画像や稀少または独自のセマンティクスを持つ画像が不適切に射影される可能性があり、top-kのような典型的なアルゴリズムによって生成される結果の関連性と多様性が低下します。これらの問題に対応するため、本論文ではCoLTと呼ばれる新しい手法を提案し、画像を正確に分類するためのより代表的で頑健な表現を生成することを試みます。具体的には、CoLTはまず、セマンティクス対応コントラスト学習を用いて既存の一対一クロスモーダルシステムの初期表現を強化することで、セマンティクス対応の画像特徴を抽出します。その後、トランスフォーマーベースのトークンクラス分類器を開発し、すべての特徴を対応するカテゴリに取り込むようにします。最後に、最終的な検索結果を形成するために各カテゴリから画像を検索する後処理アルゴリズムを設計します。Div400およびDiv150Credという二つの実世界のデータセットに関する広範な実験により、CoLTが多様性を効果的に向上させ、従来の方法を全体として上回ること（より高いF1スコアで）が示されました。
        </label>
        <input type="checkbox" id="Panel119" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In addition to relevance, diversity is an important yet less studied performance metric of cross-modal image retrieval systems, which is critical to user experience. Existing solutions for diversity-aware image retrieval either explicitly post-process the raw retrieval results from standard retrieval systems or try to learn multi-vector representations of images to represent their diverse semantics. However, neither of them is good enough to balance relevance and diversity. On the one hand, standard retrieval systems are usually biased to common semantics and seldom exploit diversity-aware regularization in training, which makes it difficult to promote diversity by post-processing. On the other hand, multi-vector representation methods are not guaranteed to learn robust multiple projections. As a result, irrelevant images and images of rare or unique semantics may be projected inappropriately, which degrades the relevance and diversity of the results generated by some typical algorithms like top-k. To cope with these problems, this paper presents a new method called CoLT that tries to generate much more representative and robust representations for accurately classifying images. Specifically, CoLT first extracts semantics-aware image features by enhancing the preliminary representations of an existing one-to-one cross-modal system with semantics-aware contrastive learning. Then, a transformer-based token classifier is developed to subsume all the features into their corresponding categories. Finally, a post-processing algorithm is designed to retrieve images from each category to form the final retrieval result. Extensive experiments on two real-world datasets Div400 and Div150Cred show that CoLT can effectively boost diversity, and outperforms the existing methods as a whole (with a higher F1 score).
        </div> </ul> <br>



        <label for="Panel120">
        <strong> From Region to Patch: Attribute-Aware Foreground-Background Contrastive Learning for Fine-Grained Fashion Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianfeng+Dong">Jianfeng Dong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoman+Peng">Xiaoman Peng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhe+Ma">Zhe Ma</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daizong+Liu">Daizong Liu</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoye+Qu">Xiaoye Qu</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xun+Yang">Xun Yang</a> (6), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jixiang+Zhu">Jixiang Zhu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Baolong+Liu">Baolong Liu</a> (1) </u>  <br>
        1:  Zhejiang Gongshang University & Zhejiang Key Lab of E-Commerce, 2:  Zhejiang Gongshang University, 3:  Zhejiang University, 4:  Peking University, 5:  Huazhong University of Science and Technology, 6:  University of Science and Technology of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591690">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=From Region to Patch: Attribute-Aware Foreground-Background Contrastive Learning for Fine-Grained Fashion Retrieval">Google Scholar</a></div>
        (120)
        <br>
        <b>概要:　</b> 属性特化型ファッション検索（ASFR）は、近年ますます注目を集めている情報検索課題です。従来のファッション検索が主に全体的な類似性の最適化に焦点を当てているのに対し、ASFRタスクは属性特化の類似性に注目しており、より細やかで解釈しやすい検索結果を提供します。属性特化の類似性は通常、画像の特定の微細な領域に対応するため、我々は属性関連の視覚特徴を抽出するためのリージョンからパッチへのフレームワーク（RPF）を提案します。このフレームワークは、リージョン認識ブランチとパッチ認識ブランチで構成され、粗から細へのアプローチで正確な検索を実現します。具体的には、まずリージョン認識ブランチを用いて、与えられた属性のセマンティクスに関連する潜在的な領域を特定します。その後、特定された領域が粗く、背景の視覚内容を依然として含んでいることを考慮し、パッチ認識ブランチを用いて、前段階で拡大された領域からパッチ単位で属性関連の詳細を抽出します。このハイブリッドアーキテクチャにより、リージョンの特定と特徴抽出のバランスが取れます。さらに、従来の研究が属性関連の前景特徴の識別にのみ焦点を当てているのに対し、我々は属性非関連の背景特徴も対比的な方法で詳細な視覚コンテキストを区別するために重要であると主張します。従って、前景と背景の表現に基づく新しいE-InfoNCE損失を提案し、属性特化表現の識別性を向上させます。3つのデータセットに対する広範な実験により、提案したフレームワークの有効性が実証され、さらに我々のRPFがドメイン外のファッション画像に対しても優れた汎化性能を示すことが分かりました。我々のソースコードはhttps://github.com/HuiGuanLab/RPFで公開されています。
        </label>
        <input type="checkbox" id="Panel120" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Attribute-specific fashion retrieval (ASFR) is a challenging information retrieval task, which has attracted increasing attention in recent years. Different from traditional fashion retrieval which mainly focuses on optimizing holistic similarity, the ASFR task concentrates on attribute-specific similarity, resulting in more fine-grained and interpretable retrieval results. As the attribute-specific similarity typically corresponds to the specific subtle regions of images, we propose a Region-to-Patch Framework (RPF) that consists of a region-aware branch and a patch-aware branch to extract fine-grained attribute-related visual features for precise retrieval in a coarse-to-fine manner. In particular, the region-aware branch is first to be utilized to locate the potential regions related to the semantic of the given attribute. Then, considering that the located region is coarse and still contains the background visual contents, the patch-aware branch is proposed to capture patch-wise attribute-related details from the previous amplified region. Such a hybrid architecture strikes a proper balance between region localization and feature extraction. Besides, different from previous works that solely focus on discriminating the attribute-relevant foreground visual features, we argue that the attribute-irrelevant background features are also crucial for distinguishing the detailed visual contexts in a contrastive manner. Therefore, a novel E-InfoNCE loss based on the foreground and background representations is further proposed to improve the discrimination of attribute-specific representation. Extensive experiments on three datasets demonstrate the effectiveness of our proposed framework, and also show a decent generalization of our RPF on out-of-domain fashion images. Our source code is available at https://github.com/HuiGuanLab/RPF.
        </div> </ul> <br>



        <label for="Panel121">
        <strong> Multi-view Multi-aspect Neural Networks for Next-basket Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiying+Deng">Zhiying Deng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianjun+Li">Jianjun Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Guo">Zhiqiang Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Liu">Wei Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Li+Zou">Li Zou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guohui+Li">Guohui Li</a> (1) </u>  <br>
        1:  Huazhong University of Science and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591738">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multi-view Multi-aspect Neural Networks for Next-basket Recommendation">Google Scholar</a></div>
        (121)
        <br>
        <b>概要:　</b> 次バスケット推薦（NBR）は、ユーザーの歴史的なバスケットシーケンスに基づいて一連のアイテムを推薦することを目的とした推薦の一種です。既存のNBR方法には、次の二つの制限があります：（1）低レベルのアイテム間相関を見過ごしており、これが粗粒度のアイテム表現につながること、および（2）繰り返される行動における見せかけの興味を考慮に入れず、ユーザーの興味学習が最適でないことです。これらの制限を克服するために、私たちは次バスケット推薦の新しい解決策として、Multi-view Multi-aspect Neural Recommendation（MMNR）を提案します。MMNRは、まずユーザー側とアイテム側の両方からの相互作用を正規化し、それぞれが見せかけの興味を取り除くことを目指し、異なる視点からのアイテムを重みとして利用して各相互作用アイテムの差別化された表現を構築し、包括的なユーザーの興味を学習します。次に、低レベルのアイテム間相関をキャプチャするために、MMNRはアイテムの異なる側面をモデル化し、アイテムの解離した表現を取得することで、複数のユーザーの興味を完全にキャプチャします。実世界データセットを用いた広範な実験により、MMNRの有効性が実証され、複数の最先端のNBR方法を一貫して上回ることが示されました。
        </label>
        <input type="checkbox" id="Panel121" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Next-basket recommendation (NBR) is a type of recommendation that aims to recommend a set of items to users according to their historical basket sequences. Existing NBR methods suffer from two limitations: (1) overlooking low-level item correlations, which results in coarse-grained item representation; and (2) failing to consider spurious interests in repeated behaviors, leading to suboptimal user interest learning. To address these limitations, we propose a novel solution named Multi-view Multi-aspect Neural Recommendation (MMNR) for NBR, which first normalizes the interactions from both the user-side and item-side, respectively, aiming to remove the spurious interests, and utilizes them as weights for items from different views to construct differentiated representations for each interaction item, enabling comprehensive user interest learning. Then, to capture low-level item correlations, MMNR models different aspects of items to obtain disentangled representations of items, thereby fully capturing multiple user interests. Extensive experiments on real-world datasets demonstrate the effectiveness of MMNR, showing that it consistently outperforms several state-of-the-art NBR methods.
        </div> </ul> <br>



        <label for="Panel122">
        <strong> Cross-Market Product-Related Question Answering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Negin+Ghasemi">Negin Ghasemi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mohammad+Aliannejadi">Mohammad Aliannejadi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hamed+Bonab">Hamed Bonab</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Evangelos+Kanoulas">Evangelos Kanoulas</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Arjen+P.+de+Vries">Arjen P. de Vries</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=James+Allan">James Allan</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Djoerd+Hiemstra">Djoerd Hiemstra</a> (1) </u>  <br>
        1:  Radboud University, 2:  University of Amsterdam, 3:  Amazon Inc., 4:  University of Massachusetts Amherst <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591658">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Cross-Market Product-Related Question Answering">Google Scholar</a></div>
        (122)
        <br>
        <b>概要:　</b> Amazon、eBay、Etsyなどのオンラインショップは、複数の国でその存在感を拡大し続けており、何千もの商品がある資源の乏しい市場を創出しています。私たちは、商品のユーザー生成データ（例：評価、レビュー、商品に関連する質問）が限られている市場を資源の乏しい市場と考えます。このような市場では、情報検索システムがユーザーの質問に対する答えを見つけるのに役立つ可能性が低くなります。その結果、オンラインで投稿された質問が長期間未解決のままになることがあります。本研究では、資源の豊富な市場で利用可能なデータを使用して、資源の乏しい市場の新しい質問に答えるという、新しい問題であるクロスマーケット質問応答の影響を調査します。この問題の潜在的な影響を調査するために、Amazonの英国（資源の乏しい）および米国（資源の豊富な）の現地市場から新しいデータセットXMarket-QAを収集し、注釈を付けました。クロスマーケット質問応答タスクの範囲を理解するためにデータ分析を行いました。この分析では、英国市場で最初の質問が回答されるまでの時間ギャップがほぼ1年であることが示されました。また、英国市場で最初の質問が投稿されるのは、同じ商品に関して米国市場ですでに平均28の質問に回答されているときであることが示されています。人間の注釈から、英国市場の質問の65％が米国市場内で回答可能であり、クロスマーケット質問応答の概念が支持されることが示されています。これらの発見に触発され、トレーニングフェーズで商品の類似性を利用して、資源の豊富な市場からの回答を取得し、資源の乏しい市場での質問に答えるために使用できる新しい手法CMJimを開発しました。我々の評価では、CMJimが競争力のあるベースラインと比較して大幅な改善を示しました。
        </label>
        <input type="checkbox" id="Panel122" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Online shops such as Amazon, eBay, and Etsy continue to expand their presence in multiple countries, creating new resource-scarce marketplaces with thousands of items. We consider a marketplace to be resource-scarce when only limited user-generated data is available about the products (e.g., ratings, reviews, and product-related questions). In such a marketplace, an information retrieval system is less likely to help users find answers to their questions about the products. As a result, questions posted online may go unanswered for extended periods. This study investigates the impact of using available data in a resource-rich marketplace to answer new questions in a resource-scarce marketplace, a new problem we call cross-market question answering. To study this problem's potential impact, we collect and annotate a new dataset, XMarket-QA, from Amazon's UK (resource-scarce) and US (resource-rich) local marketplaces. We conduct a data analysis to understand the scope of the cross-market question-answering task. This analysis shows a temporal gap of almost one year between the first question answered in the UK marketplace and the US marketplace. Also, it shows that the first question about a product is posted in the UK marketplace only when 28 questions, on average, have already been answered about the same product in the US marketplace. Human annotations demonstrate that, on average, 65% of the questions in the UK marketplace can be answered within the US marketplace, supporting the concept of cross-market question answering. Inspired by these findings, we develop a new method, CMJim, which utilizes product similarities across marketplaces in the training phase for retrieving answers from the resource-rich marketplace that can be used to answer a question in the resource-scarce marketplace. Our evaluations show CMJim's significant improvement compared to competitive baselines.
        </div> </ul> <br>



        <label for="Panel123">
        <strong> Next Basket Recommendation with Intent-aware Hypergraph Adversarial Network </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ran+Li">Ran Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liang+Zhang">Liang Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guannan+Liu">Guannan Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junjie+Wu">Junjie Wu</a> (4) </u>  <br>
        1:  Beihang University, 2:  Nanyang Technological University, 3:  Beihang University & Key Laboratory of Data Intelligence and Management, 4:  Beihang University & Key Laboratory of Data Intelligence and Management <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591742">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Next Basket Recommendation with Intent-aware Hypergraph Adversarial Network">Google Scholar</a></div>
        (123)
        <br>
        <b>概要:　</b> 次のバスケット推奨 (Next Basket Recommendation, NBR)は、ユーザーにアイテムのバスケットを推奨することで、オンラインビジネスにおける有望なプロモーション手法となっています。NBRの主な課題は、同じバスケット内で互いに依存するアイテムの複雑な関係に根ざしており、ユーザーの多様な購買意図と関連しています。これは従来の推奨タスクにおけるペアワイズ（対アイテム）関係をはるかに超えており、既存のNBR手法が主にバスケット間のアイテム間関係のみをモデル化していることから十分に対処されていません。そのため、本研究では、バスケット単位の購買記録からハイパーグラフを構築し、ハイパーエッジの背後にあるバスケット間およびバスケット内のアイテム関係を探ります。特に、HyperGraph Neural Networkの強みを分解表現学習と組み合わせ、ハイパーエッジの購買意図を意識した表現を抽出し、ユーザーの購買パターンの微妙な違いを特徴付けます。さらに、従来のアイテム単位の最適化における情報損失を考慮し、対敵ネットワークを通じて高品質のネガティブバスケットを生成する新しいバスケット単位最適化手法を提案します。４つの異なるデータセットで実施された広範な実験により、最新のNBR手法に対する優れた性能が実証されました。特に、我々の方法は繰り返しと探索的の両方のアイテムをバスケットとしてバランスよく推奨することが示されました。
        </label>
        <input type="checkbox" id="Panel123" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Next Basket Recommendation (NBR) that recommends a basket of items to users has become a promising promotion artifice for online businesses. The key challenge of NBR is rooted in the complicated relations of items that are dependent on one another in a same basket with users' diverse purchasing intentions, which goes far beyond the pairwise item relations in traditional recommendation tasks, and yet has not been well addressed by existing NBR methods that mostly model the inter-basket item relations only. To that end, in this paper, we construct a hypergraph from basket-wise purchasing records and probe the inter-basket and intra-basket item relations behind the hyperedges. In particular, we combine the strength of HyperGraph Neural Network with disentangled representation learning to derive the intent-aware representations of hyperedges for characterizing the nuances of user purchasing patterns. Moreover, considering the information loss in traditional item-wise optimization, we propose a novel basket-wise optimization scheme via an adversarial network to generate high-quality negative baskets. Extensive experiments conducted on four different data sets demonstrate the superior performances over the state-of-the-art NBR methods. Notably, our method is shown to strike a good balance in recommending both repeated and explorative items as a basket.
        </div> </ul> <br>



        <label for="Panel124">
        <strong> When Search Meets Recommendation: Learning Disentangled Search Representation for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zihua+Si">Zihua Si</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhongxiang+Sun">Zhongxiang Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Zhang">Xiao Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Xu">Jun Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoxue+Zang">Xiaoxue Zang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Song">Yang Song</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kun+Gai">Kun Gai</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ji-Rong+Wen">Ji-Rong Wen</a> (1) </u>  <br>
        1:  Renmin University of China, 2:  Kuaishou Technology Co., 3:  Unaffiliated <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591786">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=When Search Meets Recommendation: Learning Disentangled Search Representation for Recommendation">Google Scholar</a></div>
        (124)
        <br>
        <b>概要:　</b> 摘要<br>現代のオンラインサービスプロバイダー、特にオンラインショッピングプラットフォームは、異なるユーザーニーズに応えるために検索および推薦（S&R）サービスの両方を提供しています。しかし、S&Rサービスからのユーザー行動データを効果的に統合する手段はほとんどありません。既存の多くのアプローチは、S&Rの行動を単純に別々に扱うか、両方のサービスからデータを集約して共同最適化するものです。しかし、これらはS&Rにおけるユーザーの意図が明確に異なることを無視しています。本論文では、S&R行動における類似および非類似の表現を分離することで、ユーザーの検索興味を推薦に活用する検索強化フレームワーク「SESRec」（Sequential Recommendation for Search-Enhanced）を提案します。具体的には、SESRecは、ユーザーの検索クエリとアイテムの相互作用に基づいてクエリとアイテムの埋め込みを整列させ、それらの類似性を計算します。2つのトランスフォーマーエンコーダを使用して、S&R行動の文脈的表現を独立して学習します。その後、コントラスト学習タスクを設計し、S&Rの行動シーケンスから類似および非類似の表現の分離を監督します。最後に、注意メカニズムを用いて、文脈的表現および類似・非類似の興味を含む2つの分離された行動の3つの視点からユーザーの興味を抽出します。産業データセットと公開データセットの両方で行った広範な実験により、SESRecが最新モデルを一貫して上回ることが示されました。実証的研究は、SESRecがS&R行動から類似および非類似のユーザー興味を成功裏に分離することをさらに検証しました。
        </label>
        <input type="checkbox" id="Panel124" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Modern online service providers such as online shopping platforms often provide both search and recommendation (S&R) services to meet different user needs. Rarely has there been any effective means of incorporating user behavior data from both S&R services. Most existing approaches either simply treat S&R behaviors separately, or jointly optimize them by aggregating data from both services, ignoring the fact that user intents in S&R can be distinctively different. In our paper, we propose a Search-Enhanced framework for the Sequential Recommendation (SESRec) that leverages users' search interests for recommendation, by disentangling similar and dissimilar representations within S&R behaviors. Specifically, SESRec first aligns query and item embeddings based on users' query-item interactions for the computations of their similarities. Two transformer encoders are used to learn the contextual representations of S&R behaviors independently. Then a contrastive learning task is designed to supervise the disentanglement of similar and dissimilar representations from behavior sequences of S&R. Finally, we extract user interests by the attention mechanism from three perspectives, i.e., the contextual representations, the two separated behaviors containing similar and dissimilar interests. Extensive experiments on both industrial and public datasets demonstrate that SESRec consistently outperforms state-of-the-art models. Empirical studies further validate that SESRec successfully disentangle similar and dissimilar user interests from their S&R behaviors.
        </div> </ul> <br>



        <label for="Panel125">
        <strong> Unsupervised Readability Assessment via Learning from Weak Readability Signals </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuliang+Liu">Yuliang Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiwei+Jiang">Zhiwei Jiang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yafeng+Yin">Yafeng Yin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cong+Wang">Cong Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sheng+Chen">Sheng Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaoling+Chen">Zhaoling Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qing+Gu">Qing Gu</a> (1) </u>  <br>
        1:  Nanjing University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591695">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Unsupervised Readability Assessment via Learning from Weak Readability Signals">Google Scholar</a></div>
        (125)
        <br>
        <b>概要:　</b> 教師なし可読性評価は、モデル訓練のための手動ラベル付きデータを使用せずに、テキストの読みやすさを評価することを目指します。ラベル付きデータの欠如により、モデルが可読性を理解するのが難しくなるため、これは困難な課題です。本論文では、「弱い可読性信号からニューラルモデルを学習するフレームワーク (Learning a neural model from Weak Readability Signals, LWRS)」を提案します。LWRSはラベル付きデータに依存するのではなく、異なる側面からテキストの可読性を記述する一連のヒューリスティック信号を利用し、モデルがランキングのための可読性スコアを出力するように導きます。具体的には、複数のヒューリスティックな弱い信号を効果的にモデル訓練に利用するために、我々は、ラベルなしテキストを複数の可読性関連の側面からランク付けするマルチシグナル学習モデルを構築しました。このモデルは、信号間および信号内学習に基づいてランク付けを行います。また、部分順序ペア間の連鎖結合を減らすために、ペアワイズランキングのパラダイムを採用しています。さらに、全ての信号のバッチレベルのコンセンサス分布に基づいて、最も代表的な信号を特定することを提案します。この戦略は、グラウンドトゥルースラベルがない状況でも、可読性と最も相関する予測信号を特定するのに役立ちます。3つの公共の可読性評価データセットで実験を行い、実験結果は、LWRSが各ヒューリスティック信号およびその組み合わせを大幅に上回り、いくつかの教師あり方法と同等の性能を発揮できることを示しています。さらに、一つのデータセットで訓練されたLWRSは、他のデータセット、さらには他言語のデータセットにも効果的に転移できることが実証されており、その優れた汎用性と広い応用可能性を示しています。
        </label>
        <input type="checkbox" id="Panel125" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Unsupervised readability assessment aims to evaluate the reading difficulty of text without any manually-labeled data for model training. This is a challenging task because the absence of labeled data makes it difficult for the model to understand what readability is. In this paper, we propose a novel framework to Learn a neural model from Weak Readability Signals (LWRS). Instead of relying on labeled data, LWRS utilizes a set of heuristic signals that specialize in describing text readability from different aspects to guide the model in outputting readability scores for ranking. Specifically, to effectively use multiple heuristic weak signals for model training, we build a multi-signal learning model that ranks the unlabeled texts from multiple readability-related aspects based on intra- and inter-signal learning. We also adopt the pairwise ranking paradigm to reduce the cascade coupling among partial-order pairs. Furthermore, we propose identifying the most representative signal based on the batch-level consensus distribution of all signals. This strategy helps identify the predicted signal that is most correlated with readability in the absence of ground-truth labels. We conduct experiments on three public readability assessment datasets. The experimental results demonstrate that our LWRS outperforms each heuristic signal and their combinations significantly, and can even perform comparably with some supervised methods. Additionally, our LWRS trained on one dataset can be effectively transferred to other datasets, including those in other languages, which indicates its good generalization and potential for wide application.
        </div> </ul> <br>



        <label for="Panel126">
        <strong> What If: Generating Code to Answer Simulation Questions in Chemistry Texts </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gal+Peretz">Gal Peretz</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mousa+Arraf">Mousa Arraf</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kira+Radinsky">Kira Radinsky</a> (1) </u>  <br>
        1:  Technion - Israel Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591783">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=What If: Generating Code to Answer Simulation Questions in Chemistry Texts">Google Scholar</a></div>
        (126)
        <br>
        <b>概要:　</b> 化学や生物学において、多くの文章が複雑なプロセスを記述しています。本研究では、化学反応プロセスを描写するテキストと、異なる環境条件下でそのプロセスの結果に関する質問に焦点を当てます。このようなプロセスに関する質問に答えるためには、プロセスに関与する様々な要素の相互作用を理解し、他の条件下でのプロセス実行中の状態遷移をシミュレートする必要があります。我々は、プロセスをシミュレートするためのコードを生成し実行することで、こうした質問に答えることができると仮定します。このため、プロセスを表現するためのドメイン固有言語（DSL）を定義します。我々は、化学者がキュレーションし、コンピュータ科学者が注釈を付けた一連の独自のデータセットをコミュニティに提供します。このデータセットは、プロセスのテキスト、シミュレーションに関する質問、およびDSLで表現された対応するコンピュータコードで構成されています。我々は、新しい状態遷移セマンティック報酬を用いた強化学習に基づくニューラルプログラム合成アプローチを提案します。この新しい報酬は、予測されたコードと参照コードとの実行時のセマンティック類似性に基づいています。これにより、複雑なプロセス遷移のシミュレーションが可能となり、シミュレーションに関する質問に答えることができます。我々のアプローチは、シミュレーション質問の精度を大幅に向上させました：最先端のニューラルプログラム合成アプローチの83%の精度および最先端のエンドツーエンドテキストベースアプローチの54%の精度に対し、我々は88%の精度を達成しました。
        </label>
        <input type="checkbox" id="Panel126" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Many texts, especially in chemistry and biology, describe complex processes. We focus on texts that describe a chemical reaction process and questions that ask about the process's outcome under different environmental conditions. To answer questions about such processes, one needs to understand the interactions between the different entities involved in the process and simulate their state transitions during the process execution under other conditions. We hypothesize that generating code and executing it to simulate the process will allow answering such questions. We, therefore, define a domain-specific language (DSL) to represent processes. We contribute to the community a unique dataset curated by chemists and annotated by computer scientists. The dataset is composed of process texts, simulation questions, and their corresponding computer codes represented by the DSL. We propose a neural program synthesis approach based on reinforcement learning with a novel state-transition semantic reward. The novel reward is based on the run-time semantic similarity between the predicted code and the reference code. This allows simulating complex process transitions and thus answering simulation questions. Our approach yields a significant boost in accuracy for simulation questions: we achieved 88% accuracy as opposed to 83% accuracy of the state-of-the-art neural program synthesis approaches and 54% accuracy of state-of-the-art end-to-end text-based approaches.
        </div> </ul> <br>



        <label for="Panel127">
        <strong> ErrorCLR: Semantic Error Classification, Localization and Repair for Introductory Programming Assignments </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siqi+Han">Siqi Han</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yu+Wang">Yu Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuesong+Lu">Xuesong Lu</a> (1) </u>  <br>
        1:  East China Normal University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591680">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=ErrorCLR: Semantic Error Classification, Localization and Repair for Introductory Programming Assignments">Google Scholar</a></div>
        (127)
        <br>
        <b>概要:　</b> プログラミング教育の大規模な展開において、学生がプログラミングを習得するための自動フィードバックの利用が増えています。重要なフィードバックの一形態として、学生のプログラムにおける意味的エラーを指摘し、プログラムの修正に対するヒントを提供するものがあります。このような自動フィードバックは、エラーの分類、位置特定、および修正というタスクの解決に本質的に依存しています。これらのタスクをサポートするためのデータセットは存在していますが、すべてのタスクを支援するアノテーションを持つデータセットは存在しないと観察されています。そのため、意味的エラーのフィードバックに関する既存のアプローチは、エラー分類、位置特定、および修正を独立したタスクとして扱っており、それぞれのタスクにおけるパフォーマンスが最適でない結果を招いています。さらに、既存のデータセットはプログラミング課題の数が少ないか、各課題に対して少数のプログラムしか含まれていません。そのため、既存のアプローチはしばしば規則ベースの手法を利用し、少数のプログラミング課題でそれらを評価しています。<br><br>これらの課題に対処するために、まず新しいデータセットCOJ2022の作成について説明します。このデータセットには、初級プログラミングコースの498課題に提出された5,914件の意味的エラーを含むCプログラムが含まれており、各プログラムにはエラーの種類と位置のアノテーションが付与され、同じ学生が提出した修正済みプログラムも含まれています。COJ2022が既存のデータセットに比べて様々な面で優れていることを示します。次に、意味的エラーの分類、位置特定、および修正を相互に関連するタスクとして扱い、これらを解決するために新しい二段階の手法ErrorCLRを提案します。具体的には、最初の段階でグラフマッチングネットワークに基づくモデルを訓練し、学生のプログラムにおける潜在的な意味的エラーを共同で分類および位置特定します。次の段階では、エラーの種類と位置の情報を用いてバグのあるプログラムのエラースパンをマスクし、CodeT5モデルを訓練して正しいスパンを予測します。予測されたスパンはエラースパンを置き換え、修正されたプログラムを形成します。実験結果は、ErrorCLRがCOJ2022および他の公開データセットにおいて、全てのタスクにおいて比較方法を著しく上回るパフォーマンスを示すことを示しています。また、ErrorCLRのグラフマッチングネットワークが学習した内容を視覚化および解釈するケーススタディも実施しました。ソースコードとCOJ2022はhttps://github.com/DaSESmartEdu/ErrorCLRで公開しています。
        </label>
        <input type="checkbox" id="Panel127" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Programming education at scale increasingly relies on automated feedback to help students learn to program. An important form of feedback is to point out semantic errors in student programs and provide hints for program repair. Such automated feedback depends essentially on solving the tasks of classification, localization and repair of semantic errors. Although there are datasets for the tasks, we observe that they do not have the annotations supporting all three tasks. As such, existing approaches for semantic error feedback treat error classification, localization and repair as independent tasks, resulting in sub-optimal performance on each task. Moreover, existing datasets either contain few programming assignments or have few programs for each assignment. Therefore, existing approaches often leverage rule-based methods and evaluate them with a small number of programming assignments. To tackle the problems, we first describe the creation of a new dataset COJ2022 that contains 5,914 C programs with semantic errors submitted to 498 different assignments in an introductory programming course, where each program is annotated with the error types and locations and is coupled with the repaired program submitted by the same student. We show the advantages of COJ2022 over existing datasets on various aspects. Second, we treat semantic error classification, localization and repair as dependent tasks, and propose a novel two-stage method ErrorCLR to solve them. Specifically, in the first stage we train a model based on graph matching networks to jointly classify and localize potential semantic errors in student programs, and in the second stage we mask error spans in buggy programs using information of error types and locations and train a CodeT5 model to predict correct spans. The predicted spans replace the error spans to form repaired programs. Experimental results show that ErrorCLR remarkably outperforms the comparative methods for all three tasks on COJ2022 and other public datasets. We also conduct a case study to visualize and interpret what is learned by the graph matching network in ErrorCLR. We have released the source code and COJ2022 at https://github.com/DaSESmartEdu/ErrorCLR.
        </div> </ul> <br>



        <label for="Panel128">
        <strong> A Geometric Framework for Query Performance Prediction in Conversational Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guglielmo+Faggioli">Guglielmo Faggioli</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nicola+Ferro">Nicola Ferro</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cristina+Ioana+Muntean">Cristina Ioana Muntean</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Raffaele+Perego">Raffaele Perego</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nicola+Tonellotto">Nicola Tonellotto</a> (3) </u>  <br>
        1:  University of Padova, 2:  ISTI-CNR, 3:  University of Pisa <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591625">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Geometric Framework for Query Performance Prediction in Conversational Search">Google Scholar</a></div>
        (128)
        <br>
        <b>概要:　</b> 近年の情報検索（IR）および自然言語処理（NLP）の進展により、ユーザーが検索エンジンとやり取りする方法は急速に進化しており、マルチターン会話が従来の一発で行うテキストクエリに取って代わりつつあります。その対話型の特性から、会話型検索（CS）はクエリ性能予測（QPP）技術の恩恵を最も受けるシナリオの一つです。しかし、CS分野におけるQPPは比較的新しい分野であり、適切なフレーミングが欠如しています。本研究では、このギャップに対処するために、CS分野におけるQPPの適用に関するフレームワークを提案し、それを用いて予測器のパフォーマンスを評価します。我々は、独立したクエリではなく一連の密接に関連する発話として情報ニーズを持つCSシナリオにおけるパフォーマンス予測の意義を特徴づけます。CS分野におけるQPPモデルの使用方法として、診断ツールとして、会話中のシステムの挙動を調整するため、および次の発話におけるシステムのパフォーマンスを予測するための三つの主要な方法を特定します。CS分野におけるQPPの確立された評価手順が欠如しているため、各使用ケースに対してQPPを評価するためのプロトコルを提案します。さらに、会話型検索ドメインで最も一般的なアプローチである高密度ニューラル検索モデルで最適に動作するように設計された空間ベースのQPPモデルを導入します。我々は、提案されたQPPアプローチが異なるシナリオとコレクションにおいて、最先端技術に対する予測性能を大幅に向上させることを示します。
        </label>
        <input type="checkbox" id="Panel128" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Thanks to recent advances in IR and NLP, the way users interact with search engines is evolving rapidly, with multi-turn conversations replacing traditional one-shot textual queries. Given its interactive nature, Conversational Search (CS) is one of the scenarios that can benefit the most from Query Performance Prediction (QPP) techniques. QPP for the CS domain is a relatively new field and lacks proper framing. In this study, we address this gap by proposing a framework for the application of QPP in the CS domain and use it to evaluate the performance of predictors. We characterize what it means to predict the performance in the CS scenario, where information needs are not independent queries but a series of closely related utterances. We identify three main ways to use QPP models in the CS domain: as a diagnostic tool, as a way to adjust the system's behaviour during a conversation, or as a way to predict the system's performance on the next utterance. Due to the lack of established evaluation procedures for QPP in the CS domain, we propose a protocol to evaluate QPPs for each of the use cases. Additionally, we introduce a set of spatial-based QPP models designed to work the best in the conversational search domain, where dense neural retrieval models are the most common approaches and query cutoffs are typically small. We show how the proposed QPP approaches improve significantly the predictive performance over the state-of-the-art in different scenarios and collections.
        </div> </ul> <br>



        <label for="Panel129">
        <strong> DMBIN: A Dual Multi-behavior Interest Network for Click-Through Rate Prediction via Contrastive Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tianqi+He">Tianqi He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kaiyuan+Li">Kaiyuan Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shan+Chen">Shan Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haitao+Wang">Haitao Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiang+Liu">Qiang Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xingxing+Wang">Xingxing Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dong+Wang">Dong Wang</a> (1) </u>  <br>
        1:  Meituan.com <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591669">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=DMBIN: A Dual Multi-behavior Interest Network for Click-Through Rate Prediction via Contrastive Learning">Google Scholar</a></div>
        (129)
        <br>
        <b>概要:　</b> クリック率（CTR）予測は、多くのオンラインアプリケーションにおいて重要な役割を果たし、ユーザーのクリック確率を推定することを目的としています。クリック、カート追加、注文など、様々なインタラクティブ行動からユーザーの興味をモデル化することが、CTR予測の主流のアプローチになりつつあります。我々は、様々なユーザー行動には二つの重要な内在的特徴が含まれていると主張します：1）各行動の差異は、ユーザーの行動固有の興味の異なる側面を明らかにします。例えば、必要に応じてクリックすることがあっても、購入の際には評価により注意を払うことがあります。2）各行動の一貫性は、ユーザーの行動不変の興味を含んでいます。例えば、ユーザーはインタラクションしたアイテムを他のアイテムより好む傾向があります。したがって、大量の行動情報から差異と一貫性のシグナルを切り離す必要があります。しかしながら、従来の方法はこの現象を十分に研究しておらず、推奨性能を制限しています。この課題に対処するために、我々は新しいDual Multi-Behavior Interest Network（DMBIN) を提案し、各種行動から行動固有と行動不変の興味を切り離すことで、より良い推奨を実現します。具体的には、DMBINは様々な行動間の差異と一貫性の特徴を形式化します。二つの実世界データセットに基づく広範な実験と実証的な分析により、DMBINが最先端の方法よりも顕著に優れていることが示されました。さらに、DMBINはMeituanのオンライン有料検索広告システムに導入され、CTRとCPMでそれぞれ2.11％および2.76％の改善を達成しました。
        </label>
        <input type="checkbox" id="Panel129" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Click-through rate (CTR) prediction plays a critical role in various online applications, aiming to estimate the user's click probability. User interest modeling from various interactive behaviors(e.g., click, add-to-cart, order) is becoming a mainstream approach to CTR prediction. We argue that the various user behaviors contain two important intrinsic characteristics: 1) The discrepancy in various behaviors reveals different aspects of user's behavior-specific interests. For example, one may click out of need but pay more attention to the rating when purchasing. 2) The consistency of various behaviors contains user's behavior-invariant interest. For example, the user prefers interacted items rather than other items. Therefore, it is necessary to disentangle the discrepancy and consistency signals from the massive behavior information. Unfortunately, previous methods have yet to study this phenomenon well, which limits the recommendation performance. To tackle this challenge, we propose a novel Dual Multi-Behavior Interest Network (DMBIN for short) to disentangle behavior-specific and behavioral-invariant interests from various behaviors for a better recommendation. Specifically, DMBIN formalizethe discrepancy and consistency characteristics among various behaviors. Extensive experiments and empirical analysis on two real-world datasets demonstrate that DMBIN significantly outperforms the state-of-the-art methods. Moreover, DMBIN is also deployed in the online sponsored search advertising system in Meituan and achieves 2.11% and 2.76% improvement on CTR and CPM, respectively.s the dismantlement task as two contrastive learning tasks of multi-behavior interests extracted through the Multi-behavior Interest Module: Multi-behavior Interest Contrast(MIC) task and Multi-behavior Interest Alignment(MIA) task. These two tasks focus on extracting
        </div> </ul> <br>



        <label for="Panel130">
        <strong> EulerNet: Adaptive Feature Interaction Learning via Euler's Formula for CTR Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhen+Tian">Zhen Tian</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ting+Bai">Ting Bai</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wayne+Xin+Zhao">Wayne Xin Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ji-Rong+Wen">Ji-Rong Wen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhao+Cao">Zhao Cao</a> (3) </u>  <br>
        1:  Renmin University of China & Beijing Key Laboratory of Big Data Management and Analysis Methods, 2:  Beijing University of Posts and Telecommunications & Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, 3:  Huawei <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591681">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=EulerNet: Adaptive Feature Interaction Learning via Euler's Formula for CTR Prediction">Google Scholar</a></div>
        (130)
        <br>
        <b>概要:　</b> CTR予測タスクにおいて効果的な高次特徴相互作用を学習することは非常に重要です。しかし、オンラインのeコマースプラットフォームにおいて大量の特徴との高次相互作用を計算することは非常に時間がかかります。既存の多くの手法は、手動で最大次数を設計し、それから不要な相互作用をフィルタリングします。これにより、高次特徴の組み合わせの指数的な増加による高い計算コストは削減されますが、制約された次数の特徴学習の最適化が不十分であるためにモデル能力が劣化する問題は依然として残ります。モデル能力を維持しつつ効率性を保つ解決策は技術的な課題であり、十分に解決されていません。この問題に対処するために、我々はEulerNetと名付けられた適応的特徴相互作用学習モデルを提案します。このモデルでは、Eulerの公式に従って特徴相互作用を複素数空間で学習します。EulerNetは、特徴相互作用の指数関数的な増加を、複素数特徴のモジュラス（絶対値）と位相の単純な線形結合に変換することで、効率的に高次特徴相互作用を適応的に学習できるようにします。さらに、EulerNetは暗黙的および明示的な特徴相互作用を統一されたアーキテクチャに組み込み、相互強化を達成し、主にモデル能力を向上させます。このネットワークはデータから完全に学習可能であり、事前にデザインされた特徴相互作用の形式や次数を必要としません。3つの公開データセットで行った広範な実験により、我々のアプローチの有効性と効率性が実証されました。コードは以下で利用可能です： https://github.com/RUCAIBox/EulerNet。
        </label>
        <input type="checkbox" id="Panel130" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Learning effective high-order feature interactions is very crucial in the CTR prediction task. However, it is very time-consuming to calculate high-order feature interactions with massive features in online e-commerce platforms. Most existing methods manually design a maximal order and further filter out the useless interactions from them. Although they reduce the high computational costs caused by the exponential growth of high-order feature combinations, they still suffer from the degradation of model capability due to the suboptimal learning of the restricted feature orders. The solution to maintain the model capability and meanwhile keep it efficient is a technical challenge, which has not been adequately addressed. To address this issue, we propose an adaptive feature interaction learning model, named as EulerNet, in which the feature interactions are learned in a complex vector space by conducting space mapping according to Euler's formula. EulerNet converts the exponential powers of feature interactions into simple linear combinations of the modulus and phase of the complex features, making it possible to adaptively learn the high-order feature interactions in an efficient way. Furthermore, EulerNet incorporates the implicit and explicit feature interactions into a unified architecture, which achieves the mutual enhancement and largely boosts the model capabilities. Such a network can be fully learned from data, with no need of pre-designed form or order for feature interactions. Extensive experiments conducted on three public datasets have demonstrated the effectiveness and efficiency of our approach. Our code is available at: https://github.com/RUCAIBox/EulerNet.
        </div> </ul> <br>



        <label for="Panel131">
        <strong> Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Zhang">Yang Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tianhao+Shi">Tianhao Shi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuli+Feng">Fuli Feng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenjie+Wang">Wenjie Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dingxian+Wang">Dingxian Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangnan+He">Xiangnan He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongdong+Zhang">Yongdong Zhang</a> (1) </u>  <br>
        1:  University of Science and Technology of China, 2:  National University of Singapore, 3:  Etsy Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591755">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation">Google Scholar</a></div>
        (131)
        <br>
        <b>概要:　</b> クリック率（CTR）予測は、レコメンダーシステムにおいて中心的な役割を果たし、ユーザーに対する最終段階のアイテム順位付け機能を提供します。CTRの課題に取り組むための鍵は、予測に有用な特徴相互作用を学習することであり、通常は歴史的なクリックデータを使って経験的リスク最小化（ERM）パラダイムにより達成されます。代表的な手法には、ファクトライゼーションマシンやディープインタレストネットワークがあり、これらは産業界で広く成功を収めています。しかし、このようなアプローチでは、必然的に不安定な特徴相互作用、すなわち歴史的データでは強い相関を示すものの、将来の利用に対しては一般化が困難な相互作用を学習してしまいます。本研究では、CTRの課題を再定式化し、歴史的データに対するERMを追求する代わりに、歴史的データを時系列順にいくつかの期間（エンバイロンメント）に分割し、それを通じて期間を超えて安定した特徴相互作用を学習することを目指します。このような特徴相互作用は、将来の行動データを予測するためにより良く一般化できると考えられます。しかしながら、クリックデータはエンバイロンメントに依存しない相関とエンバイロンメント特有の相関の両方が混在しているため、既存の不変学習ソリューション（例えば、不変リスク最小化）は適用できないという技術的な課題があります。これを解決するために、我々は特徴エンベディングを分離し、これら二種類の相関を別々に捉えるDisentangled Invariant Learning（DIL）を提案します。さらに、モデリング効率を向上させるために、特徴フィールドの高次レベルで分離を行うLightDILを設計しました。広範な実験により、CTRのための安定した特徴相互作用を学習する上でのDILの有効性が実証されました。
        </label>
        <input type="checkbox" id="Panel131" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Click-Through Rate (CTR) prediction plays a core role in recommender systems, serving as the final-stage filter to rank items for a user. The key to addressing the CTR task is learning feature interactions that are useful for prediction, which is typically achieved by fitting historical click data with the Empirical Risk Minimization (ERM) paradigm. Representative methods include Factorization Machines and Deep Interest Network, which have achieved wide success in industrial applications. However, such a manner inevitably learns unstable feature interactions, i.e., the ones that exhibit strong correlations in historical data but generalize poorly for future serving. In this work, we reformulate the CTR task --- instead of pursuing ERM on historical data, we split the historical data chronologically into several periods (a.k.a, environments), aiming to learn feature interactions that are stable across periods. Such feature interactions are supposed to generalize better to predict future behavior data. Nevertheless, a technical challenge is that existing invariant learning solutions like Invariant Risk Minimization are not applicable, since the click data entangles both environment-invariant and environment-specific correlations. To address this dilemma, we propose Disentangled Invariant Learning (DIL) which disentangles feature embeddings to capture the two types of correlations separately. To improve the modeling efficiency, we further design LightDIL which performs the disentanglement at the higher level of the feature field. Extensive experiments demonstrate the effectiveness of DIL in learning stable feature interactions for CTR.
        </div> </ul> <br>



        <label for="Panel132">
        <strong> News Popularity Beyond the Click-Through-Rate for Personalized Recommendations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ashutosh+Nayak">Ashutosh Nayak</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mayur+Garg">Mayur Garg</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rajasekhara+Reddy+Duvvuru+Muni">Rajasekhara Reddy Duvvuru Muni</a> (1) </u>  <br>
        1:  Samsung R&D Institute <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591741">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=News Popularity Beyond the Click-Through-Rate for Personalized Recommendations">Google Scholar</a></div>
        (132)
        <br>
        <b>概要:　</b> ニュース記事の人気検出は、ユーザーへの関連する推薦を行い、最大限のビジネス価値を引き出すためのユーザーエンゲージメントを促進する上で重要です。いいね、シェア、コメントなどのよく知られたメトリクスの中でも、クリック率（CTR）はデフォルトの人気指標として進化してきました。しかし、CTRはニュース記事が表示される確率に大きく影響され、それは推薦アルゴリズムに依存しています。さらに、CTRはニュース記事の寿命を考慮しておらず、人間の文脈的な行動嗜好を見逃してしまいます。本研究では、マイクロソフトによってオープンソース化されたMINDデータセットを使用して、既存の人気指標を調査し、新たに6つの人気指標を提案します。我々の目的は、人気を測定する際の異なる視点に対する認識を喚起し、提案された指標の利点と欠点を人間のクリック行動に対して議論することです。我々は、CTR予測と比較して提案された指標の予測可能性を評価しました。さらに、異なるテストケースを通じて提案された指標の有用性を評価しました。我々の結果は、適切な人気指標を使用することで、初期のニュースコーパス（アイテムセット）を50％削減しつつ、未フィルタのニュースコーパスに基づく推薦システムと比べて99％の合計クリックを達成できることを示しています。同様に、我々の結果は、表示当たりに推薦される記事の実効数を減らすことで、ニュースプラットフォーム上でのユーザー体験が向上する可能性があることを示しています。本論文で提案された指標は、特に消耗品アイテム（例：ビデオリールやブログ）を持つ推薦システムにおいて、他のコンテキストでも有用である可能性があります。
        </label>
        <input type="checkbox" id="Panel132" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Popularity detection of news articles is critical for making relevant recommendations for users and drive user engagement for maximum business value. Among several well-known metrics such as likes, shares, comments, Click-Through-Rate (CTR) has evolved as a default metric of popularity. However, CTR is highly influenced by the probability of news articles getting an impression, which in turn depends on the recommendation algorithm. Furthermore, it does not consider the age of the news articles, which are highly perishable and also misses out on human contextual behavioral preferences towards news. Here, we use the MIND dataset, open sourced by Microsoft to investigate the existing metrics of popularity and propose six new metrics. Our aim is to create awareness about the different perspectives of measuring popularity while discussing the advantages and disadvantages of the proposed metrics with respect to the human click behavior. We evaluated the predictability of the proposed metrics in comparison to CTR prediction. We further evaluated the utility of the proposed metrics through different test cases. Our results indicate that by using appropriate popularity metrics, we can reduce the initial news corpus (item set) by 50% and still could achieve 99% of the total clicks as compared to unfiltered news corpus based recommender systems. Similarly, our results show that we can reduce the effective number of articles recommended per impression that could improve user experience with the news platforms. The metrics proposed in this paper can be useful in other contexts, especially in recommenders with perishable items e.g. video reels or blogs.
        </div> </ul> <br>



        <label for="Panel133">
        <strong> Online Conversion Rate Prediction via Neural Satellite Networks in Delayed Feedback Advertising </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiming+Liu">Qiming Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haoming+Li">Haoming Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Ao">Xiang Ao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuyao+Guo">Yuyao Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhihong+Dong">Zhihong Dong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruobing+Zhang">Ruobing Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiong+Chen">Qiong Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianfeng+Tong">Jianfeng Tong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qing+He">Qing He</a> (1) </u>  <br>
        1:  Institute of Computing Technology, 2:  Tencent <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591747">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Online Conversion Rate Prediction via Neural Satellite Networks in Delayed Feedback Advertising">Google Scholar</a></div>
        (133)
        <br>
        <b>概要:　</b> 遅延フィードバックは、リアルタイムのコンバージョン率（CVR）予測を要求するコストパーコンバージョン表示戦略の普及により、オンライン広告における主要な障害の一つとなっています。このため、観測されるデータには、一時的にフィードバックがないが、後にコンバートする大量の偽陰性が含まれています。このようなバイアスのかかったデータ分布で学習することは、モデルの性能を著しく損なう可能性があります。一般的なアプローチは、サンプルがコンバートするかどうかを確認するために一定期間待ってから学習を行いますが、データの新鮮さを保証するソリューションは現行の研究では未だ十分に検討されていません。本研究では、オンラインCVR予測のためのニューラル衛星ネットワーク（DFSN）による遅延フィードバックモデリングを提案します。これにより、データの新鮮さの問題に対処し、適応的な待機ウィンドウを可能にします。まず、主モデルに長い待機ウィンドウを割り当て、多くのコンバージョンをカバーし、偽陰性を大幅に減少させます。同時に、最新のデータから学習する2種類の衛星モデルを考案し、オンライン転移学習技術を利用してその知識を十分に活用します。衛星からの情報を活用することで、主モデルはデータの新鮮さの問題に対処し、従来の方法より優れた性能を達成することができます。2つの実世界の広告データセットにおける広範な実験を通じて、我々のモデルの優位性を実証します。
        </label>
        <input type="checkbox" id="Panel133" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The delayed feedback is becoming one of the main obstacles in online advertising due to the pervasive deployment of the cost-per-conversion display strategy requesting a real-time conversion rate (CVR) prediction. It makes the observed data contain a large number of fake negatives that temporarily have no feedback but will convert later. Training on such biased data distribution would severely harm the performance of models. Prevailing approaches wait for a set period of time to see if samples convert before training on them, but solutions to guaranteeing data freshness remain under-explored by current research. In this work, we propose Delayed Feed-back modeling via neural Satellite Networks (DFSN for short) for online CVR prediction. It tackles the issue of data freshness to permit adaptive waiting windows. We first assign a long waiting window for our main model to cover most of conversions and greatly reduce fake negatives. Meanwhile, two kinds of satellite models are devised to learn from the latest data, and online transfer learning techniques are utilized to sufficiently exploit their knowledge. With information from satellites, our main model can deal with the issue of data freshness, achieving better performance than previous methods. Extensive experiments on two real-world advertising datasets demonstrate the superiority of our model.
        </div> </ul> <br>



        <label for="Panel134">
        <strong> A Topic-aware Summarization Framework with Different Modal Side Information </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiuying+Chen">Xiuying Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mingzhe+Li">Mingzhe Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shen+Gao">Shen Gao</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Cheng">Xin Cheng</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiang+Yang">Qiang Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qishen+Zhang">Qishen Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Gao">Xin Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangliang+Zhang">Xiangliang Zhang</a> (5) </u>  <br>
        1:  KAUST, 2:  Ant Group, 3:  Shandong university, 4:  Peking University, 5:  University of Notre Dame & KAUST <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591630">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Topic-aware Summarization Framework with Different Modal Side Information">Google Scholar</a></div>
        (134)
        <br>
        <b>概要:　</b> 自動は、Web上での文書の急増において重要な役割を果たします。CNN.comやWikiHow.comのようなコンテンツウェブサイトでは、メイン文書の他に動画、画像、クエリなど様々な補助情報が掲載されており、これらは注意を引きつけたり理解を助けたりするために使われます。このような補助情報は、記事の本質を明示的または暗示的に述べていることが多いため、より良いの作成に利用できます。しかし、既存の補助情報を考慮した手法の多くは、単一モダリティまたはマルチモダリティの補助情報を統合するように設計されており、互いに効果的に適応することができません。そこで本論文では、様々なモダリティの補助情報を柔軟に組み込むことができる一般的なフレームワークを提案します。補助情報を用いた柔軟なモデルの設計における主な課題は次の通りです：(1) 補助情報がテキスト形式またはビジュアル形式であり、モデルがそれを文書と同じ意味空間に統合して統一する必要があること、(2) 補助情報が様々な観点からの情報を含んでおり、モデルがに有用な観点を認識する必要があること。この2つの課題に対処するために、まず我々は文書と様々な種類の補助情報から潜在トピックを共同で発見する統一トピックエンコーダを提案します。学習されたトピックは、トピック認識インタラクションを通じてグラフエンコーダ内で複数の入力間の情報の流れを柔軟に橋渡しし、案内します。次に、単一モダリティまたはマルチモダリティの情報を統一された意味空間に整列させるために三重項コントラスト学習機構を提案し、の質を向上させます。結果として、我々のモデルは、三つの公的な単一モダリティまたはマルチモダリティのベンチマークデータセットにおいて、強力なベースラインを大きく上回る性能を示しました。
        </label>
        <input type="checkbox" id="Panel134" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Automatic summarization plays an important role in the exponential document growth on the Web. On content websites such as CNN.com and WikiHow.com, there often exist various kinds of side information along with the main document for attention attraction and easier understanding, such as videos, images, and queries. Such information can be used for better summarization, as they often explicitly or implicitly mention the essence of the article. However, most of the existing side-aware summarization methods are designed to incorporate either single-modal or multi-modal side information, and cannot effectively adapt to each other. In this paper, we propose a general summarization framework, which can flexibly incorporate various modalities of side information. The main challenges in designing a flexible summarization model with side information include: (1) the side information can be in textual or visualformat, and the model needs to align and unify it with the document into the same semantic space, (2) the side inputs can contain information from variousaspects, and the model should recognize the aspects useful for summarization. To address these two challenges, we first propose a unified topic encoder, which jointly discovers latent topics from the document and various kinds of side information. The learned topics flexibly bridge and guide the information flow between multiple inputs in a graph encoder through a topic-aware interaction. We secondly propose a triplet contrastive learning mechanism to align the single-modal or multi-modal information into a unified semantic space, where thesummary quality is enhanced by better understanding thedocument andside information. Results show that our model significantly surpasses strong baselines on three public single-modal or multi-modal benchmark summarization datasets.
        </div> </ul> <br>



        <label for="Panel135">
        <strong> Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search? </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuai+Wang">Shuai Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Harrisen+Scells">Harrisen Scells</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bevan+Koopman">Bevan Koopman</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guido+Zuccon">Guido Zuccon</a> (1) </u>  <br>
        1:  The University of Queensland, 2:  Leipzig University, 3:  CSIRO <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591703">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search?">Google Scholar</a></div>
        (135)
        <br>
        <b>概要:　</b> システマティックレビューは、特定の研究質問に対する包括的な文献レビューです。これらのレビューは、医学における最も高い形態のエビデンスとされています。システマティックレビューの作成プロセスの一環として、再現性と理解可能性を確保するために複雑なブール検索式が開発されます。しかし、高品質なブール検索式を開発することは難しく、時間がかかり、図書館員などの専門検索者の専門知識を必要とすることが多いです。最近のトランスフォーマーベースの生成モデルの進展により、ユーザーの指示を効果的に追従し、その指示に基づいた回答を生成する能力が示されています。本研究では、システマティックレビューの文献検索のために複雑なブール検索式を自動生成および改良する手段としてChatGPTを調査します。総じて、ChatGPTは効果的なブール検索式を生成する可能性があることがわかりました。ChatGPTの複雑な指示に従い、高度に精密な検索式を生成する能力は、特に時間が制約となる迅速レビューにおいて、高精度のためにリコールを犠牲にできる場合、システマティックレビューを行う研究者にとって有用なツールとなる可能性があります。また、ChatGPTをこのタスクに使用する際のいくつかの注意点を指摘し、広く受け入れられる前にさらなる検証が必要であることを強調しています。
        </label>
        <input type="checkbox" id="Panel135" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Systematic reviews are comprehensive literature reviews for a highly focused research question. These reviews are considered the highest form of evidence in medicine. Complex Boolean queries are developed as part of the systematic review creation process to retrieve literature, as they permit reproducibility and understandability. However, it is difficult and time-consuming to develop high-quality Boolean queries, often requiring the expertise of expert searchers like librarians. Recent advances in transformer-based generative models have shown their ability to effectively follow user instructions and generate answers based on these instructions. In this paper, we investigate ChatGPT as a means for automatically formulating and refining complex Boolean queries for systematic review literature search. Overall, our research finds that ChatGPT has the potential to generate effective Boolean queries. The ability of ChatGPT to follow complex instructions and generate highly precise queries makes it a tool of potential value for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and where one can trade off higher precision for lower recall. We also identify several caveats in using ChatGPT for this task, highlighting that this technology needs further validation before it is suitable for widespread uptake.
        </div> </ul> <br>



        <label for="Panel136">
        <strong> FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sebastian+Hofstätter">Sebastian Hofstätter</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiecao+Chen">Jiecao Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Karthik+Raman">Karthik Raman</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hamed+Zamani">Hamed Zamani</a> (4) </u>  <br>
        1:  Cohere, 2:  Bytedance Inc., 3:  Google Research, 4:  University of Massachusetts Amherst <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591687">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation">Google Scholar</a></div>
        (136)
        <br>
        <b>概要:　</b> 検索強化生成（Retrieval-augmented generation）モデルは、単独の言語モデルに比べて多くの利点を提供します。具体的には、与えられたクエリに対するテキスト応答に加え、更新可能な知識ベースから取得される出典アイテムも提供されます。しかし、これらのモデルはシステムとしての複雑さが増し、長い入力に対応する必要があります。本研究では、先端的な検索強化FiDモデルの効率を大幅に向上させつつ、同じレベルの有効性を維持するFiD-Lightを紹介します。我々のFiD-Lightモデルは、エンコーダ（パッセージを別々にエンコードする）からデコーダ（連結されたエンコード表現を使用する）への情報フローを制限します。さらに、テキストソースポインターを通じてFiD-Lightを再ランキング機能で適応させ、上位ランクの出典精度を向上させました。我々の実験では、7つの多様な知識集約タスク（KILT）において、FiD-Lightがクエリ遅延と有効性の間のパレートフロンティアを一貫して改善することを示しています。FiD-Lightはソースポインターを使うことで、テキスト生成と出典検索の評価において6つのKILTタスクで新たな最先端の結果を樹立し、高い効率性を維持します。
        </label>
        <input type="checkbox" id="Panel136" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Retrieval-augmented generation models offer many benefits over standalone language models: besides a textual answer to a given query they provide provenance items retrieved from an updateable knowledge base. However, they are also more complex systems and need to handle long inputs. In this work, we introduce FiD-Light to strongly increase the efficiency of the state-of-the-art retrieval-augmented FiD model, while maintaining the same level of effectiveness. Our FiD-Light model constrains the information flow from the encoder (which encodes passages separately) to the decoder (using concatenated encoded representations). Furthermore, we adapt FiD-Light with re-ranking capabilities through textual source pointers, to improve the top-ranked provenance precision. Our experiments on a diverse set of seven knowledge intensive tasks (KILT) show FiD-Light consistently improves the Pareto frontier between query latency and effectiveness. FiD-Light with source pointing sets substantial new state-of-the-art results on six KILT tasks for combined text generation and provenance retrieval evaluation, while maintaining high efficiency.
        </div> </ul> <br>



        <label for="Panel137">
        <strong> A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiangui+Chen">Jiangui Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruqing+Zhang">Ruqing Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiafeng+Guo">Jiafeng Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiqun+Liu">Yiqun Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yixing+Fan">Yixing Fan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xueqi+Cheng">Xueqi Cheng</a> (1) </u>  <br>
        1:  ICT, 2:  University of Amsterdam, 3:  Tsinghua University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591631">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning">Google Scholar</a></div>
        (137)
        <br>
        <b>概要:　</b> 知識集約型の言語タスク（KILT）は、大規模な外部知識コーパスから高品質で関連性のある文脈を抽出することでメリットを享受します。タスク固有のリトリーバー（例えば、文書リトリーバー、パッセージリトリーバー、文リトリーバー、エンティティリトリーバー）を学習させ、適切な意味的粒度で関連文脈を返すことにより、エンドツーエンドのタスクの性能を向上させることができます。ただし、タスク固有のリトリーバーは新しいドメインやタスクへの一般化能力が低く、実際に様々な特化したリトリーバーを展開するのはコストがかかる場合があります。これを解決するために、私たちは異なるリトリーバータスクに対して堅牢な性能を持ちながら、タスク固有の有効性も兼ね備えた統一的な生成リトリーバー（UGR: Unified Generative Retriever）を提案します。この目標を達成するために、以下の二つの主要な貢献を行います：（i）異なるリトリーバータスクを単一の生成形式に統一するために、KILTの異なる粒度レベルでの関連文脈を識別するためのn-gramベースの識別子を導入します。（ii）単一モデルで異なるリトリーバータスクに対応するために、プロンプト学習戦略を採用し、各タスクのプロンプトトークンを設計する三つの方法を調査します。この方法により、提案されたUGRモデルは、一般化のためにタスク間で共通の知識を共有できるだけでなく、タスク固有の特性を区別することで、異なるリトリーバータスクを効果的に実行できます。UGRは、うまく設計されたプロンプトを用いて、異種のリトリーバーコーパスを用いて教師ありのマルチタスク方式で訓練します。KILTベンチマークでの実験結果は、インドメインデータセット、アウトオブドメインデータセット、および未見タスクにおけるUGRの有効性を示しています。
        </label>
        <input type="checkbox" id="Panel137" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge-intensive language tasks (KILTs) benefit from retrieving high-quality relevant contexts from large external knowledge corpora. Learning task-specific retrievers that return relevant contexts at an appropriate level of semantic granularity, such as a document retriever, passage retriever, sentence retriever, and entity retriever, may help to achieve better performance on the end-to-end task. But a task-specific retriever usually has poor generalization ability to new domains and tasks, and it may be costly to deploy a variety of specialised retrievers in practice. We propose a unified generative retriever (UGR) that combines task-specific effectiveness with robust performance over different retrieval tasks in KILTs. To achieve this goal, we make two major contributions: (i) To unify different retrieval tasks into a single generative form, we introduce an n-gram-based identifier for relevant contexts at different levels of granularity in KILTs. And (ii) to address different retrieval tasks with a single model, we employ a prompt learning strategy and investigate three methods to design prompt tokens for each task. In this way, the proposed UGR model can not only share common knowledge across tasks for better generalization, but also perform different retrieval tasks effectively by distinguishing task-specific characteristics. We train UGR on a heterogeneous set of retrieval corpora with well-designed prompts in a supervised and multi-task fashion. Experimental results on the KILT benchmark demonstrate the effectiveness of UGR on in-domain datasets, out-of-domain datasets, and unseen tasks.
        </div> </ul> <br>



        <label for="Panel138">
        <strong> RHB-Net: A Relation-aware Historical Bridging Network for Text2SQL Auto-Completion </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bolong+Zheng">Bolong Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Bi">Lei Bi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruijie+Xi">Ruijie Xi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lu+Chen">Lu Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunjun+Gao">Yunjun Gao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaofang+Zhou">Xiaofang Zhou</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Christian+S.+Jensen">Christian S. Jensen</a> (4) </u>  <br>
        1:  Huazhong University of Science and Technology, 2:  Zhejiang University, 3:  Hong Kong University of Science and Technology, 4:  Aalborg University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591759">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=RHB-Net: A Relation-aware Historical Bridging Network for Text2SQL Auto-Completion">Google Scholar</a></div>
        (138)
        <br>
        <b>概要:　</b> データベースクエリへの自然言語インターフェースであるText2SQLは、深層学習の進展により大幅な改善が見られました。しかし、最近の進展にもかかわらず、既存のText2SQLの提案は、完全な形の質問を入力として要求します。これにより、データベースの専門知識が不足していたり、基盤となるデータベーススキーマに不慣れだったりして、完全な質問を作成に苦労するユーザーが取り残されます。この欠点を克服するために、部分的または不完全な質問も入力として受け付けるText2SQLオートコンプリート（TSAC）の新しい問題について研究します。具体的には、TSAC問題は、完全かつ実行可能なSQLクエリを予測することです。この問題を解決するために、関係対応履歴ブリッジングネットワーク（RHB-Net）を提案します。このネットワークは、関係対応のユニオンエンコーダと抽出生成敏感デコーダで構成されています。RHB-Netは、質問とデータベーススキーマの間の関係をモデル化し、部分的なクエリで示される曖昧な意図を予測します。さらに、履歴クエリブリッジング（過去のデータベースクエリを統合する）と動的コンテキスト構築（同じSQL要素の繰り返し生成を防止する）という2つの最適化戦略を提案します。実世界のデータを用いた実験により、RHB-Netがベースラインアルゴリズムを上回る能力があることが証明されました。
        </label>
        <input type="checkbox" id="Panel138" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Test2SQL, a natural language interface to database querying, has seen considerable improvement, in part due to advances in deep learning. However, despite recent improvement, existing Text2SQL proposals allow only input in the form of complete questions. This leaves behind users who struggle to formulate complete questions, e.g., because they lack database expertise or are unfamiliar with the underlying database schema. To address this shortcoming, we study the novel problem of Text2SQL Auto-Completion (TSAC) that extends Text2SQL to also take partial or incomplete questions as input. Specifically, the TSAC problem is to predict the complete, executable SQL query. To solve the problem, we propose a novel Relation-aware Historical Bridging Network (RHB-Net) that consists of a relation-aware union encoder and an extraction-generation sensitive decoder. RHB-Net models relations between questions and database schemas and predicts the ambiguous intents expressed in partial queries. We also propose two optimization strategies: historical query bridging that fuses historical database queries, and a dynamic context construction that prevents repeated generation of the same SQL elements. Extensive experiments with real-world data offer evidence that RHB-Net is capable of outperforming baseline algorithms.
        </div> </ul> <br>



        <label for="Panel139">
        <strong> M2GNN: Metapath and Multi-interest Aggregated Graph Neural Network for Tag-based Cross-domain Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zepeng+Huai">Zepeng Huai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuji+Yang">Yuji Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mengdi+Zhang">Mengdi Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhongyi+Zhang">Zhongyi Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yichun+Li">Yichun Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Wu">Wei Wu</a> (2) </u>  <br>
        1:  School of Artificial Intelligence, 2:  Meituan <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591720">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=M2GNN: Metapath and Multi-interest Aggregated Graph Neural Network for Tag-based Cross-domain Recommendation">Google Scholar</a></div>
        (139)
        <br>
        <b>概要:　</b> クロスドメイン推薦 (CDR) は、データのスパース性問題を軽減する効果的な方法です。コンテンツベースのCDRは、特にコールドスタートユーザーやアイテムの相互作用が少ない場合、ほとんどの製品がテキストで記述できるため、有望な分野の一つです。しかし、2つの重要な課題がまだ未解決です。(1) コンテンツモデリングの観点から、十分な長文の説明は実際の推薦システムでは稀であり、軽量なテキスト特徴（キーワードやタグなど）の方がアクセスしやすいが、既存の方法では不適切にモデル化されています。(2) CDRの観点から、すべてのクロスドメインにおける興味が必ずしも有益であるとは限りません。ドメイン固有の特徴により、一部のシグナルはソースドメインでの推薦には有益であっても、ターゲットドメインでは有害です。したがって、有用な興味を蒸留する方法が重要です。これらの2つの問題を解決するために、メタパスと多興味集約型グラフニューラルネットワーク（M2GNN）を提案します。具体的には、タグベースのコンテンツをモデル化するために、ユーザー、アイテム、およびタグの間のセマンティック関連性を保持する異種情報ネットワークを構築しました。メタパススキーマはドメイン固有の知識に基づいて事前定義され、1つのドメインに1つのメタパスが用意されています。ユーザー表現は階層的集約フレームワークを持つGNNによって学習され、イントラメタパス集約はまず些末なタグをフィルタリングし、インターメタパス集約はさらに役に立たない興味をフィルタリングします。オフライン実験とオンラインのA/Bテストでは、M2GNNが最先端の手法やDianpingの現在の産業推薦システムに対して大幅な改善を達成することが示されています。さらなる分析では、M2GNNが解釈可能な推薦を提供することが分かりました。
        </label>
        <input type="checkbox" id="Panel139" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Cross-domain recommendation (CDR) is an effective way to alleviate the data sparsity problem. Content-based CDR is one of the most promising branches since most kinds of products can be described by a piece of text, especially when cold-start users or items have few interactions. However, two vital issues are still under-explored: (1) From the content modeling perspective, sufficient long-text descriptions are usually scarce in a real recommender system, more often the light-weight textual features, such as a few keywords or tags, are more accessible, which is improperly modeled by existing methods. (2) From the CDR perspective, not all inter-domain interests are helpful to infer intra-domain interests. Caused by domain-specific features, there are part of signals benefiting for recommendation in the source domain but harmful for that in the target domain. Therefore, how to distill useful interests is crucial. To tackle the above two problems, we propose a metapath and multi-interest aggregated graph neural network (M2GNN). Specifically, to model the tag-based contents, we construct a heterogeneous information network to hold the semantic relatedness between users, items, and tags in all domains. The metapath schema is predefined according to domain-specific knowledge, with one metapath for one domain. User representations are learned by GNN with a hierarchical aggregation framework, where the intra-metapath aggregation firstly filters out trivial tags and the inter-metapath aggregation further filters out useless interests. Offline experiments and online A/B tests demonstrate that M2GNN achieves significant improvements over the state-of-the-art methods and current industrial recommender system in Dianping, respectively. Further analysis shows that M2GNN offers an interpretable recommendation.
        </div> </ul> <br>



        <label for="Panel140">
        <strong> AutoTransfer: Instance Transfer for Cross-Domain Recommendations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingtong+Gao">Jingtong Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyu+Zhao">Xiangyu Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Chen">Bo Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fan+Yan">Fan Yan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huifeng+Guo">Huifeng Guo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruiming+Tang">Ruiming Tang</a> (2) </u>  <br>
        1:  City University of Hong Kong, 2:  Huawei Noah's Ark Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591701">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=AutoTransfer: Instance Transfer for Cross-Domain Recommendations">Google Scholar</a></div>
        (140)
        <br>
        <b>概要:　</b> クロスドメインレコメンデーション（CDR）は、データが豊富なドメインからの情報を利用して、データが不足しているドメインを支援するための広く使用される手法です。CDR研究の主要な課題は、ソースドメインからターゲットドメインへの有益な情報の効果的かつ効率的な転送です。現在、既存の多くのCDR手法は、ターゲットドメインを強化するためにソースドメインから暗黙の情報を抽出することに焦点を当てています。しかし、抽出された暗黙の情報の隠れた構造は特定のCDRモデルに高度に依存しており、再利用や転送が容易ではありません。加えて、抽出された暗黙の情報は、トレーニング中の特定のCDRの中間部分構造内にのみ現れ、より多くの用途に保持されることは容易ではありません。<br><br>こうした課題を踏まえ、本論文ではAutoTransferを提案します。これは、インスタンス転送ポリシーネットワークを備え、ソースドメインからターゲットドメインへインスタンスを選択的に転送することでレコメンデーションの精度を改善します。具体的には、AutoTransferはエージェントとして機能し、ソースドメインから情報量が多く、転送可能なインスタンスのサブセットを適応的に選択します。特筆すべきは、この選択されたサブセットが高い再利用性を持ち、ターゲットドメインの将来の様々なレコメンデーションシステム（RS）モデルのトレーニングを改善するために保存できる点です。2つの公開されたCDRベンチマークデータセットにおける実験結果は、提案手法が最先端のCDRベースラインおよび古典的なシングルドメインレコメンデーション（SDR）アプローチを上回ることを示しています。実装コードは簡単に再現可能なように公開されています。
        </label>
        <input type="checkbox" id="Panel140" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Cross-Domain Recommendation (CDR) is a widely used approach for leveraging information from domains with rich data to assist domains with insufficient data. A key challenge of CDR research is the effective and efficient transfer of helpful information from source domain to target domain. Currently, most existing CDR methods focus on extracting implicit information from the source domain to enhance the target domain. However, the hidden structure of the extracted implicit information is highly dependent on the specific CDR model, and is therefore not easily reusable or transferable. Additionally, the extracted implicit information only appears within the intermediate substructure of specific CDRs during training and is thus not easily retained for more use. In light of these challenges, this paper proposes AutoTransfer, with an Instance Transfer Policy Network, to selectively transfers instances from source domain to target domain for improved recommendations. Specifically, AutoTransfer acts as an agent that adaptively selects a subset of informative and transferable instances from the source domain. Notably, the selected subset possesses extraordinary re-utilization property that can be saved for improving model training of various future RS models in target domain. Experimental results on two public CDR benchmark datasets demonstrate that the proposed method outperforms state-of-the-art CDR baselines and classic Single-Domain Recommendation (SDR) approaches. The implementation code is available for easy reproduction.
        </div> </ul> <br>



        <label for="Panel141">
        <strong> Beyond the Overlapping Users: Cross-Domain Recommendation via Adaptive Anchor Link Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Zhao">Yi Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaozhuo+Li">Chaozhuo Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiquan+Peng">Jiquan Peng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaohan+Fang">Xiaohan Fang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Feiran+Huang">Feiran Huang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Senzhang+Wang">Senzhang Wang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xing+Xie">Xing Xie</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jibing+Gong">Jibing Gong</a> (5) </u>  <br>
        1:  Yanshan University, 2:  Microsoft Research Asia, 3:  Jinan University, 4:  Central South University, 5:  Yanshan University & The Key Laboratory for Computer Virtual Technology and System Integration of Hebei Province <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591642">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Beyond the Overlapping Users: Cross-Domain Recommendation via Adaptive Anchor Link Learning">Google Scholar</a></div>
        (141)
        <br>
        <b>概要:　</b> クロスドメイン推奨（CDR）は、複数のドメインから補助的な情報を取り入れて推奨性能を向上させることができます。従来のCDR手法は主に重複するユーザーに依存しており、知識は同一の自然人に属するソースとターゲットのアイデンティティ間で伝達されます。しかし、このようなヒューリスティックな仮定は普遍的に適用可能ではありません。というのも、個人が異なるドメインで異なった、あるいは矛盾する嗜好を示すことがあり、潜在的なノイズが発生する可能性があるからです。本論文では、異なるドメインのユーザー間のアンカーリンクをタスク関連のクロスドメイン相関を学習するための学習可能なパラメータとして捉えます。新たに提案する最適輸送ベースのモデルALCDRは、アンカーリンクを正確に推論し、ドメイン内およびドメイン間の視点から協調的なシグナルを深く統合することを目指しています。我々の提案は実世界のデータセットで広範に評価され、実験結果はその優位性を示しています。
        </label>
        <input type="checkbox" id="Panel141" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Cross-Domain Recommendation (CDR) is capable of incorporating auxiliary information from multiple domains to advance recommendation performance. Conventional CDR methods primarily rely on overlapping users, whereby knowledge is conveyed between the source and target identities belonging to the same natural person. However, such a heuristic assumption is not universally applicable due to an individual may exhibit distinct or even conflicting preferences in different domains, leading to potential noises. In this paper, we view the anchor links between users of various domains as the learnable parameters to learn the task-relevant cross-domain correlations. A novel optimal transport based model ALCDR is further proposed to precisely infer the anchor links and deeply aggregate collaborative signals from the perspectives of intra-domain and inter-domain. Our proposal is extensively evaluated over real-world datasets, and experimental results demonstrate its superiority.
        </div> </ul> <br>



        <label for="Panel142">
        <strong> PLATE: A Prompt-Enhanced Paradigm for Multi-Scenario Recommendations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuhao+Wang">Yuhao Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyu+Zhao">Xiangyu Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Chen">Bo Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qidong+Liu">Qidong Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huifeng+Guo">Huifeng Guo</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huanshuo+Liu">Huanshuo Liu</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yichao+Wang">Yichao Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rui+Zhang">Rui Zhang</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruiming+Tang">Ruiming Tang</a> (3) </u>  <br>
        1:  City University of Hong Kong, 2:  Huawei Noah's Ark Lab, 3:  Huawei Noah's Ark Lab, 4:  Sun Yat-sen University, 5:  ruizhang.info <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591750">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=PLATE: A Prompt-Enhanced Paradigm for Multi-Scenario Recommendations">Google Scholar</a></div>
        (142)
        <br>
        <b>概要:　</b> 推薦システムの商業応用が急速に増加する中、複数シナリオ推薦（MSR）は注目を集めており、複数のドメインからのデータを活用して同時に推薦性能を向上させます。しかし、統一的なディープレコメンダーシステム（DRS）を訓練すると、ドメイン間の共通性と差異を明確に把握できず、各ドメイン毎に個別のモデルを訓練すると全体的な情報を見落とし、計算コストも高くなります。同様に、各ドメインに対するファインチューニングも非効率で、ファインチューニングの効率を向上させるためのプロンプトチューニング技術は、大規模なトランスフォーマーに依存しています。本研究では、複数シナリオ推薦のための新しいプロンプト強化パラダイムを提案します。具体的には、すべてのドメインからのデータを使用して事前訓練された統一DRS基盤モデルを最初に構築し、ドメイン間の共通性を捉えます。その後、2つの新しいプロンプトモジュールを用いたプロンプトチューニングを行い、様々なドメインやユーザー間の違いを捉えます。Douban、Amazon、Ali-CCPデータセットでの実験により、提案パラダイムの効果性が実証され、以下の2つの顕著な強みが明らかになりました: (i) 各種DRS基盤モデルとの高い互換性、(ii) プロンプトチューニングフェーズではわずか6%の訓練パラメータで高い計算効率とストレージ効率を実現。再現を容易にするための実装コードも公開しています。
        </label>
        <input type="checkbox" id="Panel142" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> With the explosive growth of commercial applications of recommender systems, multi-scenario recommendation (MSR) has attracted considerable attention, which utilizes data from multiple domains to improve their recommendation performance simultaneously. However, training a unified deep recommender system (DRS) may not explicitly comprehend the commonality and difference among domains, whereas training an individual model for each domain neglects the global information and incurs high computation costs. Likewise, fine-tuning on each domain is inefficient, and recent advances that apply the prompt tuning technique to improve fine-tuning efficiency rely solely on large-sized transformers. In this work, we propose a novel prompt-enhanced paradigm for multi-scenario recommendation. Specifically, a unified DRS backbone model is first pre-trained using data from all the domains in order to capture the commonality across domains. Then, we conduct prompt tuning with two novel prompt modules, capturing the distinctions among various domains and users. Our experiments on Douban, Amazon, and Ali-CCP datasets demonstrate the effectiveness of the proposed paradigm with two noticeable strengths: (i) its great compatibility with various DRS backbone models, and (ii) its high computation and storage efficiency with only 6% trainable parameters in prompt tuning phase. The implementation code is available for easy reproduction.
        </div> </ul> <br>



        <label for="Panel143">
        <strong> LightGT: A Light Graph Transformer for Multimedia Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yinwei+Wei">Yinwei Wei</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenqi+Liu">Wenqi Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fan+Liu">Fan Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Wang">Xiang Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liqiang+Nie">Liqiang Nie</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tat-Seng+Chua">Tat-Seng Chua</a> (1) </u>  <br>
        1:  National University of Singapore, 2:  Shandong University, 3:  University of Science and Technology of China, 4:  Harbin Institute of Technology (Shenzhen) <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591716">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=LightGT: A Light Graph Transformer for Multimedia Recommendation">Google Scholar</a></div>
        (143)
        <br>
        <b>概要:　</b> マルチメディア推薦方法は、協調フィルタリング（CF）ベースの推薦システムを強化するために、ユーザーの好みをマルチモーダル情報から発見することを目指しています。しかし、抽出された特徴が推薦に無関係な過剰な情報を含んでいるため、ユーザーの好みのモデリングやユーザーとアイテムの相互作用の予測における特徴抽出の影響をほとんど考慮していません。抽出された特徴から有用な特徴を捉えるために、Transformerモデルを利用して、同じユーザーが過去に相互作用したアイテム間の相関を確立します。その効果と効率の課題を考慮し、新しいTransformerベースの推薦モデル、Light Graph Transformerモデル（LightGT）を提案します。この中で、効果的な類似度測定のためにモーダル固有の埋め込みおよび層ごとの位置エンコーダを開発し、自己注意スコアリングの効率を向上させるために軽量な自己注意ブロックを提示します。これらの設計に基づき、ユーザーとアイテムの相互作用を予測するために、市販のアイテムの特徴からユーザーの好みを効果的かつ効率的に学習することができます。Movielens、Tiktok、Kwaiデータセットで広範な実験を行い、LightGTが最先端のベースラインを大幅に上回り、時間も短縮できることを実証しました。我々のコードは公開されています: https://github.com/Liuwq-bit/LightGT.
        </label>
        <input type="checkbox" id="Panel143" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multimedia recommendation methods aim to discover the user preference on the multi-modal information to enhance the collaborative filtering (CF) based recommender system. Nevertheless, they seldom consider the impact of feature extraction on the user preference modeling and prediction of the user-item interaction, as the extracted features contain excessive information irrelevant to the recommendation. To capture the informative features from the extracted ones, we resort to Transformer model to establish the correlation between the items historically interacted by the same user. Considering its challenges in effectiveness and efficiency, we propose a novel Transformer-based recommendation model, termed as Light Graph Transformer model (LightGT). Therein, we develop a modal-specific embedding and a layer-wise position encoder for the effective similarity measurement, and present a light self-attention block to improve the efficiency of self-attention scoring. Based on these designs, we can effectively and efficiently learn the user preference from the off-the-shelf items' features to predict the user-item interactions. Conducting extensive experiments on Movielens, Tiktok and Kwai datasets, we demonstrate that LigthGT significantly outperforms the state-of-the-art baselines with less time. Our code is publicly available at: https://github.com/Liuwq-bit/LightGT.
        </div> </ul> <br>



        <label for="Panel144">
        <strong> Dual Semantic Knowledge Composed Multimodal Dialog Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaolin+Chen">Xiaolin Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuemeng+Song">Xuemeng Song</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yinwei+Wei">Yinwei Wei</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liqiang+Nie">Liqiang Nie</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tat-Seng+Chua">Tat-Seng Chua</a> (3) </u>  <br>
        1:  School of Software, 2:  School of Computer Science and Technology, 3:  School of Computing, 4:  School of Computer Science and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591673">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Dual Semantic Knowledge Composed Multimodal Dialog Systems">Google Scholar</a></div>
        (144)
        <br>
        <b>概要:　</b> テキスト応答生成は、マルチモーダルなタスク指向対話システムにおいて重要な課題です。既存の研究が一定の進展を遂げているものの、以下の二つの重大な制約に悩まされています: 1) 属性知識に焦点を当てる一方で、異なるエンティティ間の相関を明らかにし、応答生成を促進する関係知識を無視していること、2) クロスエントロピー損失に基づく出力レベルの指導のみが行われ、表現レベルの正則化が欠如していることです。これらの制約に対処するために、新たなマルチモーダルタスク指向対話システム（MDS-S2）を考案しました。具体的には、MDS-S2はまず知識ベースからコンテキストに関連する属性知識と関係知識を同時に取得し、n-hopグラフウォークによって非直観的な関係知識を抽出します。次に、属性知識と関係知識が異なるレベルの質問に応答するのに有益であると考慮し、MDS-S^2には隠れた合成応答表現を得るためのマルチレベル知識合成モジュールを設計しました。さらに、合成応答表現と正解応答表現から意味情報を抽出するための一連の潜在クエリ変数を考案し、これにより表現レベルの意味正則化を行います。公的なデータセットを用いた広範な実験により、提案したMDS-S2の優位性が確認されました。研究コミュニティを支援するために、コードとパラメータを公開しました。
        </label>
        <input type="checkbox" id="Panel144" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Textual response generation is an essential task for multimodal task-oriented dialog systems. Although existing studies have achieved fruitful progress, they still suffer from two critical limitations: 1) focusing on the attribute knowledge but ignoring the relation knowledge that can reveal the correlations between different entities and hence promote the response generation, and 2)only conducting the cross-entropy loss based output-level supervision but lacking the representation-level regularization. To address these limitations, we devise a novel multimodal task-oriented dialog system (named MDS-S2). Specifically, MDS-S2 first simultaneously acquires the context related attribute and relation knowledge from the knowledge base, whereby the non-intuitive relation knowledge is extracted by the n-hop graph walk. Thereafter, considering that the attribute knowledge and relation knowledge can benefit the responding to different levels of questions, we design a multi-level knowledge composition module in MDS-S^2 to obtain the latent composed response representation. Moreover, we devise a set of latent query variables to distill the semantic information from the composed response representation and the ground truth response representation, respectively, and thus conduct the representation-level semantic regularization. Extensive experiments on a public dataset have verified the superiority of our proposed MDS-S2. We have released the codes and parameters to facilitate the research community.
        </div> </ul> <br>



        <label for="Panel145">
        <strong> MAMO: Fine-Grained Vision-Language Representations Learning with Masked Multimodal Modeling </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zijia+Zhao">Zijia Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Longteng+Guo">Longteng Guo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xingjian+He">Xingjian He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuai+Shao">Shuai Shao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zehuan+Yuan">Zehuan Yuan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jing+Liu">Jing Liu</a> (1) </u>  <br>
        1:  Institute of Automation, 2:  Bytedance Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591721">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MAMO: Fine-Grained Vision-Language Representations Learning with Masked Multimodal Modeling">Google Scholar</a></div>
        (145)
        <br>
        <b>概要:　</b> マルチモーダル表現学習は、さまざまな視覚と言語のタスク（例えば、画像テキスト検索や視覚質問応答など）で有望な改善を示しており、マルチメディア情報システムの発展を大きく前進させました。既存の方法のほとんどは視覚と言語の間でグローバルレベルのアラインメントを構築する点で優れていますが、効果的なきめ細かい画像テキスト相互作用に欠けています。本論文では、きめ細かいマルチモーダル表現を学習するために、共同マスクマルチモーダルモデリング法を提案します。私たちの方法は、画像テキスト入力に対して共同マスキングを行い、マスクされた信号の回復のために暗黙的および明示的なターゲットを統合します。暗黙的ターゲットは視覚と言語に統一され、バイアスのない目標を提供し、モデルはマスクされていない入力の潜在的なマルチモーダル表現を予測します。明示的ターゲットはさらに、画像パッチのモメンタム視覚特徴や単語トークンの概念といった、高レベルで意味的な情報を回復することによって、マルチモーダル表現を豊かにします。このようなマスキングモデリングプロセスを通じて、私たちのモデルはきめ細かいマルチモーダル相互作用を学習するだけでなく、高レベルの表現と低・中レベルの予測ターゲット（例えば、画像ピクセルや離散的な視覚トークン）との意味的なギャップを回避します。したがって、ゼロショットとファインチューニングの両方の設定で優れたパフォーマンスを発揮する、意味的に豊かなマルチモーダル表現を生成します。我々の事前学習モデル（MAMOと命名）は、画像テキスト検索、視覚質問応答、視覚推論や弱教師付き視覚グラウンディングなど、さまざまな下流の視覚と言語のタスクで最先端の性能を達成します。
        </label>
        <input type="checkbox" id="Panel145" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multimodal representation learning has shown promising improvements on various vision-language tasks (e.g., image-text retrieval, visual question answering, etc) and has significantly advanced the development of multimedia information systems. Most existing methods excel at building global-level alignment between vision and language while lacking effective fine-grained image-text interaction. In this paper, we propose a jointly masked multimodal modeling method to learn fine-grained multimodal representations. Our method performs joint masking on image-text input and integrates both implicit and explicit targets for the masked signals to recover. The implicit target provides a unified and debiased objective for vision and language, where the model predicts latent multimodal representations of the unmasked input. The explicit target further enriches the multimodal representations by recovering high-level and semantically meaningful information: momentum visual features of image patches and concepts of word tokens. Through such a masked modeling process, our model not only learns fine-grained multimodal interaction, but also avoids the semantic gap between high-level representations and low-or mid-level prediction targets (e.g., image pixels, discrete vision tokens), thus producing semantically rich multimodal representations that perform well on both zero-shot and fine-tuned settings. Our pre-trained model (named MAMO) achieves state-of-the-art performance on various downstream vision-language tasks, including image-text retrieval, visual question answering, visual reasoning, and weakly-supervised visual grounding.
        </div> </ul> <br>



        <label for="Panel146">
        <strong> Multimodal Counterfactual Learning Network for Multimedia-based Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuaiyang+Li">Shuaiyang Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dan+Guo">Dan Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kang+Liu">Kang Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Richang+Hong">Richang Hong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Feng+Xue">Feng Xue</a> (2) </u>  <br>
        1:  Hefei University of Technology, 2:  Hefei University of Technology & Institute of Artificial Intelligence <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591739">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multimodal Counterfactual Learning Network for Multimedia-based Recommendation">Google Scholar</a></div>
        (146)
        <br>
        <b>概要:　</b> マルチメディアベースのレコメンデーション (MMRec) は、ユーザーの履歴インタラクションにおける補助情報としてマルチモーダルなコンテンツ（画像、テキスト説明など）を活用し、ユーザーの好みを特定します。ほとんどのMMRecアプローチは、ユーザーが関与したアイテムのマルチモーダルなコンテンツを大量に利用してユーザーの興味を予測しますが、ユーザーが関与しなかったアイテムのマルチモーダルなコンテンツの潜在的な影響を無視しています。実際、ユーザーが関与したアイテムのマルチモーダルコンテンツには、ユーザーの好みに無関係な特徴が少量含まれており、これはユーザーの好みとの誤った相関かもしれません。これが推奨性能を低下させる原因となります。本研究では、ユーザーが関与しなかったアイテムのマルチモーダルなコンテンツをさらに活用し、対因論に基づく反事実推論によりユーザーの好みと無関係な部分を識別・排除できると主張します。マルチモーダルなユーザーの好みのモデリングを超えて、我々は新しいモデルであるMultimodal Counterfactual Learning Network (MCLN)を提案します。このモデルでは、ユーザーが関与しなかったアイテムのマルチモーダルコンテンツを追加で活用し、ユーザーの興味により合致するユーザーの好み関連マルチモーダルコンテンツの表現をさらに純化します。その結果、最新の性能を実現します。広範な実験を行い、MCLNの有効性と合理性を検証しました。MCLNの完全なコードはhttps://github.com/hfutmars/MCLNで公開しています。
        </label>
        <input type="checkbox" id="Panel146" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multimedia-based recommendation (MMRec) utilizes multimodal content (images, textual descriptions, etc.) as auxiliary information on historical interactions to determine user preferences. Most MMRec approaches predict user interests by exploiting a large amount of multimodal contents of user-interacted items, ignoring the potential effect of multimodal content of user-uninteracted items. As a matter of fact, there is a small portion of user preference-irrelevant features in the multimodal content of user-interacted items, which may be a kind of spurious correlation with user preferences, thereby degrading the recommendation performance. In this work, we argue that the multimodal content of user-uninteracted items can be further exploited to identify and eliminate the user preference-irrelevant portion inside user-interacted multimodal content, for example by counterfactual inference of causal theory. Going beyond multimodal user preference modeling only using interacted items, we propose a novel model called Multimodal Counterfactual Learning Network (MCLN), in which user-uninteracted items' multimodal content is additionally exploited to further purify the representation of user preference-relevant multimodal content that better matches the user's interests, yielding state-of-the-art performance. Extensive experiments are conducted to validate the effectiveness and rationality of MCLN. We release the complete codes of MCLN at https://github.com/hfutmars/MCLN.
        </div> </ul> <br>



        <label for="Panel147">
        <strong> Law Article-Enhanced Legal Case Matching: A Causal Learning Approach </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhongxiang+Sun">Zhongxiang Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Xu">Jun Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Zhang">Xiao Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenhua+Dong">Zhenhua Dong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ji-Rong+Wen">Ji-Rong Wen</a> (1) </u>  <br>
        1:  Renmin Unversity of China, 2:  Huawei <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591709">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Law Article-Enhanced Legal Case Matching: A Causal Learning Approach">Google Scholar</a></div>
        (147)
        <br>
        <b>概要:　</b> 法的判例のマッチングは、ソースケースとターゲットケースの類似性を自動的に推定するモデルを構築するものであり、インテリジェントな法システムにおいて重要な役割を果たしています。セマンティックテキストマッチングモデルは、ソースケースとターゲットケースが長文のテキストドキュメントとして扱われるタスクに適用されています。これらの汎用的なマッチングモデルは、法的判例のテキストに基づいて予測を行うだけであり、法的判例のマッチングにおいて法条文が果たす重要な役割を見落としています。現実世界では、マッチング結果（例：関連性ラベル）は法条文によって劇的に影響されます。なぜなら、法的判例の内容や判決は法に基づいて根本的に形成されているからです。因果関係の観点から見ると、マッチングの決定は法的判例で引用された法条文からの媒介効果と、法的判例の重要な状況（例：詳細な事実説明）の直接効果によって影響を受けます。この観察に基づき、本論文は「Law-Match」と呼ばれるモデルアグノスティックな因果学習フレームワークを提案します。このフレームワークの下では、対応する法条文を尊重して法的判例のマッチングモデルが学習されます。一対の法的判例と関連する法条文が与えられた場合、Law-Matchは法条文の埋め込みを操作変数（IV）とし、法的判例の埋め込みを処置と見なします。IV回帰を使用して、処置は法関連部分と非法関連部分に分解され、それぞれ媒介効果と直接効果を反映します。そして、これらの二つの部分が異なる重みで結合され、最終的なマッチング予測を支援します。フレームワークはモデルアグノスティックであり、多数の法的判例マッチングモデルが基礎モデルとして適用可能であることを示します。包括的な実験により、Law-Matchは三つの公開データセットで最先端のベースラインを上回る成果を示すことができます。
        </label>
        <input type="checkbox" id="Panel147" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Legal case matching, which automatically constructs a model to estimate the similarities between the source and target cases, has played an essential role in intelligent legal systems. Semantic text matching models have been applied to the task where the source and target legal cases are considered as long-form text documents. These general-purpose matching models make the predictions solely based on the texts in the legal cases, overlooking the essential role of the law articles in legal case matching. In the real world, the matching results (e.g., relevance labels) are dramatically affected by the law articles because the contents and the judgments of a legal case are radically formed on the basis of law. From the causal sense, a matching decision is affected by the mediation effect from the cited law articles by the legal cases, and the direct effect of the key circumstances (e.g., detailed fact descriptions) in the legal cases. In light of the observation, this paper proposes a model-agnostic causal learning framework called Law-Match, under which the legal case matching models are learned by respecting the corresponding law articles. Given a pair of legal cases and the related law articles, Law-Match considers the embeddings of the law articles as instrumental variables(IVs), and the embeddings of legal cases as treatments. Using IV regression, the treatments can be decomposed into law-related and law-unrelated parts, respectively reflecting the mediation and direct effects. These two parts are then combined with different weights to collectively support the final matching prediction. We show that the framework is model-agnostic, and a number of legal case matching models can be applied as the underlying models. Comprehensive experiments show that Law-Match can outperform state-of-the-art baselines on three public datasets.
        </div> </ul> <br>



        <label for="Panel148">
        <strong> Learn from Relational Correlations and Periodic Events for Temporal Knowledge Graph Reasoning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ke+Liang">Ke Liang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lingyuan+Meng">Lingyuan Meng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Meng+Liu">Meng Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Liu">Yue Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenxuan+Tu">Wenxuan Tu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siwei+Wang">Siwei Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sihang+Zhou">Sihang Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinwang+Liu">Xinwang Liu</a> (1) </u>  <br>
        1:  National University of Defense Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591711">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Learn from Relational Correlations and Periodic Events for Temporal Knowledge Graph Reasoning">Google Scholar</a></div>
        (148)
        <br>
        <b>概要:　</b> 時間的知識グラフ（TKG）の推論は、時間軸に沿った欠落しているイベントの推測を目的として広く研究されており、異なるタイムスタンプの一連のKGスナップショットで構成されています。以前のモデルでは、スナップショット内の構造情報とスナップショット間の時間的相互作用の2つの情報が、主に推論のための表現学習に寄与していました。しかし、これらのモデルは、（1）前者の情報に対する関係の間の意味的関連性、及び（2）後者の情報に対する周期的な時間パターンを活用することに失敗しています。そのため、このような不十分な情報の利用は表現力を妨げ、最適なパフォーマンスを達成できない結果を招いています。これらの制限に対処するために、我々はRPCと呼ばれる新しい推論モデルを提案します。このモデルは、関係の相関性と周期的パターンの両方の情報を十分に活用するために2つの新しい対応ユニット、すなわち関係対応ユニット（RCU）と周期対応ユニット（PCU）を組み込みました。具体的には、関係グラフ畳み込みネットワーク（RGCN）とRCUを用いて、エンティティと関係のスナップショット内のグラフ構造情報をそれぞれエンコードします。さらに、ゲート付き再帰ユニット（GRU）とPCUは、それぞれ順次および周期的なスナップショット間の時間相互作用を処理します。加えて、時間に依存しないモデルのタイムベクトルは、time2vectorエンコーダーによって生成され、事実のスコアリングを行う時間依存デコーダーをガイドします。6つのベンチマークデータセットにおける広範な実験により、RPCは最先端のTKGRモデルを上回る性能を発揮することが示され、我々のモデルにおける2つの新しい戦略の有効性も実証されました。
        </label>
        <input type="checkbox" id="Panel148" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Reasoning on temporal knowledge graphs (TKGR), aiming to infer missing events along the timeline, has been widely studied to alleviate incompleteness issues in TKG, which is composed of a series of KG snapshots at different timestamps. Two types of information, i.e., intra-snapshot structural information and inter-snapshot temporal interactions, mainly contribute to the learned representations for reasoning in previous models. However, these models fail to leverage (1) semantic correlations between relationships for the former information and (2) the periodic temporal patterns along the timeline for the latter one. Thus, such insufficient mining manners hinder expressive ability, leading to sub-optimal performances. To address these limitations, we propose a novel reasoning model, termed RPC, which sufficiently mines the information underlying the Relational correlations and Periodic patterns via two novel Correspondence units, i.e., relational correspondence unit (RCU) and periodic correspondence unit (PCU). Concretely, relational graph convolutional network (RGCN) and RCU are used to encode the intra-snapshot graph structural information for entities and relations, respectively. Besides, the gated recurrent units (GRU) and PCU are designed for sequential and periodic inter-snapshot temporal interactions, separately. Moreover, the model-agnostic time vectors are generated by time2vector encoders to guide the time-dependent decoder for fact scoring. Extensive experiments on six benchmark datasets show that RPC outperforms the state-of-the-art TKGR models, and also demonstrate the effectiveness of two novel strategies in our model.
        </div> </ul> <br>



        <label for="Panel149">
        <strong> Dynamic Mixed Membership Stochastic Block Model for Weighted Labeled Networks </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gaël+Poux-Médard">Gaël Poux-Médard</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Julien+Velcin">Julien Velcin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sabine+Loudcher">Sabine Loudcher</a> (1) </u>  <br>
        1:  Université de Lyon <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591675">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Dynamic Mixed Membership Stochastic Block Model for Weighted Labeled Networks">Google Scholar</a></div>
        (149)
        <br>
        <b>概要:　</b> 実世界の多くのネットワークは時間とともに進化します。これまでの文献では、ラベルなしまたは単一のメンバーシップ構造を前提とした動的ネットワークモデルが提案されてきました。一方で、新しいファミリーである混合メンバーシップ確率ブロックモデル (Mixed Membership Stochastic Block Models, MMSBM) は、混合メンバーシップクラスタリングを前提として、静的なラベル付きネットワークをモデル化することを可能にしています。本研究では、このモデルクラスを拡張し、混合メンバーシップの仮定の下で動的ラベル付きネットワークを推定する方法を提案します。我々のアプローチは、モデルパラメータに時間的な事前分布を導入する形式をとり、動態が突然変化しないという単一の仮定に頼ります。我々の方法は既存のアプローチとは大きく異なり、より複雑なシステム—動的ラベル付きネットワークをモデル化することが可能です。合成データセットと実データセットを用いた複数の実験を通じて、我々の方法の堅牢性を実証しました。我々のアプローチの主な関心点の一つは、良い結果を得るために非常に少ない訓練データしか必要としないことです。困難な条件下での性能向上により、自動化学習ツールの適用範囲が広がり、特にデータセットが小さいことが機械学習手法の導入における大きな障害となっている社会科学など、多くの分野において応用が可能となります。
        </label>
        <input type="checkbox" id="Panel149" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Most real-world networks evolve over time. Existing literature proposes models for dynamic networks that are either unlabeled or assumed to have a single membership structure. On the other hand, a new family of Mixed Membership Stochastic Block Models (MMSBM) allows to model static labeled networks under the assumption of mixed-membership clustering. In this work, we propose to extend this later class of models to infer dynamic labeled networks under a mixed membership assumption. Our approach takes the form of a temporal prior on the model's parameters. It relies on the single assumption that dynamics are not abrupt. We show that our method significantly differs from existing approaches, and allows to model more complex systems --dynamic labeled networks. We demonstrate the robustness of our method with several experiments on both synthetic and real-world datasets. A key interest of our approach is that it needs very few training data to yield good results. The performance gain under challenging conditions broadens the variety of possible applications of automated learning tools --as in social sciences, which comprise many fields where small datasets are a major obstacle to the introduction of machine learning methods.
        </div> </ul> <br>



        <label for="Panel150">
        <strong> DREAM: Adaptive Reinforcement Learning based on Attention Mechanism for Temporal Knowledge Graph Reasoning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shangfei+Zheng">Shangfei Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongzhi+Yin">Hongzhi Yin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tong+Chen">Tong Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Quoc+Viet+Hung+Nguyen">Quoc Viet Hung Nguyen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Chen">Wei Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Zhao">Lei Zhao</a> (1) </u>  <br>
        1:  Soochow University, 2:  The University of Queensland, 3:  Griffith University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591671">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=DREAM: Adaptive Reinforcement Learning based on Attention Mechanism for Temporal Knowledge Graph Reasoning">Google Scholar</a></div>
        (150)
        <br>
        <b>概要:　</b> 時系列知識グラフ (TKG)は、イベントの時系列的な進化をモデル化するもので、近年ますます注目を集めています。TKGは本質的に不完全であるため、欠落した要素を推論することが必要です。既存のTKG推論手法は、未来の欠落イベントを予測する能力を持ちますが、明示的な推論経路を生成することができず、説明可能性に欠けます。近年の進展により、従来の知識グラフにおけるマルチホップ推論のための強化学習 (RL) が優れた説明可能性とパフォーマンスを見せ始めたことで、TKG推論におけるRL技術の探求に新たな機会が開かれました。しかし、RLベースのTKG推論手法のパフォーマンスは、以下の理由で制限されています：(1) 時系列的進化と意味的依存を同時に捕捉する能力が不足していること；(2) 手動設計の報酬に過度に依存していること。これらの課題を克服するために、我々はアテンションメカニズムに基づく適応型強化学習モデル (DREAM) を提案し、未来の欠落要素を予測します。具体的には、このモデルは次の2つのコンポーネントを含みます：(1) 意味的依存と時系列的進化を同時に捕捉する多面的アテンション表現学習法；(2) 報酬関数を適応的に学習する適応型RLフレームワークを使用したマルチホップ推論。実験結果は、DREAMが公開データセットにおいて最先端モデルを上回る性能を示すことを実証しています。
        </label>
        <input type="checkbox" id="Panel150" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Temporal knowledge graphs (TKGs) model the temporal evolution of events and have recently attracted increasing attention. Since TKGs are intrinsically incomplete, it is necessary to reason out missing elements. Although existing TKG reasoning methods have the ability to predict missing future events, they fail to generate explicit reasoning paths and lack explainability. As reinforcement learning (RL) for multi-hop reasoning on traditional knowledge graphs starts showing superior explainability and performance in recent advances, it has opened up opportunities for exploring RL techniques on TKG reasoning. However, the performance of RL-based TKG reasoning methods is limited due to: (1) lack of ability to capture temporal evolution and semantic dependence jointly; (2) excessive reliance on manually designed rewards. To overcome these challenges, we propose an adaptive reinforcement learning model based on attention mechanism (DREAM) to predict missing elements in the future. Specifically, the model contains two components: (1) a multi-faceted attention representation learning method that captures semantic dependence and temporal evolution jointly; (2) an adaptive RL framework that conducts multi-hop reasoning by adaptively learning the reward functions. Experimental results demonstrate DREAM outperforms state-of-the-art models on public datasets.
        </div> </ul> <br>



        <label for="Panel151">
        <strong> Dynamic Graph Evolution Learning for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haoran+Tang">Haoran Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shiqing+Wu">Shiqing Wu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guandong+Xu">Guandong Xu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qing+Li">Qing Li</a> (1) </u>  <br>
        1:  The Hong Kong Polytechnic University, 2:  University of Technology Sydney <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591674">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Dynamic Graph Evolution Learning for Recommendation">Google Scholar</a></div>
        (151)
        <br>
        <b>概要:　</b> グラフニューラルネットワーク（GNN）に基づいたアルゴリズムは、高次の接続性を利用する優れた能力により、推薦タスクにおいて卓越したパフォーマンスを達成しています。しかし、既存のほとんどのGNNベースの推薦モデルは、ノードの動的進化を無視しています。具体的には、ユーザーがアイテムと継続的に相互作用することで環境（例えば、隣接関係や構造）が急速に変化する点です。さらに、動的推薦における埋め込みのヒューリスティックな正規化は、モデル学習プロセスと切り離されており、全体のシステムが最適化されていません。本論文では、動的な環境において満足のいく推薦を生成するための新しいフレームワーク「Dynamic Graph Evolution Learning（DGEL）」を提案します。まず、固有の相互作用潜在力、時間経過による隣接関係の拡張、共生的ローカル構造学習の観点から、ノードに対する3つの効率的なリアルタイム更新学習方法を設計しました。次に、動的な埋め込みに対して再スケーリング強化ネットワークを構築し、正規化プロセスとモデル学習を適応的かつ自動的に橋渡しします。最後に、相互作用マッチングタスクと将来予測タスクを統合的に訓練することで、さらにパフォーマンスを向上させます。3つの実世界のデータセットに対する広範な実験により、提案したDGELの有効性と改善が実証されました。コードはhttps://github.com/henrictang/DGELで利用可能です。
        </label>
        <input type="checkbox" id="Panel151" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Graph neural network (GNN) based algorithms have achieved superior performance in recommendation tasks due to their advanced capability of exploiting high-order connectivity between users and items. However, most existing GNN-based recommendation models ignore the dynamic evolution of nodes, where users will continuously interact with items over time, resulting in rapid changes in the environment (e.g., neighbor and structure). Moreover, the heuristic normalization of embeddings in dynamic recommendation is de-coupled with the model learning process, making the whole system suboptimal. In this paper, we propose a novel framework for generating satisfying recommendations in dynamic environments, called Dynamic Graph Evolution Learning (DGEL). First, we design three efficient real-time update learning methods for nodes from the perspectives of inherent interaction potential, time-decay neighbor augmentation, and symbiotic local structure learning. Second, we construct the re-scaling enhancement networks for dynamic embeddings to adaptively and automatically bridge the normalization process with model learning. Third, we leverage the interaction matching task and the future prediction task together for joint training to further improve performance. Extensive experiments on three real-world datasets demonstrate the effectiveness and improvements of our proposed DGEL. The code is available at https://github.com/henrictang/DGEL.
        </div> </ul> <br>



        <label for="Panel152">
        <strong> Causal Decision Transformer for Recommender Systems via Offline Reinforcement Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siyu+Wang">Siyu Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaocong+Chen">Xiaocong Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dietmar+Jannach">Dietmar Jannach</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lina+Yao">Lina Yao</a> (3) </u>  <br>
        1:  The University of New South Wales, 2:  University of Klagenfurt, 3:  Data61 <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591648">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Causal Decision Transformer for Recommender Systems via Offline Reinforcement Learning">Google Scholar</a></div>
        (152)
        <br>
        <b>概要:　</b> 強化学習に基づくレコメンダーシステムは近年、注目を集めています。しかし、エージェントがそのレコメンデーションポリシーを最適化するために依存する報酬関数の設計は、しばしば容易ではありません。ユーザーの行動の背後にある因果関係を探ることは、報酬関数に代わってエージェントがユーザーの動的な興味を捉える指針となり得ます。さらに、シミュレーション環境の典型的な制約（例えば、データの非効率性）のために、多くの研究は大規模な状況に広く適用することができません。いくつかの研究はオフラインデータセットをシミュレーターに変換しようと試みていますが、データの非効率性により学習プロセスがさらに遅くなります。強化学習の特性（すなわち、相互作用による学習）により、単一の相互作用中に十分なデータを収集することはできません。さらに、従来の強化学習アルゴリズムは、オフラインデータセットから直接学習するための強固な能力を持っていません。本論文では、レコメンダーシステムのための因果決定トランスフォーマー（CDT4Rec）という新しいモデルを提案します。CDT4Recは、オンライン相互作用ではなくデータセットから学習するオフライン強化学習システムです。また、CDT4Recはトランスフォーマーアーキテクチャを採用しており、大規模なオフラインデータセットを処理し、データ内の短期および長期の依存関係を捉えて、行動、状態、および報酬の因果関係を推定することができます。本モデルの実現可能性と優位性を示すために、我々は6つの実世界のオフラインデータセットと1つのオンラインシミュレーターで実験を行いました。
        </label>
        <input type="checkbox" id="Panel152" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Reinforcement learning-based recommender systems have recently gained popularity. However, the design of the reward function, on which the agent relies to optimize its recommendation policy, is often not straightforward. Exploring the causality underlying users' behavior can take the place of the reward function in guiding the agent to capture the dynamic interests of users. Moreover, due to the typical limitations of simulation environments (e.g., data ineffi- ciency), most of the work cannot be broadly applied in large-scale situations. Although some works attempt to convert the offline dataset into a simulator, data inefficiency makes the learning pro- cess even slower. Because of the nature of reinforcement learning (i.e., learning by interaction), it cannot collect enough data to train during a single interaction. Furthermore, traditional reinforcement learning algorithms do not have a solid capability like supervised learning methods to learn from offline datasets directly. In this paper, we propose a new model named the causal decision transformer for recommender systems (CDT4Rec). CDT4Rec is an offline reinforce- ment learning system that can learn from a dataset rather than from online interaction. Moreover, CDT4Rec employs the transformer architecture, which is capable of processing large offline datasets and capturing both short-term and long-term dependencies within the data to estimate the causal relationship between action, state, and reward. To demonstrate the feasibility and superiority of our model, we have conducted experiments on six real-world offline datasets and one online simulator.
        </div> </ul> <br>



        <label for="Panel153">
        <strong> SCHash: Speedy Simplicial Complex Neural Networks via Randomized Hashing </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuan+Tan">Xuan Tan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Wu">Wei Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chuan+Luo">Chuan Luo</a> (2) </u>  <br>
        1:  Central South University, 2:  Beihang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591762">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SCHash: Speedy Simplicial Complex Neural Networks via Randomized Hashing">Google Scholar</a></div>
        (153)
        <br>
        <b>概要:　</b> グラフは非線形データ構造として広く利用されており、効果的なグラフ解析はビッグデータ時代の重要な情報検索アプリケーションに貢献することができます。現在、基本的なグラフマイニングの問題の一つにグラフ埋め込みがあり、これはグラフを低次元の特徴ベクトルとして表現し、グラフ内のコンテンツと構造情報を保持することを目指します。グラフ埋め込み技術はかなり進化しましたが、従来の方法は主にグラフ内のノード間の二者関係に焦点を当てており、そのため、これらの手法の表現力は限られています。最近では、グラフ内のノード間の高次相互作用を記述するシンプレクシャル複体（simplicial complexes）を探究し、シンプレクシャル複体に基づくいくつかのグラフニューラルネットワーク（GNN）アルゴリズムが提案されました。しかし、これらのGNNアプローチは多くのパラメータの学習が必要であるため、実行時間や空間の観点から非常に非効率的です。本稿では、SCHashと名付けた簡単かつ高速なグラフ埋め込みアルゴリズムを提案します。ローカリティ・センシティブ・ハッシング（LSH）技術を採用することで、SCHashはGNNフレームワーク内のシンプレクシャル複体から得られる高次情報を捕捉し、精度と効率のバランスをうまく取ることができます。当社の広範な実験結果は、精度の観点から、提案したSCHashアルゴリズムの性能が最先端のGNNアルゴリズムと同等であることを明確に示しています。また、既存のLSHアルゴリズムよりも高い精度を達成しています。効率の面では、SCHashはGNNアルゴリズムよりも2〜4桁高速であり、既存のLSHアルゴリズムよりも効率的です。
        </label>
        <input type="checkbox" id="Panel153" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Graphs, as a non-linear data structure, are ubiquitous in practice, and efficient graph analysis can benefit important information retrieval applications in the era of big data. Currently, one of the fundamental graph mining problems is graph embedding, which aims to represent the graph as a low-dimensional feature vector with the content and structural information in the graph preserved. Although the graph embedding technique has evolved considerably, traditional methods mainly focus on node pairwise relationship in graphs, which makes the representational power of such schemes limited. Recently, a number of works have explored the simplicial complexes, which describe the higher-order interactions between nodes in the graphs, and further proposed several Graph Neural Network (GNN) algorithms based on simplicial complexes. However, these GNN approaches are highly inefficient in terms of running time and space, due to massive parameter learning. In this paper, we propose a simple and speedy graph embedding algorithm dubbed SCHash. Through adopting the Locality Sensitive Hashing (LSH) technique, SCHash captures the higher-order information derived from the simplicial complex in the GNN framework, and it can achieve a good balance between accuracy and efficiency. Our extensive experiments clearly show that, in terms of accuracy, the performance of our proposed SCHash algorithm is comparable to that of state-of-the-art GNN algorithms; also, SCHash achieves higher accuracy than the existing LSH algorithms. In terms of efficiency, SCHash runs faster than GNN algorithms by 2 ~ 4 orders of magnitude, and is more efficient than the existing LSH algorithms.
        </div> </ul> <br>



        <label for="Panel154">
        <strong> A Critical Reexamination of Intra-List Distance and Dispersion </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Naoto+Ohsaka">Naoto Ohsaka</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Riku+Togashi">Riku Togashi</a> (1) </u>  <br>
        1:  CyberAgent <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591623">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Critical Reexamination of Intra-List Distance and Dispersion">Google Scholar</a></div>
        (154)
        <br>
        <b>概要:　</b> 推薦結果の多様化は、ユーザーの情報ニーズに伴う不確実性に対処する有望な手法です。多様化された推薦において特に重要なのは、適切な多様性目標を定義し最適化することです。本研究では、選択されたアイテム間の平均ペアワイズ距離として定義される最も一般的な多様性目標であるintra-list distance (ILD) と、類似しているがあまり知られていない目標である、最小ペアワイズ距離で定義される分散について再検討します。その簡潔さと柔軟性により、ILDと分散は数多くの多様化された推薦研究において使用されてきました。それにもかかわらず、実際にはこれらの目標がどのようなアイテムを好むのかはわかっていません。理論的かつ実験的観点から、ILDと分散を批判的に再検討します。我々の理論的結果は、これらの目標が潜在的な欠点を有することを明らかにしています。ILDは非常に近いアイテムを選択する可能性がある一方、分散は距離の離れたアイテムペアを見落とす可能性があります。ILDと分散の競合相手として、バンド幅パラメータを調整することによりILDと分散の間を補間できる多様性目標Gaussian ILDを設計しました。実世界のデータを用いた実験結果によって、理論的な結果を裏付け、ILDと分散の極端な挙動を確認しました。
        </label>
        <input type="checkbox" id="Panel154" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Diversification of recommendation results is a promising approach for coping with the uncertainty associated with users' information needs. Of particular importance in diversified recommendation is to define and optimize an appropriate diversity objective. In this study, we revisit the most popular diversity objective called intra-list distance (ILD), defined as the average pairwise distance between selected items, and a similar but lesser known objective called dispersion, which is the minimum pairwise distance. Owing to their simplicity and flexibility, ILD and dispersion have been used in a plethora of diversified recommendation research. Nevertheless, we do not actually know what kind of items are preferred by them.  We present a critical reexamination of ILD and dispersion from theoretical and experimental perspectives. Our theoretical results reveal that these objectives have potential drawbacks: ILD may select duplicate items that are very close to each other, whereas dispersion may overlook distant item pairs. As a competitor to ILD and dispersion, we design a diversity objective called Gaussian ILD, which can interpolate between ILD and dispersion by tuning the bandwidth parameter. We verify our theoretical results by experimental results using real-world data and confirm the extreme behavior of ILD and dispersion in practice.
        </div> </ul> <br>



        <label for="Panel155">
        <strong> Contrastive Learning for Signed Bipartite Graphs </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zeyu+Zhang">Zeyu Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiamou+Liu">Jiamou Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kaiqi+Zhao">Kaiqi Zhao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Song+Yang">Song Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xianda+Zheng">Xianda Zheng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yifei+Wang">Yifei Wang</a> (2) </u>  <br>
        1:  University of Electronic Science and Technology of China & The University of Auckland, 2:  The University of Auckland <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591655">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Contrastive Learning for Signed Bipartite Graphs">Google Scholar</a></div>
        (155)
        <br>
        <b>概要:　</b> 本論文は、社会ネットワーク、推薦システム、および論文評価プラットフォームにおいて一般的に見られる符号付き二部グラフのグラフ表現学習のロバスト性を向上させるために、コントラスト学習を初めて使用するものである。既存の符号付きグラフに対するコントラスト学習方法では、2種類のノードを持ち、異なる種類のノード間のみが接続される符号付き二部グラフにおいて、同じ種類のノード間の暗黙の関係を捉えることができない。我々は、符号付き二部グラフコントラスト学習（Signed Bipartite Graph Contrastive Learning, SBGCL）法を提案し、同じ種類のノード間の暗黙の関係を保持しながらロバストなノード表現を学習する。SBGCLは、新しい2層のグラフ増強方法で符号付き二部グラフを拡張する。最上位レベルでは、異なる種類のノード間の元の相互作用を示す視点と、同じ種類のノード間の暗黙の関係を示す視点の2つの視点を維持する。下位レベルでは、確率的摂動戦略を用いて各視点で2つの摂動グラフを作成する。その後、摂動グラフから正と負のサンプルを構築し、多視点コントラスト損失を設計して2つの視点から学習されたノード表現を統一する。結果は、提案したモデルが現実世界のデータセットで最先端の方法よりも効果的であることを示している。
        </label>
        <input type="checkbox" id="Panel155" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This paper is the first to use contrastive learning to improve the robustness of graph representation learning for signed bipartite graphs, which are commonly found in social networks, recommender systems, and paper review platforms. Existing contrastive learning methods for signed graphs cannot capture implicit relations between nodes of the same type in signed bipartite graphs, which have two types of nodes and edges only connect nodes of different types. We propose a Signed Bipartite Graph Contrastive Learning (SBGCL) method to learn robust node representation while retaining the implicit relations between nodes of the same type. SBGCL augments a signed bipartite graph with a novel two-level graph augmentation method. At the top level, we maintain two perspectives of the signed bipartite graph, one presents the original interactions between nodes of different types, and the other presents the implicit relations between nodes of the same type. At the bottom level, we employ stochastic perturbation strategies to create two perturbed graphs in each perspective. Then, we construct positive and negative samples from the perturbed graphs and design a multi-perspective contrastive loss to unify the node presentations learned from the two perspectives. Results show proposed model is effective over state-of-the-art methods on real-world datasets.
        </div> </ul> <br>



        <label for="Panel156">
        <strong> It's Enough: Relaxing Diagonal Constraints in Linear Autoencoders for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jaewan+Moon">Jaewan Moon</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hye-young+Kim">Hye-young Kim</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jongwuk+Lee">Jongwuk Lee</a> (1) </u>  <br>
        1:  Sungkyunkwan University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591704">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=It's Enough: Relaxing Diagonal Constraints in Linear Autoencoders for Recommendation">Google Scholar</a></div>
        (156)
        <br>
        <b>概要:　</b> 線形オートエンコーダモデルは、L2正則化とゼロ対角制約を用いた凸最適化を通じてアイテム間の重み行列を学習します。そのシンプルさにもかかわらず、これらのモデルは高度な非線形モデルと比べて驚くべき性能を示しています。本論文は、線形オートエンコーダにおける二つの用語の特性を理論的に理解することを目的としています。特異値分解（SVD）および主成分分析（PCA）の観点から、L2正則化は高順位の主成分の影響を強化することが明らかにされました。一方、ゼロ対角制約は低順位の主成分の影響を減少させ、人気のないアイテムの性能劣化を引き起こします。この分析に触発されて、我々は対角不等式制約を用いたシンプルで効果的な線形オートエンコーダモデル、Relaxed Linear AutoEncoder (RLAE) と Relaxed Denoising Linear AutoEncoder (RDLAE)を提案します。我々はこれらのモデルが対角制約の度合いを調整することで線形オートエンコーダを一般化することを証明しました。実験結果は、我々のモデルが6つのベンチマークデータセットにおいて最新の線形および非線形モデルと同等またはそれ以上の性能を示し、特に長尾アイテムの精度を大幅に向上させることを示しています。これらの結果は、線形オートエンコーダにおける正則化と対角制約に関する我々の理論的洞察を支持するものです。
        </label>
        <input type="checkbox" id="Panel156" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Linear autoencoder models learn an item-to-item weight matrix via convex optimization with L2 regularization and zero-diagonal constraints. Despite their simplicity, they have shown remarkable performance compared to sophisticated non-linear models. This paper aims to theoretically understand the properties of two terms in linear autoencoders. Through the lens of singular value decomposition (SVD) and principal component analysis (PCA), it is revealed that L2 regularization enhances the impact of high-ranked PCs. Meanwhile, zero-diagonal constraints reduce the impact of low-ranked PCs, leading to performance degradation for unpopular items. Inspired by this analysis, we propose simple-yet-effective linear autoencoder models using diagonal inequality constraints, called Relaxed Linear AutoEncoder (RLAE) and Relaxed Denoising Linear AutoEncoder (RDLAE). We prove that they generalize linear autoencoders by adjusting the degree of diagonal constraints. Experimental results demonstrate that our models are comparable or superior to state-of-the-art linear and non-linear models on six benchmark datasets; they significantly improve the accuracy of long-tail items. These results also support our theoretical insights on regularization and diagonal constraints in linear autoencoders.
        </div> </ul> <br>



        <label for="Panel157">
        <strong> Uncertainty Quantification for Extreme Classification </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jyun-Yu+Jiang">Jyun-Yu Jiang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei-Cheng+Chang">Wei-Cheng Chang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiong+Zhang">Jiong Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cho-Jui+Hsieh">Cho-Jui Hsieh</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hsiang-Fu+Yu">Hsiang-Fu Yu</a> (1) </u>  <br>
        1:  Amazon Search, 2:  University of California <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591780">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Uncertainty Quantification for Extreme Classification">Google Scholar</a></div>
        (157)
        <br>
        <b>概要:　</b> 不確実性定量化は、意思決定のための信頼できる機械学習モデルを得るために最も重要な課題のひとつです。しかし、この分野の多くの研究は小さなラベル空間を持つ問題にのみ焦点を当てており、ビッグデータの時代におけるWebスケールの機械学習アプリケーションにとって重要なタスクであるeXtreme Multi-label Classification（XMC）を無視してきました。さらに、膨大なラベル空間は、ノイズの多い検索結果や不確実性定量化における難解な計算上の課題をもたらす可能性があります。本論文では、確率的アンサンブルベースのフレームワークを用いて、ツリー型XMCモデルに対する一般的な不確実性定量化のアプローチを検討することを目的とします。特に、XMCにおけるラベルレベルおよびインスタンスレベルの不確実性を分析し、ビームサーチに基づく一般的な近似フレームワークを提案し、ロングテールのXMC予測下で理論的保証付きで効率的に不確実性を推定します。６つの大規模な実世界データセットでの実証研究により、我々のフレームワークが予測性能において単一モデルを上回るだけでなく、ラベルの誤分類や分布外検出に対する強力な不確実性ベースのベースラインとして機能し、さらに大幅な速度向上も実現することが示されました。加えて、不確実性定量化を伴うディープXMCモデルに基づき、より良い最新の成果をもたらすことも可能です。
        </label>
        <input type="checkbox" id="Panel157" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Uncertainty quantification is one of the most crucial tasks to obtain trustworthy and reliable machine learning models for decision making. However, most research in this domain has only focused on problems with small label spaces and ignored eXtreme Multi-label Classification (XMC), which is an essential task in the era of big data for web-scale machine learning applications. Moreover, enormous label spaces could also lead to noisy retrieval results and intractable computational challenges for uncertainty quantification. In this paper, we aim to investigate general uncertainty quantification approaches for tree-based XMC models with a probabilistic ensemble-based framework. In particular, we analyze label-level and instance-level uncertainty in XMC, and propose a general approximation framework based on beam search to efficiently estimate the uncertainty with a theoretical guarantee under long-tail XMC predictions. Empirical studies on six large-scale real-world datasets show that our framework not only outperforms single models in predictive performance, but also can serve as strong uncertainty-based baselines for label misclassification and out-of-distribution detection, with significant speedup. Besides, our framework can further yield better state-of-the-art results based on deep XMC models with uncertainty quantification.
        </div> </ul> <br>



        <label for="Panel158">
        <strong> Distillation-Enhanced Graph Masked Autoencoders for Bundle Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuyang+Ren">Yuyang Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhang+Haonan">Zhang Haonan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Luoyi+Fu">Luoyi Fu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinbing+Wang">Xinbing Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenghu+Zhou">Chenghu Zhou</a> (2) </u>  <br>
        1:  Shanghai Jiao Tong University, 2:  Institute of Geographical Sciences and Natural Resources Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591666">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Distillation-Enhanced Graph Masked Autoencoders for Bundle Recommendation">Google Scholar</a></div>
        (158)
        <br>
        <b>概要:　</b> バンドル推薦は、ユーザーに一括してアイテムのバンドルを推薦することを目的としており、ユーザーとバンドル(U-B)のインタラクション情報、および補助的なユーザーとアイテム(U-I)のインタラクション情報やバンドル・アイテム関連情報を利用します。最近の手法では、通常、2つのグラフニューラルネットワーク(GNN)を使用して、ユーザーのバンドルに対する好みをU-Bグラフ（バンドルビュー）とU-Iグラフ（アイテムビュー）から個別にモデル化します。しかし、統計分析を行った結果、補助的なU-I情報が次の理由により十分に活用されていないことがわかりました：1) 予測結果を疎に組み合わせることでは、両方のビューからの知識を十分に統合できない。2) ローカルなU-BおよびU-Iの協調関係が一致しない場合があり、これによりGNNはU-Iグラフからユーザーのバンドルに対する好みを不正確にモデル化する可能性があります。3) U-Iのインタラクションは通常、均等にモデル化されますが、ユーザーのバンドルに対する好みに関連する重要なインタラクションが軽視されることがよくあります。これらの分析に基づき、私たちはバンドル推薦のための蒸留強化グラフマスク付きオートエンコーダ(DGMAE)を提案します。私たちのフレームワークは、U-Bグラフから第1次およびそれ以上のU-B関係の知識を抽出し、それを工夫されたグラフマスクオートエンコーダ（学生モデル）に注入します。この学生モデルは、U-Iグラフから重要なローカルおよびグローバルU-I関係を共同で捉えるための2つの重要な設計を持っています。具体的には、グローバルな関係学習のためにトランスフォーマー強化GNNエンコーダを設計しており、これによりユーザーのバンドルに対する好みを描写するモデルの表現力が向上します。同時に、学生モデルがユーザーのバンドルに対する好みを示唆する潜在的な重要なU-Iエッジを特定するように指導するための適応エッジマスキング戦略と再構築ターゲットを設計しました。ベンチマークデータセットでの広範な実験により、DGMAEが最先端の手法に比べて大幅に改善されることが示されました。
        </label>
        <input type="checkbox" id="Panel158" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Bundle recommendation aims to recommend a bundle of items to users as a whole with user-bundle (U-B) interaction information, and auxiliary user-item (U-I) interaction and bundle-item affiliation information. Recent methods usually use two graph neural networks (GNNs) to model user's bundle preferences separately from the U-B graph (bundle view) and U-I graph (item view). However, by conducting statistical analysis, we find that the auxiliary U-I information is far underexplored due to the following reasons: 1) Loosely combining the predicted results cannot well synthesize the knowledge from both views. 2) The local U-B and U-I collaborative relations might not be consistent, leading to GNN's inaccurate modeling of user's bundle preference from the U-I graph. 3) The U-I interactions are usually modeled equally while the significant ones corresponding to user's bundle preference are less emphasized. Based on these analyses, we propose a Distillation-enhanced Graph Masked AutoEncoder (DGMAE) for bundle recommendation. Our framework extracts the knowledge of first- and higher-order U-B relations from the U-B graph and injects it into a well-designed graph masked autoencoder (student model). The student model is built with two key designs to jointly capture significant local and global U-I relations from the U-I graph. In specific, we design a transformer-enhanced GNN encoder for global relation learning, which increases the model's representational power of depicting user's bundle preferences. Meanwhile, an adaptive edge masking strategy and reconstruction target are designed on the significant U-I edges to guide the student model to identify the potential ones suggesting user's bundle preferences. Extensive experiments on benchmark datasets show the significant improvements of DGMAE over the SOTA methods.
        </div> </ul> <br>



        <label for="Panel159">
        <strong> Candidate-aware Graph Contrastive Learning for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+He">Wei He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guohao+Sun">Guohao Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinhu+Lu">Jinhu Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiu+Susie+Fang">Xiu Susie Fang</a> (1) </u>  <br>
        1:  Donghua University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591647">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Candidate-aware Graph Contrastive Learning for Recommendation">Google Scholar</a></div>
        (159)
        <br>
        <b>概要:　</b> :<br>近年、グラフニューラルネットワーク（GNN）は主流の推薦システムの手法となっており、ユーザー-アイテム相互作用グラフ上で畳み込み操作を行うことにより、ノード間の高次協調信号を捉えて異なるアイテムに対するユーザーの好みを予測します。しかし、現実のシナリオでは、ユーザー-アイテム相互作用グラフは非常に疎であり、多くのユーザーはごく少数のアイテムとしか相互作用しません。このため、GNNは高品質なノード埋め込みの学習が困難となります。この問題を解決するため、グラフ対比学習（GCL）に基づく推薦システム手法が提案されました。GCLは、正のペアの類似性を最大化し、負のペアの類似性を最小化することで埋め込みの品質を向上させます。しかし、ほとんどのGCLベースの方法では、ランダムなノード/エッジの削除や属性マスキングといったヒューリスティックデータ拡張法を用いて対比ペアを構成するため、重要な情報が失われることがあります。GCLベースの方法におけるこれらの問題を解決するために、新たな手法「推薦のための候補認識型グラフ対比学習（CGCL）」を提案します。CGCLでは、異なる層でのユーザーと候補アイテムの埋め込みの関係性を探り、類似したセマンティック埋め込みを用いて対比ペアを構成します。提案するCGCLによって、構造的隣接対比学習オブジェクト、候補対比学習オブジェクト、および候補構造的隣接対比学習オブジェクトを構築し、高品質なノード埋め込みを得ることができます。提案モデルを検証するために、3つの公開データセットで広範な実験を行いました。様々な最先端のDNN、GNN、およびGCLベースの方法と比較して、提案するCGCLはすべての指標で大幅な改善を達成しました。
        </label>
        <input type="checkbox" id="Panel159" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recently, Graph Neural Networks (GNNs) have become a mainstream recommender system method, where it captures high-order collaborative signals between nodes by performing convolution operations on the user-item interaction graph to predict user preferences for different items. However, in real scenarios, the user-item interaction graph is extremely sparse, which means numerous users only interact with a small number of items, resulting in the inability of GNN in learning high-quality node embeddings. To alleviate this problem, the Graph Contrastive Learning (GCL)-based recommender system method is proposed. GCL improves embedding quality by maximizing the similarity of the positive pair and minimizing the similarity of the negative pair. However, most GCL-based methods use heuristic data augmentation methods, i.e., random node/edge drop and attribute masking, to construct contrastive pairs, resulting in the loss of important information. To solve the problems in GCL-based methods, we propose a novel method, Candidate-aware Graph Contrastive Learning for Recommendation, called CGCL. In CGCL, we explore the relationship between the user and the candidate item in the embedding at different layers and use similar semantic embeddings to construct contrastive pairs. By our proposed CGCL, we construct structural neighbor contrastive learning objects, candidate contrastive learning objects, and candidate structural neighbor contrastive learning objects to obtain high-quality node embeddings. To validate the proposed model, we conducted extensive experiments on three publicly available datasets. Compared with various state-of-the-art DNN-, GNN- and GCL-based methods, our proposed CGCL achieved significant improvements in all indicators.
        </div> </ul> <br>



        <label for="Panel160">
        <strong> Graph Transformer for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaoliu+Li">Chaoliu Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lianghao+Xia">Lianghao Xia</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xubin+Ren">Xubin Ren</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yaowen+Ye">Yaowen Ye</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yong+Xu">Yong Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chao+Huang">Chao Huang</a> (3) </u>  <br>
        1:  South China University of Technology, 2:  University of Hong Kong, 3:  University of Hong Kong <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591723">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Graph Transformer for Recommendation">Google Scholar</a></div>
        (160)
        <br>
        <b>概要:　</b> 本論文は、生成的自己教師あり学習とグラフトランスフォーマーアーキテクチャを統合することにより、レコメンダーシステムにおける表現学習の新しいアプローチを提案します。我々は、性能向上のために関連する自己教師ありプレテキストタスクを用いた高品質なデータ拡張の重要性を強調します。この目的を達成するために、情報的なユーザーアイテム相互作用パターンを蒸留する、理性的な生成的自己教師あり学習を通じて自己監督拡張プロセスを自動化する新しいアプローチを提案します。提案されたレコメンダーシステム「Graph Transformer (GFormer)」は、選択的な拡張を行うためのパラメータ化された協調的理論発見を提供しながら、グローバルなユーザーアイテム関係を維持します。GFormerでは、理性的な自己教師あり学習がグラフトランスフォーマーにおけるタスク適応型不変化を伴うグラフ協調フィルタリングに影響を与えることを許可します。実験結果は、GFormerが異なるデータセットにおいてベースラインを超えて一貫して性能を向上させる能力があることを明らかにしています。さらに、いくつかの詳細な実験により、さまざまな側面から不変の理論認識拡張を調査しています。本研究のソースコードは以下のリンクで公開されています：https://github.com/HKUDS/GFormer。
        </label>
        <input type="checkbox" id="Panel160" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This paper presents a novel approach to representation learning in recommender systems by integrating generative self-supervised learning with graph transformer architecture. We highlight the importance of high-quality data augmentation with relevant self-supervised pretext tasks for improving performance. Towards this end, we propose a new approach that automates the self-supervision augmentation process through a rationale-aware generative SSL that distills informative user-item interaction patterns. The proposed recommender with Graph Transformer (GFormer) that offers parameterized collaborative rationale discovery for selective augmentation while preserving global-aware user-item relationships. In GFormer, we allow the rationale-aware SSL to inspire graph collaborative filtering with task-adaptive invariant rationalization in graph transformer. The experimental results reveal that our GFormer has the capability to consistently improve the performance over baselines on different datasets. Several in-depth experiments further investigate the invariant rationale-aware augmentation from various aspects. The source code for this work is publicly available at: https://github.com/HKUDS/GFormer.
        </div> </ul> <br>



        <label for="Panel161">
        <strong> Manipulating Federated Recommender Systems: Poisoning with Synthetic Users and Its Countermeasures </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Yuan">Wei Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Quoc+Viet+Hung+Nguyen">Quoc Viet Hung Nguyen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tieke+He">Tieke He</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liang+Chen">Liang Chen</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongzhi+Yin">Hongzhi Yin</a> (1) </u>  <br>
        1:  The University of Queensland, 2:  Griffith University, 3:  Nanjing University, 4:  Sun Yat-Sen University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591722">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Manipulating Federated Recommender Systems: Poisoning with Synthetic Users and Its Countermeasures">Google Scholar</a></div>
        (161)
        <br>
        <b>概要:　</b> フェデレーテッド推薦システム（FedRecs）は、ユーザーデータを共有せずに、共同で推薦モデルを学習するためのプライバシー保護手法とされています。すべての参加者は勾配をアップロードすることでシステムに直接影響を与えることができるため、FedRecsは悪意のあるクライアントによるポイズニング攻撃に対して脆弱です。しかし、既存のFedRecsに対するポイズニング攻撃の多くは何らかの事前知識に基づいているか、効果が低いものです。FedRecsの実際の脆弱性を明らかにするために、本論文では、事前知識に依存せず、ターゲットアイテムのランクと露出率を効果的に操作する新たなポイズニング攻撃手法を提案します。具体的には、ターゲットアイテムの代替商品を考慮して毒された勾配をアップロードする一群の合成悪意ユーザーによって、ターゲットアイテムの露出率を操作します。我々は、現実世界の2つの推薦データセットにおいて、2つの広く使われているFedRecs（Fed-NCFおよびFed-LightGCN）を用いて広範な実験を行いました。その実験結果は、最先端の攻撃と比較して、ターゲットアイテムの露出率を遥かに少ない悪意ユーザーと少ないグローバルエポックで大幅に向上させることができることを示しています。このセキュリティホールを明らかにするだけでなく、我々はFedRecsに対するポイズニング攻撃に対する新たな対策を設計しました。具体的には、階層型勾配クリッピングと疎化された更新を提案し，既存のポイズニング攻撃に対抗します。実証結果は、提案した防御メカニズムがFedRecsの堅牢性を向上させることを示しています。
        </label>
        <input type="checkbox" id="Panel161" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Federated Recommender Systems (FedRecs) are considered privacy-preserving techniques to collaboratively learn a recommendation model without sharing user data. Since all participants can directly influence the systems by uploading gradients, FedRecs are vulnerable to poisoning attacks of malicious clients. However, most existing poisoning attacks on FedRecs are either based on some prior knowledge or with less effectiveness. To reveal the real vulnerability of FedRecs, in this paper, we present a new poisoning attack method to manipulate target items' ranks and exposure rates effectively in the top-K recommendation without relying on any prior knowledge. Specifically, our attack manipulates target items' exposure rate by a group of synthetic malicious users who upload poisoned gradients considering target items' alternative products. We conduct extensive experiments with two widely used FedRecs (Fed-NCF and Fed-LightGCN) on two real-world recommendation datasets. The experimental results show that our attack can significantly improve the exposure rate of unpopular target items with extremely fewer malicious users and fewer global epochs than state-of-the-art attacks. In addition to disclosing the security hole, we design a novel countermeasure for poisoning attacks on FedRecs. Specifically, we propose a hierarchical gradient clipping with sparsified updating to defend against existing poisoning attacks. The empirical results demonstrate that the proposed defending mechanism improves the robustness of FedRecs.
        </div> </ul> <br>



        <label for="Panel162">
        <strong> Topic-oriented Adversarial Attacks against Black-box Neural Ranking Models </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yu-An+Liu">Yu-An Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruqing+Zhang">Ruqing Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiafeng+Guo">Jiafeng Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Chen">Wei Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yixing+Fan">Yixing Fan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xueqi+Cheng">Xueqi Cheng</a> (1) </u>  <br>
        1:  ICT, 2:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591777">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Topic-oriented Adversarial Attacks against Black-box Neural Ranking Models">Google Scholar</a></div>
        (162)
        <br>
        <b>概要:　</b> ニューラルランキングモデル (NRM) は情報検索分野で大きな注目を集めています。しかし、NRMsは一般的なニューラルネットワークの脆弱性を引き継ぐ可能性があり、これが悪意あるSEO実践者によって悪用される恐れがあります。近年、NRMに対する敵対的攻撃はペア攻撃の設定で検討されており、特定のクエリに対してターゲットドキュメントに敵対的な摂動を生成することが主流です。本論文では、より一般的な摂動の種類に焦点を当て、NRMsに対するトピック指向な敵対的ランキング攻撃タスクを提案します。このタスクは、同じトピックを持つクエリ群においてターゲットドキュメントのランキングを上昇させるために、目に見えない摂動を見つけることを目的としています。このタスクのために静的および動的な設定の両方を定義し、主に意思決定ベースのブラックボックス攻撃に注目します。我々は代理ランキングモデルに基づく新しいフレームワークを提案し、トピック指向の攻撃パフォーマンスを向上させます。この攻撃問題はマルコフ決定過程 (MDP) として形式化され、強化学習を用いて解決されます。特に、トピック指向の報酬関数がポリシーをガイドし、グループ内のできるだけ多くのクエリに対してランキングが上昇する成功した敵対例を見つけることを目指します。実験結果は、提案されたフレームワークが既存の攻撃戦略を大幅に上回ることを示しており、NRMsを現実世界で適用する際の潜在的リスクが存在することを改めて指摘します。
        </label>
        <input type="checkbox" id="Panel162" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Neural ranking models (NRMs) have attracted considerable attention in information retrieval. Unfortunately, NRMs may inherit the adversarial vulnerabilities of general neural networks, which might be leveraged by black-hat search engine optimization practitioners. Recently, adversarial attacks against NRMs have been explored in the paired attack setting, generating an adversarial perturbation to a target document for a specific query. In this paper, we focus on a more general type of perturbation and introduce the topic-oriented adversarial ranking attack task against NRMs, which aims to find an imperceptible perturbation that can promote a target document in ranking for a group of queries with the same topic. We define both static and dynamic settings for the task and focus on decision-based black-box attacks. We propose a novel framework to improve topic-oriented attack performance based on a surrogate ranking model. The attack problem is formalized as a Markov decision process (MDP) and addressed using reinforcement learning. Specifically, a topic-oriented reward function guides the policy to find a successful adversarial example that can be promoted in rankings to as many queries as possible in a group. Experimental results demonstrate that the proposed framework can significantly outperform existing attack strategies, and we conclude by re-iterating that there exist potential risks for applying NRMs in the real world.
        </div> </ul> <br>



        <label for="Panel163">
        <strong> RCENR: A Reinforced and Contrastive Heterogeneous Network Reasoning Model for Explainable News Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Jiang">Hao Jiang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chuanzhen+Li">Chuanzhen Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Juanjuan+Cai">Juanjuan Cai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingling+Wang">Jingling Wang</a> (1) </u>  <br>
        1:  Communication University of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591753">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=RCENR: A Reinforced and Contrastive Heterogeneous Network Reasoning Model for Explainable News Recommendation">Google Scholar</a></div>
        (163)
        <br>
        <b>概要:　</b> 既存のニュースレコメンデーション手法は、疎かつ弱いインタラクションデータに悩まされ、その有効性と説明可能性が低下します。知識推論は、知識グラフ内の推論経路を探求することでデータの希薄さを緩和し、明示的な推奨の説明を提供することができます。しかし、従来の方法で使用される無理やりの前処理アプローチは、急速に変化するニュースレコメンデーションには適していません。したがって、我々は説明可能なニュースレコメンデーションモデル「強化学習を用いた対照的異種ネットワーク推論モデル（RCENR）」を提案します。このモデルは、NHN-R2およびMR&COフレームワークで構成されています。NHN-R2フレームワークは、レコメンデーションを強化し推論の次元と多様性を拡張するためにユーザー/ニュースのサブグラフを生成します。MR&COフレームワークは、強化学習ベースの戦略と対照的学習を組み合わせ、自己監督型かつ効率的なモデル訓練を行います。MINDデータセットでの実験により、RCENRはレコメンデーション精度を向上させ、多様で信頼性のある説明を提供できることが示されました。
        </label>
        <input type="checkbox" id="Panel163" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Existing news recommendation methods suffer from sparse and weak interaction data, leading to reduced effectiveness and explainability. Knowledge reasoning, which explores inferential trajectories in the knowledge graph, can alleviate data sparsity and provide explicitly recommended explanations. However, brute-force pre-processing approaches used in conventional methods are not suitable for fast-changing news recommendation. Therefore, we propose an explainable news recommendation model: the Reinforced and Contrastive Heterogeneous Network Reasoning Model for Explainable News Recommendation (RCENR), consisting of NHN-R2 and MR&CO frameworks. The NHN-R2 framework generates user/news subgraphs to enhance recommendation and extend the dimensions and diversity of reasoning. The MR&CO framework incorporates contrastive learning with a reinforcement-based strategy for self-supervised and efficient model training. Experiments on the MIND dataset show that RCENR is able to improve recommendation accuracy and provide diverse and credible explanations.
        </div> </ul> <br>



        <label for="Panel164">
        <strong> Seq-HGNN: Learning Sequential Node Representation on Heterogeneous Graph </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenguang+Du">Chenguang Du</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kaichun+Yao">Kaichun Yao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hengshu+Zhu">Hengshu Zhu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Deqing+Wang">Deqing Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuzhen+Zhuang">Fuzhen Zhuang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hui+Xiong">Hui Xiong</a> (4) </u>  <br>
        1:  Beihang University, 2:  Institute of Software Chinese Academy of Sciences, 3:  Career Science Lab, 4:  The Hong Kong University of Science and Technology (Guangzhou) <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591765">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Seq-HGNN: Learning Sequential Node Representation on Heterogeneous Graph">Google Scholar</a></div>
        (164)
        <br>
        <b>概要:　</b> 近年、異種グラフニューラルネットワーク（HGNNs）の情報検索（IR）アプリケーションにおける急速な発展が見られます。多くの既存のHGNNは、異種グラフ内の構造的および意味的情報を捉えるため、様々なカスタムグラフ畳み込みを設計しています。しかし、既存のHGNNは通常、各ノードを複数層のグラフ畳み込み計算内で単一のベクトルとして表現するため、高次のグラフ畳み込み層が異なる関係および異なる順序からの情報を区別できず、メッセージ伝播における情報の損失を引き起こします。この問題を解決するため、シーケンシャルノード表現を用いた新しい異種グラフニューラルネットワーク、Seq-HGNNを提案します。単一ベクトルノード表現による情報損失を避けるため、まず各ノードをノードメッセージ伝播中にメタパス表現のシーケンスとして表現するシーケンシャルノード表現学習メカニズムを設計します。次に、重要なメタパスを特定し、その表現をコンパクトなものに集約する異種表現融合モジュールを提案します。Heterogeneous Graph Benchmark（HGB）とOpen Graph Benchmark（OGB）の4つの広く使用されるデータセットで広範な実験を行いました。実験結果は、提案手法が最先端のベースラインを精度と効率の両方で上回ることを示しています。ソースコードはhttps://github.com/nobrowning/SEQ_HGNNで公開されています。
        </label>
        <input type="checkbox" id="Panel164" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recent years have witnessed the rapid development of heterogeneous graph neural networks (HGNNs) in information retrieval (IR) applications. Many existing HGNNs design a variety of tailor-made graph convolutions to capture structural and semantic information in heterogeneous graphs. However, existing HGNNs usually represent each node as a single vector in the multi-layer graph convolution calculation, which makes the high-level graph convolution layer fail to distinguish information from different relations and different orders, resulting in the information loss in the message passing. Then we propose a novel heterogeneous graph neural network with sequential node representation, namely Seq-HGNN. To avoid the information loss caused by the single vector node representation, we first design a sequential node representation learning mechanism to represent each node as a sequence of meta-path representations during the node message passing. Then we propose a heterogeneous representation fusion module, empowering Seq-HGNN to identify important meta-paths and aggregate their representations into a compact one. We conduct extensive experiments on four widely used datasets from Heterogeneous Graph Benchmark (HGB) and Open Graph Benchmark (OGB). Experimental results show that our proposed method outperforms state-of-the-art baselines in both accuracy and efficiency. The source code is available at https://github.com/nobrowning/SEQ_HGNN.
        </div> </ul> <br>



        <label for="Panel165">
        <strong> A Lightweight Constrained Generation Alternative for Query-focused Summarization </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhichao+Xu">Zhichao Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daniel+Cohen">Daniel Cohen</a> (2) </u>  <br>
        1:  University of Utah, 2:  Dataminr <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591936">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Lightweight Constrained Generation Alternative for Query-focused Summarization">Google Scholar</a></div>
        (165)
        <br>
        <b>概要:　</b> 焦点型（QFS）は、与えられたクエリの情報ニーズを満たし、的スニペット生成などさまざまな情報検索（IR）アプリケーションに役立つドキュメントのを提供することを目的としています。現在のQFSアプローチは、通常、大型言語モデルに微調整した追加情報（例：クエリ-回答の関連性やクエリとドキュメント間の詳細なトークンレベルの相互作用）を注入することが含まれます。しかし、これらの方法は追加のパラメータやトレーニングを必要とし、新しいデータセット分布には一般化しにくいという問題があります。この問題を軽減するために、我々は現在のQFS方式に代わるものとして、追加のサブアーキテクチャやトレーニングに依存しない、新たに開発された制約生成モデルNeurological Decoding (NLD)を活用することを提案します。まず、軽量な勾配帰属モデルを使用してドキュメントから重要なトークンを特定し、これにより構築された語彙制約を強制することで生成されたがこれらの制約を満たすようにします。この軽量なアプローチは、制約の構築には汎用のニューラル検索モデルを使用し、QFSの生成には標準的な生成言語モデルを利用するため、追加のパラメータや微調整を必要としません。我々は、2つの公開QFSコレクションでこのアプローチの有効性を実証し、最先端モデルとほぼ同等の性能を達成しながら、複雑さを大幅に軽減することができました。
        </label>
        <input type="checkbox" id="Panel165" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Query-focused summarization (QFS) aims to provide a summary of a document that satisfies information need of a given query and is useful in various IR applications, such as abstractive snippet generation. Current QFS approaches typically involve injecting additional information, e.g. query-answer relevance or fine-grained token-level interaction between a query and document, into a finetuned large language model. However, these approaches often require extra parameters & training, and generalize poorly to new dataset distributions. To mitigate this, we propose leveraging a recently developed constrained generation model Neurological Decoding (NLD) as an alternative to current QFS regimes which rely on additional sub-architectures and training. We first construct lexical constraints by identifying important tokens from the document using a lightweight gradient attribution model, then subsequently force the generated summary to satisfy these constraints by directly manipulating the final vocabulary likelihood. This lightweight approach requires no additional parameters or finetuning as it utilizes both an off-the-shelf neural retrieval model to construct the constraints and a standard generative language model to produce the QFS. We demonstrate the efficacy of this approach on two public QFS collections achieving near parity with the state-of-the-art model with substantially reduced complexity.
        </div> </ul> <br>



        <label for="Panel166">
        <strong> A Mathematical Word Problem Generator with Structure Planning and Knowledge Enhancement </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Longhu+Qin">Longhu Qin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiayu+Liu">Jiayu Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenya+Huang">Zhenya Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kai+Zhang">Kai Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Liu">Qi Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Binbin+Jin">Binbin Jin</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Enhong+Chen">Enhong Chen</a> (4) </u>  <br>
        1:  School of Computer Science and Technology, 2:  School of Data Science, 3:  Huawei Cloud Computing Technologies Co., 4:  Anhui Province Key Laboratory of Big Data Analysis and Application <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591937">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Mathematical Word Problem Generator with Structure Planning and Knowledge Enhancement">Google Scholar</a></div>
        (166)
        <br>
        <b>概要:　</b> 方程式とトピックに従った制御可能で多様な数学的文章問題 (MWP) を自動生成することは、情報検索と自然言語生成において重要な課題です。最近のディープラーニングモデルは、主に問題の読みやすさの向上に焦点を当てていますが、数学的な論理の一貫性を見落としてしまい、解けない問題を生成しがちです。本研究では、人間による問題作成プロセスからインスピレーションを受け、「計画-生成」ステップに従って、数学的構造計画と知識強化生成モデル (MaPKG) を提案します。具体的には、文レベルの方程式計画を行う新しい動的計画モジュールと、方程式の構造表現と外部の常識知識を組み込んだ単語レベル生成のための二重アテンション機構を提案します。2つのMWPデータセットに関する広範な実験により、我々のモデルがより解決可能で、高品質かつ多様な問題を保証できることを示します。コードはhttps://github.com/KenelmQLH/MaPKG.gitで公開しています。
        </label>
        <input type="checkbox" id="Panel166" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Automatically generating controllable and diverse mathematical word problems (MWPs) which conform to equations and topics is a crucial task in information retrieval and natural language generation. Recent deep learning models mainly focus on improving the problem readability but overlook the mathematical logic coherence, which tends to generate unsolvable problems. In this paper, we draw inspiration from the human problem-designing process and propose a Mathematical structure Planning and Knowledge enhanced Generation model (MaPKG), following the "plan-then-generate" steps. Specifically, we propose a novel dynamic planning module to make sentence-level equation plans and a dual-attention mechanism for word-level generation, incorporating equation structure representation and external commonsense knowledge. Extensive experiments on two MWP datasets show our model can guarantee more solvable, high-quality, and diverse problems. Our code is available at https://github.com/KenelmQLH/MaPKG.git
        </div> </ul> <br>



        <label for="Panel167">
        <strong> Mixup-based Unified Framework to Overcome Gender Bias Resurgence </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liu+Yu">Liu Yu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuzhou+Mao">Yuzhou Mao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jin+Wu">Jin Wu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fan+Zhou">Fan Zhou</a> (1) </u>  <br>
        1:  University of Electronic Science and Technology of China & Kashi Institute of Electronics and Information Industry, 2:  University of Electronic Science and Technology of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591938">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Mixup-based Unified Framework to Overcome Gender Bias Resurgence">Google Scholar</a></div>
        (167)
        <br>
        <b>概要:　</b> 事前学習された言語モデル（PLMs）には、不要な社会的バイアスがしばしば含まれています。最近の研究では、PLMsに内在するバイアスの軽減に取り組んでいます。しかし、アプリケーションに対する別々のファインチューニングは、内在するバイアスの軽減には有害です。デバイアスされたPLMsを下流のタスクにファインチューニングする際に、バイアスの再発現問題が生じます。ファインチューニング中にPLMsの望ましくないステレオタイプ的な関連付けを排除するために、新しい統一的な視点からミックスアップベースのフレームワークMix-Debiasを提案します。これは、デバイアスされたPLMsとファインチューニングを直接結びつけるものです。Mix-Debiasの鍵は、外部コーパスから拡張されたペアを使用して、反事実的に拡張された下流データセットに対してミックスアップベースの線形補間を適用することにあります。さらに、オリジナルの拡張ペアと性別バランスの取れたペアが空間的に近くなるように配置正則化子を設計しました。実験結果から、Mix-Debiasは、アプリケーションの性能を維持しつつ、PLMsのバイアスを低減できることが示されました。
        </label>
        <input type="checkbox" id="Panel167" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Unwanted social biases are usually encoded in pretrained language models (PLMs). Recent efforts are devoted to mitigating intrinsic bias encoded in PLMs. However, the separate fine-tuning on applications is detrimental to intrinsic debiasing. A bias resurgence issue arises when fine-tuning the debiased PLMs on downstream tasks. To eliminate undesired stereotyped associations in PLMs during fine-tuning, we present a mixup-based framework Mix-Debias from a new unified perspective, which directly combines debiasing PLMs with fine-tuning applications. The key to Mix-Debias is applying mixup-based linear interpolation on counterfactually augmented downstream datasets, with expanded pairs from external corpora. Besides, we devised an alignment regularizer to ensure original augmented pairs and gender-balanced counterparts are spatially closer. Experimental results show that Mix-Debias can reduce biases in PLMs while maintaining a promising performance in applications.
        </div> </ul> <br>



        <label for="Panel168">
        <strong> A Model-Agnostic Popularity Debias Training Framework for Click-Through Rate Prediction in Recommender System </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fan+Zhang">Fan Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qijie+Shen">Qijie Shen</a> (2) </u>  <br>
        1:  Shopee, 2:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591939">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Model-Agnostic Popularity Debias Training Framework for Click-Through Rate Prediction in Recommender System">Google Scholar</a></div>
        (168)
        <br>
        <b>概要:　</b> レコメンダーシステム（RS）は、多様なシナリオで広く適用され、ユーザーが必要な情報を効率的に取得するのを支援しています。同時に、このようなシステムにおける人気バイアスの問題が広く認識されています。この課題に対処するために、我々はモデル非依存型人気度デバイアストレーニングフレームワーク（MDTF）という新しい方法を提案します。MDTFは二つの基本モジュールから成り立っています。1) 一般ランクモデル（GRM）：これはモデルに依存せず、任意のランクモデルとして実装できます。2) 人気度デバイスモジュール（PDM）：これは候補アイテムの競争力と人気度がCTRに与える影響を推定し、コールドスタートユーザーのフィードバックを利用してGRMの損失を再重み付けします。MDTFはこれらの二つのモジュールをエンドツーエンドのマルチタスク学習フレームワークにシームレスに統合します。実世界のオフラインデータセットとオンラインのA/Bテストの両方で実施した広範な実験により、最先端の手法に対する優位性が示されました。
        </label>
        <input type="checkbox" id="Panel168" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recommender system (RS) is widely applied in a multitude of scenarios to aid individuals obtaining the information they require efficiently. At the same time, the prevalence of popularity bias in such systems has become a widely acknowledged issue. To address this challenge, we propose a novel method named Model-Agnostic Popularity Debias Training Framework (MDTF). It consists of two basic modules including 1) General Ranking Model (GRM), which is model-agnostic and can be implemented as any ranking models; and 2) Popularity Debias Module (PDM), which estimates the impact of the competitiveness and popularity of candidate items on the CTR, by utilizing the feedback of cold-start users to re-weigh the loss in GRM. MDTF seamlessly integrates these two modules in an end-to-end multi-task learning framework. Extensive experiments on both real-world offline dataset and online A/B test demonstrate its superiority over state-of-the-art methods.
        </div> </ul> <br>



        <label for="Panel169">
        <strong> A Simple yet Effective Framework for Few-Shot Aspect-Based Sentiment Analysis </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zengzhi+Wang">Zengzhi Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiming+Xie">Qiming Xie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rui+Xia">Rui Xia</a> (1) </u>  <br>
        1:  Nanjing University of Science and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591940">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Simple yet Effective Framework for Few-Shot Aspect-Based Sentiment Analysis">Google Scholar</a></div>
        (169)
        <br>
        <b>概要:　</b> 事前学習と微調整のパラダイムは、アスペクトベース感情分析（ABSA）の分野における主流のフレームワークとなっています。このパラダイムは、細かいアスペクト感情付けのアノテーションが十分に存在するドメインでは高い性能を発揮していますが、人手によるアノテーションが不足しているドメインでの少ないデータを用いたABSA（few-shot ABSA）の実施には依然として課題が残っています。本研究では、ドメインギャップと目的ギャップという2種類のギャップが、事前学習された言語モデル（PLM）からABSAタスクへの知識転移を妨げると主張します。この問題に対処するため、我々はFS-ABSAと呼ばれるシンプルかつ効果的なフレームワークを提案します。このフレームワークでは、ドメイン適応型の事前学習とテキスト-インフィリング微調整を行います。エンド・ツー・エンドABSAタスクをテキスト-インフィリングの問題として捉え、テキスト-インフィリングの目的を持つドメイン適応型の事前学習を実施することで、2つのギャップを縮小し、知識転移を促進します。実験結果は、提案モデルが少ないデータ設定下でベースラインを凌駕する説得力のある性能を達成し、完全に監督された設定下でも最先端の性能を新たなレベルに向上させることを示しています。さらに、本フレームワークの一般性と有効性を示すために、非英語の低リソース言語2つにも適用しました。
        </label>
        <input type="checkbox" id="Panel169" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The pre-training and fine-tuning paradigm has become the main-stream framework in the field of Aspect-Based Sentiment Analysis (ABSA). Although it has achieved sound performance in the domains containing enough fine-grained aspect-sentiment annotations, it is still challenging to conduct few-shot ABSA in domains where manual annotations are scarce. In this work, we argue that two kinds of gaps, i.e., domain gap and objective gap, hinder the transfer of knowledge from pre-training language models (PLMs) to ABSA tasks. To address this issue, we introduce a simple yet effective framework called FS-ABSA, which involves domain-adaptive pre-training and text-infilling fine-tuning. We approach the End-to-End ABSA task as a text-infilling problem and perform domain-adaptive pre-training with the text-infilling objective, narrowing the two gaps and consequently facilitating the knowledge transfer. Experiments show that the resulting model achieves more compelling performance than baselines under the few-shot setting while driving the state-of-the-art performance to a new level across datasets under the fully-supervised setting. Moreover, we apply our framework to two non-English low-resource languages to demonstrate its generality and effectiveness.
        </div> </ul> <br>



        <label for="Panel170">
        <strong> A Static Pruning Study on Sparse Neural Retrievers </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Carlos+Lassance">Carlos Lassance</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Simon+Lupart">Simon Lupart</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hervé+Déjean">Hervé Déjean</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Stéphane+Clinchant">Stéphane Clinchant</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nicola+Tonellotto">Nicola Tonellotto</a> (2) </u>  <br>
        1:  Naver Labs Europe, 2:  University of Pisa <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591941">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Static Pruning Study on Sparse Neural Retrievers">Google Scholar</a></div>
        (170)
        <br>
        <b>概要:　</b> 最近、DeepImpact、uniCOIL、SPLADEなどのスパースニューラル・リトリーバーが、転置インデックスを用いた効率的かつ効果的な検索方法として導入されました。これらは単語の重要性を学習し、場合によってはドキュメントの拡張も行うことで、BM25のような従来の単語袋モデルに比べてより効果的なドキュメントランキングを提供します。しかし、これらのスパースニューラル・リトリーバーは、従来のモデルに比べて計算コストとクエリ処理のレイテンシを増加させることが示されています。これを改善するために、転置インデックス上のクエリ処理の効率を向上させるためのよく知られた手法である静的プルーニングを適用しました。実験では、ドキュメント中心、単語中心、およびアグノスティックプルーニングの三つの静的プルーニング戦略を試し、多様なデータセットでスパースニューラル・リトリーバーに対してもこれらの手法が有効であることを確認しました。特に、静的プルーニングは効果のわずかな損失（≤ 2%の低下）で2倍の速度向上を達成し、使用例によっては効果に最小限の影響（≤ 8%の低下）で4倍の速度向上も可能であることを示しました。さらに、ニューラルリランカーが静的にプルーニングされたインデックスの候補に対しても堅牢であることを確認しました。
        </label>
        <input type="checkbox" id="Panel170" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Sparse neural retrievers, such as DeepImpact, uniCOIL and SPLADE, have been introduced recently as an efficient and effective way to perform retrieval with inverted indexes. They aim to learn term importance and, in some cases, document expansions, to provide a more effective document ranking compared to traditional bag-of-words retrieval models such as BM25. However, these sparse neural retrievers have been shown to increase the computational costs and latency of query processing compared to their classical counterparts. To mitigate this, we apply a well-known family of techniques for boosting the efficiency of query processing over inverted indexes: static pruning. We experiment with three static pruning strategies, namely document-centric, term-centric and agnostic pruning, and we assess, over diverse datasets, that these techniques still work with sparse neural retrievers. In particular, static pruning achieves 2x speedup with negligible effectiveness loss (≤ 2% drop) and, depending on the use case, even 4x speedup with minimal impact on the effectiveness (≤ 8% drop). Moreover, we show that neural rerankers are robust to candidates from statically pruned indexes.
        </div> </ul> <br>



        <label for="Panel171">
        <strong> A Unified Formulation for the Frequency Distribution of Word Frequencies using the Inverse Zipf's Law </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Can+Özbey">Can Özbey</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Talha+Çolakoğlu">Talha Çolakoğlu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=M.+Şafak+Bilici">M. Şafak Bilici</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ekin+Can+Erkuş;">Ekin Can Erkuş;</a> (1) </u>  <br>
        1:  Huawei Turkey R&D Center <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591942">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Unified Formulation for the Frequency Distribution of Word Frequencies using the Inverse Zipf's Law">Google Scholar</a></div>
        (171)
        <br>
        <b>概要:　</b> 本論文は、単語の頻度分布に対するジップの提案したべき法則近似について、数十年にわたる広範な研究の一環として、そのテーマに多くの変種が存在することを指摘します。しかし、単語頻度のケースに関する調査は比較的少ないとされています。本論文では、総単語数、語彙サイズ、および形状パラメータの関数として、基礎的なランクサイズ分布の逆数からその解析的表現を導出することにより、対数-対数目盛における低頻度の非線形な挙動を説明する統一的なフレームワークを提供します。また、経験的な低頻度確率の少数を用いて形状パラメータを頑健に推定するための効率的な方法として、相対エントロピー最小化に基づく手法を提示します。提案手法の有効性を示すために、屈折度の異なる選択された言語セットに対して実験を行いました。
        </label>
        <input type="checkbox" id="Panel171" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The power-law approximation for the frequency distribution of words postulated by Zipf has been extensively studied for decades, which led to many variations on the theme. However, comparatively less attention has been paid to the investigation of the case of word frequencies. In this paper, we derive its analytical expression from the inverse of the underlying rank-size distribution as a function of total word count, vocabulary size and the shape parameter, thereby providing a unified framework to explain the nonlinear behavior of low frequencies on the log-log scale. We also present an efficient method based on relative entropy minimization for a robust estimation of the shape parameter using a small number of empirical low-frequency probabilities. Experiments were carried out for a selected set of languages with varying degrees of inflection in order to demonstrate the effectiveness of the proposed approach.
        </div> </ul> <br>



        <label for="Panel172">
        <strong> Adapting Learned Sparse Retrieval for Long Documents </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Thong+Nguyen">Thong Nguyen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sean+MacAvaney">Sean MacAvaney</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrew+Yates">Andrew Yates</a> (1) </u>  <br>
        1:  University of Amsterdam, 2:  University of Glasgow <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591943">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Adapting Learned Sparse Retrieval for Long Documents">Google Scholar</a></div>
        (172)
        <br>
        <b>概要:　</b> 学習済みスパース検索（Learned Sparse Retrieval、LSR）は、クエリや文書を語彙に沿ったスパースウェイトベクトルに変換するニューラル検索手法群です。SpladeのようなLSRアプローチは短文には効果的ですが、長い文書に対してどの程度有効かは明らかではありません。そこで、本研究ではLSRを長文に適応させるための既存の集約手法を検討し、プロキシマルスコアリングが長文処理に不可欠であることを明らかにしました。この特性を活用するため、シーケンシャル依存モデル（Sequential Dependence Model、SDM）の2つの適応版、ExactSDMとSoftSDMを提案します。ExactSDMは正確なクエリ用語の依存関係のみを仮定し、SoftSDMはトランスフォーマーのマスクドランゲージモデルの頭を使用して特定された拡張用語とクエリ用語の依存関係をモデル化するポテンシャル関数を使用します。MSMARCOドキュメントおよびTREC Robust04データセットでの実験では、ExactSDMとSoftSDMの両方が異なる文書長制約に対して既存のLSR集約手法を上回っていることが示されました。意外なことに、SoftSDMはExactSDMに対して性能上の利点を提供しませんでした。これは、用語依存性をモデル化する際にソフトな近接一致が必須ではないことを示唆しています。全体として、本研究はLSRを用いた長文処理についての洞察を提供し、その性能を向上させる適応手法を提案します。
        </label>
        <input type="checkbox" id="Panel172" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Learned sparse retrieval (LSR) is a family of neural retrieval methods that transform queries and documents into sparse weight vectors aligned with a vocabulary. While LSR approaches like Splade work well for short passages, it is unclear how well they handle longer documents. We investigate existing aggregation approaches for adapting LSR to longer documents and find that proximal scoring is crucial for LSR to handle long documents. To leverage this property, we proposed two adaptations of the Sequential Dependence Model (SDM) to LSR: ExactSDM and SoftSDM. ExactSDM assumes only exact query term dependence, while SoftSDM uses potential functions that model the dependence of query terms and their expansion terms (i.e., terms identified using a transformer's masked language modeling head). Experiments on the MSMARCO Document and TREC Robust04 datasets demonstrate that both ExactSDM and SoftSDM outperform existing LSR aggregation approaches for different document length constraints. Surprisingly, SoftSDM does not provide any performance benefits over ExactSDM. This suggests that soft proximity matching is not necessary for modeling term dependence in LSR. Overall, this study provides insights into handling long documents with LSR, proposing adaptations that improve its performance.
        </div> </ul> <br>



        <label for="Panel173">
        <strong> ADL: Adaptive Distribution Learning Framework for Multi-Scenario CTR Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinyun+Li">Jinyun Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huiwen+Zheng">Huiwen Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuanlin+Liu">Yuanlin Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Minfang+Lu">Minfang Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lixia+Wu">Lixia Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haoyuan+Hu">Haoyuan Hu</a> (1) </u>  <br>
        1:  Cainiao Network <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591944">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=ADL: Adaptive Distribution Learning Framework for Multi-Scenario CTR Prediction">Google Scholar</a></div>
        (173)
        <br>
        <b>概要:　</b> 大規模な商業プラットフォームでは、多様なビジネス戦略のために多数の業務シナリオが関与します。複数のシナリオに同時にクリックスルーレート（CTR）予測を提供するために、既存の多シナリオモデルは特定のビジネス戦略に基づいてシナリオを手動でグループ化し、シナリオ固有のネットワークを明示的に構築します。しかし、この事前定義されたデータ分割プロセスは事前知識に大きく依存しており、各シナリオの基本的なデータ分布を見落とす可能性があり、そのためモデルの表現能力を制限します。上記の問題に対して、我々は適応分布学習（ADL）を提案します。これは、クラスタリングプロセスと分類プロセスから構成されるエンドツーエンドの最適化分布フレームワークです。具体的には、カスタマイズされた動的ルーティングメカニズムを持つ分布適応モジュールを設計しました。このルーティングアルゴリズムは、事前知識を導入してデータを事前に割り当てる代わりに、各サンプルに対してどのクラスターに属するかを決定するための分布係数を適応的に提供します。各クラスターは特定の分布に対応しており、モデルがこれらの異なるクラスター間の共通点と相違点を十分に把握できるようにします。我々の結果は、公共および大規模な産業データセットの両方でADLの有効性と効率性を示しています。モデルは、他の方法と比較して訓練段階での時間コストを50%以上削減しながら、驚くべき予測精度を達成しました。
        </label>
        <input type="checkbox" id="Panel173" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Large-scale commercial platforms usually involve numerous business scenarios for diverse business strategies. To provide click-through rate (CTR) predictions for multiple scenarios simultaneously, existing promising multi-scenario models explicitly construct scenario-specific networks by manually grouping scenarios based on particular business strategies. Nonetheless, this pre-defined data partitioning process heavily relies on prior knowledge, and it may neglect the underlying data distribution of each scenario, hence limiting the model's representation capability. Regarding the above issues, we propose Adaptive Distribution Learning (ADL): an end-to-end optimization distribution framework which is composed of a clustering process and classification process. Specifically, we design a distribution adaptation module with a customized dynamic routing mechanism. Instead of introducing prior knowledge for pre-defined data allocation, this routing algorithm adaptively provides a distribution coefficient for each sample to determine which cluster it belongs to. Each cluster corresponds to a particular distribution so that the model can sufficiently capture the commonalities and distinctions between these distinct clusters. Our results on both public and large-scale industrial datasets show the effectiveness and efficiency of ADL: the model yields impressive prediction accuracy with more than 50% reduction in time cost during the training phase when compared to other methods.
        </div> </ul> <br>



        <label for="Panel174">
        <strong> Adversarial Meta Prompt Tuning for Open Compound Domain Adaptive Intent Detection </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Feiteng+Fang">Feiteng Fang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Min+Yang">Min Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chengming+Li">Chengming Li</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruifeng+Xu">Ruifeng Xu</a> (4) </u>  <br>
        1:  University of Science and Technology of China, 2:  SIAT, 3:  Shenzhen MSU-BIT University, 4:  Harbin Institute of Technology (Shenzhen) <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591945">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Adversarial Meta Prompt Tuning for Open Compound Domain Adaptive Intent Detection">Google Scholar</a></div>
        (174)
        <br>
        <b>概要:　</b> インテント検出は対話システムにおいて重要な役割を果たします。本論文では、オープンコンパウンドドメイン適応（OCDA）をインテント検出に適用した初の研究を紹介します。OCDAは未知のドメインに対する一般化を向上する利点をもたらします。インテント検出のためのOCDAは、実際的なドメイン適応の設定であり、ラベル付きソースドメインからインテント分類器を学習し、ソースドメインとは異なるインテントクラスを含むラベルなしコンパウンドターゲットドメインに適応されます。推論時には、以前に見たことのないインテントクラスを含むオープンドメインでインテント分類器をテストします。この目的のために、私たちはオープンコンパウンドドメイン適応型インテント検出のための「Adversarial Meta Prompt Tuning 方法」（AMPT）を提案します。具体的には、言語プロンプトを使用して大規模な事前訓練済み言語モデル（PLM）から豊富な知識を引き出し、メタ学習により迅速な適応を助ける優れたプロンプト初期化を自動的に見つけるメタプロンプトチューニング方法を提案します。さらに、異なるドメインのドメイン不変表現を取得するために、ドメイン逆訓練技術を活用します。メタ学習、プロンプトチューニング、および逆訓練の協力効果を活用することで、未知のオープンドメインに効果的に一般化できるインテント分類器を学習できます。HWU64およびCLINCの二つのベンチマークデータセットでの実験結果は、私たちのモデルが強力な競合モデルと比較して、未知のドメインに対して実質的に優れた一般化表現を学習できることを示しています。
        </label>
        <input type="checkbox" id="Panel174" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Intent detection plays an essential role in dialogue systems. This paper takes the lead to study open compound domain adaptation (OCDA) for intent detection, which brings the advantage of improved generalization to unseen domains. OCDA for intent detection is indeed a more realistic domain adaptation setting, which learns an intent classifier from labeled source domains and adapts it to unlabeled compound target domains containing different intent classes with the source domains. At inference time, we test the intent classifier in open domains that contain previously unseen intent classes. To this end, we propose an Adversarial Meta Prompt Tuning method (called AMPT) for open compound domain adaptive intent detection. Concretely, we propose a meta prompt tuning method, which utilizes language prompts to elicit rich knowledge from large-scale pre-trained language models (PLMs) and automatically finds better prompt initialization that facilitates fast adaptation via meta learning. Furthermore, we leverage a domain adversarial training technique to acquire domain-invariant representations of diverse domains. By taking advantage of the collaborative effect of meta learning, prompt tuning, and adversarial training, we can learn an intent classifier that can effectively generalize to unseen open domains. Experimental results on two benchmark datasets (i.e., HWU64 and CLINC) show that our model can learn substantially better-generalized representations for unseen domains compared with strong competitors.
        </div> </ul> <br>



        <label for="Panel175">
        <strong> Affective Relevance: Inferring Emotional Responses via fNIRS Neuroimaging </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tuukka+Ruotsalo">Tuukka Ruotsalo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kalle+Mäkelä">Kalle Mäkelä</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michiel+M.+Spapé">Michiel M. Spapé</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Luis+A.+Leiva">Luis A. Leiva</a> (3) </u>  <br>
        1:  University of Copenhagen and University of Helsinki, 2:  University of Helsinki, 3:  University of Luxembourg <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591946">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Affective Relevance: Inferring Emotional Responses via fNIRS Neuroimaging">Google Scholar</a></div>
        (175)
        <br>
        <b>概要:　</b> 情報検索（IR）は、ランキングおよび評価方法の主要な基礎として、一般的な関連性の概念に依存しています。しかし、IRは、より微細な情動的経験を考慮していません。ここでは、関連性の別の次元として、ヒトの脳から直接デコードされた情動反応を検討します。我々は、7つの異なるシナリオをカバーする実験を報告し、機能的近赤外分光法（fNIRS）を用いて、視覚的イメージコンテンツに対するユーザーの情動的反応を、よく使用される2つの感情的次元（価数（否定性と肯定性）および覚醒度（退屈さと興奮度））で測定および予測しました。我々の結果は、fNIRSを使用して情動状態を成功裏にデコードでき、IR研究における現在の関連性の概念を補完するために利用できることを示しています。例えば、我々は感情状態の4クラス分類において、均衡精度0.39とAUC 0.61を達成しました（ランダム分類器では均衡精度0.25とAUC 0.5）。同様に、高覚醒度画像の検索では、Precision@20が0.684に達しました。我々の研究は、IR評価、情動フィードバック、および情報フィルタリングにおいて情動状態を取り入れる新たな道を開きます。
        </label>
        <input type="checkbox" id="Panel175" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Information retrieval (IR) relies on a general notion of relevance, which is used as the principal foundation for ranking and evaluation methods. However, IR does not account for more a nuanced affective experience. Here, we consider the emotional response decoded directly from the human brain as an alternative dimension of relevance. We report an experiment covering seven different scenarios in which we measure and predict how users emotionally respond to visual image contents by using functional near-infrared spectroscopy (fNIRS) neuroimaging on two commonly used affective dimensions: valence (negativity and positivity) and arousal (boredness and excitedness). Our results show that affective states can be successfully decoded using fNIRS, and utilized to complement the present notion of relevance in IR studies. For example, we achieved 0.39 Balanced accuracy and 0.61 AUC in 4-class classification of affective states (vs. 0.25 Balanced accuracy and 0.5 AUC of a random classifier). Likewise, we achieved 0.684 Precision@20 when retrieving high-arousal images. Our work opens new avenues for incorporating emotional states in IR evaluation, affective feedback, and information filtering.
        </div> </ul> <br>



        <label for="Panel176">
        <strong> Popularity Debiasing from Exposure to Interaction in Collaborative Filtering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuanhao+Liu">Yuanhao Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Cao">Qi Cao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huawei+Shen">Huawei Shen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunfan+Wu">Yunfan Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuchang+Tao">Shuchang Tao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xueqi+Cheng">Xueqi Cheng</a> (3) </u>  <br>
        1:  Data Intelligence System Research Center, 2:  Data Intelligence System Research Center, 3:  CAS Key Lab of Network Data Science and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591947">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Popularity Debiasing from Exposure to Interaction in Collaborative Filtering">Google Scholar</a></div>
        (176)
        <br>
        <b>概要:　</b> 推薦システムはしばしば人気アイテムの過剰推薦による人気偏向の問題に悩まされます。その結果、非人気アイテムが犠牲になります。既存の研究は一般的に、逆傾向重み付け、因果介入、または対抗訓練を用いて、各アイテムの推薦（露出）の数を平等または比例的にすることに焦点を当てています。しかし、非人気アイテムの露出を増加させても、クリックやインタラクションが増えるわけではなく、利益の偏りをもたらし、実際に合理的な人気偏向の解消には至りません。本論文では、新たな人気偏向の判断基準を提案します。すなわち、偏りのない推薦システムでは、人気アイテムと非人気アイテムの両方が、それを「好む」ユーザーの数に比例してインタラクションを受けるべきというIPL基準です。この基準に基づき、IPL正則化項を含む偏向解消フレームワークを提案します。このフレームワークは、人気偏向の解消と推薦性能の向上を同時に実現できることが理論的に示されています。4つの公開データセットで実施した実験により、代表的な協調フィルタリングモデル2つに本フレームワークを組み込むことで、推薦性能を維持しつつ、人気偏向が効果的に緩和されることが示されました。
        </label>
        <input type="checkbox" id="Panel176" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recommender systems often suffer from popularity bias, where popular items are overly recommended while sacrificing unpopular items. Existing researches generally focus on ensuring the number of recommendations (exposure) of each item is equal or proportional, using inverse propensity weighting, causal intervention, or adversarial training. However, increasing the exposure of unpopular items may not bring more clicks or interactions, resulting in skewed benefits and failing in achieving real reasonable popularity debiasing. In this paper, we propose a new criterion for popularity debiasing, i.e., in an unbiased recommender system, both popular and unpopular items should receive Interactions Proportional to the number of users who Like it, namely IPL criterion. Under the guidance of the criterion, we then propose a debiasing framework with IPL regularization term which is theoretically shown to achieve a win-win situation of both popularity debiasing and recommendation performance. Experiments conducted on four public datasets demonstrate that when equipping two representative collaborative filtering models with our framework, the popularity bias is effectively alleviated while maintaining the recommendation performance.
        </div> </ul> <br>



        <label for="Panel177">
        <strong> Always Strengthen Your Strengths: A Drift-Aware Incremental Learning Framework for CTR Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Congcong+Liu">Congcong Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Teng">Fei Teng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiwei+Zhao">Xiwei Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhangang+Lin">Zhangang Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinghe+Hu">Jinghe Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingping+Shao">Jingping Shao</a> (1) </u>  <br>
        1:  JD.COM <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591948">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Always Strengthen Your Strengths: A Drift-Aware Incremental Learning Framework for CTR Prediction">Google Scholar</a></div>
        (177)
        <br>
        <b>概要:　</b> CTR予測は、レコメンデーションシステムやオンライン広告プラットフォームにおいて極めて重要です。しかし、時間と共に変動するユーザー生成データストリームは、モデルが新しいデータ分布に継続的に適応する場合、壊滅的な忘却を引き起こす可能性があります。従来の壊滅的忘却対策は、メモリ制約や多様なデータ分布のため導入が困難です。これを解決するために、我々はCTR予測のためのアンサンブル学習に基づいた新しいドリフト対応の増分学習フレームワークを提案します。このフレームワークは、ストリーミングデータの明示的なエラーに基づくドリフト検出を用いて、適応力の高いアンサンブルを強化し、入力分布に一致しないアンサンブルを凍結することで壊滅的な干渉を回避します。我々の手法は、オフライン実験とA/Bテストにおいて比較対象となる全てのベースラインを上回りました。
        </label>
        <input type="checkbox" id="Panel177" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> CTR prediction is crucial in recommendation systems and online advertising platforms, where user-generated data streams that drift over time can lead to catastrophic forgetting if the model continuously adapts to new data distribution. Conventional strategies for catastrophic forgetting are challenging to deploy due to memory constraints and diverse data distributions. To address this, we propose a novel drift-aware incremental learning framework based on ensemble learning for CTR prediction, which uses explicit error-based drift detection on streaming data to strengthen well-adapted ensembles and freeze ensembles that do not match the input distribution, avoiding catastrophic interference. Our method outperforms all baselines considered in offline experiments and A/B tests.
        </div> </ul> <br>



        <label for="Panel178">
        <strong> Attacking Pre-trained Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiqing+Wu">Yiqing Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruobing+Xie">Ruobing Xie</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhao+Zhang">Zhao Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongchun+Zhu">Yongchun Zhu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuzhen+Zhuang">Fuzhen Zhuang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jie+Zhou">Jie Zhou</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongjun+Xu">Yongjun Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qing+He">Qing He</a> (1) </u>  <br>
        1:  Institute of Computing Technology, 2:  WeChat, 3:  Institute of Artificial Intelligence, 4:  WeChat <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591949">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Attacking Pre-trained Recommendation">Google Scholar</a></div>
        (178)
        <br>
        <b>概要:　</b> 最近、一連の先駆的な研究により、事前学習済みモデルが連続的な推薦において有力であることが示され、さまざまな下流推薦タスクに対して全知的な統一事前学習済み推薦モデルを構築する道が明らかにされました。これらの進展にもかかわらず、従来の推薦システムの脆弱性も新たな形で事前学習済み推薦に存在し、事前学習済み推薦モデルのセキュリティはまだ探索されておらず、その広範な実用的応用が脅かされる可能性があります。本研究では、事前学習済み推薦におけるバックドア攻撃のための新しいフレームワークを提案します。事前学習の段階でバックドアを簡単に挿入し、対象のアイテムの露出率を特定のユーザーグループに対して増加させることができることを示します。具体的には、基本的な置換攻撃とプロンプト強化型の2つの新規かつ効果的なバックドア攻撃を、さまざまな推薦事前学習の使用シナリオにおいて設計しました。実世界のデータセットにおける実験結果は、提案された攻撃戦略がクリーンなモデルと比較して対象アイテムの露出率を数百倍にまで顕著に向上させることを示しています。ソースコードはhttps://github.com/wyqing20/APRecで公開されています。
        </label>
        <input type="checkbox" id="Panel178" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recently, a series of pioneer studies have shown the potency of pre-trained models in sequential recommendation, illuminating the path of building an omniscient unified pre-trained recommendation model for different downstream recommendation tasks. Despite these advancements, the vulnerabilities of classical recommender systems also exist in pre-trained recommendation in a new form, while the security of pre-trained recommendation model is still unexplored, which may threaten its widely practical applications. In this study, we propose a novel framework for backdoor attacking in pre-trained recommendation. We demonstrate the provider of the pre-trained model can easily insert a backdoor in pre-training, thereby increasing the exposure rates of target items to target user groups. Specifically, we design two novel and effective backdoor attacks: basic replacement and prompt-enhanced, under various recommendation pre-training usage scenarios. Experimental results on real-world datasets show that our proposed attack strategies significantly improve the exposure rates of target items to target users by hundreds of times in comparison to the clean model. The source codes are released in https://github.com/wyqing20/APRec.
        </div> </ul> <br>



        <label for="Panel179">
        <strong> Attention-guided Multi-step Fusion: A Hierarchical Fusion Network for Multimodal Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yan+Zhou">Yan Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jie+Guo">Jie Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Sun">Hao Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bin+Song">Bin Song</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Richard+Yu">Fei Richard Yu</a> (2) </u>  <br>
        1:  Xidian University, 2:  Shenzhen University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591950">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Attention-guided Multi-step Fusion: A Hierarchical Fusion Network for Multimodal Recommendation">Google Scholar</a></div>
        (179)
        <br>
        <b>概要:　</b> マルチモーダルレコメンデーションの主な目的は、アイテムのマルチモーダル情報を合理的に活用することで、レコメンデーションの性能を向上させることです。従来の研究では、アイテムIDの埋め込みとアイテムのマルチモーダル特徴を直接統合しており、マルチモーダル特徴に含まれる本来の意味関係を無視していました。本論文では、注意誘導型マルチステップ融合ネットワーク（TMFUN）という、新しく効果的なマルチモーダルレコメンデーションモデルを提案します。具体的には、我々のモデルはまず、モダリティ特徴グラフとアイテム特徴グラフを構築し、潜在的なアイテム間のセマンティック構造をモデル化します。次に、注意モジュールを使用してユーザーとアイテムのインタラクションデータとマルチモーダルデータの間の本来の関係を特定し、マルチモーダルデータが異なるインタラクションに与える影響を評価し、アイテム特徴の初期融合を実現します。さらに、我々のモデルは注意誘導型マルチステップ融合戦略と対比学習を通じてアイテム表現を最適化し、レコメンデーションの性能を向上させます。三つの実世界データセットでの広範な実験により、我々のモデルが最先端のモデルに比べて優れた性能を持つことが示されました。
        </label>
        <input type="checkbox" id="Panel179" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The main idea of multimodal recommendation is the rational utilization of the item's multimodal information to improve the recommendation performance. Previous works directly integrate item multimodal features with item ID embeddings, ignoring the inherent semantic relations contained in the multimodal features. In this paper, we propose a novel and effective aTtention-guided Multi-step FUsion Network for multimodal recommendation, named TMFUN. Specifically, our model first constructs modality feature graph and item feature graph to model the latent item-item semantic structures. Then, we use the attention module to identify inherent connections between user-item interaction data and multimodal data, evaluate the impact of multimodal data on different interactions, and achieve early-step fusion of item features. Furthermore, our model optimizes item representation through the attention-guided multi-step fusion strategy and contrastive learning to improve recommendation performance. The extensive experiments on three real-world datasets show that our model has superior performance compared to the state-of-the-art models.
        </div> </ul> <br>



        <label for="Panel180">
        <strong> Attention Mixtures for Time-Aware Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Viet+Anh+Tran">Viet Anh Tran</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guillaume+Salha-Galvan">Guillaume Salha-Galvan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bruno+Sguerra">Bruno Sguerra</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Romain+Hennequin">Romain Hennequin</a> (1) </u>  <br>
        1:  Deezer Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591951">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Attention Mixtures for Time-Aware Sequential Recommendation">Google Scholar</a></div>
        (180)
        <br>
        <b>概要:　</b> トランスフォーマーはシーケンシャルレコメンデーションにおいて強力な手法として台頭してきました。しかし、既存のアーキテクチャは、ユーザーの嗜好と時間的コンテキストの複雑な依存関係をしばしば見落としています。本稿では、この制限に対処するために改良されたトランスフォーマーシーケンシャルレコメンダーシステム「MOJITO」を紹介します。MOJITOは、ガウス混合モデルを用いた注意機構に基づく時間的コンテキストおよびアイテム埋め込み表現を活用してシーケンシャルモデリングを行います。このアプローチにより、過去の行動と時間的コンテキストに応じて、ユーザーに次に推奨すべきアイテムを正確に予測することが可能になります。我々は、いくつかの実世界のデータセットにおいて、既存のトランスフォーマーをシーケンシャルレコメンデーションで実証的に上回ることにより、本手法の有効性を示します。
        </label>
        <input type="checkbox" id="Panel180" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Transformers emerged as powerful methods for sequential recommendation. However, existing architectures often overlook the complex dependencies between user preferences and the temporal context. In this short paper, we introduce MOJITO, an improved Transformer sequential recommender system that addresses this limitation. MOJITO leverages Gaussian mixtures of attention-based temporal context and item embedding representations for sequential modeling. Such an approach permits to accurately predict which items should be recommended next to users depending on past actions and the temporal context. We demonstrate the relevance of our approach, by empirically outperforming existing Transformers for sequential recommendation on several real-world datasets.
        </div> </ul> <br>



        <label for="Panel181">
        <strong> Augmenting Passage Representations with Query Generation for Enhanced Cross-Lingual Dense Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shengyao+Zhuang">Shengyao Zhuang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linjun+Shou">Linjun Shou</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guido+Zuccon">Guido Zuccon</a> (1) </u>  <br>
        1:  The University of Queensland, 2:  Microsoft <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591952">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Augmenting Passage Representations with Query Generation for Enhanced Cross-Lingual Dense Retrieval">Google Scholar</a></div>
        (181)
        <br>
        <b>概要:　</b> 多言語で事前学習された言語モデル（PLMs）に依存する効果的なクロスリンガル密集検索法は、関連性マッチングタスクとクロスリンガルアライメントタスクの両方を包含するように訓練する必要があります。しかし、訓練に必要なクロスリンガルデータはしばしば不足しています。本研究では、訓練に追加のクロスリンガルデータを使用する代わりに、クロスリンガルクエリ生成を利用して、元のパッセージの言語以外の言語でクエリを生成し、それらをパッセージ表現に付加する手法を提案します。これらの拡張表現は推論時に使用され、異なるターゲット言語にわたる情報をより多くエンコードすることができます。クロスリンガルクエリジェネレータの訓練には、密集検索器の訓練に使用するデータ以外の追加データは必要ありません。ジェネレータの訓練は、ジェネレータの事前訓練タスク（T5のテキスト生成訓練）とファインチューニングタスク（クエリ生成）が非常に類似しているため、効果的です。このジェネレータの使用は推論時のクエリ遅延を増加させず、任意のクロスリンガル密集検索法と組み合わせることができます。ベンチマーククロスリンガル情報検索データセットでの実験結果は、我々の手法が既存のクロスリンガル密集検索法の効果を向上させることが示されています。我々の手法の実装と生成されたすべてのクエリファイルは、以下のリンクで公開されています：https://github.com/ielab/xQG4xDR。
        </label>
        <input type="checkbox" id="Panel181" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Effective cross-lingual dense retrieval methods that rely on multilingual pre-trained language models (PLMs) need to be trained to encompass both the relevance matching task and the cross-language alignment task. However, cross-lingual data for training is often scarcely available. In this paper, rather than using more cross-lingual data for training, we propose to use cross-lingual query generation to augment passage representations with queries in languages other than the original passage language. These augmented representations are used at inference time so that the representation can encode more information across the different target languages. Training of a cross-lingual query generator does not require additional training data to that used for the dense retriever. The query generator training is also effective because the pre-training task for the generator (T5 text-to-text training) is very similar to the fine-tuning task (generation of a query). The use of the generator does not increase query latency at inference and can be combined with any cross-lingual dense retrieval method. Results from experiments on a benchmark cross-lingual information retrieval dataset show that our approach can improve the effectiveness of existing cross-lingual dense retrieval methods. Implementation of our methods, along with all generated query files are made publicly available at https://github.com/ielab/xQG4xDR.
        </div> </ul> <br>



        <label for="Panel182">
        <strong> AutoDPQ: Automated Differentiable Product Quantization for Embedding Compression </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Gan">Xin Gan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuhao+Wang">Yuhao Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyu+Zhao">Xiangyu Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wanyu+Wang">Wanyu Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiqi+Wang">Yiqi Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zitao+Liu">Zitao Liu</a> (3) </u>  <br>
        1:  City University of Hong Kong, 2:  National University of Defense Technology, 3:  Guangdong Institute of Smart Education <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591953">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=AutoDPQ: Automated Differentiable Product Quantization for Embedding Compression">Google Scholar</a></div>
        (182)
        <br>
        <b>概要:　</b> ディープレコメンダーシステムは通常、ユーザーとアイテムのための多数の特徴フィールドを含み、多くの低頻度特徴を持ちます。これらの低頻度特徴は、その膨大な量と十分な訓練の不足により、予測精度を低下させ、大容量のストレージスペースを必要とします。一部の先駆的な研究では、ストレージスペースとモデル予測可能性のトレードオフ問題に対処するために、埋め込み圧縮技術を模索してきました。しかし、これらの方法は、低頻度特徴の埋め込みをさまざまな特徴フィールドで圧縮する際に、高度な人間の経験とハイパーパラメータ探索中の計算資源が必要なため、困難が伴います。本論文では、各特徴フィールドの低頻度特徴を自動的に適応的な規模にコンパクト化するAutoDPQフレームワークを提案します。実験結果は、AutoDPQがパラメータ空間を大幅に削減しながら、レコメンデーション精度を向上させることを示しています。さらに、AutoDPQは様々なディープCTRモデルと互換性があり、そのパフォーマンスを高効率で大幅に向上させることが可能です。
        </label>
        <input type="checkbox" id="Panel182" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Deep recommender systems typically involve numerous feature fields for users and items, with a large number of low-frequency features. These low-frequency features would reduce the prediction accuracy with large storage space due to their vast quantity and inadequate training. Some pioneering studies have explored embedding compression techniques to address this issue of the trade-off between storage space and model predictability. However, these methods have difficulty compacting the embedding of low-frequency features in various feature fields due to the high demand for human experience and computing resources during hyper-parameter searching. In this paper, we propose the AutoDPQ framework, which automatically compacts low-frequency feature embeddings for each feature field to an adaptive magnitude. Experimental results indicate that AutoDPQ can significantly reduce the parameter space while improving recommendation accuracy. Moreover, AutoDPQ is compatible with various deep CTR models by improving their performance significantly with high efficiency.
        </div> </ul> <br>



        <label for="Panel183">
        <strong> Bayesian Knowledge-driven Critiquing with Indirect Evidence </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Armin+Toroghi">Armin Toroghi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Griffin+Floto">Griffin Floto</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenwei+Tang">Zhenwei Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Scott+Sanner">Scott Sanner</a> (1) </u>  <br>
        1:  University of Toronto <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591954">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Bayesian Knowledge-driven Critiquing with Indirect Evidence">Google Scholar</a></div>
        (183)
        <br>
        <b>概要:　</b> 対話型レコメンダーシステム (CRS) は、ユーザーとシステムのインタラクションを複数回にわたって行うことで、レコメンデーションの表現力とパーソナライゼーションを強化します。クリティーキングは、ユーザーが推奨されたアイテムの属性についてフィードバックを提供することで、レコメンデーションを反復的に改善することを可能にする、CRSのよく知られたパラダイムです。既存のクリティーキング手法は『私は西洋映画が好きです』というように、ユーザーのリクエストに直接的な属性を利用していますが、知識グラフ (KG) に保存されたアイテムに関する豊かな文脈情報やサイド情報をクリティーキングパラダイムに組み込む機会は見過ごされていました。この豊富な知識を確立された推論手法と共に活用することで、『私は戦争による退役軍人への影響を描いた映画が好きです』という複雑な知識に基づくフィードバックを自然なユーザーシステム対話の中で可能にする、新しいクリティーキングベースのレコメンダーが実現されます。本研究では、KGを統合することでクリティーキングベースのレコメンデーションの柔軟性を高め、新しいベイズ推論フレームワークを提案します。このフレームワークは、関係知識に基づくフィードバックを用いた推論を可能にします。本提案では、ガウス尤度を考慮してフレームワークを構築し、KGを用いた2つの著名なレコメンデーションデータセットで評価しました。評価結果は、間接的なKGベースのフィードバック（すなわち、推奨アイテム自体ではなく推奨アイテムの関係特性）を活用することで、ワンショットレコメンダーと比較してパーソナライズされたレコメンデーションが15%以上改善することを示しています。本研究は、リッチな知識コンテンツと間接的な証拠を推論するメカニズムとしてクリティーキングインタラクションを用いる新しいパラダイムを提案します。
        </label>
        <input type="checkbox" id="Panel183" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Conversational recommender systems (CRS) enhance the expressivity and personalization of recommendations through multiple turns of user-system interaction. Critiquing is a well-known paradigm for CRS that allows users to iteratively refine recommendations by providing feedback about attributes of recommended items. While existing critiquing methodologies utilize direct attributes of items to address user requests such as 'I prefer Western movies', the opportunity of incorporating richer contextual and side information about items stored in Knowledge Graphs (KG) into the critiquing paradigm has been overlooked. Employing this substantial knowledge together with a well-established reasoning methodology paves the way for critique-based recommenders to allow for complex knowledge-based feedback (e.g., 'I like movies featuring war side effects on veterans') which may arise in natural user-system conversations. In this work, we aim to increase the flexibility of critique-based recommendation by integrating KGs and propose a novel Bayesian inference framework that enables reasoning with relational knowledge-based feedback. We study and formulate the framework considering a Gaussian likelihood and evaluate it on two well-known recommendation datasets with KGs. Our evaluations demonstrate the effectiveness of our framework in leveraging indirect KG-based feedback (i.e., preferred relational properties of items rather than preferred items themselves), often improving personalized recommendations over a one-shot recommender by more than 15%. This work enables a new paradigm for using rich knowledge content and reasoning over indirect evidence as a mechanism for critiquing interactions with CRS.
        </div> </ul> <br>



        <label for="Panel184">
        <strong> Behavior Modeling for Point of Interest Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haitian+Chen">Haitian Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qingyao+Ai">Qingyao Ai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhijing+Wu">Zhijing Wu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhihong+Wang">Zhihong Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiqun+Liu">Yiqun Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Min+Zhang">Min Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shaoping+Ma">Shaoping Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Juan+Hu">Juan Hu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Naiqiang+Tan">Naiqiang Tan</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hua+Chai">Hua Chai</a> (3) </u>  <br>
        1:  Tsinghua University, 2:  Beijing Institute of Technology, 3:  Didi Chuxing <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591955">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Behavior Modeling for Point of Interest Search">Google Scholar</a></div>
        (184)
        <br>
        <b>概要:　</b> ロケーションベースのサービスの人気が高まる中、注目すべき場所（POI）検索は近年大きな関心を集めています。既存のPOI検索に関する研究は主に、クエリとPOIのマッチングに基づいて関連するPOIを取得するための優れた検索モデルの構築に焦点を当てています。しかし、POI検索におけるユーザーの行動、すなわちユーザーが検索エンジンの結果ページ（SERP）をどのように調べるかについてはほとんど検討されていません。ユーザー行動の深い理解は、効果的なユーザーモデルおよび検索モデルを開発し、検索品質を向上させるための鍵として広く認識されています。したがって、本研究では、POI検索におけるユーザーの行動を調査するために、ユーザーの視線の動きとSERPに対する暗黙的なフィードバックを収集するラボ実験を提案します。収集したデータに基づいて、(1) POI検索におけるクエリレベルのユーザー行動パターン、すなわちSERPの検査および相互作用、(2) POI検索におけるセッションレベルのユーザー行動パターン、すなわちクエリの再構成、検索の終了などを分析します。我々の研究はPOI検索におけるユーザー行動に光を当て、関連する研究トピックに関する将来の研究に潜在的な利益をもたらす可能性があります。
        </label>
        <input type="checkbox" id="Panel184" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> With the increasing popularity of location-based services, the point-of-interest (POI) search has received considerable attention in recent years. Existing studies on POI search mostly focus on how to construct better retrieval models to retrieve the relevant POI based on query-POI matching. However, user behavior in POI search, i.e., how users examine the search engine result page (SERP), is mostly underexplored. A good understanding of user behavior is well-recognized as a key to develop effective user models and retrieval models to improve the search quality. Therefore, in this paper, we propose to investigate user behavior in POI search with a lab study in which users' eye movements and their implicit feedback on the SERP are collected. Based on the collected data, we analyze (1) query-level user behavior patterns in POI search, i.e., examination and interactions on SERP; (2) session-level user behavior patterns in POI search, i.e., query reformulation, termination of search, etc. Our work sheds light on user behavior in POI search and could potentially benefit future studies on related research topics.
        </div> </ul> <br>



        <label for="Panel185">
        <strong> Benchmarking Middle-Trained Language Models for Neural Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hervé+Déjean">Hervé Déjean</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Stephane+Clinchant">Stephane Clinchant</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Carlos+Lassance">Carlos Lassance</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Simon+Lupart">Simon Lupart</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Thibault+Formal">Thibault Formal</a> (1) </u>  <br>
        1:  Naver Labs Europe <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591956">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Benchmarking Middle-Trained Language Models for Neural Search">Google Scholar</a></div>
        (185)
        <br>
        <b>概要:　</b> ミドルトレーニング方法は、Masked Language Model (MLM) のプレトレーニングと最終的なファインチューニングの間のギャップを埋めることを目指します。最近のモデルであるCoCondenser、RetroMAE、LexMAEは、MLMタスクがトランスフォーマーネットワークをリトリーバル向けにプレトレーニングするには不十分であると主張し、様々なタスクを提案しています。これらの革新的な方法に興味を持ち、これらのモデルが異なるファインチューニングプロトコルを使用しているため、ミドルトレーニングのメリットを評価するのが難しいことに気付きました。本論文では、同一のファインチューニング条件下でCoCondenser、RetroMAE、LexMAEのベンチマークを提案します。様々なファインチューニングプロトコルおよび異なるコレクション（MS MARCO、Wikipedia）におけるミドルトレーニングの下で、デンスアプローチとスパースアプローチの両方を比較します。標準的なMLMのファインチューニングに加えて、任意でCLSがパッセージの単語頻度を予測するミドルトレーニングのベースラインも使用します。スパースアプローチに関しては、これらの方法間にほとんど統計的な差がないことがわかりました。ファインチューニング手続きが効果的であるほど、これらのモデル間の違いは少なくなります。デンスアプローチについては、MS MARCOをミドルトレーニングコレクションとして使用したRetroMAEがほとんどの設定で優れた結果を示しました。最後に、リトリーバルコレクションに対するミドルトレーニング、つまり、それに適応した言語モデルを使用することが重要な要素であることを示します。全体として、ミドルトレーニング方法を評価するためには、より良い実験設定が採用されるべきです。
        </label>
        <input type="checkbox" id="Panel185" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Middle training methods aim to bridge the gap between the Masked Language Model (MLM) pre-training and the final finetuning for retrieval. Recent models such as CoCondenser, RetroMAE, and LexMAE argue that the MLM task is not sufficient enough to pre-train a transformer network for retrieval and hence propose various tasks to do so. Intrigued by those novel methods, we noticed that all these models used different finetuning protocols, making it hard to assess the benefits of middle training. We propose in this paper a benchmark of CoCondenser, RetroMAE, and LexMAE, under the same finetuning conditions. We compare both dense and sparse approaches under various finetuning protocols and middle training on different collections (MS MARCO, Wikipedia). We use additional middle training baselines, such as a standard MLM finetuning on the retrieval collection, optionally augmented by a CLS predicting the passage term frequency. For the sparse approach, our study reveals that there is almost no statistical difference between those methods: the more effective the finetuning procedure is, the less difference there is between those models. For the dense approach, RetroMAE using MS MARCO as middle-training collection shows excellent results in almost all the settings. Finally, we show that middle training on the retrieval collection, thus adapting the language model to it, is a critical factor. Overall, a better experimental setup should be adopted to evaluate middle training methods.
        </div> </ul> <br>



        <label for="Panel186">
        <strong> BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sreyan+Ghosh">Sreyan Ghosh</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Utkarsh+Tyagi">Utkarsh Tyagi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sonal+Kumar">Sonal Kumar</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dinesh+Manocha">Dinesh Manocha</a> (1) </u>  <br>
        1:  University of Maryland College Park <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591957">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER">Google Scholar</a></div>
        (186)
        <br>
        <b>概要:　</b> バイオメディカル固有表現認識（BioNER）は、バイオメディカルテキストから固有表現を識別する基本的なタスクです。しかし、BioNERはデータの極端な不足と、注釈に必要な高度に専門的な知識のため、高品質なラベル付きデータの欠如に苦しんでいます。一般的な低リソースNERに対してデータ拡張は非常に効果的であると示されていますが、既存のデータ拡張技術はBioNERに対して実際的かつ多様な拡張を生成することに失敗しています。本論文では、低リソースBioNERのための新しいデータ拡張フレームワークであるBioAugを提案します。BARTに基づいて構築されたBioAugは、選択的マスキングと知識拡張に基づく新しいテキスト再構築タスクを解決するように訓練されています。訓練後、我々は条件生成を行い、訓練段階と同様に選択的に破壊されたテキストを条件として多様な拡張を生成します。我々は、5つのベンチマークBioNERデータセットにおいてBioAugの有効性を示し、BioAugがすべてのベースラインよりも大幅に優れている（1.5％〜21.5％の絶対改善）こと、そしてより事実に基づいた多様な拡張を生成できることを示します。コード: https://github.com/Sreyan88/BioAug.
        </label>
        <input type="checkbox" id="Panel186" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Biomedical Named Entity Recognition (BioNER) is the fundamental task of identifying named entities from biomedical text. However, BioNER suffers from severe data scarcity and lacks high-quality labeled data due to the highly specialized and expert knowledge required for annotation. Though data augmentation has shown to be highly effective for low-resource NER in general, existing data augmentation techniques fail to produce factual and diverse augmentations for BioNER. In this paper, we present BioAug, a novel data augmentation framework for low-resource BioNER. BioAug, built on BART, is trained to solve a novel text reconstruction task based on selective masking and knowledge augmentation. Post training, we perform conditional generation and generate diverse augmentations conditioning BioAug on selectively corrupted text similar to the training stage. We demonstrate the effectiveness of BioAug on 5 benchmark BioNER datasets and show that BioAug outperforms all our baselines by a significant margin (1.5%-21.5% absolute improvement) and is able to generate augmentations that are both more factual and diverse. Code: https://github.com/Sreyan88/BioAug.
        </div> </ul> <br>



        <label for="Panel187">
        <strong> BKD: A Bridge-based Knowledge Distillation Method for Click-Through Rate Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yin+Deng">Yin Deng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yingxin+Chen">Yingxin Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+Dong">Xin Dong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lingchao+Pan">Lingchao Pan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hai+Li">Hai Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Cheng">Lei Cheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linjian+Mo">Linjian Mo</a> (2) </u>  <br>
        1:  Ant Group, 2:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591958">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=BKD: A Bridge-based Knowledge Distillation Method for Click-Through Rate Prediction">Google Scholar</a></div>
        (187)
        <br>
        <b>概要:　</b> クリック率（CTR）の予測モデルは、ユーザー行動の根底にある特徴相互作用を学習し、これは推薦システムにおいて重要です。そのサイズと複雑さから、既存のアプローチは適用範囲が限られています。推論の遅延を減少させるために、推薦システムでは知識蒸留技術が利用されています。しかし、学生モデルの容量が低いため、教師モデルと学生モデルのネットワークアーキテクチャの複雑さに大きな差があると知識蒸留プロセスは効果が低減します。我々は、「Bridge-based Knowledge Distillation（BKD）」と呼ばれる新しい知識蒸留アプローチを提案します。これは、橋渡しモデルを使用して、教師モデルの潜在表現から学生モデルの学習を促進するものです。橋渡しモデルはグラフニューラルネットワーク（GNN）に基づいており、GNNのエッジを活用して重要な特徴相互作用の関係を特定し、一方で冗長性を低減して効率を向上させます。知識蒸留の効率をさらに高めるために、抽出した知識を分離し、各コンポーネントを個別に学生モデルに転送することで、各モジュールの蒸留の十分性を向上させることを目指しました。広範な実験結果により、提案されたBKDアプローチがさまざまなタスクにおいて最先端の競争相手を上回ることが示されています。
        </label>
        <input type="checkbox" id="Panel187" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Prediction models for click-through rate (CTR) learn feature interactions underlying user behaviors, which are crucial in recommendation systems. Due to their size and complexity, existing approaches have a limited range of applications. In order to decrease inference delay, knowledge distillation techniques have been used in recommendation systems. Due to the student model's lower capacity, the knowledge distillation process is less effective when there is a significant difference in the complexity of the network architecture between the teacher model and the student model. We present a novel knowledge distillation approach called Bridge-based Knowledge Distillation (BKD), which employs a bridge model to facilitate the student model's learning from the teacher model's latent representations. The bridge model is based on Graph Neural Networks (GNNs), and leverages the edges of GNNs to identify significant feature interaction relationships, while simultaneously reducing redundancy for improved efficiency. To further enhance the efficiency of knowledge distillation, we decoupled the extracted knowledge and transferred each component separately to the student model, aiming to improve the distillation sufficiency of each module. Extensive experimental results show that our proposed BKD approach outperforms state-of-the-art competitors on various tasks.
        </div> </ul> <br>



        <label for="Panel188">
        <strong> Calibration Learning for Few-shot Novel Product Description </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zheng+Liu">Zheng Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mingjing+Wu">Mingjing Wu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Peng">Bo Peng</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yichao+Liu">Yichao Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Peng">Qi Peng</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chong+Zou">Chong Zou</a> (4) </u>  <br>
        1:  University College London, 2:  Nanyang Technological University, 3:  Newcastle University, 4:  China Institute of Atomic Energy <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591959">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Calibration Learning for Few-shot Novel Product Description">Google Scholar</a></div>
        (188)
        <br>
        <b>概要:　</b> Eコマースの分野では、新製品の急速な導入が製品説明生成において課題となっています。従来の手法は多数のラベル付きデータセットに依存していますが、新しい製品に関してはデータが限られているため、これらのデータセットはしばしば利用できません。この問題に対処するために、少数ショットの新製品説明に対する校正学習アプローチを提案します。我々の手法は校正のために少量のラベル付きデータを活用し、新製品の意味論的表現をプロンプトとして使用することで、正確かつ情報豊富な説明を生成します。この手法を新製品の大規模な3つのEコマースデータセットで評価し、特にデータが限られている場合において、既存の手法と比較して生成された製品説明の品質を大幅に向上させる効果を示しました。また、異なるモジュールが性能に与える影響を理解するための分析も実施しました。
        </label>
        <input type="checkbox" id="Panel188" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In the field of E-commerce, the rapid introduction of new products poses challenges for product description generation. Traditional approaches rely on large labelled datasets, which are often unavailable for novel products with limited data. To address this issue, we propose a calibration learning approach for few-shot novel product description. Our method leverages a small amount of labelled data for calibration and utilizes the novel product's semantic representation as prompts to generate accurate and informative descriptions. We evaluate our approach on three large-scale e-commerce datasets of novel products and demonstrate its effectiveness in significantly improving the quality of generated product descriptions compared to existing methods, especially when only limited data is available. We also conduct the analysis to understand the impact of different modules on the performance.
        </div> </ul> <br>



        <label for="Panel189">
        <strong> Can Generative LLMs Create Query Variants for Test Collections? An Exploratory Study </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Marwah+Alaofi">Marwah Alaofi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Luke+Gallagher">Luke Gallagher</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mark+Sanderson">Mark Sanderson</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Falk+Scholer">Falk Scholer</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Paul+Thomas">Paul Thomas</a> (2) </u>  <br>
        1:  RMIT University, 2:  Microsoft <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591960">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Can Generative LLMs Create Query Variants for Test Collections? An Exploratory Study">Google Scholar</a></div>
        (189)
        <br>
        <b>概要:　</b> この論文では、大規模言語モデル（LLM）を使用して、情報ニーズの説明から自動的にクエリおよびクエリのバリエーションを生成する効用を探ります。設定されたバックストーリーとして説明される情報ニーズの集合を考慮し、LLMによって生成されたクエリが人間によって生成されたクエリとどの程度類似しているかを調査します。様々な指標を使用して類似性を定量化し、テストコレクションを構築する際に各セットの使用がドキュメントプールにどのように貢献するかを検証します。我々の結果は、クエリのバリエーションを生成する際にLLMの潜在能力を示しています。完全に人間が生成する多様なバリエーションを捉えることはできないものの、関連するドキュメントの似たセットを生成し、プールの深さが100の場合に71.1%の重複に達することが確認されました。
        </label>
        <input type="checkbox" id="Panel189" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This paper explores the utility of a Large Language Model (LLM) to automatically generate queries and query variants from a description of an information need. Given a set of information needs described as backstories, we explore how similar the queries generated by the LLM are to those generated by humans. We quantify the similarity using different metrics and examine how the use of each set would contribute to document pooling when building test collections. Our results show potential in using LLMs to generate query variants. While they may not fully capture the wide variety of human-generated variants, they generate similar sets of relevant documents, reaching up to 71.1% overlap at a pool depth of 100.
        </div> </ul> <br>



        <label for="Panel190">
        <strong> Causal Disentangled Variational Auto-Encoder for Preference Understanding in Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siyu+Wang">Siyu Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaocong+Chen">Xiaocong Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Quan+Z.+Sheng">Quan Z. Sheng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yihong+Zhang">Yihong Zhang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lina+Yao">Lina Yao</a> (4) </u>  <br>
        1:  The University of New South Wales, 2:  Macquarie University, 3:  Osaka University, 4:  Data61 <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591961">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Causal Disentangled Variational Auto-Encoder for Preference Understanding in Recommendation">Google Scholar</a></div>
        (190)
        <br>
        <b>概要:　</b> 推薦モデルは一般的に観測されたユーザーのインタラクションデータに基づいて訓練されますが、ユーザーの意思決定プロセスにおける潜在因子間の相互作用は、複雑で絡み合ったデータをもたらします。これらの潜在因子を分離して、それらの基礎的な表現を明らかにすることは、推薦モデルのロバスト性、解釈可能性、および制御可能性を向上させることができます。本論文では、推薦システムにおけるインタラクションデータから因果関係に基づく分離表現を学習する新しいアプローチである因果分離変分オートエンコーダ（Causal Disentangled Variational Auto-Encoder, CaD-VAE）を紹介します。CaD-VAEの手法は、既存の分離手法のように独立性を強制するのではなく、実世界の推薦シナリオにおける意味的に関連する因子間の因果関係を考慮します。このアプローチは構造的因果モデルを利用して、潜在因子間の因果関係を記述する因果表現を生成します。結果から、CaD-VAEが既存の手法を上回り、推薦システムにおける複雑なユーザー行動データを分離するための有望な解決策を提供することが示されています。
        </label>
        <input type="checkbox" id="Panel190" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recommendation models are typically trained on observational user interaction data, but the interactions between latent factors in users' decision-making processes lead to complex and entangled data. Disentangling these latent factors to uncover their underlying representation can improve the robustness, interpretability, and controllability of recommendation models. This paper introduces the Causal Disentangled Variational Auto-Encoder (CaD-VAE), a novel approach for learning causal disentangled representations from interaction data in recommender systems. The CaD-VAE method considers the causal relationships between semantically related factors in real-world recommendation scenarios, rather than enforcing independence as in existing disentanglement methods. The approach utilizes structural causal models to generate causal representations that describe the causal relationship between latent factors. The results demonstrate that CaD-VAE outperforms existing methods, offering a promising solution for disentangling complex user behavior data in recommendation systems.
        </div> </ul> <br>



        <label for="Panel191">
        <strong> CEC: Towards Learning Global Optimized Recommendation through Causality Enhanced Conversion Model </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ran+Le">Ran Le</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guo-qing+Jiang">Guo-qing Jiang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiufeng+Shu">Xiufeng Shu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruidong+Han">Ruidong Han</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qianzhong+Li">Qianzhong Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yacheng+Li">Yacheng Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Li">Xiang Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Lin">Wei Lin</a> (2) </u>  <br>
        1:  Meituan, 2:  Unaffiliated <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591962">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=CEC: Towards Learning Global Optimized Recommendation through Causality Enhanced Conversion Model">Google Scholar</a></div>
        (191)
        <br>
        <b>概要:　</b> ほとんどのEコマースプラットフォームは、ユーザーが自分の気に入った商品を購入するための複数のエントリー（例：レコメンデーション、検索、ショッピングカートなど）で構成されています。レコメンデーションエントリーに関する研究の多くは、レコメンデーションエントリー内でのコンバージョン量の向上に焦点を当てています。しかし、この方法ではEコマースプラットフォーム全体のコンバージョン量の増加を保証することはできません。この目標をレコメンデーションエントリーのみを最適化して達成するために、本論文ではレコメンデーションエントリーの表示とコンバージョンの因果関係をモデル化することに焦点を当て、二段階の因果関係強化コンバージョン（CEC）モデルを提案します。第一段階では、レコメンデーションエントリーの表示を処置と定義し、処置の有無に応じた条件付きコンバージョン率を推定し、対応する個別処置効果（ITE）を計算します。第二段階では、推定されたITEをコンバージョン損失におけるインスタンス重み付けのための重み項に変換するために、傾向スコア正規化（PN）ベースの方法を提案します。大規模な食品Eコマースシナリオにおける広範なオフラインおよびオンライン実験は、CECモデルがプラットフォームの全体的なコンバージョン量を向上させることができる重要なインスタンスにより焦点を当てられることを示しています。
        </label>
        <input type="checkbox" id="Panel191" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Most e-commerce platforms consist of multiple entries (e.g., recommendation, search, shopping cart and etc.) for users to purchase their liked items. Among the research on the recommendation entry, most of them focus on improving the conversion volumes merely in the recommendation entry. However, such way could not ensure an increase in the global conversion volumes of the e-commerce platform. To achieve this goal by optimizing the recommendation entry only, in this paper, we focus on modeling the causality between the recommendation-entry-impression and the conversion by proposing the two-stage Causality Enhanced Conversion (CEC) model. In the first stage, we define the recommendation-entry-impression as treatment, then we estimate the conversion rate conditioned on the inclusion or exclusion of treatment respectively and calculate the corresponding individual treatment effect (ITE). In the second stage, we propose a propensity-normalization (PN) based method to transform the learned ITE to a weight term for instance weighting in the conversion loss. Extensive offline and online experiments on a large-scale food e-commerce scenario demonstrate that the CEC model could focus more on those conversed instances that can improve the global conversion volumes of the platform.
        </div> </ul> <br>



        <label for="Panel192">
        <strong> Click-Conversion Multi-Task Model with Position Bias Mitigation for Sponsored Search in eCommerce </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yibo+Wang">Yibo Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanbing+Xue">Yanbing Xue</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Liu">Bo Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Musen+Wen">Musen Wen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenting+Zhao">Wenting Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Stephen+Guo">Stephen Guo</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philip+S.+Yu">Philip S. Yu</a> (1) </u>  <br>
        1:  University of Illinois Chicago, 2:  Walmart eCommerce, 3:  Indeed <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591963">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Click-Conversion Multi-Task Model with Position Bias Mitigation for Sponsored Search in eCommerce">Google Scholar</a></div>
        (192)
        <br>
        <b>概要:　</b> 位置バイアスとは、ユーザーが検索結果リストにおいてクエリの実際の関連性に関わらず、上位にランクされたアイテムに注目する現象を指します。この位置バイアスは多くのランキングシステムにおいて一般的であり、トレーニングデータにおける位置バイアスがランキングモデルを偏らせ、アイテムのランキングの不公平さ、クリック率（CTR）およびコンバージョン率（CVR）の予測につながります。アイテムのCTRとCVR予測の双方における位置バイアスを同時に緩和するために、位置バイアスのないCTRおよびCVR予測モデルとして、我々はPosition-Aware Click-Conversion（PACC）と位置エンベディングを用いたPACC（PACC-PE）の2つを提案します。PACCは確率分解に基づいており、位置情報を確率としてモデル化します。PACC-PEはニューラルネットワークを用いて、商品固有の位置情報をエンベディングとしてモデル化します。Eコマースのスポンサー商品検索データセットに対する実験では、提案したモデルがランキングの有効性を向上させ、CTRおよびCVR予測における位置バイアスを大幅に軽減できることを示しています。
        </label>
        <input type="checkbox" id="Panel192" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Position bias, the phenomenon whereby users tend to focus on higher-ranked items of the search result list regardless of the actual relevance to queries, is prevailing in many ranking systems. Position bias in training data biases the ranking model, leading to increasingly unfair item rankings, click-through-rate (CTR), and conversion rate (CVR) predictions. To jointly mitigate position bias in both item CTR and CVR prediction, we propose two position-bias-free CTR and CVR prediction models: Position-Aware Click-Conversion (PACC) and PACC via Position Embedding (PACC-PE). PACC is built upon probability decomposition and models position information as a probability. PACC-PE utilizes neural networks to model product-specific position information as embedding. Experiments on the E-commerce sponsored product search dataset show that our proposed models have better ranking effectiveness and can greatly alleviate position bias in both CTR and CVR prediction.
        </div> </ul> <br>



        <label for="Panel193">
        <strong> Computational Versus Perceived Popularity Miscalibration in Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Oleg+Lesota">Oleg Lesota</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gustavo+Escobedo">Gustavo Escobedo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yashar+Deldjoo">Yashar Deldjoo</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bruce+Ferwerda">Bruce Ferwerda</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Simone+Kopeinik">Simone Kopeinik</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Elisabeth+Lex">Elisabeth Lex</a> (6), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Navid+Rekabsaz">Navid Rekabsaz</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Markus+Schedl">Markus Schedl</a> (1) </u>  <br>
        1:  Johannes Kepler University Linz and Linz Institute of Technology, 2:  Johannes Kepler University Linz, 3:  Polytechnic University of Bari, 4:  Jönköping University, 5:  Know-Center GmbH, 6:  Graz University of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591964">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Computational Versus Perceived Popularity Miscalibration in Recommender Systems">Google Scholar</a></div>
        (193)
        <br>
        <b>概要:　</b> 推薦リストにおける人気バイアスは、人気のあるコンテンツの過剰表示を指し、多くの推薦アルゴリズムにとっての課題です。以前の研究では、ユーザーの推薦リスト内のアイテムの人気度と、そのインタラクション履歴内のアイテムの人気度を関連付けることで、人気バイアスを定量化するためのいくつかのオフライン指標が提案されてきました。これら二つの要素間の不一致は、人気の誤校正と呼ばれます。人気指標は人気バイアスを測定するための簡明で明確な手段を提供しますが、それが実際にユーザーの人気バイアスの認知を反映しているかどうかは不明です。この研究ギャップに対処するために、Prolificにおいて56名の参加者を対象としたクラウドソーシングユーザースタディを実施し、（1）一般的な推薦アルゴリズム間で知覚される人気誤校正のレベルが異なるかどうかを調査し、（2）知覚される人気誤校正と一般的なオフライン指標による対応する定量化との相関を評価します。この研究は、標準化されたLFM-2bデータセットを使用した音楽推薦という明確で重要なドメインにおいて実施され、5つの推薦アルゴリズムの人気誤校正をJensen-Shannon距離（JSD）を用いて定量化します。先行研究の結果に挑戦する形で、ユーザーは一般的に、人気誤校正としてフレーミングされた場合にはアルゴリズム間の人気バイアスの有意な違いを認識していることを観察しました。また、JSDはユーザーの人気の認知と中程度の相関を示しますが、不人気の認知とは相関がありません。
        </label>
        <input type="checkbox" id="Panel193" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Popularity bias in recommendation lists refers to over-representation of popular content and is a challenge for many recommendation algorithms. Previous research has suggested several offline metrics to quantify popularity bias, which commonly relate the popularity of items in users' recommendation lists to the popularity of items in their interaction history. Discrepancies between these two factors are referred to as popularity miscalibration. While popularity metrics provide a straightforward and well-defined means to measure popularity bias, it is unknown whether they actually reflect users' perception of popularity bias. To address this research gap, we conduct a crowd-sourced user study on Prolific, involving 56 participants, to (1) investigate whether the level of perceived popularity miscalibration differs between common recommendation algorithms, (2) assess the correlation between perceived popularity miscalibration and its corresponding quantification according to a common offline metric. We conduct our study in a well-defined and important domain, namely music recommendation using the standardized LFM-2b dataset, and quantify popularity miscalibration of five recommendation algorithms by utilizing Jensen-Shannon distance (JSD). Challenging the findings of previous studies, we observe that users generally do perceive significant differences in terms of popularity bias between algorithms if this bias is framed as popularity miscalibration. In addition, JSD correlates moderately with users' perception of popularity, but not with their perception of unpopularity.
        </div> </ul> <br>



        <label for="Panel194">
        <strong> Connecting Unseen Domains: Cross-Domain Invariant Learning in Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Zhang">Yang Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Shen">Yue Shen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dong+Wang">Dong Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinjie+Gu">Jinjie Gu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guannan+Zhang">Guannan Zhang</a> (1) </u>  <br>
        1:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591965">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Connecting Unseen Domains: Cross-Domain Invariant Learning in Recommendation">Google Scholar</a></div>
        (194)
        <br>
        <b>概要:　</b> ウェブアプリケーションが拡大し、多様なサービスを提供する中で、ユーザーのインタラクションはさまざまなシナリオに存在します。この情報の豊富さを活用するために、クロスドメインレコメンデーション（CDR）は近年、大きな注目を集めています。しかし、既存のCDRアプローチは主に観測されたドメイン間の情報転送に焦点を当てており、未見のドメインへの一般化にはあまり関心が払われていません。一般化の目的には不変学習に関する最近の研究が役立つものの、不変な嗜好みに依存するのみでは保守的過ぎ、未見のドメインが若干変わった場合に中程度のパフォーマンスに終わる可能性があります。本論文では、CDRとドメイン一般化の両方を統一的な因果不変視点で考慮する新しいフレームワークを提案します。ユーザーのインタラクションはドメイン不変な嗜好とドメイン特有の嗜好によって決定されると仮定します。提案されたアプローチは、観測行動から不変な嗜好と特有の嗜好を敵対的学習の方法で区別します。さらに、新規のドメインルーティングモジュールが設計され、未見のドメインを観測されたドメインに接続します。公共および業界のデータセットに対する広範な実験により、CDRおよびドメイン一般化設定の両方における提案アプローチの有効性が証明されました。
        </label>
        <input type="checkbox" id="Panel194" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> As web applications continue to expand and diversify their services, user interactions exist in different scenarios. To leverage this wealth of information, cross-domain recommendation (CDR) has gained significant attention in recent years. However, existing CDR approaches mostly focus on information transfer between observed domains, with little attention paid to generalizing to unseen domains. Although recent research on invariant learning can help for the purpose of generalization, relying only on invariant preference may be overly conservative and result in mediocre performance when the unseen domain shifts slightly. In this paper, we present a novel framework that considers both CDR and domain generalization through a united causal invariant view. We assume that user interactions are determined by domain-invariant preference and domain-specific preference. The proposed approach differentiates the invariant preference and the specific preference from observational behaviors in a way of adversarial learning. Additionally, a novel domain routing module is designed to connect unseen domains to observed domains. Extensive experiments on public and industry datasets have proved the effectiveness of the proposed approach under both CDR and domain generalization settings.
        </div> </ul> <br>



        <label for="Panel195">
        <strong> ConQueR: Contextualized Query Reduction using Search Logs </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hye-young+Kim">Hye-young Kim</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Minjin+Choi">Minjin Choi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sunkyung+Lee">Sunkyung Lee</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Eunseong+Choi">Eunseong Choi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Young-In+Song">Young-In Song</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jongwuk+Lee">Jongwuk Lee</a> (1) </u>  <br>
        1:  Sungkyunkwan University, 2:  NAVER Corp. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591966">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=ConQueR: Contextualized Query Reduction using Search Logs">Google Scholar</a></div>
        (195)
        <br>
        <b>概要:　</b> アドホック検索において、クエリの言語的なギャップを軽減するための主要な手法はクエリの再構成です。さまざまな解決策の中でも、クエリの削減は冗長な用語を効果的に除去し、長いクエリから簡潔なユーザー意図を明確にします。しかし、隠れた多様なユーザー意図を捕捉することは困難です。本論文では、事前訓練された言語モデル（PLM）を用いた文脈化クエリ削減（ConQueR）を提案します。具体的には、冗長なクエリをコア用語抽出とサブクエリ選択の二つの異なる観点から削減します。ひとつは、元のクエリからコア用語を用語レベルで抽出し、もうひとつは、サブクエリが元のクエリに対して適切な削減であるかどうかをシーケンスレベルで判断します。これらは異なる粒度のレベルで機能し、互いに補完し合うため、最終的にはアンサンブルの方法で統合されます。商業的なウェブ検索エンジンから収集した実世界の検索ログを用いて、ConQueRの削減品質を評価しました。その結果、最良の競合モデルに対して最大8.45%の正確一致スコア向上を達成しました。
        </label>
        <input type="checkbox" id="Panel195" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Query reformulation is a key mechanism to alleviate the linguistic chasm of query in ad-hoc retrieval. Among various solutions, query reduction effectively removes extraneous terms and specifies concise user intent from long queries. However, it is challenging to capture hidden and diverse user intent. This paper proposes Contextualized Query Reduction (ConQueR) using a pre-trained language model (PLM). Specifically, it reduces verbose queries with two different views: core term extraction and sub-query selection. One extracts core terms from an original query at the term level, and the other determines whether a sub-query is a suitable reduction for the original query at the sequence level. Since they operate at different levels of granularity and complement each other, they are finally aggregated in an ensemble manner. We evaluate the reduction quality of ConQueR on real-world search logs collected from a commercial web search engine. It achieves up to 8.45% gains in exact match scores over the best competing model.
        </div> </ul> <br>



        <label for="Panel196">
        <strong> Context-Aware Modeling via Simulated Exposure Page for CTR Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Li">Xiang Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuwei+Chen">Shuwei Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jian+Dong">Jian Dong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jin+Zhang">Jin Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongkang+Wang">Yongkang Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xingxing+Wang">Xingxing Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dong+Wang">Dong Wang</a> (1) </u>  <br>
        1:  Meituan <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591967">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Context-Aware Modeling via Simulated Exposure Page for CTR Prediction">Google Scholar</a></div>
        (196)
        <br>
        <b>概要:　</b> クリック率（CTR）の予測は、複数のアイテムをユーザーリクエストごとに生成して提示する産業用推薦システムや広告システムにおいて、重要な役割を果たします。ユーザーのアイテムに対するクリックアクションは、他の提示されるアイテム（文脈アイテムと呼ばれる）によって影響を受けますが、現在のCTR予測方法は文脈アイテムの生成前に実行されるため、この文脈を利用していません。本論文では、この制約に対処するために「Contextual Items Simulation and Modeling（CISM）」を提案します。具体的には、オンラインサービスの遅延に影響を与えずに露出ページをシミュレートする「Near-line Context Simulation Center」と、候補アイテムに対するユーザーごとの文脈をシミュレート結果から学習する「Online Context Modeling Transformer」を提案しています。さらに知識蒸留を導入してCTR予測をさらに改善します。公共および産業用データセットを用いた広範な実験により、CISMの有効性が実証されました。現在、CISMはMeituan Waimaiのオンラインディスプレイ広告システムに導入され、主流のトラフィックを処理しています。
        </label>
        <input type="checkbox" id="Panel196" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Click-through rate (CTR) prediction plays a crucial role in industrial recommendation and advertising systems, which generate and expose multiple items for each user request. Although the user's click action on an item will be affected by the other exposed items (called contextual items), current CTR prediction methods do not exploit this context because CTR prediction is performed before the contextual items are generated. This paper introduces a solution Contextual Items Simulation and Modeling (CISM) to tackle this limitation. Specifically, we propose a near-line Context Simulation Center to simulate exposure page without affecting online service latency, and an online Context Modeling Transformer to learn user-wise context from the simulated results w.r.t. the candidate item. In addition, knowledge distillation is introduced to further improve CTR prediction. Extensive experiments on both public and industrial datasets demonstrate the effectiveness of CISM. Currently, CISM has been deployed in the online display advertising system of Meituan Waimai, serving the main traffic.
        </div> </ul> <br>



        <label for="Panel197">
        <strong> Contrastive Learning for Conversion Rate Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wentao+Ouyang">Wentao Ouyang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rui+Dong">Rui Dong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiuwu+Zhang">Xiuwu Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaofeng+Guo">Chaofeng Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinmei+Luo">Jinmei Luo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangzheng+Liu">Xiangzheng Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanlong+Du">Yanlong Du</a> (1) </u>  <br>
        1:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591968">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Contrastive Learning for Conversion Rate Prediction">Google Scholar</a></div>
        (197)
        <br>
        <b>概要:　</b> 広告システムにおけるコンバージョン率（CVR）予測は重要な役割を果たします。近年、教師付きの深層ニューラルネットワークモデルがCVR予測で有望な性能を示しています。しかし、これらのモデルはデータを大量に必要とし、膨大な量の訓練データが求められます。オンライン広告システムでは、数百万から数十億の広告が存在するにもかかわらず、ユーザーはその中のごく一部にクリックし、さらに少ない数の広告にコンバージョンします。このデータの希少性の問題が、これらの深層モデルの能力を制限しています。本論文では、CVR予測のための対照学習（CL4CVR）フレームワークを提案します。このフレームワークは、教師付きのCVR予測タスクと対照学習タスクを関連付けることで、大量のラベルなしデータを活用し、優れたデータ表現を学習し、CVR予測の性能を向上させます。CVR予測問題に対照学習タスクを適用するために、特徴マスキングではなく埋め込みマスキング（EM）を提案し、拡張サンプルの2つのビューを作成します。また、ユーザー行動データの自然な特性を考慮して、アンカーサンプルと同じ特徴を持つサンプルを排除する偽陰性排除（FNE）コンポーネントも提案します。さらに、希少ですが貴重なユーザーのコンバージョンイベントを最大限に活用するために、各アンカーサンプルのために追加の正のサンプルを含む、教師付き正例包含（SPI）コンポーネントも提案します。実世界の2つのコンバージョンデータセットでの実験結果は、CL4CVRの優れた性能を示しています。ソースコードはhttps://github.com/DongRuiHust/CL4CVRで入手可能です。
        </label>
        <input type="checkbox" id="Panel197" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Conversion rate (CVR) prediction plays an important role in advertising systems. Recently, supervised deep neural network-based models have shown promising performance in CVR prediction. However, they are data hungry and require an enormous amount of training data. In online advertising systems, although there are millions to billions of ads, users tend to click only a small set of them and to convert on an even smaller set. This data sparsity issue restricts the power of these deep models. In this paper, we propose the Contrastive Learning for CVR prediction (CL4CVR) framework. It associates the supervised CVR prediction task with a contrastive learning task, which can learn better data representations exploiting abundant unlabeled data and improve the CVR prediction performance. To tailor the contrastive learning task to the CVR prediction problem, we propose embedding masking (EM), rather than feature masking, to create two views of augmented samples. We also propose a false negative elimination (FNE) component to eliminate samples with the same feature as the anchor sample, to account for the natural property in user behavior data. We further propose a supervised positive inclusion (SPI) component to include additional positive samples for each anchor sample, in order to make full use of sparse but precious user conversion events. Experimental results on two real-world conversion datasets demonstrate the superior performance of CL4CVR. The source code is available at https://github.com/DongRuiHust/CL4CVR.
        </div> </ul> <br>



        <label for="Panel198">
        <strong> Curriculum Modeling the Dependence among Targets with Multi-task Learning for Financial Marketing </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunpeng+Weng">Yunpeng Weng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xing+Tang">Xing Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liang+Chen">Liang Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiuqiang+He">Xiuqiang He</a> (1) </u>  <br>
        1:  FiT <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591969">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Curriculum Modeling the Dependence among Targets with Multi-task Learning for Financial Marketing">Google Scholar</a></div>
        (198)
        <br>
        <b>概要:　</b> 多くの現実世界のアプリケーションにおけるマルチタスク学習は、通常、論理的な順序依存関係を持つタスクを含みます。例えば、オンラインマーケティングでは、インプレッションからクリック、コンバージョンへのカスケード行動パターンが複数のタスクとしてモデリングされ、現在の研究ではタスク間の順序依存関係は明示的に定義された関数や暗黙的に転送される情報で接続されることが一般的です。これらの方法は、タスクシーケンスに沿ってポジティブフィードバックが希少になるため、ロングパス順序タスクにおけるデータの希少性問題を緩和します。しかし、エラーの蓄積や負の転送は下流のタスクに対して重大な問題となります。特に、トレーニングの開始段階では、前のタスクのパラメータの最適化がまだ収束しておらず、そのため下流のタスクに転送される情報が負になることがあります。本論文では、複数の順序依存タスク学習に対して新しい事前情報統合（PIM）モジュールを用いて論理依存関係を明示的にモデル化する事前情報統合モデル（PIMM）を提案します。具体的には、PIMはトレーニングの間に真のラベル情報または前のタスクの予測情報をソフトサンプリング戦略でランダムに選択し、下流のタスクに転送します。易から難へというカリキュラムパラダイムに従い、サンプリング確率を動的に調整して、トレーニングと共に下流のタスクが有効な情報を取得できるようにします。公的および製品データセットでのオフライン実験結果は、PIMMが最先端のベースラインを上回ることを確認しました。さらに、PIMMを大規模なFinTechプラットフォームに展開し、オンライン実験でもPIMMの有効性が実証されました。
        </label>
        <input type="checkbox" id="Panel198" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multi-task learning for various real-world applications usually involves tasks with logical sequential dependence. For example, in online marketing, the cascade behavior pattern of impression \rightarrow click \rightarrow conversion is usually modeled as multiple tasks in a multi-task manner, where the sequential dependence between tasks is simply connected with an explicitly defined function or implicitly transferred information in current works. These methods alleviate the data sparsity problem for long-path sequential tasks as the positive feedback becomes sparser along with the task sequence. However, the error accumulation and negative transfer will be a severe problem for downstream tasks. Especially, at the beginning stage of training, the optimization for parameters of former tasks is not converged yet, and thus the information transferred to downstream tasks is negative. In this paper, we propose a prior information merged model (PIMM), which explicitly models the logical dependence among tasks with a novel prior information merged (PIM) module for multiple sequential dependence task learning in a curriculum manner. Specifically, the PIM randomly selects the true label information or the prior task prediction with a soft sampling strategy to transfer to the downstream task during the training. Following an easy-to-difficult curriculum paradigm, we dynamically adjust the sampling probability to ensure that the downstream task will get the effective information along with the training. The offline experimental results on both public and product datasets verify that PIMM outperforms state-of-the-art baselines. Moreover, we deploy the PIMM in a large-scale FinTech platform, and the online experiments also demonstrate the effectiveness of PIMM.
        </div> </ul> <br>



        <label for="Panel199">
        <strong> Decomposing Logits Distillation for Incremental Named Entity Recognition </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Duzhen+Zhang">Duzhen Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yahan+Yu">Yahan Yu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Feilong+Chen">Feilong Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiuyi+Chen">Xiuyi Chen</a> (1) </u>  <br>
        1:  Baidu Inc., 2:  Huawei Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591970">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Decomposing Logits Distillation for Incremental Named Entity Recognition">Google Scholar</a></div>
        (199)
        <br>
        <b>概要:　</b> インクリメンタル固有表現認識(INER)は、新しいデータを用いてモデルを継続的に訓練し、新たなエンティティタイプを認識する一方で、以前に学習した内容を忘れずに保持することを目的としています。これまでのINER手法は、知識蒸留により予測されたロジットを保持するLogits Distillation(LD)が、この難題を効果的に緩和することを示してきました。本論文では、予測されたロジットが入力トークンが特定のエンティティタイプに属する可能性を測定する二つの項に分解できることを発見しました。しかし、従来のLDは、これら二つの項の和のみを保持し、各コンポーネントの変化を考慮していません。各項を明示的に制約するために、新たなDecomposing Logits Distillation(DLD)手法を提案し、モデルの旧知識を保持する能力を高め、破滅的忘却を軽減します。さらに、DLDはモデルに依存せず、実装も容易です。広範な実験により、DLDが三つのデータセットの十のINER設定において、最新のINER手法の性能を一貫して向上させることが示されました。
        </label>
        <input type="checkbox" id="Panel199" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Incremental Named Entity Recognition (INER) aims to continually train a model with new data, recognizing emerging entity types without forgetting previously learned ones. Prior INER methods have shown that Logits Distillation (LD), which involves preserving predicted logits via knowledge distillation, effectively alleviates this challenging issue. In this paper, we discover that a predicted logit can be decomposed into two terms that measure the likelihood of an input token belonging to a specific entity type or not. However, the traditional LD only preserves the sum of these two terms without considering the change in each component. To explicitly constrain each term, we propose a novel Decomposing Logits Distillation (DLD) method, enhancing the model's ability to retain old knowledge and mitigate catastrophic forgetting. Moreover, DLD is model-agnostic and easy to implement. Extensive experiments show that DLD consistently improves the performance of state-of-the-art INER methods across ten INER settings in three datasets.
        </div> </ul> <br>



        <label for="Panel200">
        <strong> Denoise to Protect: A Method to Robustify Visual Recommenders from Adversaries </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Felice+Antonio+Merra">Felice Antonio Merra</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Vito+Walter+Anelli">Vito Walter Anelli</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tommaso+Di+Noia">Tommaso Di Noia</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daniele+Malitesta">Daniele Malitesta</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alberto+Carlo+Maria+Mancino">Alberto Carlo Maria Mancino</a> (2) </u>  <br>
        1:  Amazon, 2:  Politecnico di Bari <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591971">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Denoise to Protect: A Method to Robustify Visual Recommenders from Adversaries">Google Scholar</a></div>
        (200)
        <br>
        <b>概要:　</b> 製品画像の統合により、ビジュアルベースの推薦システム（VRS）の推薦性能は向上しますが、同時にノイズが含まれた画像を作成して推薦の動作を変える攻撃者に対して脆弱になる可能性があります。近年、これらのリスクに対する意識を高めるため、ますます強力な対敵攻撃が登場しています。しかし、効果的な防御方法はいまだ緊急の課題です。本研究では、アイテム画像を悪意のある摂動からクリーンアップする新しい防御方法「Adversarial Image Denoiser（AiD）」を提案します。特に、クリーン画像と対敵画像の視覚的な違いを最小限に抑えつつ、信頼できる環境でのランキング性能を維持することを目的としたトレーニング戦略を設計しました。標準的なVRSに対する三つの最先端の対敵攻撃を用いて、AiDの有効性を評価する実験を行いました。コードとデータセットはhttps://github.com/sisinflab/Denoise-to-protect-VRSで公開しています。
        </label>
        <input type="checkbox" id="Panel200" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> While the integration of product images enhances the recommendation performance of visual-based recommender systems (VRSs), this can make the model vulnerable to adversaries that can produce noised images capable to alter the recommendation behavior. Recently, stronger and stronger adversarial attacks have emerged to raise awareness of these risks; however, effective defense methods are still an urgent open challenge. In this work, we propose "Adversarial Image Denoiser" (AiD), a novel defense method that cleans up the item images by malicious perturbations. In particular, we design a training strategy whose denoising objective is to minimize both the visual differences between clean and adversarial images and preserve the ranking performance in authentic settings. We perform experiments to evaluate the efficacy of AiD using three state-of-the-art adversarial attacks mounted against standard VRSs. Code and datasets at https://github.com/sisinflab/Denoise-to-protect-VRS.
        </div> </ul> <br>



        <label for="Panel201">
        <strong> DeviceGPT: A Generative Pre-Training Transformer on the Heterogenous Graph for Internet of Things </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yimo+Ren">Yimo Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinfa+Wang">Jinfa Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hong+Li">Hong Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongsong+Zhu">Hongsong Zhu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Limin+Sun">Limin Sun</a> (1) </u>  <br>
        1:  University of Chinese Academy of Science & Institute of Information Engineering <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591972">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=DeviceGPT: A Generative Pre-Training Transformer on the Heterogenous Graph for Internet of Things">Google Scholar</a></div>
        (201)
        <br>
        <b>概要:　</b> 近年、グラフニューラルネットワーク（GNN）は、学問および産業分野における広範な構造化データのモデリングに採用されています。インターネット技術が急速に発展する中で、デバイス識別、位置情報取得など、性能向上を必要とするインターネットデバイスのための意義深い応用がますます増えています。GNNのいくつかの成功事例を再現するために、本稿では、異質グラフ上で自己教師あり学習を用いて生成事前学習トランスフォーマーに基づいたDeviceGPTを提案します。これにより、大規模データベースからデバイス間の豊富なインタラクション情報を効率的に学習します。実世界のデータセットで行った実験では、DeviceGPTが複数のインターネットアプリケーションにおいて競争力のある結果を達成できることが示されました。
        </label>
        <input type="checkbox" id="Panel201" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recently, Graph neural networks (GNNs) have been adopted to model a wide range of structured data from academic and industry fields. With the rapid development of Internet technology, there are more and more meaningful applications for Internet devices, including device identification, geolocation and others, whose performance needs improvement. To replicate the several claimed successes of GNNs, this paper proposes DeviceGPT based on a generative pre-training transformer on a heterogeneous graph via self-supervised learning to learn interactions-rich information of devices from its large-scale databases well. The experiments on the dataset constructed from the real world show DeviceGPT could achieve competitive results in multiple Internet applications.
        </div> </ul> <br>



        <label for="Panel202">
        <strong> Dimension-Prompts Boost Commonsense Consolidation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiazhan+Feng">Jiazhan Feng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chongyang+Tao">Chongyang Tao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tao+Shen">Tao Shen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chang+Liu">Chang Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongyan+Zhao">Dongyan Zhao</a> (4) </u>  <br>
        1:  Peking University, 2:  Microsoft Corporation, 3:  University of Technology Sydney, 4:  Peking University & National Key Laboratory of General Artificial Intelligence <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591973">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Dimension-Prompts Boost Commonsense Consolidation">Google Scholar</a></div>
        (202)
        <br>
        <b>概要:　</b> ニューラル知識モデルは共通認識に基づく知識の基盤を進展させてきました。これらのモデルは、選別された小規模の共通認識知識グラフ（CS-KG）を言語モデルにパラメータ化することで、一般化能力を高めます。現在のトレンドは、複数のCS-KGソース（例えば、ATOMIC、ConceptNet）を単一のモデルに直接混合して、シードを拡張することです。しかし、このような力ずくの混合は、以下の理由で効果的な知識統合を妨げることが避けられません：①ソース間の関係が曖昧、多義的、または不一致であること、および②異なるタイプ（例えば、因果、時間）的な知識が絡み合って学習されること。これを緩和するために、私たちは共通認識知識の次元という概念を採用し、新しい次元非交叉知識モデル（D2KM）学習パラダイムを提案します。これは、次元特有のソフトプロンプトを持つ生成言語モデルを訓練し、異なる次元に沿った知識の獲得を分離し、CS-KGソース間での次元内の統合を促進するものです。実験では、私たちの知識モデルが標準シナリオとゼロショットシナリオの両方でベースラインモデルより優れていることが示されました。
        </label>
        <input type="checkbox" id="Panel202" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Neural knowledge models emerged and advanced common-sense-centric knowledge grounding. They parameterize a small seed curated commonsense knowledge graph (CS-KG) in a language model to generalize more. A current trend is to scale the seed up by directly mixing multiple sources of CS-KG (e.g., ATOMIC, ConceptNet) into one model. But, such brute-force mixing inevitably hinders effective knowledge consolidation due to i) ambiguous, polysemic, and/or inconsistent relations across sources and ii) knowledge learned in an entangled manner despite distinct types (e.g., causal, temporal). To mitigate this, we adopt a concept of commonsense knowledge dimension and propose a brand-new dimension-disentangled knowledge model (D2KM) learning paradigm with multiple sources. That is, a generative language model with dimension-specific soft prompts is trained to disentangle knowledge acquisitions along with different dimensions and facilitate potential intra-dimension consolidation across CS-KG sources. Experiments show our knowledge model outperforms its baselines in both standard and zero-shot scenarios.
        </div> </ul> <br>



        <label for="Panel203">
        <strong> Disentangling User Conversations with Voice Assistants for Online Shopping </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nikhita+Vedula">Nikhita Vedula</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Marcus+Collins">Marcus Collins</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Oleg+Rokhlenko">Oleg Rokhlenko</a> (1) </u>  <br>
        1:  Amazon <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591974">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Disentangling User Conversations with Voice Assistants for Online Shopping">Google Scholar</a></div>
        (203)
        <br>
        <b>概要:　</b> 会話の解きほぐしは、会話の発言を識別し、異なるスレッドにグループ化することを目的としています。既存の方法は主に三人以上の複数の話者がいる会話を解きほぐすことに焦点を当て、明示的または暗示的に話者関連の特徴信号を取り入れて解きほぐしを行います。ほとんどの既存モデルはモデルの訓練に大量の人間によるアノテーションデータを必要とし、発言間のペア関係に重きを置いて会話の文脈をあまり考慮していません。本研究では、コントラスト学習目的を持つマルチタスク学習アプローチDiSCを提案し、ユーザーと仮想音声アシスタントの2人の話者間の会話を解きほぐすことを目指します。これは新しいドメインであるeコマースに適用されます。我々は会話の「スレッド」を定義する複数の方法と粒度について分析します。DiSCは発言間の関係と発言とそのスレッド文脈との関係を同時に学習します。我々は、手作業でラベル付けすることなく自動的に作成された複数のマルチスレッド会話データセットでモデルを訓練および評価しました。公開データセットおよび商業用音声アシスタントからの実際の買い物会話に関する実験結果は、DiSCが最新のベースラインを、機械評価と人間評価の両面で少なくとも3%上回ることを示しています。また、DiSCが買い物ドメインにおける対話応答生成の向上にどのように寄与するかも実証します。
        </label>
        <input type="checkbox" id="Panel203" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Conversation disentanglement aims to identify and group utterances from a conversation into separate threads. Existing methods primarily focus on disentangling multi-party conversations with three or more speakers, explicitly or implicitly incorporating speaker-related feature signals to disentangle. Most existing models require a large amount of human annotated data for model training, and often focus on pairwise relations between utterances, not accounting much for the conversational context. In this work, we propose a multi-task learning approach with a contrastive learning objective, DiSC, to disentangle conversations between two speakers -- a user and a virtual speech assistant, for a novel domain of e-commerce. We analyze multiple ways and granularities to define conversation "threads''. DiSC jointly learns the relation between pairs of utterances, as well as between utterances and their respective thread context. We train and evaluate our models on multiple multi-threaded conversation datasets that were automatically created, without any human labeling effort. Experimental results on public datasets as well as real-world shopping conversations from a commercial speech assistant show that DiSC outperforms state-of-the-art baselines by at least 3%, across both automatic and human evaluation metrics. We also demonstrate how DiSC improves downstream dialog response generation in the shopping domain.
        </div> </ul> <br>



        <label for="Panel204">
        <strong> DocGraphLM: Documental Graph Language Model for Information Extraction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongsheng+Wang">Dongsheng Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Ma">Zhiqiang Ma</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Armineh+Nourbakhsh">Armineh Nourbakhsh</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kang+Gu">Kang Gu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sameena+Shah">Sameena Shah</a> (2) </u>  <br>
        1:  JPMorgan AI Research, 2:  JPMorgan AI Research, 3:  Dartmouth College <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591975">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=DocGraphLM: Documental Graph Language Model for Information Extraction">Google Scholar</a></div>
        (204)
        <br>
        <b>概要:　</b> 視覚的に豊かなドキュメント理解（VrDU）の進展により、複雑なレイアウトを持つドキュメントから情報抽出や質問応答が可能になりました。ここで主に二つのアーキテクチャが出現しました—LLM（大規模言語モデル）に触発されたトランスフォーマーモデルと、グラフニューラルネットワークです。本論文では、事前学習言語モデルとグラフセマンティクスを組み合わせた新しいフレームワークであるDocGraphLMを紹介します。その達成のために、1) ドキュメントを表現するための共同エンコーダーアーキテクチャと、2) ドキュメントグラフを再構築するための新しいリンク予測手法を提案します。DocGraphLMは、ノード間の方向と距離の両方を予測し、近傍復元を優先し遠いノードの検出を低減する収束的な共同損失関数を使用します。三つの最先端データセットに対する我々の実験では、グラフ機能を採用することでIE（情報抽出）とQA（質問応答）のタスクにおいて一貫した改善が確認されました。さらに、グラフ機能を採用することで、リンク予測を通じてのみ構築されたにもかかわらず、学習プロセス中の収束が加速することを報告します。
        </label>
        <input type="checkbox" id="Panel204" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Advances in Visually Rich Document Understanding (VrDU) have enabled information extraction and question answering over documents with complex layouts. Two tropes of architectures have emerged-transformer-based models inspired by LLMs, and Graph Neural Networks. In this paper, we introduce DocGraphLM, a novel framework that combines pre-trained language models with graph semantics. To achieve this, we propose 1) a joint encoder architecture to represent documents, and 2) a novel link prediction approach to reconstruct document graphs. DocGraphLM predicts both directions and distances between nodes using a convergent joint loss function that prioritizes neighborhood restoration and downweighs distant node detection. Our experiments on three SotA datasets show consistent improvement on IE and QA tasks with the adoption of graph features. Moreover, we report that adopting the graph features accelerates convergence in the learning process druing training, despite being solely constructed through link prediction.
        </div> </ul> <br>



        <label for="Panel205">
        <strong> Edge-cloud Collaborative Learning with Federated and Centralized Features </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zexi+Li">Zexi Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qunwei+Li">Qunwei Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Zhou">Yi Zhou</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenliang+Zhong">Wenliang Zhong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guannan+Zhang">Guannan Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chao+Wu">Chao Wu</a> (1) </u>  <br>
        1:  Zhejiang University, 2:  Ant Group, 3:  The University of Utah <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591976">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Edge-cloud Collaborative Learning with Federated and Centralized Features">Google Scholar</a></div>
        (205)
        <br>
        <b>概要:　</b> フェデレーテッドラーニング（FL）は、ユーザーのプライバシーを犠牲にすることなく、エッジコンピューティングを行うための一般的な方法です。現在のFLのパラダイムは、データがエッジにのみ存在し、クラウドサーバーはモデル平均化のみを行うと仮定しています。しかし、レコメンダーシステムのような現実の状況では、クラウドサーバーは豊富な特徴量と計算リソースを持っています。具体的には、クラウドは履歴的かつインタラクティブな特徴量を保存し、エッジはプライバシーが重要でリアルタイムの特徴量を保存します。本稿では、エッジ側の特徴量とクラウド側の特徴量を共同で利用し、特徴量の埋め込みと予測ロジットの共有によって両者間の双方向知識転移を実現する「エッジ-クラウド協調知識転移フレームワーク（ECCT）」を提案します。ECCTは、パーソナライゼーションの強化、モデルの異種性の許容、トレーニングの非同期性の許容、通信負担の軽減など、さまざまな利点を統合します。公開データセットおよび産業データセットでの広範な実験により、ECCTの有効性が実証されました。
        </label>
        <input type="checkbox" id="Panel205" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Federated learning (FL) is a popular way of edge computing that does not compromise user's privacy. Current FL paradigms assume data only resides on the edge, while cloud servers only perform model averaging. However, in real-life situations such as recommender systems, the cloud server usually has abundant features and computation resources. Specifically, the cloud stores historical and interactive features, and the edge stores privacy-sensitive and real-time features. In this paper, our proposed Edge-Cloud Collaborative Knowledge Transfer Framework (ECCT) jointly utilizes the edge-side features and the cloud-side features, enabling bi-directional knowledge transfer between the two by sharing feature embeddings and prediction logits. ECCT consolidates various benefits, including enhancing personalization, enabling model heterogeneity, tolerating training asynchronization, and relieving communication burdens. Extensive experiments on public and industrial datasets demonstrate the effectiveness of ECCT.
        </div> </ul> <br>



        <label for="Panel206">
        <strong> SLIM: Sparsified Late Interaction for Multi-Vector Retrieval with Inverted Indexes </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Minghan+Li">Minghan Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sheng-Chieh+Lin">Sheng-Chieh Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xueguang+Ma">Xueguang Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jimmy+Lin">Jimmy Lin</a> (1) </u>  <br>
        1:  University of Waterloo <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591977">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SLIM: Sparsified Late Interaction for Multi-Vector Retrieval with Inverted Indexes">Google Scholar</a></div>
        (206)
        <br>
        <b>概要:　</b> 本論文は、スパース化遅延相互作用を用いたマルチベクター（SLIM）インデックスによる検索手法を紹介します。マルチベクター検索手法は、様々な検索データセットでその有効性が実証されており、中でもColBERTは、事前学習された言語モデルの文脈化トークン埋め込みの遅延相互作用に基づく最も確立された手法です。しかし、効率的なColBERTの実装には複雑なエンジニアリングが必要であり、市販の検索ライブラリを利用することができないため、実用化が妨げられています。この問題に対処するために、SLIMはまず各文脈化トークンベクターをスパースで高次元な語彙空間にマッピングし、次にこれらのスパースなトークン埋め込み間の遅延相互作用を行います。その後、スコアを細かく調整するモジュールを備えた逆インデックス検索を含む効率的な二段階検索アーキテクチャを導入し、これによりスパース化遅延相互作用を近似します。この方法はLuceneなどの市販の語彙検索ライブラリと完全に互換性があります。SLIMは、ColBERTと比較してMS MARCO PassagesやBEIRで競争力のある精度を達成しつつ、CPU上でははるかに小規模かつ高速です。我々の知る限り、スパースなトークン表現をマルチベクター検索に活用するのはこれが初めてです。ソースコードとデータは、Pyserini IRツールキットに統合されています。
        </label>
        <input type="checkbox" id="Panel206" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This paper introduces Sparsified Late Interaction for Multi-vector (SLIM) retrieval with inverted indexes. Multi-vector retrieval methods have demonstrated their effectiveness on various retrieval datasets, and among them, ColBERT is the most established method based on the late interaction of contextualized token embeddings of pre-trained language models. However, efficient ColBERT implementations require complex engineering and cannot take advantage of off-the-shelf search libraries, impeding their practical use. To address this issue, SLIM first maps each contextualized token vector to a sparse, high-dimensional lexical space before performing late interaction between these sparse token embeddings. We then introduce an efficient two-stage retrieval architecture that includes inverted index retrieval followed by a score refinement module to approximate the sparsified late interaction, which is fully compatible with off-the-shelf lexical search libraries such as Lucene. SLIM achieves competitive accuracy on MS MARCO Passages and BEIR compared to ColBERT while being much smaller and faster on CPUs. To our knowledge, we are the first to explore using sparse token representations for multi-vector retrieval. Source code and data are integrated into the Pyserini IR toolkit.
        </div> </ul> <br>



        <label for="Panel207">
        <strong> Evaluating Cross-modal Generative Models Using Retrieval Task </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shivangi+Bithel">Shivangi Bithel</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Srikanta+Bedathur">Srikanta Bedathur</a> (1) </u>  <br>
        1:  IIT Delhi <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591979">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Evaluating Cross-modal Generative Models Using Retrieval Task">Google Scholar</a></div>
        (207)
        <br>
        <b>概要:　</b> 生成モデルは世界を席巻しており、Stable DiffusionやDALL-Eのような画像生成モデルは写実的な画像を生成し、BLIP、GIT、ClipCap、ViT-GPT2といった画像キャプション生成モデルは説明的かつ情報豊富なキャプションを生成します。これらのモデルが驚くべき結果を出すのは事実である一方、体系的な評価が欠如しており、研究のさらなる進展が困難になっています。現状では、Inception ScoreやFréchet Inception Distanceのようなヒューリスティックな指標が画像生成タスクで広く使用され、BLEU、CIDEr、SPICE、METEOR、BERTScore、CLIPScoreといった指標が画像キャプション生成タスクで一般的です。しかし、これらの指標は解釈が難しく、情報検索コミュニティが取り組んできたユーザ行動モデルに基づいたものではありません。本論文では、参照テキストと画像を用いてクロスモーダル（画像からテキスト、テキストから画像）生成モデルの有効性を評価する新しいクロスモーダル検索フレームワークを提案します。正規化割引累積利得（nDCG'@K）やランクバイアス付き精度（RBP'@K）などの不完全な判断に対する調整を行ったユーザ行動に基づくスコアリングモデルの使用を提案しています。ECCV CaptionやFlickr8k-EXPERTSベンチマークデータセットを用いた実験により、提案された検索タスクに対する様々な画像キャプション生成モデルおよび画像生成モデルの有効性が実証されました。結果からは、nDCG'@KおよびRBP'@Kスコアは、モデル選択においてCLIPScoreを除くヒューリスティック指標と一致していることも示されています。
        </label>
        <input type="checkbox" id="Panel207" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Generative models have taken the world by storm -- image generative models such as Stable Diffusion and DALL-E generate photo-realistic images, whereas image captioning models such as BLIP, GIT, ClipCap, and ViT-GPT2 generate descriptive and informative captions. While it may be true that these models produce remarkable results, their systematic evaluation is missing, making it hard to advance the research further. Currently, heuristic metrics such as the Inception Score and the Fréchet Inception Distance are the most prevalent metrics for the image generation task, while BLEU, CIDEr, SPICE, METEOR, BERTScore, and CLIPScore are common for the image captioning task. Unfortunately, these are poorly interpretable and are not based on the solid user-behavior model that the Information Retrieval community has worked towards. In this paper, we present a novel cross-modal retrieval framework to evaluate the effectiveness of cross-modal (image-to-text and text-to-image) generative models using reference text and images. We propose the use of scoring models based on user-behavior, such as Normalized Discounted Cumulative Gain (nDCG'@K ) and Rank-Biased Precision (RBP'@K) adjusted for incomplete judgments. Experiments using ECCV Caption and Flickr8k-EXPERTS benchmark datasets demonstrate the effectiveness of various image captioning and image generation models for the proposed retrieval task. Results also indicate that the nDCG'@K and RBP'@K scores are consistent with heuristics-driven metrics, excluding CLIPScore, in model selection.
        </div> </ul> <br>



        <label for="Panel208">
        <strong> Event-Aware Adaptive Clustering Uplift Network for Insurance Creative Ranking </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wanjie+Tao">Wanjie Tao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huihui+Liu">Huihui Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuqi+Li">Xuqi Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qun+Dai">Qun Dai</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hong+Wen">Hong Wen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zulong+Chen">Zulong Chen</a> (1) </u>  <br>
        1:  Alibaba Group, 2:  Nanjing University of Aeronautics and Astronautics <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591980">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Event-Aware Adaptive Clustering Uplift Network for Insurance Creative Ranking">Google Scholar</a></div>
        (208)
        <br>
        <b>概要:　</b> 従来のeコマースプラットフォームにおいて、パーソナライズされた商品束ね推薦は大きな付加価値を持つことが証明されており、適切なマーケティングクリエイティブを表示することでユーザーの購入意欲を向上させます。本稿では、新しい推薦問題である「ポップアップ一回限りのマーケティング（POM）」を提案します。POMでは、商品束ねマーケティングクリエイティブがユーザーが主アイテムを支払う際に一度だけポップアップ表示されます。POMはeコマースプラットフォームにおいて普遍的なアプリケーションとなり、「モバイル購入時にモバイルケースをバンドル購入する」や「航空券購入時に保険をバンドル購入する」などが例として挙げられます。しかし、多くの既存の推薦手法は、このシナリオの特性を考慮していないため、POMのクリエイティブマーケティングに対して最適ではありません。これを解決するために、我々は「イベント対応適応クラスタリングアップリフトネットワーク（EACU-Net）」という新しいフレームワークを提案します。これは我々の知る限り、この分野での初の試みです。EACU-Netは次の3つのモジュールで構成されています。(1) イベント対応グラフカスケード学習：異種グラフネットワークを用いて、ユーザー属性、イベントカテゴリ、クリエイティブ要素の埋め込みを包括的に段階的に学習する。(2) 適応クラスタリングアップリフトネットワーク：同じ文脈内でのクリエイティブに対するユーザーの感受性を学習する。(3) イベント対応情報ゲインネットワーク：イベントの影響を受けたサンプルからより多くの情報を学習する。実世界のeコマースプラットフォームでの広範なオフラインおよびオンライン評価により、提案モデルが最先端手法と比較して優れた性能を示すことが実証されました。
        </label>
        <input type="checkbox" id="Panel208" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In the classical e-commerce platforms, the personalized product-tying recommendation has proven to be of great added value, which improves users' purchase willingness to product-tying by displaying the suitable marketing creative. In this paper, we present a new recommendation problem, i.e., the Pop-up One-time Marketing (POM), where the product-tying marketing creative only pops up one time when the user pays for the main item. POM has become a ubiquitous application in e-commerce platforms, e.g., buy the mobile tying mobile case and buy flight ticket tying insurance. However, many existing recommendation methods are sub-optimal for the creative marketing in the POM scenario due to unconsidering the unique characteristics in the scenario. To tackle this problem, we propose a novel framework named Event-aware Adaptive Clustering Uplift Network (EACU-Net) for the POM scenario, which is to our best knowledge the first attempt along this line. EACU-Net contains three modules: (1) the event-aware graph cascading learning, which employs a heterogeneous graph network to comprehensively learn the embedding for the user attributes, event categories, and creative elements by stage. (2) an adaptive clustering uplift network, which learns the sensitivity of users to creatives under the same context. (3) an event-aware information gain network to learn more information from samples with event affection. Extensive offline and online evaluations on a real-world e-commerce platform demonstrate the superior performance of the proposed model compared with the state-of-the-art method.
        </div> </ul> <br>



        <label for="Panel209">
        <strong> Examining the Impact of Uncontrolled Variables on Physiological Signals in User Studies for Information Processing Activities </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kaixin+Ji">Kaixin Ji</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Damiano+Spina">Damiano Spina</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Danula+Hettiachchi">Danula Hettiachchi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Flora+Dilys+Salim">Flora Dilys Salim</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Falk+Scholer">Falk Scholer</a> (1) </u>  <br>
        1:  RMIT University, 2:  The University of New South Wales <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591981">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Examining the Impact of Uncontrolled Variables on Physiological Signals in User Studies for Information Processing Activities">Google Scholar</a></div>
        (209)
        <br>
        <b>概要:　</b> 序論<br>生理的信号は、情報アクセスシステムとやり取りするユーザーの行動や関与度を理解するための客観的な尺度として応用する可能性があります。しかしながら、これらの信号は非常に感度が高く、実験室でのユーザー研究には多くのコントロールが必要です。タスクの順序や持続時間などのコントロールされた変数や非コントロールされた（すなわち交絡する）変数が、観測された信号にどの程度影響を与えるかを調査するために、パイロット研究を実施しました。各参加者は4種類の情報処理活動（読書、リスニング、スピーキング、書き込み）を完了し、その間に血液量脈波、電気活動値、および瞳孔反応に関するデータを収集しました。その後、ユーザー研究で一般的に発生するコントロールされた変数および非コントロールされた変数の影響を調べるために、機械学習アプローチを使用しました。タスクの持続時間はモデルの性能に大きな影響を与えることが分かり、それがターゲット変数に対する洞察を提供するのではなく、個人差を反映していることが示唆されました。本研究は、生理的信号を用いた情報検索におけるユーザー研究において、こうした変数に対する理解を深めることに寄与します。
        </label>
        <input type="checkbox" id="Panel209" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Physiological signals can potentially be applied as objective measures to understand the behavior and engagement of users interacting with information access systems. However, the signals are highly sensitive, and many controls are required in laboratory user studies. To investigate the extent to which controlled or uncontrolled (i.e., confounding) variables such as task sequence or duration influence the observed signals, we conducted a pilot study where each participant completed four types of information-processing activities (READ, LISTEN, SPEAK, and WRITE). Meanwhile, we collected data on blood volume pulse, electrodermal activity, and pupil responses. We then used machine learning approaches as a mechanism to examine the influence of controlled and uncontrolled variables that commonly arise in user studies. Task duration was found to have a substantial effect on the model performance, suggesting it represents individual differences rather than giving insight into the target variables. This work contributes to our understanding of such variables in using physiological signals in information retrieval user studies.
        </div> </ul> <br>



        <label for="Panel210">
        <strong> Explain Like I am BM25: Interpreting a Dense Model's Ranked-List with a Sparse Approximation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michael+Llordes">Michael Llordes</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Debasis+Ganguly">Debasis Ganguly</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sumit+Bhatia">Sumit Bhatia</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chirag+Agarwal">Chirag Agarwal</a> (2) </u>  <br>
        1:  University of Glasgow, 2:  Adobe Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591982">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Explain Like I am BM25: Interpreting a Dense Model's Ranked-List with a Sparse Approximation">Google Scholar</a></div>
        (210)
        <br>
        <b>概要:　</b> ニューラル検索モデル（NRM）は、密なドキュメント表現を介して意味的な意味を捉える能力により、統計的手法を上回ることが示されています。しかし、これらのモデルは明示的な用語一致に依存しないため、解釈可能性が低いという問題があります。局所的なクエリごとの説明として、NRMの結果と同等のクエリを持つスパース検索システムの結果セットとの類似性を最大化することによって生成される「同等クエリ」という概念を導入します。次に、このアプローチをRM3ベースのクエリ拡張などの既存の方法と比較し、検索効果と各アプローチによって生成される用語の違いについて対比します。
        </label>
        <input type="checkbox" id="Panel210" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Neural retrieval models (NRMs) have been shown to outperform their statistical counterparts owing to their ability to capture semantic meaning via dense document representations. These models, however, suffer from poor interpretability as they do not rely on explicit term matching. As a form of local per-query explanations, we introduce the notion of equivalent queries that are generated by maximizing the similarity between the NRM's results and the result set of a sparse retrieval system with the equivalent query. We then compare this approach with existing methods such as RM3-based query expansion and contrast differences in retrieval effectiveness and in the terms generated by each approach.
        </div> </ul> <br>



        <label for="Panel211">
        <strong> Exploiting Cluster-Skipping Inverted Index for Semantic Place Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Enes+Recep+Cinar">Enes Recep Cinar</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ismail+Sengor+Altingovde">Ismail Sengor Altingovde</a> (1) </u>  <br>
        1:  Middle East Technical University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591983">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Exploiting Cluster-Skipping Inverted Index for Semantic Place Retrieval">Google Scholar</a></div>
        (211)
        <br>
        <b>概要:　</b> セマンティックプレイスリトリーバルは、知識グラフから与えられたクエリに対して、テキスト的に関連し、かつ空間的に近いトップkの場所エンティティを見つけることを目的としています。本研究では、セマンティックプレイスリトリーバルの効率を向上させるための貢献として、二つのアプローチを紹介します。第一に、知識グラフ上の探索深度に対する直感的な制限を適用することで、空間キーワードクエリの処理に用いられるIR-treeインデックス方式[7]をセマンティックプレイスリトリーバルに適用できることを示します。第二に、この問題に対する新しい解決策として、元々トピックごとにクラスター化されたドキュメントコレクションの検索のために提案されたクラスタースキッピング・インバーテッドインデックス（CS-IIS）[1, 4]のアイデアを適用します。我々の実験では、CS-IISはCPU時間の点でIR-treeと同等でありながら、クエリ処理中のI/O時間において大幅な効率向上を示すことが確認されました。
        </label>
        <input type="checkbox" id="Panel211" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Semantic place retrieval aims to find the top-k place entities, which are both textually relevant and spatially close to a given query, from a knowledge graph. In this work, our contribution toward improving the efficiency of semantic place retrieval is two-fold. First, we show that by applying an ad hoc yet intuitive restriction on the depth of search on the knowledge graph, it is possible to adopt IR-tree indexing scheme [7], which has been introduced for processing spatial keyword queries, for the semantic place retrieval scenario. Secondly, as a novel solution to this problem, we adapt the idea of cluster-skipping inverted index (CS-IIS) [1, 4], which has been originally proposed for retrieval over topically clustered document collections. Our experiments show that CS-IIS is comparable to IR-tree in terms of CPU time, while it yields substantial efficiency gains in terms of I/O time during query processing.
        </div> </ul> <br>



        <label for="Panel212">
        <strong> Exploiting Ubiquitous Mentions for Document-Level Relation Extraction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruoyu+Zhang">Ruoyu Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanzeng+Li">Yanzeng Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Minhao+Zhang">Minhao Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Zou">Lei Zou</a> (1) </u>  <br>
        1:  Peking University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591984">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Exploiting Ubiquitous Mentions for Document-Level Relation Extraction">Google Scholar</a></div>
        (212)
        <br>
        <b>概要:　</b> 近年では、関係抽出（RE）の分野において、文レベルから文書レベルへの移行が観察されており、新しい定式化、新しい手法、そして新たな見解が登場しています。しかし、根本的な概念である「メンション」が十分に考慮されておらず、その定義も明確ではありません。現在のデータセットは通常、自動的に検出された名前付きエンティティをメンションとして使用しており、これが参照の欠如問題を引き起こしています。この現象がモデルの推論能力を妨げていることを示します。この問題に対処するために、代名詞や共通名詞などの共参照をメンションに組み込むことを提案し、それに基づいて広く使用されているDocREDベンチマークをR-DocREDとして再定義し、再注釈します。さまざまな手法を評価し、徹底的な実験を行うことで、我々の定式化の有効性を示します。具体的には、共参照の組み込みが長期依存性を削減し、対抗的および低リソース環境下でのモデルの堅牢性と一般化能力を向上させることが結果として示されています。この新しいデータセットは、今後の研究のために公開されています。
        </label>
        <input type="checkbox" id="Panel212" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recent years have witnessed the transition from sentence-level to document-level in relation extraction (RE), with new formulation, new methods and new insights. Yet, the fundamental concept, mention, is not well-considered and well-defined. Current datasets usually use automatically-detected named entities as mentions, which leads to the missing reference problem. We show that such phenomenon hinders models' reasoning abilities. To address it, we propose to incorporate coreferences (e.g. pronouns and common nouns) into mentions, based on which we refine and re-annotate the widely-used DocRED benchmark as R-DocRED. We evaluate various methods and conduct thorough experiments to demonstrate the efficacy of our formula. Specifically, the results indicate that incorporating coreferences helps reduce the long-term dependencies, further improving models' robustness and generalization under adversarial and low-resource settings. The new dataset is made publicly available for future research.
        </div> </ul> <br>



        <label for="Panel213">
        <strong> Exploration of Unranked Items in Safe Online Learning to Re-Rank </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hiroaki+Shiino">Hiroaki Shiino</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kaito+Ariu">Kaito Ariu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kenshi+Abe">Kenshi Abe</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Riku+Togashi">Riku Togashi</a> (1) </u>  <br>
        1:  CyberAgent <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591985">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Exploration of Unranked Items in Safe Online Learning to Re-Rank">Google Scholar</a></div>
        (213)
        <br>
        <b>概要:　</b> オンライン・ランク学習（OLTR）問題に対するバンディットアルゴリズムは、ユーザーフィードバックを活用して長期的な収益を最大化することを目的とすることが多いです。しかし、実践的な観点から見ると、これらのアルゴリズムは積極的な探索のためにユーザー体験を損なうリスクが高いです。そのため、近年では安全な探索の需要が高まっています。安全な探索へのアプローチの一つとして、すでに保証された品質を持つ元のランキングの質を徐々に向上させる方法があります。本論文では、現在のランキングにあるアイテムの一つと、ランキング外（未ランク）アイテムを効率的に交換して探索を行う安全なOLTRアルゴリズムを提案します。探索に用いる未ランクアイテムは、クルバック・ライブラー上方信頼限界（KL-UCB）に基づいて楽観的に選定し、選ばれたアイテムを含むアイテムを安全に再ランク付けします。実験を通じて、提案されたアルゴリズムは安全性を損なうことなく、ベースラインに比べて長期的な後悔を改善することを示します。
        </label>
        <input type="checkbox" id="Panel213" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Bandit algorithms for online learning to rank (OLTR) problems often aim to maximize long-term revenue by utilizing user feedback. From a practical point of view, however, such algorithms have a high risk of hurting user experience due to their aggressive exploration. Thus, there has been a rising demand for safe exploration in recent years. One approach to safe exploration is to gradually enhance the quality of an original ranking that is already guaranteed acceptable quality. In this paper, we propose a safe OLTR algorithm that efficiently exchanges one of the items in the current ranking with an item outside the ranking (i.e., an unranked item) to perform exploration. We select an unranked item optimistically to explore based on Kullback-Leibler upper confidence bounds (KL-UCB) and safely re-rank the items including the selected one. Through experiments, we demonstrate that the proposed algorithm improves long-term regret from baselines without any safety violation.
        </div> </ul> <br>



        <label for="Panel214">
        <strong> Fairness for both Readers and Authors: Evaluating Summaries of User Generated Content </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Garima+Chhikara">Garima Chhikara</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kripabandhu+Ghosh">Kripabandhu Ghosh</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Saptarshi+Ghosh">Saptarshi Ghosh</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Abhijnan+Chakraborty">Abhijnan Chakraborty</a> (4) </u>  <br>
        1:  Indian Institute of Technology, 2:  Indian Institute of Science Education and Research Kolkata, 3:  Indian Institute of Technology Kharagpur, 4:  Indian Institute of Technology Delhi <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591986">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Fairness for both Readers and Authors: Evaluating Summaries of User Generated Content">Google Scholar</a></div>
        (214)
        <br>
        <b>概要:　</b> : テキスト内容のには、長文ドキュメントのから、ユーザー生成コンテンツ（例：ツイート、Facebook または Reddit の投稿）のに至るまで、多くの応用があります。伝統的に、の焦点は読者を最も満足させるを生成することにありました。本研究では、読者と著者の両方の満足度が重要であるとする二面的な問題として、ユーザー生成コンテンツのに取り組みます。3つの調査を通じて、ユーザー生成コンテンツにおいて、参照とアルゴリズム生成の類似性を測定する従来の評価アプローチでは、著者の満足度を把握できないことを示します。私たちは、CROSSEMという著者満足度に基づく評価指標を提案し、経験的に、現行の評価パラダイムを補完する可能性があることを示します。さらに、読者と著者の間での個別の公平性を考慮するために、満足度の不平等という考え方を提案します。我々の知る限りでは、これはユーザー生成コンテンツのための公正な評価フレームワークを開発する最初の試みであり、この分野における多くの将来の研究を誘発する可能性があります。
        </label>
        <input type="checkbox" id="Panel214" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Summarization of textual content has many applications, ranging from summarizing long documents to recent efforts towards summarizing user generated text (e.g., tweets, Facebook or Reddit posts). Traditionally, the focus of summarization has been to generate summaries which can best satisfy the readers. In this work, we look at summarization of user-generated content as a two-sided problem where satisfaction of both readers and authors is crucial. Through three surveys, we show that for user-generated content, traditional evaluation approach of measuring similarity between reference summaries and algorithmic summaries cannot capture author satisfaction. We propose an author satisfaction-based evaluation metric CROSSEM which, we show empirically, can potentially complement the current evaluation paradigm. We further propose the idea of inequality in satisfaction, to account for individual fairness amongst readers and authors. To our knowledge, this is the first attempt towards developing a fair summary evaluation framework for user generated content, and is likely to spawn lot of future research in this space.
        </div> </ul> <br>



        <label for="Panel215">
        <strong> Faster Dynamic Pruning via Reordering of Documents in Inverted Indexes </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Erman+Yafay">Erman Yafay</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ismail+Sengor+Altingovde">Ismail Sengor Altingovde</a> (1) </u>  <br>
        1:  Middle East Technical University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591987">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Faster Dynamic Pruning via Reordering of Documents in Inverted Indexes">Google Scholar</a></div>
        (215)
        <br>
        <b>概要:　</b> タイトル:広く使用されている動的プルーニングアルゴリズム（例えば、MaxScore、WAND、BMW）は、これまでにスコア付けされた文書の中でk番目に高いスコア（すなわちヒープ閾値）を追跡し、トップkの結果リストに入れない文書のスコア付けを避けます。明らかに、ヒープ閾値が最終値に早く収束するほど、スキップされる文書の数が増え、したがってプルーニングアルゴリズムの効率が向上します。本論文では、過去のクエリに対するアクセスカウントとランクに基づいて、倒立インデックス内の文書を再配置するアプローチをカスタマイズします。頻繁に検索される文書をポスティングリストの先頭に保存することで、クエリ処理中にヒープ閾値を早期に計算することを目指します。我々のアプローチは、全ての3つの動的プルーニングアルゴリズムに対し大幅なスピードアップ（最大1.33倍）をもたらし、文書の再配置に関する文献で使用されている2つの強力なベースラインを上回る成果を示しています。
        </label>
        <input type="checkbox" id="Panel215" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Widely used dynamic pruning algorithms (such as MaxScore, WAND and BMW) keep track of the k-th highest score (i.e., heap threshold) among the documents that are scored so far, to avoid scoring the documents that cannot get into the top-k result list. Obviously, the faster the heap threshold converges to its final value, the larger will be the number of skipped documents and hence, the efficiency gains of the pruning algorithms. In this paper, we tailor approaches that reorder the documents in the inverted index based on their access counts and ranks for previous queries. By storing such frequently retrieved documents at front of the postings lists, we aim to compute the heap threshold earlier during the query processing. Our approach yields substantial speedups (up to 1.33x) for all three dynamic pruning algorithms and outperforms two strong baselines that have been employed for document reordering in the literature.
        </div> </ul> <br>



        <label for="Panel216">
        <strong> FINAL: Factorized Interaction Layer for CTR Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jieming+Zhu">Jieming Zhu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qinglin+Jia">Qinglin Jia</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guohao+Cai">Guohao Cai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Quanyu+Dai">Quanyu Dai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingjie+Li">Jingjie Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenhua+Dong">Zhenhua Dong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruiming+Tang">Ruiming Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rui+Zhang">Rui Zhang</a> (2) </u>  <br>
        1:  Huawei Noah's Ark Lab, 2:  ruizhang.info <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591988">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=FINAL: Factorized Interaction Layer for CTR Prediction">Google Scholar</a></div>
        (216)
        <br>
        <b>概要:　</b> マルチレイヤーパーセプトロン（MLP）は、クリック率（CTR）予測の多くの深層モデルにおいて核心的な要素として機能します。しかし、標準的なMLPネットワークは乗法的特徴相互作用の学習に非効率であり、特徴相互作用の学習はCTR予測において重要なテーマとなっています。既存の特徴相互作用ネットワークは、MLPの学習補完に効果的ですが、単独で適用した場合にはMLPほどの性能を発揮しないことが多いです。したがって、MLPネットワークと統合することが必要であり、性能を向上させることが求められます。この状況から、MLPのバックボーンに代わる可能性のあるより良い選択肢を探る動機が生まれました。ファクター化マシンからインスパイアされ、本稿では、広く使用されている線形層を拡張し、二次の特徴相互作用を学習できるファクターライズドインタラクションレイヤー（FINAL）を提案します。MLPに似て、複数のFINALレイヤーを積み重ねてFINALブロックを構築することで、指数的に増加する特徴相互作用を実現します。我々は、特徴相互作用とMLPを単一のFINALブロックに統合し、その効果を実証的に示しています。さらに、2つのFINALブロックを組み合わせた二重ストリームCTRモデルのアンサンブルを探求し、オープンベンチマークデータセットで新しい最先端の結果を達成しました。FINALはビルディングブロックとして簡単に採用でき、Huaweiの複数のアプリケーションでビジネスメトリクスの向上を達成しました。我々のソースコードはMindSpore/modelsおよびFuxiCTR/model_zooで公開予定です。
        </label>
        <input type="checkbox" id="Panel216" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multi-layer perceptron (MLP) serves as a core component in many deep models for click-through rate (CTR) prediction. However, vanilla MLP networks are inefficient in learning multiplicative feature interactions, making feature interaction learning an essential topic for CTR prediction. Existing feature interaction networks are effective in complementing the learning of MLPs, but they often fall short of the performance of MLPs when applied alone. Thus, their integration with MLP networks is necessary to achieve improved performance. This situation motivates us to explore a better alternative to the MLP backbone that could potentially replace MLPs. Inspired by factorization machines, in this paper, we propose FINAL, a factorized interaction layer that extends the widely-used linear layer and is capable of learning 2nd-order feature interactions. Similar to MLPs, multiple FINAL layers can be stacked into a FINAL block, yielding feature interactions with an exponential degree growth. We unify feature interactions and MLPs into a single FINAL block and empirically show its effectiveness as a replacement for the MLP block. Furthermore, we explore the ensemble of two FINAL blocks as an enhanced two-stream CTR model, setting a new state-of-the-art on open benchmark datasets. FINAL can be easily adopted as a building block and has achieved business metric gains in multiple applications at Huawei. Our source code will be made available at MindSpore/models and FuxiCTR/model_zoo.
        </div> </ul> <br>



        <label for="Panel217">
        <strong> Forget Me Now: Fast and Exact Unlearning in Neighborhood-based Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sebastian+Schelter">Sebastian Schelter</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mozhdeh+Ariannezhad">Mozhdeh Ariannezhad</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (1) </u>  <br>
        1:  University of Amsterdam, 2:  AIRLab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591989">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Forget Me Now: Fast and Exact Unlearning in Neighborhood-based Recommendation">Google Scholar</a></div>
        (217)
        <br>
        <b>概要:　</b> 現代の検索および推薦システムは、ログに記録されたインタラクションデータを使用して最適化されています。このようなシステムのユーザーが、自分のデータの一部をこれらのシステムから削除できるようにするための社会的圧力が高まっています。本論文では、スパースで高次元のデータセットに対する近傍型推薦モデルから、ユーザーデータを「忘却」することに焦点を当てます。我々はこのようなモデルのためのカスタムトップkインデックスであるcabooseを提案し、ユーザーインタラクションの迅速かつ正確な削除を可能にします。実験的には、cabooseが競争力のあるインデックス構築時間を提供し、1秒未満の忘却を可能にし（100万人のユーザーおよび2億5600万件のインタラクションから構築された大規模インデックスでも）、さらに3つの最先端次バスケット推薦モデルに統合した場合、ユーザーが敏感なアイテムを効果的に削除するために予測を調整できることを確認しました。
        </label>
        <input type="checkbox" id="Panel217" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Modern search and recommendation systems are optimized using logged interaction data. There is increasing societal pressure to enable users of such systems to have some of their data deleted from those systems. This paper focuses on "unlearning" such user data from neighborhood-based recommendation models on sparse, high-dimensional datasets. We present caboose, a custom top-k index for such models, which enables fast and exact deletion of user interactions. We experimentally find that caboose provides competitive index building times, makes sub-second unlearning possible (even for a large index built from one million users and 256 million interactions), and, when integrated into three state-of-the-art next-basket recommendation models, allows users to effectively adjust their predictions to remove sensitive items.
        </div> </ul> <br>



        <label for="Panel218">
        <strong> Friend Ranking in Online Games via Pre-training Edge Transformers </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liang+Yao">Liang Yao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiazhen+Peng">Jiazhen Peng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shenggong+Ji">Shenggong Ji</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiang+Liu">Qiang Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongyun+Cai">Hongyun Cai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Feng+He">Feng He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xu+Cheng">Xu Cheng</a> (1) </u>  <br>
        1:  Tencent Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591990">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Friend Ranking in Online Games via Pre-training Edge Transformers">Google Scholar</a></div>
        (218)
        <br>
        <b>概要:　</b> フレンドリコールは、オンラインゲームにおけるデイリーアクティブユーザー（DAU）を増加させる重要な方法です。この問題は、適切な非アクティブ（失われた）フレンドのランキングリストを生成することにあります。従来のフレンドリコール手法は、フレンドの親密度といったルールや、失ったプレイヤーの復帰確率を予測するための分類器の訓練に焦点を当てていましたが、（アクティブな）プレイヤーの特徴情報や過去のフレンドリコールイベントを無視していました。本研究では、フレンドリコールをリンク予測問題として扱い、アクティブプレイヤーと失われたプレイヤーの特徴および過去のイベントを利用できるいくつかのリンク予測手法を探求します。さらに、新しいエッジトランスフォーマーモデルを提案し、このモデルをマスクドオートエンコーダーで事前訓練します。我々の手法は、3つのTencentゲームにおけるオフライン実験およびオンラインA/Bテストで最先端の結果を達成しました。
        </label>
        <input type="checkbox" id="Panel218" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Friend recall is an important way to improve Daily Active Users (DAU) in online games. The problem is to generate a proper inactive (lost) friend ranking list essentially. Traditional friend recall methods focus on rules like friend intimacy or training a classifier for predicting lost players' return probability, but ignore feature information of (active) players and historical friend recall events. In this work, we treat friend recall as a link prediction problem and explore several link prediction methods which can use features of both active and lost players, as well as historical events. Furthermore, we propose a novel Edge Transformer model and pre-train the model via masked auto-encoders. Our method achieves state-of-the-art results in the offline experiments and online A/B Tests of three Tencent games.
        </div> </ul> <br>



        <label for="Panel219">
        <strong> Gated Attention with Asymmetric Regularization for Transformer-based Continual Graph Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongxiang+Lin">Hongxiang Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruiqi+Jia">Ruiqi Jia</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoqing+Lyu">Xiaoqing Lyu</a> (1) </u>  <br>
        1:  Wangxuan Institute of Computer Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591991">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Gated Attention with Asymmetric Regularization for Transformer-based Continual Graph Learning">Google Scholar</a></div>
        (219)
        <br>
        <b>概要:　</b> 継続的グラフ学習（Continual Graph Learning, CGL）は、グラフニューラルネットワークにおけるトポロジカル特徴に起因するカタストロフィックフォーゲッティング問題（Topological-Feature-Induced Catastrophic Forgetting, TCF）を緩和することを目指し、情報検索の分野で重要な役割を果たします。TCFは主に、古いタスクのノード特徴の忘却および古いタスクと新しいタスクに共有されるトポロジカル特徴の忘却によって引き起こされます。既存のCGL手法は、異なるタスク間で共有されるトポロジカル特徴の忘却に十分な注意を払っていません。本論文では、トランスフォーマーベースのCGL手法（Trans-CGL）を提案し、トランスフォーマーの特性を最大限に活用してTCF問題を緩和します。具体的には、ノード特徴の忘却を軽減するために、パラメータの分離に基づくゲート付き注意メカニズムを導入し、古いタスクと新しいタスクを学習する際にモデルが相互に独立するようにします。さらに、異なるタスク間でトポロジカル情報を保存する共有パラメータの忘却に対処するために、非対称マスク注意正則化モジュールを提案し、共有トポロジカル情報を保持するように共有注意パラメータを制約します。比較実験により、この手法が現実世界の4つのデータセットで競争力のある性能を達成することが示されました。
        </label>
        <input type="checkbox" id="Panel219" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Continual graph learning (CGL) aims to mitigate the topological-feature-induced catastrophic forgetting problem (TCF) in graph neural networks, which plays an essential role in the field of information retrieval. The TCF is mainly caused by the forgetting of node features of old tasks and the forgetting of topological features shared by old and new tasks. Existing CGL methods do not pay enough attention to the forgetting of topological features shared between different tasks. In this paper, we propose a transformer-based CGL method (Trans-CGL), thereby taking full advantage of the transformer's properties to mitigate the TCF problem. Specifically, to alleviate forgetting of node features, we introduce a gated attention mechanism for Trans-CGL based on parameter isolation that allows the model to be independent of each other when learning old and new tasks. Furthermore, to address the forgetting of shared parameters that store topological information between different tasks, we propose an asymmetric mask attention regularization module to constrain the shared attention parameters ensuring that the shared topological information is preserved. Comparative experiments show that the method achieves competitive performance on four real-world datasets.
        </div> </ul> <br>



        <label for="Panel220">
        <strong> Generative Relevance Feedback with Large Language Models </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Iain+Mackie">Iain Mackie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shubham+Chatterjee">Shubham Chatterjee</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jeffrey+Dalton">Jeffrey Dalton</a> (1) </u>  <br>
        1:  University of Glasgow <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591992">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Generative Relevance Feedback with Large Language Models">Google Scholar</a></div>
        (220)
        <br>
        <b>概要:　</b> 現在のクエリ展開モデルは、擬似関連フィードバックを使用して初回検索の効果を向上させていますが、初期の結果が関連性がない場合には失敗します。検索結果から言語モデルを構築する代わりに、大規模言語モデルから生成された長文テキストを用いて確率的フィードバックモデルを構築するGenerative Relevance Feedback（GRF）を提案します。我々は、生成タスク（クエリ、エンティティ、事実、ニュース記事、文書、エッセイ）を変化させることで、テキスト生成の有効な方法を研究します。多様なクエリと文書集をカバーする文書検索ベンチマークでGRFを評価した結果、GRF手法が以前のPRF手法を大幅に上回ることが示されました。具体的には、RM3展開と比較してMAPで5-19%、NDCG@10で17-24%の改善を達成し、すべてのデータセットで最先端のリコールを実現しました。
        </label>
        <input type="checkbox" id="Panel220" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Current query expansion models use pseudo-relevance feedback to improve first-pass retrieval effectiveness; however, this fails when the initial results are not relevant. Instead of building a language model from retrieved results, we propose Generative Relevance Feedback (GRF) that builds probabilistic feedback models from long-form text generated from Large Language Models. We study the effective methods for generating text by varying the zero-shot generation subtasks: queries, entities, facts, news articles, documents, and essays. We evaluate GRF on document retrieval benchmarks covering a diverse set of queries and document collections, and the results show that GRF methods significantly outperform previous PRF methods. Specifically, we improve MAP between 5-19% and NDCG@10 17-24% compared to RM3 expansion, and achieve state-of-the-art recall across all datasets.
        </div> </ul> <br>



        <label for="Panel221">
        <strong> Gradient Coordination for Quantifying and Maximizing Knowledge Transference in Multi-Task Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuanhua+Yang">Xuanhua Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianxin+Zhao">Jianxin Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shaoguo+Liu">Shaoguo Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liang+Wang">Liang Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Zheng">Bo Zheng</a> (1) </u>  <br>
        1:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591993">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Gradient Coordination for Quantifying and Maximizing Knowledge Transference in Multi-Task Learning">Google Scholar</a></div>
        (221)
        <br>
        <b>概要:　</b> マルチタスク学習（MTL）はオンライン広告システムで広く適用されています。負の転送問題に対処するために、最近の最適化手法では勾配の方向や大きさの整合性が強調されています。先行研究が共有モジュールには一般的な知識と特定の知識が含まれていることを示しているため、勾配整合性を過度に強調するとタスク特有の知識が排除される可能性があります。本稿では、関連性駆動アプローチであるCoGradを提案し、協調勾配修正を通じて知識の転送を適応的に最大化します。具体的には、他のタスクの損失削減として転送を定量化し、それを最適化して補助勾配を導出します。この勾配を元のタスク勾配に組み込むことで、モデルはタスク間の転送を自動的に最大化し、個々の損失を最小化して一般的および特定の知識の調和を促進します。さらに、CoGradを計算効率の良いものにするためにヘッセ行列の効率的な近似を導入します。オフラインおよびオンライン実験の両方で、CoGradが従来の方法を大幅に上回ることが確認されました。
        </label>
        <input type="checkbox" id="Panel221" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multi-task learning (MTL) has been widely applied in online advertising systems. To address the negative transfer issue, recent optimization methods emphasized the gradient alignment of directions or magnitudes. Since prior studies have proven that the shared modules contain both general and specific knowledge, overemphasizing on gradient alignment may crowd out task-specific knowledge. In this paper, we propose a transference-driven approach CoGrad that adaptively maximizes knowledge transference via Coordinated Gradient modification. We explicitly quantify the transference as loss reduction from one task to another, and optimize it to derive an auxiliary gradient. By incorporating this gradient into original task gradients, the model automatically maximizes inter-task transfer and minimizes individual losses, leading to general and specific knowledge harmonization. Besides, we introduce an efficient approximation of the Hessian matrix, making CoGrad computationally efficient. Both offline and online experiments verify that CoGrad significantly outperforms previous methods.
        </div> </ul> <br>



        <label for="Panel222">
        <strong> Graph Collaborative Signals Denoising and Augmentation for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ziwei+Fan">Ziwei Fan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ke+Xu">Ke Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhang+Dong">Zhang Dong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Peng">Hao Peng</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiawei+Zhang">Jiawei Zhang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philip+S.+Yu">Philip S. Yu</a> (1) </u>  <br>
        1:  University of Illinois at Chicago, 2:  Amazon Ads, 3:  Beihang University, 4:  University of California <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591994">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Graph Collaborative Signals Denoising and Augmentation for Recommendation">Google Scholar</a></div>
        (222)
        <br>
        <b>概要:　</b> グラフ協調フィルタリング（GCF）は、推薦システムにおいて高次の協調シグナルを捉えるための人気技法です。しかし、ユーザーとアイテム間のインタラクションに基づく隣接行列は、インタラクションが多いユーザーやアイテムに対してノイズが多く、インタラクションが少ないユーザーやアイテムに対しては不十分となる可能性があります。さらに、この隣接行列はユーザー間およびアイテム間の相関を無視しているため、有益な隣人を取り込む範囲が制限されることがあります。本研究では、ユーザー間およびアイテム間の相関を組み込んだ新しいグラフ隣接行列と、全ユーザーのインタラクション数を均衡させる適切に設計されたユーザーアイテムインタラクション行列を提案します。これを実現するために、グラフベースの推薦手法を事前訓練してユーザーおよびアイテムの埋め込みを取得し、top-Kサンプリングによってユーザーアイテムインタラクション行列を強化します。また、対称性のあるユーザー間およびアイテム間の相関要素を隣接行列に追加します。実験結果は、改善された隣人と低密度のユーザーアイテムインタラクション行列が、グラフベースの推薦において大きな利益をもたらすことを示しています。さらに、ユーザー間およびアイテム間の相関を含めることで、インタラクションが多いユーザーと少ないユーザーの両方に対して推薦精度が向上することを示しています。
        </label>
        <input type="checkbox" id="Panel222" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Graph collaborative filtering (GCF) is a popular technique for capturing high-order collaborative signals in recommendation systems. However, GCF's bipartite adjacency matrix, which defines the neighbors being aggregated based on user-item interactions, can be noisy for users/items with abundant interactions and insufficient for users/items with scarce interactions. Additionally, the adjacency matrix ignores user-user and item-item correlations, which can limit the scope of beneficial neighbors being aggregated. In this work, we propose a new graph adjacency matrix that incorporates user-user and item-item correlations, as well as a properly designed user-item interaction matrix that balances the number of interactions across all users. To achieve this, we pre-train a graph-based recommendation method to obtain users/items embeddings, and then enhance the user-item interaction matrix via top-K sampling. We also augment the symmetric user-user and item-item correlation components to the adjacency matrix. Our experiments demonstrate that the enhanced user-item interaction matrix with improved neighbors and lower density leads to significant benefits in graph-based recommendation. Moreover, we show that the inclusion of user-user and item-item correlations can improve recommendations for users with both abundant and insufficient interactions.
        </div> </ul> <br>



        <label for="Panel223">
        <strong> Neighborhood-based Hard Negative Mining for Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lu+Fan">Lu Fan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiashu+Pu">Jiashu Pu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rongsheng+Zhang">Rongsheng Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao-Ming+Wu">Xiao-Ming Wu</a> (1) </u>  <br>
        1:  The Hong Kong Polytechnic University, 2:  Fuxi AI Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591995">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Neighborhood-based Hard Negative Mining for Sequential Recommendation">Google Scholar</a></div>
        (223)
        <br>
        <b>概要:　</b> ネガティブサンプリングは、成功した逐次推薦モデルのトレーニングにおいて重要な役割を果たします。ただランダムなネガティブサンプル選択を用いるだけでなく、訓練と性能を向上させるために情報量の多いネガティブサンプルを見つけるための様々な戦略が提案されています。しかし、これらのアプローチの多くは構造的な情報を活用していません。本研究では、訓練が進むにつれて、異なるグループのノードペアの類似度分布が近傍オーバーラップの度合いによって大きく変化することを観察しました。これにより、異なるグループに属するアイテムペアが異なるネガティブ関係を持つ可能性が示唆されます。この観察に基づき、ユーザー行動に隠れた構造情報を利用するための、近傍オーバーラップに基づいたグラフベースのネガティブサンプリングアプローチ（GNNO）を提案します。GNNOはまず、訓練シーケンスを使用してグローバルな重み付きアイテム遷移グラフを構築します。その後、ターゲットアイテムとのグラフ上のオーバーラップの度合いに基づいて、ハードネガティブサンプルを抽出します。さらに、GNNOは難易度の異なるサンプルを段階的に使うカリキュラム学習を採用し、簡単なものから難しいものへ進行させます。アマゾンの三つのベンチマークにおける広範な実験により、GNNOの有効性が証明され、様々な最先端モデルの性能を一貫して向上させ、既存のネガティブサンプリング戦略を上回ることを示しました。コードは https://github.com/floatSDSDS/GNNO で公開します。
        </label>
        <input type="checkbox" id="Panel223" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Negative sampling plays a crucial role in training successful sequential recommendation models. Instead of merely employing random negative sample selection, numerous strategies have been proposed to mine informative negative samples to enhance training and performance. However, few of these approaches utilize structural information. In this work, we observe that as training progresses, the distributions of node-pair similarities in different groups with varying degrees of neighborhood overlap change significantly, suggesting that item pairs in distinct groups may possess different negative relationships. Motivated by this observation, we propose a graph-based negative sampling approach based on neighborhood overlap (GNNO) to exploit structural information hidden in user behaviors for negative mining. GNNO first constructs a global weighted item transition graph using training sequences. Subsequently, it mines hard negative samples based on the degree of overlap with the target item on the graph. Furthermore, GNNO employs curriculum learning to control the hardness of negative samples, progressing from easy to difficult. Extensive experiments on three Amazon benchmarks demonstrate GNNO's effectiveness in consistently enhancing the performance of various state-of-the-art models and surpassing existing negative sampling strategies. The code will be released at https://github.com/floatSDSDS/GNNO.
        </div> </ul> <br>



        <label for="Panel224">
        <strong> Hierarchical Type Enhanced Negative Sampling for Knowledge Graph Embedding </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenzhou+Lin">Zhenzhou Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zishuo+Zhao">Zishuo Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingyou+Xie">Jingyou Xie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ying+Shen">Ying Shen</a> (1) </u>  <br>
        1:  Sun Yat-sen University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591996">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Hierarchical Type Enhanced Negative Sampling for Knowledge Graph Embedding">Google Scholar</a></div>
        (224)
        <br>
        <b>概要:　</b> 知識グラフ埋め込みは、エンティティと関係を低次元のセマンティック空間に投影することで知識をモデル化することを目的としています。知識グラフは通常、肯定的な事実のみを含むため、ほとんどの知識グラフ埋め込みの研究では負のサンプルを負のサンプリングによって構築しています。動的配布に基づくサンプリング手法により大きな進展が見られたものの、もっともらしい既存情報を組み込んだ負のサンプルを選択することには依然として多くの課題が存在します。タイプ制約手法に触発され、我々は階層型タイプ強化負のサンプリング（HTENS）を提案します。この手法は、階層型エンティティタイプ情報とエンティティ-関係の共起情報を活用して、負のサンプルのサンプリング確率分布を最適化します。リンク予測タスクで実施された実験により、HTENSの有効性が示されました。さらに、HTENSは汎用性において優れており、強化された負のサンプリングを伴ったスケーラブルなシステムに統合することが可能です。
        </label>
        <input type="checkbox" id="Panel224" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge graph embedding aims at modeling knowledge by projecting entities and relations into a low-dimensional semantic space. Most of the works on knowledge graph embedding construct negative samples by negative sampling as knowledge graphs typically only contain positive facts. Although substantial progress has been made by dynamic distribution based sampling methods, selecting plausible and prior information-engaged negative samples still poses many challenges. Inspired by type constraint methods, we propose Hierarchical Type Enhanced Negative Sampling (HTENS) which leverages hierarchical entity type information and entity-relation cooccurrence information to optimize the sampling probability distribution of negative samples. The experiments performed on the link prediction task demonstrate the effectiveness of HTENS. Additionally, HTENS shows its superiority in versatility and can be integrated into scalable systems with enhanced negative sampling.
        </div> </ul> <br>



        <label for="Panel225">
        <strong> HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiaying+Lu">Jiaying Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiaming+Shen">Jiaming Shen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Xiong">Bo Xiong</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenjing+Ma">Wenjing Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Steffen+Staab">Steffen Staab</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Carl+Yang">Carl Yang</a> (1) </u>  <br>
        1:  Emory University, 2:  Google Research, 3:  University of Stuttgart, 4:  University of Stuttgart; University of Southampton <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591997">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting">Google Scholar</a></div>
        (225)
        <br>
        <b>概要:　</b> 医療意思決定プロセスは、様々な情報源から構築された知識グラフを統一的なインデックスシステムを通じて融合することにより、包括的な生物医学知識ベースを活用して向上できます。このインデックスシステムはしばしば、生物医学用語を階層的に整理し、細かい粒度を持つ整合されたエンティティを提供します。生物医学知識融合（BKF）タスクにおける監督の不足という課題に対処するため、研究者たちは様々な教師なしの手法を提案しました。しかし、これらの手法は即席の語彙的および構造的マッチングアルゴリズムに大きく依存しており、生物医学エンティティや用語が伝える豊かなセマンティクスを捉え切れません。近年、ニューラル埋め込みモデルはセマンティクスに富んだタスクで効果的であることが証明されましたが、十分なラベル付きデータが必要で適切に訓練される必要があります。ラベルの少ないBKFとニューラル埋め込みモデルのギャップを埋めるために、階層指向のプロンプトを介して大規模言語モデルの少数ショット推論能力を引き出す、教師効率の良い知識融合フレームワークHiPromptを提案します。収集されたKG-Hi-BKFベンチマークデータセットでの実証結果は、HiPromptの有効性を示しています。
        </label>
        <input type="checkbox" id="Panel225" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Medical decision-making processes can be enhanced by comprehensive biomedical knowledge bases, which require fusing knowledge graphs constructed from different sources via a uniform index system. The index system often organizes biomedical terms in a hierarchy to provide the aligned entities with fine-grained granularity. To address the challenge of scarce supervision in the biomedical knowledge fusion (BKF) task, researchers have proposed various unsupervised methods. However, these methods heavily rely on ad-hoc lexical and structural matching algorithms, which fail to capture the rich semantics conveyed by biomedical entities and terms. Recently, neural embedding models have proved effective in semantic-rich tasks, but they rely on sufficient labeled data to be adequately trained. To bridge the gap between the scarce-labeled BKF and neural embedding models, we propose HiPrompt, a supervision-efficient knowledge fusion framework that elicits the few-shot reasoning ability of large language models through hierarchy-oriented prompts. Empirical results on the collected KG-Hi-BKF benchmark datasets demonstrate the effectiveness of HiPrompt.
        </div> </ul> <br>



        <label for="Panel226">
        <strong> How Significant Attributes are in the Community Detection of Attributed Multiplex Networks </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junwei+Cheng">Junwei Cheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaobo+He">Chaobo He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kunlin+Han">Kunlin Han</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenjie+Ma">Wenjie Ma</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yong+Tang">Yong Tang</a> (1) </u>  <br>
        1:  South China Normal University, 2:  University of Southern California, 3:  China Mobile Group Zhejiang Company Limited <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591998">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=How Significant Attributes are in the Community Detection of Attributed Multiplex Networks">Google Scholar</a></div>
        (226)
        <br>
        <b>概要:　</b> 既存の属性付きマルチプレックスネットワークのコミュニティ検出手法は、異なるトポロジーからの補完情報を活用することに重点を置いていますが、属性の役割にはほとんど注意を払っていません。しかし、実際の属性付きマルチプレックスネットワークは、一貫性とノード属性の均質性という2つの独自の特徴を持っていることを観察しています。したがって、本論文では、これらの属性の2つの特性に基づいた新しい手法、ACDMを提案し、属性付きマルチプレックスネットワーク上でコミュニティを検出します。具体的には、属性の一貫性を通じてノードの共通性表現を抽出します。属性の均質性とトポロジー情報の協力は、ノードの特異性表現を明らかにします。実世界の属性付きマルチプレックスネットワークでの包括的な実験結果は、ほとんどのネットワークで我々の手法が最先端の手法を上回っていることをよく検証しています。
        </label>
        <input type="checkbox" id="Panel226" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Existing community detection methods for attributed multiplex networks focus on exploiting the complementary information from different topologies, while they are paying little attention to the role of attributes. However, we observe that real attributed multiplex networks exhibit two unique features, namely, consistency and homogeneity of node attributes. Therefore, in this paper, we propose a novel method, called ACDM, which is based on these two characteristics of attributes, to detect communities on attributed multiplex networks. Specifically, we extract commonality representation of nodes through the consistency of attributes. The collaboration between the homogeneity of attributes and topology information reveals the particularity representation of nodes. The comprehensive experimental results on real attributed multiplex networks well validate that our method outperforms state-of-the-art methods in most networks.
        </div> </ul> <br>



        <label for="Panel227">
        <strong> HyperFormer: Learning Expressive Sparse Feature Representations via Hypergraph Transformer </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kaize+Ding">Kaize Ding</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Albert+Jiongqian+Liang">Albert Jiongqian Liang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bryan+Perozzi">Bryan Perozzi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ting+Chen">Ting Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruoxi+Wang">Ruoxi Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lichan+Hong">Lichan Hong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ed+H.+Chi">Ed H. Chi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huan+Liu">Huan Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Derek+Zhiyuan+Cheng">Derek Zhiyuan Cheng</a> (2) </u>  <br>
        1:  Google, 2:  Google <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591999">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=HyperFormer: Learning Expressive Sparse Feature Representations via Hypergraph Transformer">Google Scholar</a></div>
        (227)
        <br>
        <b>概要:　</b> 高次元でスパースな特徴を持つデータに対して表現学習を行うことは、情報検索において長年の課題です。最近のディープラーニング手法はこの問題を部分的に解決することができますが、多くのスパースな特徴、特に訓練データ中での出現頻度が低い末端特徴値を扱う際にしばしば失敗します。さらに、既存の手法は異なるインスタンス間の相関関係を明示的に活用してスパース特徴の表現学習を促進することができません。これに対処するために、本論文では、スパースな特徴を持つデータの表現学習問題に対してグラフ学習の視点から取り組みます。具体的には、各ノードがデータインスタンスを表し、各ハイパーエッジが異なる特徴値を示すハイパーグラフを用いてスパースな特徴をモデル化することを提案します。我々のHypergraph Transformer (HyperFormer)に基づいて構築されたハイパーグラフ上でメッセージを伝達することで、学習された特徴表現は異なるインスタンス間の相関関係だけでなく、特徴間の相関関係も捉えます。実験結果は、提案手法がスパースな特徴の表現学習を効果的に改善できることを示しています。
        </label>
        <input type="checkbox" id="Panel227" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Learning expressive representations for high-dimensional yet sparse features has been a longstanding problem in information retrieval. Though recent deep learning methods can partially solve the problem, they often fail to handle the numerous sparse features, particularly those tail feature values with infrequent occurrences in the training data. Worse still, existing methods cannot explicitly leverage the correlations among different instances to help further improve the representation learning on sparse features since such relational prior knowledge is not provided. To address these challenges, in this paper, we tackle the problem of representation learning on feature-sparse data from a graph learning perspective. Specifically, we propose to model the sparse features of different instances using hypergraphs where each node represents a data instance and each hyperedge denotes a distinct feature value. By passing messages on the constructed hypergraphs based on our Hypergraph Transformer (HyperFormer), the learned feature representations capture not only the correlations among different instances but also the correlations among features. Our experiments demonstrate that the proposed approach can effectively improve feature representation learning on sparse features.
        </div> </ul> <br>



        <label for="Panel228">
        <strong> Best Prompts for Text-to-Image Models and How to Find Them </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nikita+Pavlichenko">Nikita Pavlichenko</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dmitry+Ustalov">Dmitry Ustalov</a> (1) </u>  <br>
        1:  Toloka <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592000">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Best Prompts for Text-to-Image Models and How to Find Them">Google Scholar</a></div>
        (228)
        <br>
        <b>概要:　</b> テキスト誘導拡散モデルの進展により、プロのアーティストが作成したものに似た視覚的に魅力的な画像を生成することが可能になりました。これらのモデルの効果は、プロンプトとして知られるテキスト記述の構成と、それに付随するキーワードに依存します。美的評価を計算上で行うのは困難であるため、理想的なプロンプトの構成とキーワードの組み合わせを決定するには人間の入力が必要です。本研究では、遺伝的アルゴリズムを用いて最も効果的なプロンプトキーワードの組み合わせを発見するための、ヒューマンインザループ手法を提案します。我々のアプローチは、同じ記述から生成される画像の視覚的魅力がどのように向上するかを示しています。
        </label>
        <input type="checkbox" id="Panel228" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Advancements in text-guided diffusion models have allowed for the creation of visually appealing images similar to those created by professional artists. The effectiveness of these models depends on the composition of the textual description, known as the prompt, and its accompanying keywords. Evaluating aesthetics computationally is difficult, so human input is necessary to determine the ideal prompt formulation and keyword combination. In this study, we propose a human-in-the-loop method for discovering the most effective combination of prompt keywords using a genetic algorithm. Our approach demonstrates how this can lead to an improvement in the visual appeal of images generated from the same description.
        </div> </ul> <br>



        <label for="Panel229">
        <strong> Improved Vector Quantization For Dense Retrieval with Contrastive Distillation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=James+O'+Neill">James O' Neill</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sourav+Dutta">Sourav Dutta</a> (1) </u>  <br>
        1:  Huawei <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592001">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Improved Vector Quantization For Dense Retrieval with Contrastive Distillation">Google Scholar</a></div>
        (229)
        <br>
        <b>概要:　</b> 最近の研究は、蒸留がベクター量子化ベースのANN（人工ニューラルネットワーク）インデックスを生成し、逆ファイルインデックスとプロダクト量子化を学習するために使用できることを特定しました。クエリとドキュメントに対して固定された教師エンコーダーを使用する利点として、従来のコントラスト学習などの教師あり学習で必要とされるラベル判断の代わりに、教師が生成するスコアを利用できる点が挙げられます。しかし現在の研究では、量子化されたクエリ埋め込みとプロダクト量子化されたドキュメント埋め込みとの内積の教師エンコーダー出力を蒸留するにとどまっています。本研究では、コントラスト学習と蒸留の利点を組み合わせ、教師が出力するコントラストスコアを学生が学習するコントラスト蒸留を使用します。MSMARCOパッセージ検索とNQオープンクエスチョンアンサリングのデータセットにおける実験結果から、コントラスト蒸留はベクター量子化された高密度検索の最先端技術を上回ることが示されました。
        </label>
        <input type="checkbox" id="Panel229" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recent work has identified that distillation can be used to create vector quantization based ANN indexes by learning the inverted file index and product quantization. The argued advantage of using a fixed teacher encoder for queries and documents is that the scores produced by the teacher can be used instead of the label judgements that are required when using traditional supervised learning, such as contrastive learning. However, current work only distills the teacher encoder outputs of dot products between quantized query embedddings and product quantized document embeddings. Our work combines the benefits of contrastive learning and distillation by using contrastive distillation whereby the teacher outputs contrastive scores that the student learns from. Our experimental results on MSMARCO passage retrieval and NQ open question answering datasets show that contrastive distillation improves over current state of the art for vector quantized dense retrieval.
        </div> </ul> <br>



        <label for="Panel230">
        <strong> Improving Conversational Passage Re-ranking with View Ensemble </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jia-Huei+Ju">Jia-Huei Ju</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sheng-Chieh+Lin">Sheng-Chieh Lin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ming-Feng+Tsai">Ming-Feng Tsai</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chuan-Ju+Wang">Chuan-Ju Wang</a> (4) </u>  <br>
        1:  Research Center for Information Technology Innovation, 2:  University of Waterloo, 3:  National Chengchi University, 4:  Research Center for Information Technology Innovation <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592002">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Improving Conversational Passage Re-ranking with View Ensemble">Google Scholar</a></div>
        (230)
        <br>
        <b>概要:　</b> 本論文では、新たに開発された擬似ラベリング手法を用いた会話型パッセージ再ランカーであるConvRerankを紹介します。我々の提案するビューアンサンブル手法は、擬似ラベルデータの品質を向上させ、その結果ConvRerankのファインチューニングを改善します。ベンチマークデータセットでの実験評価により、会話型高密度リトリーバーとConvRerankをカスケード型で組み合わせることで、効果と効率のバランスが良いことが示されました。ベースライン手法と比較して、我々のカスケードパイプラインは低い遅延と高いトップランク効果を示します。さらに詳細な分析により、会話型検索の効果を改善する我々のアプローチの可能性が確認されました。
        </label>
        <input type="checkbox" id="Panel230" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This paper presents ConvRerank, a conversational passage re-ranker that employs a newly developed pseudo-labeling approach. Our proposed view-ensemble method enhances the quality of pseudo-labeled data, thus improving the fine-tuning of ConvRerank. Our experimental evaluation on benchmark datasets shows that combining ConvRerank with a conversational dense retriever in a cascaded manner achieves a good balance between effectiveness and efficiency. Compared to baseline methods, our cascaded pipeline demonstrates lower latency and higher top-ranking effectiveness. Furthermore, the in-depth analysis confirms the potential of our approach to improving the effectiveness of conversational search.
        </div> </ul> <br>



        <label for="Panel231">
        <strong> Improving News Recommendation via Bottlenecked Multi-task Pre-training </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiongfeng+Xiao">Xiongfeng Xiao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qing+Li">Qing Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Songlin+Liu">Songlin Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kun+Zhou">Kun Zhou</a> (3) </u>  <br>
        1:  Aegis Information Technology Ltd. Co., 2:  Peking University, 3:  Renmin University of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592003">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Improving News Recommendation via Bottlenecked Multi-task Pre-training">Google Scholar</a></div>
        (231)
        <br>
        <b>概要:　</b> 近年、オンラインニュース推薦サービスにおけるディープニューラルネットワークの発展が見られます。ニュース記事は主にテキストコンテンツで構成されているため、事前学習された言語モデル（PLMs）（例：BERT）がニュースを埋め込み表現にエンコードするための基盤として広く採用されています。これらの埋め込み表現はユーザ表現の生成や意味のマッチングに利用されます。しかし、既存のPLMsは主に大規模な一般コーパスで事前学習されており、ニュース記事内の豊富な情報を捉えるために特化されていません。そのため、生成されたニュースの埋め込みはニュースの内容を表現するのに十分な情報を持っていないか、ニュース間の関係を特徴付けるのに不十分である可能性があります。この課題を解決するために、我々はボトルネック付きマルチタスク事前学習アプローチを提案します。これは、情報ボトルネックエンコーダーデコーダーアーキテクチャを利用して、有用なセマンティック情報をニュース埋め込みに圧縮します。具体的には、ニュース埋め込みが自身のニュース内容、頻繁に共起する近傍ニュース、および類似トピックのニュースを復元することを強制する3つの事前学習タスクを設計しました。我々はMINDデータセットで実験を行い、我々のアプローチが競争力のある事前学習方法を上回ることを示しました。
        </label>
        <input type="checkbox" id="Panel231" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recent years have witnessed the boom of deep neural networks in online news recommendation service. As news articles mainly consist of textual content, pre-trained language models~(PLMs) (e.g. BERT) have been widely adopted as the backbone to encode them into news embeddings, which would be utilized to generate the user representations or perform the semantic matching. However, existing PLMs are mostly pre-trained on large-scale general corpus, and have not been specially adapted for capturing the rich information within news articles. Therefore, their produced news embeddings may be not informative enough to represent the news content or characterize the relations among news. To solve it, we propose a bottlenecked multi-task pre-training approach, which relies on an information-bottleneck encoder-decoder architecture to compress the useful semantic information into the news embedding. Concretely, we design three pre-training tasks, to enforce the news embedding to recover the news contents of itself, its frequently oc-occurring neighbours, and the news with similar topics. We conduct experiments on the MIND dataset and show that our approach can outperform competitive pre-training methods.
        </div> </ul> <br>



        <label for="Panel232">
        <strong> Inference at Scale: Significance Testing for Large Search and Recommendation Experiments </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ngozi+Ihemelandu">Ngozi Ihemelandu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michael+D.+Ekstrand">Michael D. Ekstrand</a> (1) </u>  <br>
        1:  Boise State University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592004">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Inference at Scale: Significance Testing for Large Search and Recommendation Experiments">Google Scholar</a></div>
        (232)
        <br>
        <b>概要:　</b> 数々の情報検索に関する研究が、システム間の比較に適した統計手法を評価するために行われてきました。しかし、これらの研究は通常100未満のトピックを扱うTRECスタイルの実験に焦点を当てています。大規模な検索および推薦システムの実験に関しては、同様の研究は存在せず、トピックやユーザーが数千単位で関与し、関連性評価がはるかにまばらであるため、従来のTREC実験の分析に対する推奨事項がこれらの設定に適用できるかは不明です。本論文では、大規模な検索および推薦評価データを用いて有意差検定の挙動を実証的に研究します。我々の結果は、Wilcoxon検定および符号検定が大きなサンプルサイズで従来の期待されるエラー率に比べて、bootstrap法、ランダム化検定およびt検定よりも有意に高いタイプ1エラー率を示すことを明らかにしました。また、小さなサンプルサイズではそれぞれの統計検定が異なる検出力を示しましたが、大きなサンプルサイズでは検出力の違いは見られませんでした。従って、大規模評価結果の分析には符号検定およびWilcoxon検定の使用を推奨しません。Top-N推薦および大規模検索評価データには、ほとんどの検定法が統計的に有意な結果を発見する確率が100%となることを示す結果が得られました。そのため、実用的または科学的な有意性を判断するためには効果量を使用すべきです。
        </label>
        <input type="checkbox" id="Panel232" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> A number of information retrieval studies have been done to assess which statistical techniques are appropriate for comparing systems. However, these studies are focused on TREC-style experiments, which typically have fewer than 100 topics. There is no similar line of work for large search and recommendation experiments; such studies typically have thousands of topics or users and much sparser relevance judgements, so it is not clear if recommendations for analyzing traditional TREC experiments apply to these settings. In this paper, we empirically study the behavior of significance tests with large search and recommendation evaluation data. Our results show that the Wilcoxon and Sign tests show significantly higher Type-1 error rates for large sample sizes than the bootstrap, randomization and t-tests, which were more consistent with the expected error rate. While the statistical tests displayed differences in their power for smaller sample sizes, they showed no difference in their power for large sample sizes. We recommend the sign and Wilcoxon tests should not be used to analyze large scale evaluation results. Our result demonstrate that with Top-N recommendation and large search evaluation data, most tests would have a 100% chance of finding statistically significant results. Therefore, the effect size should be used to determine practical or scientific significance.
        </div> </ul> <br>



        <label for="Panel233">
        <strong> LADER: Log-Augmented DEnse Retrieval for Biomedical Literature Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qiao+Jin">Qiao Jin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrew+Shin">Andrew Shin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiyong+Lu">Zhiyong Lu</a> (1) </u>  <br>
        1:  National Institutes of Health <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592005">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=LADER: Log-Augmented DEnse Retrieval for Biomedical Literature Search">Google Scholar</a></div>
        (233)
        <br>
        <b>概要:　</b> 類似した情報ニーズを持つクエリは、似たドキュメントクリックをする傾向があります。特に、クエリが短く、上位ドキュメントがほとんどのクリックを占めるバイオメディカル文献検索エンジンではこの傾向が顕著です。この観点に基づき、我々はバイオメディカル文献検索のための新しいアーキテクチャ、すなわちLog-Augmented DEnse Retrieval (LADER)を提案します。LADERは、密なリトリーバと同様のトレーニングクエリから取得したクリックログを組み合わせて動作するシンプルなプラグインモジュールです。具体的には、LADERは密なリトリーバを用いて、与えられたクエリに対する類似ドキュメントとクエリを見つけ出します。そして、LADERは入力クエリとの類似度に基づいて、類似クエリの関連（クリックされた）ドキュメントをスコアリングします。最終的なドキュメントスコアは、(1) 密なリトリーバによるドキュメント類似度スコアと (2) 類似クエリのクリックログから得られる集計ドキュメントスコアの平均値となります。<br><br>そのシンプルさにもかかわらず、LADERは新しくリリースされたバイオメディカル文献リトリーバルのベンチマークであるTripClickにおいて新たな最先端（SOTA）性能を達成しました。頻発するクエリ（HEADクエリ）では、LADERは相対的NDCG@10で39%（0.338対0.243）上回り、最良のリトリーバルモデルを大きく凌ぎました。また、頻度の低いクエリ（TORSOクエリ）においても、LADERは従来のSOTAを11%相対的NDCG@10（0.303対0.272）上回る性能を示しました。類似クエリが希少な稀なクエリ（TAILクエリ）でも、LADERは従来のSOTA手法と比較して優位性を保っています（NDCG@10: 0.310対0.295）。全てのクエリにおいて、LADERは追加のトレーニングを要さずに密なリトリーバの性能を24%-37%相対的NDCG@10で向上させることが可能であり、更なるログの追加によってさらなる性能向上が見込まれます。我々の回帰分析によれば、より頻発し、クエリ類似度エントロピーが高く、ドキュメント類似度エントロピーが低いクエリは、ログ拡張からより多くの恩恵を受ける傾向にあります。
        </label>
        <input type="checkbox" id="Panel233" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Queries with similar information needs tend to have similar document clicks, especially in biomedical literature search engines where queries are generally short and top documents account for most of the total clicks. Motivated by this, we present a novel architecture for biomedical literature search, namely Log-Augmented DEnse Retrieval (LADER), which is a simple plug-in module that augments a dense retriever with the click logs retrieved from similar training queries. Specifically, LADER finds both similar documents and queries to the given query by a dense retriever. Then, LADER scores relevant (clicked) documents of similar queries weighted by their similarity to the input query. The final document scores by LADER are the average of (1) the document similarity scores from the dense retriever and (2) the aggregated document scores from the click logs of similar queries. Despite its simplicity, LADER achieves new state-of-the-art (SOTA) performance on TripClick, a recently released benchmark for biomedical literature retrieval. On the frequent (HEAD) queries, LADER largely outperforms the best retrieval model by 39% relative NDCG@10 (0.338 v.s. 0.243). LADER also achieves better performance on the less frequent (TORSO) queries with 11% relative NDCG@10 improvement over the previous SOTA (0.303 v.s. 0.272). On the rare (TAIL) queries where similar queries are scarce, LADER still compares favorably to the previous SOTA method (NDCG@10: 0.310 v.s. 0.295). On all queries, LADER can improve the performance of a dense retriever by 24%-37% relative NDCG@10 while not requiring additional training, and further performance improvement is expected from more logs. Our regression analysis has shown that queries that are more frequent, have higher entropy of query similarity and lower entropy of document similarity, tend to benefit more from log augmentation.
        </div> </ul> <br>



        <label for="Panel234">
        <strong> LAPCA: Language-Agnostic Pretraining with Cross-Lingual Alignment </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dmitry+Abulkhanov">Dmitry Abulkhanov</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nikita+Sorokin">Nikita Sorokin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sergey+Nikolenko">Sergey Nikolenko</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Valentin+Malykh">Valentin Malykh</a> (1) </u>  <br>
        1:  Huawei Noah's Ark Lab, 2:  Ivannikov Institute for System Programming of the RAS & Steklov Institute of Mathematics of the RAS <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592006">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=LAPCA: Language-Agnostic Pretraining with Cross-Lingual Alignment">Google Scholar</a></div>
        (234)
        <br>
        <b>概要:　</b> データ収集およびマイニングは、クロスリンガル情報検索（CLIR）における重要なボトルネックです。従来の研究では機械翻訳や反復的な訓練を使用していましたが、我々はLAPCA（クロスリンガルアライメントによる言語非依存の事前学習）と呼ばれる新しいアプローチを提案します。XLM-RoBERTaとłexaに基づいてLAPCA-LMモデルを訓練し、質問応答や文の検索タスクにおいて、例えばXOR-TyDiやMr. TyDiデータセットで、クロスリンガル知識の転送を大幅に改善します。ゼロショットクロスリンガルシナリオにおいて、このモデルは多くのスーパー バイズドメソッドを上回り、MKQAで非常に優れた性能を発揮します。
        </label>
        <input type="checkbox" id="Panel234" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Data collection and mining is a crucial bottleneck for cross-lingual information retrieval (CLIR). While previous works used machine translation and iterative training, we present a novel approach to cross-lingual pretraining called LAPCA (language-agnostic pretraining with cross-lingual alignment). We train the LAPCA-LM model based on XLM-RoBERTa and łexa that significantly improves cross-lingual knowledge transfer for question answering and sentence retrieval on, e.g., XOR-TyDi and Mr. TyDi datasets, and in the zero-shot cross-lingual scenario performs on par with supervised methods, outperforming many of them on MKQA.
        </div> </ul> <br>



        <label for="Panel235">
        <strong> Learning from Crowds with Annotation Reliability </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhi+Cao">Zhi Cao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Enhong+Chen">Enhong Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ye+Huang">Ye Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuanghong+Shen">Shuanghong Shen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenya+Huang">Zhenya Huang</a> (1) </u>  <br>
        1:  Anhui Province Key Laboratory of Big Data Analysis and Application <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592007">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Learning from Crowds with Annotation Reliability">Google Scholar</a></div>
        (235)
        <br>
        <b>概要:　</b> クラウドソーシングは、教師あり学習モデルを訓練するためのアノテートされたデータを取得するための実用的なアプローチを提供します。しかしながら、クラウドアノテーターは異なる専門知識を持ち、常に高品質なアノテーションを保証できるわけではないため、クラウドから学習することは一般的に一部のノイズを導入することによる信頼性の低い結果の問題に悩まされます。これにより、満足のいくパフォーマンスを達成することが難しくなります。本研究では、クラウドからの学習を改善するためにアノテーションの信頼性を調査しました。具体的には、まずアノテーターとデータインスタンスを因子ベクトルに投影し、アノテーターの専門性とインスタンスの難易度との間の複雑な相互作用をモデル化してアノテーションの信頼性を予測しました。学習された信頼性は、クラウドソースされたデータの品質を直接評価するために使用できます。その後、トレーニング中のゴールドラベルとして機能する新しいアノテーション、すなわちソフトアノテーションを作成しました。アノテーターの異なる強みを認識するために、各アノテーターの混乱をエンドツーエンドでモデル化しました。実世界の3つのデータセットに基づく広範な実験結果は、我々の方法の有効性を示しています。
        </label>
        <input type="checkbox" id="Panel235" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Crowdsourcing provides a practical approach for obtaining annotated data to train supervised learning models. However, since the crowd annotators may have different expertise domain and cannot always guarantee the high-quality annotations, learning from crowds generally suffers from the problem of unreliable results of introducing some noises, which makes it hard to achieve satisfying performance. In this work, we investigate the reliability of annotations to improve learning from crowds. Specifically, we first project annotator and data instance to factor vectors and model the complex interaction between annotator expertise and instance difficulty to predict annotation reliability. The learned reliability can be used to evaluate the quality of crowdsourced data directly. Then, we construct a new annotation, namely soft annotation, which serves as the gold label during the training. To recognize the different strengths of annotators, we model each annotator's confusion in an end-to-end manner. Extensive experimental results on three real-world datasets demonstrate the effectiveness of our method.
        </div> </ul> <br>



        <label for="Panel236">
        <strong> Learning Through Interpolative Augmentation of Dynamic Curvature Spaces </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Parth+Chhabra">Parth Chhabra</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Atula+Tejaswi+Neerkaje">Atula Tejaswi Neerkaje</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shivam+Agarwal">Shivam Agarwal</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ramit+Sawhney">Ramit Sawhney</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Megh+Thakkar">Megh Thakkar</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Preslav+Nakov">Preslav Nakov</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sudheer+Chava">Sudheer Chava</a> (6) </u>  <br>
        1:  Indraprastha Institute of Information Technology, 2:  Manipal Institute of Technology, 3:  University of Illinois at Urbana-Champaign, 4:  Mohamed bin Zayed University of Artificial Intelligence, 5:  BITS, 6:  Georgia Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592008">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Learning Through Interpolative Augmentation of Dynamic Curvature Spaces">Google Scholar</a></div>
        (236)
        <br>
        <b>概要:　</b> Mixupは、ランダムな例を補間することで一般化を改善する効率的なデータ増強技術です。ユークリッド空間や双曲空間におけるMixupの様々なアプローチが開発されてきましたが、これらは例の本質的な特性を十分に活用していません。すなわち、データセット全体に基づいて手動で幾何構造（ユークリッドまたは双曲）を設定しており、各例に異なる幾何構造が必要な場合もあるため、これは最適ではないかもしれません。そこで我々はDynaMixを提案します。DynaMixは、例ごとに適切な幾何構造を自動的に選択し、複数の幾何構造間でMixupを実行することで、トレーニングダイナミクスと一般化を改善するフレームワークです。画像およびテキストモダリティにおける広範な実験を通じて、DynaMixが6つの下流アプリケーションで最先端の手法を上回ることを示しました。また、DynaMixは低リソースおよび半教師あり設定においてより有用であることが分かりました。これは、幾何構造に対する確率的な視点を提供するためと考えられます。
        </label>
        <input type="checkbox" id="Panel236" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Mixup is an efficient data augmentation technique, which improves generalization by interpolating random examples. While numerous approaches have been developed for Mixup in the Euclidean and in the hyperbolic space, they do not fully use the intrinsic properties of the examples, i.e., they manually set the geometry (Euclidean or hyperbolic) based on the overall dataset, which may be sub-optimal since each example may require a different geometry. We propose DynaMix, a framework that automatically selects an example-specific geometry and performs Mixup between the different geometries to improve training dynamics and generalization. Through extensive experiments in image and text modalities we show that DynaMix outperforms state-of-the-art methods over six downstream applications. We find that DynaMix is more useful in low-resource and semi-supervised settings likely because it displays a probabilistic view of the geometry.
        </div> </ul> <br>



        <label for="Panel237">
        <strong> Learning to Ask Clarification Questions with Spatial Reasoning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Deng">Yang Deng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuaiyi+Li">Shuaiyi Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wai+Lam">Wai Lam</a> (1) </u>  <br>
        1:  The Chinese University of Hong Kong <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592009">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Learning to Ask Clarification Questions with Spatial Reasoning">Google Scholar</a></div>
        (237)
        <br>
        <b>概要:　</b> 明確化の質問をすることは、多くの会話型システムにおいて重要な要素となっており、自然言語の質問を通じて曖昧さや不確かさを効果的に解決することができます。空間情報に基づく対話の広範な応用にもかかわらず、空間的推論能力を持つ明確化の質問を学習することは未だ十分に研究されていない領域です。本研究では、この問題に対処するために「SpatialCQ」と名付けられた新しい方法を提案します。具体的には、まずテキスト記述で空間状態をエンコードすることにより、テキスト情報と空間情報の表現空間を整列させます。次に、多関係グラフを構築し、関係グラフ注意ネットワークを使用して空間関係を捕捉し、空間推論を可能にします。最後に、統一エンコーダーを使用して、マルチモーダル情報を融合し、明確化の質問を行います。最新のIGLUデータセットを用いた実験結果は、提案手法が既存のアプローチを上回ることを示しています。
        </label>
        <input type="checkbox" id="Panel237" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Asking clarifying questions has become a key element of various conversational systems, allowing for an effective resolution of ambiguity and uncertainty through natural language questions. Despite the extensive applications of spatial information grounded dialogues, it remains an understudied area on learning to ask clarification questions with the capability of spatial reasoning. In this work, we propose a novel method, named SpatialCQ, for this problem. Specifically, we first align the representation space between textual and spatial information by encoding spatial states with textual descriptions. Then a multi-relational graph is constructed to capture the spatial relations and enable spatial reasoning with relational graph attention networks. Finally, a unified encoder is adopted to fuse the multimodal information for asking clarification questions. Experimental results on the latest IGLU dataset show the superiority of the proposed method over existing approaches.
        </div> </ul> <br>



        <label for="Panel238">
        <strong> Learning to Ask Questions for Zero-shot Dialogue State Tracking </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Diogo+Tavares">Diogo Tavares</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=David+Semedo">David Semedo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alexander+Rudnicky">Alexander Rudnicky</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Joao+Magalhaes">Joao Magalhaes</a> (1) </u>  <br>
        1:  NOVA University of Lisbon, 2:  Carnegie Mellon University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592010">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Learning to Ask Questions for Zero-shot Dialogue State Tracking">Google Scholar</a></div>
        (238)
        <br>
        <b>概要:　</b> 本論文では、ゼロショットダイアログステートトラッキング（DST）を「質問生成学習」フレームワークとして実現する方法を提案します。このフレームワークは、最適な質問生成（QG）戦略をインドメインの質問応答（QA）手法と組み合わせることにより、人間の介入なしでダイアログからスロット値を抽出することを学習します。インドメインデータを用いた新しい自己教師ありQAプレトレーニングステップは、スロットフィリングアノテーションを必要とせずに構造を学習するために不可欠です。さらに、QG手法はダイアログで使用される同じ文法的な人称と一致させる必要があることを示します。MultiWOZ 2.1データセットに対する実証評価により、堅牢なQAモデルと併用した場合、我々のアプローチはゼロショットクロスドメイン適応の困難なタスクにおいて、同程度のドメイン知識がデータ作成時に利用される場合、既存のゼロショット手法を上回ることが証明されました。最後に、使用される質問の種類の影響を分析し、アルゴリズムアプローチがテンプレートベースの質問生成を上回ることを示します。
        </label>
        <input type="checkbox" id="Panel238" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> We present a method for performing zero-shot Dialogue State Tracking (DST) by casting the task as a learning-to-ask-questions framework. The framework learns to pair the best question generation (QG) strategy with in-domain question answering (QA) methods to extract slot values from a dialogue without any human intervention. A novel self-supervised QA pretraining step using in-domain data is essential to learn the structure without requiring any slot-filling annotations. Moreover, we show that QG methods need to be aligned with the same grammatical person used in the dialogue. Empirical evaluation on the MultiWOZ 2.1 dataset demonstrates that our approach, when used alongside robust QA models, outperforms existing zero-shot methods in the challenging task of zero-shot cross domain adaptation-given a comparable amount of domain knowledge during data creation. Finally, we analyze the impact of the types of questions used, and demonstrate that the algorithmic approach outperforms template-based question generation.
        </div> </ul> <br>



        <label for="Panel239">
        <strong> Limitations of Open-Domain Question Answering Benchmarks for Document-level Reasoning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ehsan+Kamalloo">Ehsan Kamalloo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Charles+L.+A.+Clarke">Charles L. A. Clarke</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Davood+Rafiei">Davood Rafiei</a> (2) </u>  <br>
        1:  University of Waterloo, 2:  University of Alberta <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592011">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Limitations of Open-Domain Question Answering Benchmarks for Document-level Reasoning">Google Scholar</a></div>
        (239)
        <br>
        <b>概要:　</b> 最近の多くのQAモデルは、全体の文章ではなく、パッセージからの回答の抽出を行っています。これは、ディープラーニングモデルが限られたコンテキストサイズに対して制約があるためです。しかし、このアプローチでは、質問に答える上で重要な文書レベルの手がかりを無視してしまいます。本論文では、文書レベルの視点から3つのオープンドメインQAベンチマークをレビューし、それらがパッセージレベルの情報に偏っていることを明らかにしました。評価対象とされた17,000の質問のうち、82件は文書レベルの推論を必要とし、パッセージベースのモデルでは回答できませんでした。これらの質問に対して、文書レベルのリトリーバル（BM25）は、密であれ疎であれパッセージレベルのリトリーバルの両方を上回る結果を示しました。このことは、オープンドメインQAにおけるモデルの文書理解能力の評価の必要性を強調しています。文書理解は、しばしば見落とされがちな課題となっています。
        </label>
        <input type="checkbox" id="Panel239" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Many recent QA models retrieve answers from passages, rather than whole documents, due to the limitations of deep learning models with limited context size. However, this approach ignores important document-level cues that can be crucial in answering questions. This paper reviews three open-domain QA benchmarks from a document-level perspective and finds that they are biased towards passage-level information. Out of 17,000 assessed questions, 82 were identified as requiring document-level reasoning and could not be answered by passage-based models. Document-level retrieval (BM25) outperformed both dense and sparse passage-level retrieval on these questions, highlighting the need for more evaluation of models' ability to understand documents, an often-overlooked challenge in open-domain QA.
        </div> </ul> <br>



        <label for="Panel240">
        <strong> LogicRec: Recommendation with Users' Logical Requirements </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenwei+Tang">Zhenwei Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Griffin+Floto">Griffin Floto</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Armin+Toroghi">Armin Toroghi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shichao+Pei">Shichao Pei</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangliang+Zhang">Xiangliang Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Scott+Sanner">Scott Sanner</a> (1) </u>  <br>
        1:  University of Toronto, 2:  University of Toronto <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592012">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=LogicRec: Recommendation with Users' Logical Requirements">Google Scholar</a></div>
        (240)
        <br>
        <b>概要:　</b> 摘要<br>ユーザーはしばしば論理的操作を伴う高い個別化要求の推奨を求めます。例えば、2つの要求の交差部分などです。このような要求は、ナチュラルに知識グラフ（KGs）上の構造化された論理クエリを形成します。現時点では、既存のレコメンダシステムはユーザーの複雑な論理的要求を処理する能力が不足しています。本研究では、ユーザーの論理的要求に基づく推奨（LogicRec）の問題を定式化し、LogicRecのベンチマークデータセットを構築します。さらに、論理的要求の検索およびユーザープリファレンスの検索に基づくLogicRecの初期解決策を提案し、2つのチャレンジに直面します。第一に、KGsは本質的に不完全です。したがって、常に欠落している真実の事実が存在し、論理的要求への回答を完全にはKGsから見つけることができません。この場合、論理クエリの回答に基づくアイテム選択は適用できません。したがって、論理クエリ埋め込み（LQE）を使用して欠落している事実を総合的に推論し、論理的要求に基づいてアイテムを検索します。第二に、回答セットが十分に活用されていません。既存のLQEメソッドはクエリと回答のペアのみを処理できますが、我々の場合では、クエリは交差したユーザープリファレンスと論理的要求となります。しかし、論理的要求とユーザープリファレンスは異なる回答セットを持ち、要求-アイテムおよびプリファレンス-アイテムペアを提供することで要求とプリファレンスに関する豊富な知識を提供します。従って、これらの回答セットを集中的に活用するために、マルチタスク知識共有メカニズムを設計します。広範な実験結果は、LogicRecタスクの重要性と提案手法の有効性を示しています。
        </label>
        <input type="checkbox" id="Panel240" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Users may demand recommendations with highly personalized requirements involving logical operations, e.g., the intersection of two requirements, where such requirements naturally form structured logical queries on knowledge graphs (KGs). To date, existing recommender systems lack the capability to tackle users' complex logical requirements. In this work, we formulate the problem of recommendation with users' logical requirements (LogicRec) and construct benchmark datasets for LogicRec. Furthermore, we propose an initial solution for LogicRec based on logical requirement retrieval and user preference retrieval, where we face two challenges. First, KGs are incomplete in nature. Therefore, there are always missing true facts, which entails that the answers to logical requirements can not be completely found in KGs. In this case, item selection based on the answers to logical queries is not applicable. We thus resort to logical query embedding (LQE) to jointly infer missing facts and retrieve items based on logical requirements. Second, answer sets are under-exploited. Existing LQE methods can only deal with query-answer pairs, where queries in our case are the intersected user preferences and logical requirements. However, the logical requirements and user preferences have different answer sets, offering us richer knowledge about the requirements and preferences by providing requirement-item and preference-item pairs. Thus, we design a multi-task knowledge-sharing mechanism to exploit these answer sets collectively. Extensive experimental results demonstrate the significance of the LogicRec task and the effectiveness of our proposed method.
        </div> </ul> <br>



        <label for="Panel241">
        <strong> Look Ahead: Improving the Accuracy of Time-Series Forecasting by Previewing Future Time Features </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Seonmin+Kim">Seonmin Kim</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dong-Kyu+Chae">Dong-Kyu Chae</a> (1) </u>  <br>
        1:  Hanyang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592013">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Look Ahead: Improving the Accuracy of Time-Series Forecasting by Previewing Future Time Features">Google Scholar</a></div>
        (241)
        <br>
        <b>概要:　</b> 時系列予測はさまざまな現実世界の分野で活発に研究され、採用されています。最近、この分野では2つの主要な研究主流が存在します。1つは、Informer、Autoformer、ReformerのようなTransformerベースのアーキテクチャを構築すること、もう1つは、TS2VecやCoSTのような対比学習に基づいた時系列表現学習フレームワークを開発することです。この両方の取り組みにより、時系列予測の性能は大幅に向上しました。本論文では、予測性能をさらに向上させるための新しい方向性を模索します。この方向性は上述の主流とは直交するものであり、モデル非依存的なスキームです。文献であまり注目されていないタイムスタンプ埋め込みに焦点を当てます。我々のアイデアはシンプルで効果的です。与えられた現在のタイムスタンプに基づいて、その近未来のタイムスタンプの埋め込みを予測し、その予測された埋め込みを時系列（値）の予測タスクで利用します。このような未来の時間情報を予測時にプレビューできれば、どの時系列予測モデルにとっても有用な追加情報として利用できると考えています。我々の実験結果は、我々の方法が最近のTransformerベースのモデルおよび時系列表現学習フレームワークの精度を一貫して大幅に向上させることを確認しました。我々のコードは以下のURLで利用可能です：https://github.com/sunsunmin/Look_Ahead
        </label>
        <input type="checkbox" id="Panel241" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Time-series forecasting has been actively studied and adopted in various real-world domains. Recently there have been two research mainstreams in this area: building Transformer-based architectures such as Informer, Autoformer and Reformer, and developing time-series representation learning frameworks based on contrastive learning such as TS2Vec and CoST. Both efforts have greatly improved the performance of time series forecasting. In this paper, we investigate a novel direction towards improving the forecasting performance even more, which is orthogonal to the aforementioned mainstreams as a model-agnostic scheme. We focus on time stamp embeddings that has been less-focused in the literature. Our idea is simple-yet-effective: based on given current time stamp, we predict embeddings of its near future time stamp and utilize the predicted embeddings in the time-series (value) forecasting task. We believe that if such future time information can be previewed at the time of prediction, they can be utilized by any time-series forecasting models as useful additional information. Our experimental results confirmed that our method consistently and significantly improves the accuracy of the recent Transformer-based models and time-series representation learning frameworks. Our code is available at: https://github.com/sunsunmin/Look_Ahead
        </div> </ul> <br>



        <label for="Panel242">
        <strong> LOVF: Layered Organic View Fusion for Click-through Rate Prediction in Online Advertising </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lingwei+Kong">Lingwei Kong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lu+Wang">Lu Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiwei+Zhao">Xiwei Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junsheng+Jin">Junsheng Jin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhangang+Lin">Zhangang Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinghe+Hu">Jinghe Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingping+Shao">Jingping Shao</a> (1) </u>  <br>
        1:  JD.com <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592014">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=LOVF: Layered Organic View Fusion for Click-through Rate Prediction in Online Advertising">Google Scholar</a></div>
        (242)
        <br>
        <b>概要:　</b> eコマースプラットフォームでは、有機的な推奨と広告推奨が通常共存しています。本研究では、有機的な推奨から得られるデータを活用し、広告シナリオにおけるクリック率予測を強化する問題をマルチビューレーニングの視点から検討します。新しい手法として、LOVF（Layered Organic View Fusion）を提案します。LOVFはマルチビューフュージョンのメカニズムを実装しており、各広告インスタンスに対して、有機的な推奨ビューから深層表現を層ごとに導出し、これらの深層表現を広告ビューの対応するバニラ表現に融合します。さまざまなバックボーンを用いた広範な実験により、LOVFが新しい現実のプロダクションデータセットで一般性、効果性、効率性を兼ね備えていることが示されました。このデータセットは、有機推奨と広告シナリオの両方からのデータを網羅しています。特筆すべきは、LOVFが世界最大級のeコマースプラットフォームであるJD.comの広告レコメンダーシステムに成功裏に展開され、オンラインA/Bテストにおいて広告クリック数と収益の顕著な向上を達成したことです。我々のコードとデータセットは、さらなる研究を促進するためにhttps://github.com/adsturing/lovfで公開されています。
        </label>
        <input type="checkbox" id="Panel242" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Organic recommendation and advertising recommendation usually coexist on e-commerce platforms. In this paper, we study the problem of utilizing data from organic recommendation to reinforce click-through rate prediction in advertising scenarios from a multi-view learning perspective. We propose a novel method, termed LOVF (Layered Organic View Fusion). LOVF implements a multi-view fusion mechanism - for each advertising instance, LOVF derives deep representations layer-by-layer from the organic recommendation view and these deep representations are then fused into the corresponding vanilla representations of the advertising view. Extensive experiments across a variety of backbones demonstrate LOVF's generality, effectiveness and efficiency on a new real-world production dataset. The dataset encompasses data from both the organic recommendation and advertising scenarios. Notably, LOVF has been successfully deployed in the advertising recommender system of JD.com, which is one of the world's largest e-commerce platforms; online A/B testing shows that LOVF achieves impressive improvement on advertising clicks and revenue. Our code and dataset are available at https://github.com/adsturing/lovf for facilitating further research.
        </div> </ul> <br>



        <label for="Panel243">
        <strong> MA-MRC: A Multi-answer Machine Reading Comprehension Dataset </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiang+Yue">Zhiang Yue</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingping+Liu">Jingping Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cong+Zhang">Cong Zhang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chao+Wang">Chao Wang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haiyun+Jiang">Haiyun Jiang</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Zhang">Yue Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xianyang+Tian">Xianyang Tian</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhedong+Cen">Zhedong Cen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanghua+Xiao">Yanghua Xiao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tong+Ruan">Tong Ruan</a> (2) </u>  <br>
        1:  Fudan University, 2:  East China University of Science and Technology, 3:  AECC Sichuan Gas Turbine Establishment, 4:  Shanghai University, 5:  Tencent AI Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592015">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MA-MRC: A Multi-answer Machine Reading Comprehension Dataset">Google Scholar</a></div>
        (243)
        <br>
        <b>概要:　</b> マシンリーディングコンプリヘンション（MRC）は、多くの質問応答アプリケーションにとって重要な課題です。しかし、既存のMRCデータセットは主に単一の解答を含むデータに焦点を当てており、実世界で一般的な複数の解答を見落としています。本論文では、単一解答と複数解答の両方を含むMRCデータセットの構築を目的としています。この目的を達成するために、新しいパイプライン法を設計しました：データ収集、データクリーニング、質問生成、およびテストセットのアノテーション。これらの手順に基づき、129Kの質問-回答-コンテクストサンプルを含む高品質な複数解答MRCデータセット（MA-MRC）を構築しました。いくつかのベースラインを実装し、MA-MRC上で広範な実験を行いました。実験結果によると、MA-MRCは挑戦的なデータセットであり、複数解答MRCタスクの今後の研究を促進する可能性があります。
        </label>
        <input type="checkbox" id="Panel243" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Machine reading comprehension (MRC) is an essential task for many question-answering applications. However, existing MRC datasets mainly focus on data with single answer and overlook multiple answers, which are common in the real world. In this paper, we aim to construct an MRC dataset with both data of single answer and multiple answers. To achieve this purpose, we design a novel pipeline method: data collection, data cleaning, question generation and test set annotation. Based on these procedures, we construct a high-quality multi-answer MRC dataset (MA-MRC) with 129K question-answer-context samples. We implement a sequence of baselines and carry out extensive experiments on MA-MRC. According to the experimental results, MA-MRC is a challenging dataset, which can facilitate the future research on the multi-answer MRC task.
        </div> </ul> <br>



        <label for="Panel244">
        <strong> Matching Point of Interests and Travel Blog with Multi-view Information Fusion </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuokai+Li">Shuokai Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingbo+Zhou">Jingbo Zhou</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jizhou+Huang">Jizhou Huang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Chen">Hao Chen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuzhen+Zhuang">Fuzhen Zhuang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qing+He">Qing He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dejing+Dou">Dejing Dou</a> (5) </u>  <br>
        1:  Institute of Computing Technology, 2:  Baidu Research, 3:  Baidu Inc., 4:  Beihang University, 5:  BCG X <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592016">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Matching Point of Interests and Travel Blog with Multi-view Information Fusion">Google Scholar</a></div>
        (244)
        <br>
        <b>概要:　</b> 近年、ユーザー生成型のPOI（興味地点）中心の旅行ブログが爆発的に増加し、人々にとってPOIの包括的理解が可能となっています。しかし、POI中心の旅行ブログの質を評価し、ランキングすることは、対象POIに関する専門知識や実際の旅行経験がなければ容易ではありません。我々は、オンライン地図サービス上での対象POIに関連するユーザー検索行動が、旅行ブログに出現するPOIの合理性を部分的に証明し、旅行ブログのランキングに寄与するという洞察を得ました。そこで、本論文では、「多視点情報によるPOIと旅行ブログのマッチング」（MOTIF）という新たなエンドツーエンドのフレームワークを提案します。具体的には、まず2つのPOIグラフを多視点情報として構築します：(1) オンライン地図サービス上のユーザー行動を反映した検索レベルのPOIグラフ、(2) 旅行ブログにおけるPOIの共起頻度を示す文書レベルのPOIグラフです。次に、これら2つのグラフの内在的な相関をより良くモデル化するために、相互情報最大化を採用して検索レベルと文書レベルの意味空間を整合させます。さらに、POI-文書関連性スコアリングのためにペアワイズランキング損失を活用しました。2つの実世界データセットを用いた広範な実験により、我々の手法の優位性が実証されました。
        </label>
        <input type="checkbox" id="Panel244" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The past few years have witnessed an explosive growth of user-generated POI-centric travel blogs, which can provide a comprehensive understanding of a POI for people. However, evaluating the quality of the POI-centric travel blogs and ranking the blogs is not a simple task without domain knowledge or actual travel experience on the target POI. Nevertheless, our insight is that the user search behavior related to the target POI on the online map service can partly valid the rationality of the POIs appearing in the travel blogs, which helps for travel blogs ranking. To this end, in this paper, we propose a novel end-to-end framework for travel blogs ranking, coined Matching POI and Travel Blogs with Multi-view InFormation (MOTIF). Concretely, we first construct two POI graphs as multi-view information: (1) the search-level POI graph which reflects the user behaviors on the online map service; and (2) the document-level POI graph which shows the POI co-occurrence frequency in travel blogs. Then, to better model the intrinsic correlation of the two graphs, we adopt Mutual Information Maximization to align the search-level and document-level semantic spaces. Moreover, we leverage a pair-wise ranking loss for POI-document relevance scoring. Extensive experiments on two real-world datasets demonstrate the superiority of our method.
        </div> </ul> <br>



        <label for="Panel245">
        <strong> MaxSimE: Explaining Transformer-based Semantic Similarity via Contextualized Best Matching Token Pairs </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Eduardo+Brito">Eduardo Brito</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Henri+Iser">Henri Iser</a> (1) </u>  <br>
        1:  Fraunhofer Institute for Intelligent Analysis and Information Systems IAIS & Lamarr Institute for Machine Learning and Artificial Intelligence <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592017">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MaxSimE: Explaining Transformer-based Semantic Similarity via Contextualized Best Matching Token Pairs">Google Scholar</a></div>
        (245)
        <br>
        <b>概要:　</b> 現在のセマンティック検索アプローチは、BERTのようなブラックボックス言語モデルに依存しており、その解釈可能性と透明性が制限されています。本研究では、セマンティック類似性を測定するために言語モデルに適用される説明方法である「MaxSimE」を提案します。我々のアプローチは、設計段階から説明可能なColBERTアーキテクチャにインスパイアされており、コンテキスト化されたクエリトークンを検索された文書から最も類似したトークンとコサイン類似度に基づいてマッチングさせることで説明を生成します。既存の事後説明方法とは異なり、これらはモデルに対する忠実性が欠けている可能性があり、そのため重要な状況で信頼性のある説明を提供できないことがあります。対照的に、我々はMaxSimEが特定の条件下で忠実な説明を生成できることを示し、LoTTeベンチマークからランク付けされた文書に対するセマンティック検索結果の解釈可能性をどのように改善するかを示します。これにより、信頼できる情報検索の可能性が示されています。
        </label>
        <input type="checkbox" id="Panel245" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Current semantic search approaches rely on black-box language models, such as BERT, which limit their interpretability and transparency. In this work, we propose MaxSimE, an explanation method for language models applied to measure semantic similarity. Our approach is inspired by the explainable-by-design ColBERT architecture and generates explanations by matching contextualized query tokens to the most similar tokens from the retrieved document according to the cosine similarity of their embeddings. Unlike existing post-hoc explanation methods, which may lack fidelity to the model and thus fail to provide trustworthy explanations in critical settings, we demonstrate that MaxSimE can generate faithful explanations under certain conditions and how it improves the interpretability of semantic search results on ranked documents from the LoTTe benchmark, showing its potential for trustworthy information retrieval.
        </div> </ul> <br>



        <label for="Panel246">
        <strong> MDDL: A Framework for Reinforcement Learning-based Position Allocation in Multi-Channel Feed </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaowen+Shi">Xiaowen Shi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ze+Wang">Ze Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuanying+Cai">Yuanying Cai</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoxu+Wu">Xiaoxu Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fan+Yang">Fan Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guogang+Liao">Guogang Liao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongkang+Wang">Yongkang Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xingxing+Wang">Xingxing Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dong+Wang">Dong Wang</a> (1) </u>  <br>
        1:  Meituan, 2:  Tsinghua Universing <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592018">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MDDL: A Framework for Reinforcement Learning-based Position Allocation in Multi-Channel Feed">Google Scholar</a></div>
        (246)
        <br>
        <b>概要:　</b> 近年では、位置配分システムの主流のアプローチとして、強化学習モデルを利用して複数のチャネルにわたってアイテムを適切な位置に配分し、それらをフィードに混合する方法が採用されています。位置配分のために強化学習（RL）モデルを訓練するために使用されるデータには、戦略データとランダムデータの2種類があります。戦略データは現在のオンラインモデルから収集されますが、状態-行動ペアの分布が不均衡であり、訓練中に重大な過大評価問題が生じます。一方、ランダムデータは状態-行動ペアの分布がより均一であるものの、ランダム探索によってプラットフォームの収益やユーザー体験に悪影響を及ぼす可能性があるため、産業シナリオでの取得は困難です。これら2種類のデータは異なる分布を持つため、これらを効果的に活用してRLモデルの訓練効果を向上させる戦略を設計することは非常に困難な問題となっています。本研究では、戦略データとランダムデータの両方を効果的に活用するためのフレームワークとして、Multi-Distribution Data Learning（MDDL）を提案します。具体的には、MDDLは戦略データにおける過大評価問題を緩和するための新しい模倣学習信号を組み込み、ランダムデータのRL信号を最大化することで効果的な学習を促進します。我々の実験では、実際の位置配分システムにおいて提案したMDDLフレームワークを評価し、従来のベースラインと比較して優れたパフォーマンスを示しました。MDDLはメイツアンフードデリバリープラットフォームに完全に展開されており、現在3億人以上のユーザーにサービスを提供しています。
        </label>
        <input type="checkbox" id="Panel246" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Nowadays, the mainstream approach in position allocation system is to utilize a reinforcement learning model to allocate appropriate locations for items in various channels and then mix them into the feed. There are two types of data employed to train reinforcement learning (RL) model for position allocation, named strategy data and random data. Strategy data is collected from the current online model, it suffers from an imbalanced distribution of stateaction pairs, resulting in severe overestimation problems during training. On the other hand, random data offers a more uniform distribution of state-action pairs, but is challenging to obtain in industrial scenarios as it could negatively impact platform revenue and user experience due to random exploration. As the two types of data have different distributions, designing an effective strategy to leverage both types of data to enhance the efficacy of the RL model training has become a highly challenging problem. In this study, we propose a framework namedMulti-Distribution Data Learning (MDDL) to address the challenge of effectively utilizing both strategy and random data for training RL models on mixed multi-distribution data. Specifically, MDDL incorporates a novel imitation learning signal to mitigate overestimation problems in strategy data and maximizes the RL signal for random data to facilitate effective learning. In our experiments, we evaluated the proposed MDDL framework in a real-world position allocation system and demonstrated its superior performance compared to the previous baseline. MDDL has been fully deployed on the Meituan food delivery platform and currently serves over 300 million users.
        </div> </ul> <br>



        <label for="Panel247">
        <strong> MDKG: Graph-Based Medical Knowledge-Guided Dialogue Generation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Usman+Naseem">Usman Naseem</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Surendrabikram+Thapa">Surendrabikram Thapa</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Zhang">Qi Zhang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liang+Hu">Liang Hu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mehwish+Nasim">Mehwish Nasim</a> (4) </u>  <br>
        1:  University of Sydney, 2:  Virginia Tech, 3:  Tongji University, 4:  The University of Western Australia & Flinders University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592019">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MDKG: Graph-Based Medical Knowledge-Guided Dialogue Generation">Google Scholar</a></div>
        (247)
        <br>
        <b>概要:　</b> 医療対話システム（MDS）は、患者との会話を通じて人間の医師のように診断を行う能力を示しています。しかし、現在のシステムはシーケンスモデリングに基づいており、医学的知識を考慮しません。このため、情報が限られた病気の場合、誤診のリスクが高まります。この問題を克服するために、我々はMDKGという医療対話生成（MDG）のためのエンドツーエンド対話システムを提案します。このシステムは、新しい病気に迅速に適応できるように設計されており、病気と症状の相関関係を推論するためのメタ知識グラフを学習し進化させることができます。我々のアプローチは、医療知識グラフを利用して病気と症状の関係を抽出し、与えられた知識グラフを進化させて病気と症状の相関関係を推論する動的なグラフベースのメタ学習フレームワークを使用します。このアプローチは医療知識を組み込んでいるため、多くの対話を必要としません。評価の結果、ベンチマークデータセットでテストした際に、我々のシステムが既存のアプローチを上回ることが示されました。
        </label>
        <input type="checkbox" id="Panel247" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Medical dialogue systems (MDS) have shown promising abilities to diagnose through a conversation with a patient like a human doctor would. However, current systems are mostly based on sequence modeling, which does not account for medical knowledge. This makes the systems more prone to misdiagnosis in case of diseases with limited information. To overcome this issue, we present MDKG, an end-to-end dialogue system for medical dialogue generation (MDG) specifically designed to adapt to new diseases by quickly learning and evolving a meta-knowledge graph that allows it to reason about disease-symptom correlations. Our approach relies on a medical knowledge graph to extract disease-symptom relationships and uses a dynamic graph-based meta-learning framework to learn how to evolve the given knowledge graph to reason about disease-symptom correlations. Our approach incorporates medical knowledge and hence reduces the need for a large number of dialogues. Evaluations show that our system outperforms existing approaches when tested on benchmark datasets.
        </div> </ul> <br>



        <label for="Panel248">
        <strong> Measuring Service-Level Learning Effects in Search Via Query-Randomized Experiments </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Paul+Musgrave">Paul Musgrave</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cuize+Han">Cuize Han</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Parth+Gupta">Parth Gupta</a> (1) </u>  <br>
        1:  Amazon Search <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592020">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Measuring Service-Level Learning Effects in Search Via Query-Randomized Experiments">Google Scholar</a></div>
        (248)
        <br>
        <b>概要:　</b> 与えられたアイテムがクエリに対してどれだけ関連しているかを判断するために、多くの現代の検索ランク付けシステムは、そのアイテムとクエリに対する過去のユーザー行動（例：クリック率）を集約した特徴量を利用します。実用上の理由から、ランク付けシステムでA/Bテストを実行する際、これらの特徴量は一般にすべてのトリートメント間で共有されます。ユーザーやセッションごとにトラフィックをランダム化する最も一般的な実験デザインでは、一方のトリートメントでのユニットの行動が他方のトリートメントの結果に影響を及ぼし、安定単位処置値の仮定（SUTVA）を違反し、測定された結果にバイアスを生じさせます。さらに、このような特徴量に利用可能な行動データの改善を目指した実験（例：オンライン探索）の場合、このパスウェイはまさに影響を与えようとしているものです。このような変化がトリートメントとコントロールに同一に起こる場合、それらは測定することができません。これに対処するために、検索クエリに基づいてトラフィックをランダム化する実験の使用を提案します。我々のアプローチを検証するため、Amazonの検索ページ上の探索・利用フレームワークに関する2つのA/Bテスト—クエリランダム化とユーザーランダム化の下で—を実施しました。理論的予測と一致して、クエリランダム化されたイテレーションは統計的に有意な効果（購入率 +0.66%、p=0.001）を測定できる一方で、ユーザーランダム化されたイテレーションではそうではない（購入率 -0.02%、p=0.851）ことがわかりました。
        </label>
        <input type="checkbox" id="Panel248" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In order to determine the relevance of a given item to a query, most modern search ranking systems make use of features which aggregate prior user behavior for that item and query (e.g. click rate). For practical reasons, when running A/B tests on ranking systems, these features are generally shared between all treatments. For the most common experiment designs, which randomize traffic by user or by session, this creates a pathway by which the behavior of units in one treatment can effect the outcomes for units in other treatments, violating the Stable Unit Treatment Value Assumption (SUTVA) and biasing measured outcomes. Moreover, for experiments targeting improvements to the behavior data available to such features (e.g. online exploration), this pathway is precisely the one we are trying to affect; if such changes occur identically in treatment and control, then they cannot be measured. To address this, we propose the use of experiments which instead randomize traffic based on the search query. To validate our approach, we perform a pair of A/B tests on an explore-exploit framework in the Amazon search page: one under query randomization, and one under user randomization. In line with the theoretical predictions, we find that the query-randomized iteration is able to measure a statistically significant effect (+0.66% Purchases, p=0.001) where the user-randomized iteration does not (-0.02% Purchases, p=0.851).
        </div> </ul> <br>



        <label for="Panel249">
        <strong> Mining Interest Trends and Adaptively Assigning Sample Weight for Session-based Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kai+Ouyang">Kai Ouyang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xianghong+Xu">Xianghong Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Miaoxin+Chen">Miaoxin Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zuotong+Xie">Zuotong Xie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hai-Tao+Zheng">Hai-Tao Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuangyong+Song">Shuangyong Song</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yu+Zhao">Yu Zhao</a> (2) </u>  <br>
        1:  Tsinghua University, 2:  China Telecom Corporation Ltd. & Data&AI Technology Company <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592021">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Mining Interest Trends and Adaptively Assigning Sample Weight for Session-based Recommendation">Google Scholar</a></div>
        (249)
        <br>
        <b>概要:　</b> セッションベースの推薦（Session-based Recommendation、SR）は、短期間のユーザー行動に基づいて次のクリックを予測することを目指しており、これはオンラインプラットフォームにとって重要です。しかし、既存の多くのSR手法は、ユーザーの嗜好がインタラクションの順序に強く関連していない場合があるという事実をある程度無視しています。さらに、異なるサンプル間の重要性の違いを無視しており、これがモデル適合の性能を制限しています。これらの問題に対処するために、我々は「興味のトレンドを抽出し適応的にサンプルの重みを割り当てる方法」（Mining Interest Trends and Adaptively Assigning Sample Weight、略称MTAW）を提唱します。具体的には、ユーザーの現在の行動と過去のすべての行動を基にして、ユーザーの瞬間的な興味をモデル化します。一方で、瞬間的な興味を識別的に統合し、ユーザーの興味の変化を捉えて、よりパーソナライズされた推薦を行います。さらに、新しい損失関数を考案し、現在のエポックにおける予測困難度に応じてサンプルの重みを動的に設定します。2つのベンチマークデータセットで行った広範な実験結果は、我々の手法の有効性と優位性を示しています。
        </label>
        <input type="checkbox" id="Panel249" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Session-based Recommendation (SR) aims to predict users' next click based on their behavior within a short period, which is crucial for online platforms. However, most existing SR methods somewhat ignore the fact that user preference is not necessarily strongly related to the order of interactions. Moreover, they ignore the differences in importance between different samples, which limits the model-fitting performance. To tackle these issues, we put forward the method, Mining Interest Trends and Adaptively Assigning Sample Weight, abbreviated as MTAW. Specifically, we model users' instant interest based on their present behavior and all their previous behaviors. Meanwhile, we discriminatively integrate instant interests to capture the changing trend of user interest to make more personalized recommendations. Furthermore, we devise a novel loss function that dynamically weights the samples according to their prediction difficulty in the current epoch. Extensive experimental results on two benchmark datasets demonstrate the effectiveness and superiority of our method.
        </div> </ul> <br>



        <label for="Panel250">
        <strong> Model-free Reinforcement Learning with Stochastic Reward Stabilization for Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tianchi+Cai">Tianchi Cai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shenliao+Bao">Shenliao Bao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiyan+Jiang">Jiyan Jiang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shiji+Zhou">Shiji Zhou</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenpeng+Zhang">Wenpeng Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lihong+Gu">Lihong Gu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinjie+Gu">Jinjie Gu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guannan+Zhang">Guannan Zhang</a> (1) </u>  <br>
        1:  Ant Group, 2:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592022">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Model-free Reinforcement Learning with Stochastic Reward Stabilization for Recommender Systems">Google Scholar</a></div>
        (250)
        <br>
        <b>概要:　</b> モデルフリー強化学習（RL）に基づくレコメンダーシステムは、部分的なフィードバックや長期的な報酬を扱う能力から、近年注目を集めています。しかし、多くの既存研究はレコメンダーシステムの重要な特徴を無視しています。それは、同じアイテムに対するユーザーのフィードバックが時期によってランダムであるということです。この確率的な報酬の特性は、決定的な報酬を持つ古典的な強化学習シナリオとは本質的に異なり、RLベースのレコメンダーシステムをはるかに挑戦的なものにしています。本論文では、まずシミュレーター環境で直接的な確率的フィードバックを使用すると、パフォーマンスが大幅に低下することを示します。そして、確率的フィードバックをより効率的に処理するために、直接的な確率的フィードバックを、教師ありモデルによって学習されたフィードバックに置き換える2つの確率的報酬安定化フレームワークを設計しました。両フレームワークはモデルに依存しないため、さまざまな教師ありモデルを効果的に利用できます。提案したフレームワークが他のRLベースのレコメンデーションベースラインよりも優れていることを、レコメンデーションシミュレータおよび産業レベルのレコメンダーシステムでの広範な実験で実証しました。
        </label>
        <input type="checkbox" id="Panel250" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Model-free RL-based recommender systems have recently received increasing research attention due to their capability to handle partial feedback and long-term rewards. However, most existing research has ignored a critical feature in recommender systems: one user's feedback on the same item at different times is random. The stochastic rewards property essentially differs from that in classic RL scenarios with deterministic rewards, which makes RL-based recommender systems much more challenging. In this paper, we first demonstrate in a simulator environment where using direct stochastic feedback results in a significant drop in performance. Then to handle the stochastic feedback more efficiently, we design two stochastic reward stabilization frameworks that replace the direct stochastic feedback with that learned by a supervised model. Both frameworks are model-agnostic, i.e., they can effectively utilize various supervised models. We demonstrate the superiority of the proposed frameworks over different RL-based recommendation baselines with extensive experiments on a recommendation simulator as well as an industrial-level recommender system.
        </div> </ul> <br>



        <label for="Panel251">
        <strong> Modeling Orders of User Behaviors via Differentiable Sorting: A Multi-task Framework to Predicting User Post-click Conversion </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Menghan+Wang">Menghan Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinming+Yang">Jinming Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuchen+Guo">Yuchen Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuming+Shen">Yuming Shen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mengying+Zhu">Mengying Zhu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanlin+Wang">Yanlin Wang</a> (4) </u>  <br>
        1:  eBay Inc., 2:  Shanghai Jiaotong University, 3:  Zhejiang University, 4:  Sun Yat-sen University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592023">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Modeling Orders of User Behaviors via Differentiable Sorting: A Multi-task Framework to Predicting User Post-click Conversion">Google Scholar</a></div>
        (251)
        <br>
        <b>概要:　</b> ユーザーのクリック後コンバージョン予測は、研究者や開発者にとって非常に関心の高いテーマです。最近の研究では、クリックデータを組み込むことで、選択バイアスとデータの希少性というクリック後行動予測における二つの重大な課題に対処するため、マルチタスク学習を採用しています。しかし、先行研究の多くはポイントワイズ学習に焦点を当てており、ラベルの順序（すなわちクリックおよびクリック後）の探索が不十分であり、この問題はリストワイズ学習問題として捉えられます。最近の微分可能なソーティングに関する進展に触発され、本論文ではユーザー行動の順序を利用してエンド・ツー・エンドでユーザーのクリック後コンバージョンを予測する新しいマルチタスクフレームワークを提案します。具体的には、異なるタスクの予測出力を統一スコアに結合する集約演算子を定義し、計算されたスコアを使用して微分可能なソーティングを通じてラベル関係をモデル化します。公的および産業データセットにおける広範な実験により、競争力のあるベースラインと比較して我々の提案モデルの優位性が示されました。
        </label>
        <input type="checkbox" id="Panel251" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> User post-click conversion prediction is of high interest to researchers and developers. Recent studies employ multi-task learning to tackle the selection bias and data sparsity problem, two severe challenges in post-click behavior prediction, by incorporating click data. However, prior works mainly foucsed on pointwise learning and the orders of labels (i.e., click and post-click) are not well explored, which naturally poses a listwise learning problem. Inspired by recent advances on differentiable sorting, in this paper, we propose a novel multi-task framework that leverages orders of user behaviors to predict user post-click conversion in an end-to-end approach. Specifically, we define an aggregation operator to combine predicted outputs of different tasks to a unified score, then we use the computed scores to model the label relations via differentiable sorting. Extensive experiments on public and industrial datasets show the superiority of our proposed model against competitive baselines.
        </div> </ul> <br>



        <label for="Panel252">
        <strong> Multi-Grained Topological Pre-Training of Language Models in Sponsored Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhoujin+Tian">Zhoujin Tian</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaozhuo+Li">Chaozhuo Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Zuo">Zhiqiang Zuo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zengxuan+Wen">Zengxuan Wen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinyue+Hu">Xinyue Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Han">Xiao Han</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haizhen+Huang">Haizhen Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Senzhang+Wang">Senzhang Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weiwei+Deng">Weiwei Deng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xing+Xie">Xing Xie</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Zhang">Qi Zhang</a> (1) </u>  <br>
        1:  Microsoft, 2:  Microsoft Research Asia, 3:  Central South University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592024">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multi-Grained Topological Pre-Training of Language Models in Sponsored Search">Google Scholar</a></div>
        (252)
        <br>
        <b>概要:　</b> リレバンスモデルは、クエリと候補広告の間の語義的近接性を測定するものであり、これはスポンサー検索システムの中核として広く認識されています。従来のリレバンスモデルは、クエリと広告内のテキストデータのみに依存しており、これらの短いテキストに含まれる語義情報の乏しさがパフォーマンスの妨げとなっています。最近では、ユーザ行動グラフを導入することにより、純粋なテキストの意味論を超えた補完情報が提供されています。有望なパフォーマンスにもかかわらず、行動強化モデルは、明示的なトポロジー集約によって導入される追加の計算によるリソースコストの増大に悩まされます。本稿では、行動グラフの多粒度トポロジ情報を理解するように言語モデルを教育する新しい多粒度トポロジ事前学習パラダイム、MGTLMを提案し、これにより明示的なグラフ集約を排除し、情報の損失を回避します。オンラインとオフラインの設定における広範な実験結果は、我々の提案の優位性を実証しています。
        </label>
        <input type="checkbox" id="Panel252" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Relevance models measure the semantic closeness between queries and the candidate ads, widely recognized as the nucleus of sponsored search systems. Conventional relevance models solely rely on the textual data within the queries and ads, whose performance is hindered by the scarce semantic information in these short texts. Recently, user behavior graphs have been incorporated to provide complementary information beyond pure textual semantics.Despite the promising performance, behavior-enhanced models suffer from exhausting resource costs due to the extra computations introduced by explicit topological aggregations. In this paper, we propose a novel Multi-Grained Topological Pre-Training paradigm, MGTLM, to teach language models to understand multi-grained topological information in behavior graphs, which contributes to eliminating explicit graph aggregations and avoiding information loss. Extensive experimental results over online and offline settings demonstrate the superiority of our proposal.
        </div> </ul> <br>



        <label for="Panel253">
        <strong> Multi-grained Representation Learning for Cross-modal Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shengwei+Zhao">Shengwei Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linhai+Xu">Linhai Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuying+Liu">Yuying Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shaoyi+Du">Shaoyi Du</a> (1) </u>  <br>
        1:  Institute of Artificial Intelligence and Robotics <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592025">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multi-grained Representation Learning for Cross-modal Retrieval">Google Scholar</a></div>
        (253)
        <br>
        <b>概要:　</b> オーディオ-テキスト検索の目的は、オーディオとテキスト間のクロスモーダル類似性関数を学習し、与えられたオーディオ/テキストから候補セット内の類似テキスト/オーディオを見つけることです。最近のオーディオ-テキスト検索モデルは、マルチモーダル特徴を単一の粗粒度の表現に集約します。しかし、単一の表現では、オーディオが異なる粒度レベルの複数のテキストで記述される状況を解決するのは困難です。これは、オーディオとテキストの間の関連パターンが複雑であるためです。そこで本研究では、特徴を包括的な表現に集約するための最適なプール関数を自動的に見つける適応集約戦略を提案し、価値のある多粒度表現を学習します。また、異なる粒度でのオーディオとテキストの複雑な相関関係に焦点を当てるために、多粒度比較学習を実施します。この間に、冗長なオーディオクリップの影響を軽減するためにテキストガイドのトークンインタラクションを使用します。我々の提案手法をAudiocapsとClothoの2つのオーディオ-テキスト検索ベンチマークデータセットで評価し、テキストからオーディオおよびオーディオからテキストへの検索において最先端の成果を達成しました。我々の発見は、マルチモーダル多粒度表現の学習の重要性を強調しています。
        </label>
        <input type="checkbox" id="Panel253" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The purpose of audio-text retrieval is to learn a cross-modal similarity function between audio and text, enabling a given audio/text to find similar text/audio from a candidate set. Recent audio-text retrieval models aggregate multi-modal features into a single-grained representation. However, single-grained representation is difficult to solve the situation that an audio is described by multiple texts of different granularity levels, because the association pattern between audio and text is complex. Therefore, we propose an adaptive aggregation strategy to automatically find the optimal pool function to aggregate the features into a comprehensive representation, so as to learn valuable multi-grained representation. And multi-grained comparative learning is carried out in order to focus on the complex correlation between audio and text in different granularity. Meanwhile, text-guided token interaction is used to reduce the impact of redundant audio clips. We evaluated our proposed method on two audio-text retrieval benchmark datasets of Audiocaps and Clotho, achieving the state-of-the-art results in text-to-audio and audio-to-text retrieval. Our findings emphasize the importance of learning multi-modal multi-grained representation.
        </div> </ul> <br>



        <label for="Panel254">
        <strong> Multiple Topics Community Detection in Attributed Networks </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaobo+He">Chaobo He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junwei+Cheng">Junwei Cheng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guohua+Chen">Guohua Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yong+Tang">Yong Tang</a> (1) </u>  <br>
        1:  South China Normal University & Pazhou Lab, 2:  South China Normal University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592026">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multiple Topics Community Detection in Attributed Networks">Google Scholar</a></div>
        (254)
        <br>
        <b>概要:　</b> 既存の手法では属性ネットワークにおいて複数のトピックを持つコミュニティを効果的に検出することが難しいため、自己教師あり学習のオートエンコーダースタイルを採用した手法、SSAGCNを提案します。SSAGCNはまず、トポロジー情報と属性情報を自動的に融合するためのエンコーダーとして働く適応型グラフ畳み込みネットワーク（AGCN）を設計し、その後、ネットワークのトポロジーと属性を同時に再構成するデュアルデコーダーを利用します。さらにモジュラリティ最大化と共同最適化戦略を導入することで、SSAGCNはエンドツーエンドで複数のトピックを持つコミュニティを検出することができます。実験結果は、SSAGCNが最先端のアプローチを上回り、トピック分析を効果的に行うことができることを示しています。
        </label>
        <input type="checkbox" id="Panel254" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Since existing methods are often not effective to detect communities with multiple topics in attributed networks, we propose a method named SSAGCN via Autoencoder-style self-supervised learning. SSAGCN firstly designs an adaptive graph convolutional network (AGCN), which is treated as the encoder for fusing topology information and attribute information automatically, and then utilizes a dual decoder to simultaneously reconstruct network topology and attributes. By further introducing the modularity maximization and the joint optimization strategies, SSAGCN can detect communities with multiple topics in an end-to-end manner. Experimental results show that SSAGCN outperforms state-of-the-art approaches, and also can be used to conduct topic analysis well.
        </div> </ul> <br>



        <label for="Panel255">
        <strong> NC2T: Novel Curriculum Learning Approaches for Cross-Prompt Trait Scoring </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yejin+Lee">Yejin Lee</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Seokwon+Jeong">Seokwon Jeong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongjin+Kim">Hongjin Kim</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tae-il+Kim">Tae-il Kim</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sung-Won+Choi">Sung-Won Choi</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Harksoo+Kim">Harksoo Kim</a> (3) </u>  <br>
        1:  Konkuk University, 2:  Kangwon National University, 3:  Konkuk University, 4:  Naver <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592027">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=NC2T: Novel Curriculum Learning Approaches for Cross-Prompt Trait Scoring">Google Scholar</a></div>
        (255)
        <br>
        <b>概要:　</b> 自動エッセイ評価（AES）は、教育分野やそれ以外の分野でも応用可能性を持つ重要な研究領域です。しかし、最近の研究は特定のドメイン内でエッセイを評価するAESモデルや全体的なスコアを使用するモデルに重点を置いており、複数の視点から詳細な項目を評価する一般化されたモデルに関する研究とリソースが不足しています。複雑な特性に基づいてエッセイを評価しスコアリングすることはコストがかかり、時間も消費するため、そのようなAES評価のためのデータセットは限られています。これらの問題に対処するために、我々はクロスプロンプト特性スコアリングAESモデルを開発し、適切なカリキュラム学習（CL）設計を提案しました。難易度スコアを考案し、主要なカリキュラムメソッドを導入することで、自然言語理解タスクにおける既存のCL戦略と比較してその有効性を実証しました。
        </label>
        <input type="checkbox" id="Panel255" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Automated essay scoring (AES) is a crucial research area with potential applications in education and beyond. However, recent studies have primarily focused on AES models that evaluate essays within a specific domain or using a holistic score, leaving a gap in research and resources for more generalized models capable of assessing essays with detailed items from multiple perspectives. As evaluating and scoring essays based on complex traits is costly and time-consuming, datasets for such AES evaluations are limited. To address these issues, we developed a cross-prompt trait scoring AES model and proposed a suitable curriculum learning (CL) design. By devising difficulty scores and introducing the key curriculum method, we demonstrated its effectiveness compared to existing CL strategies in natural language understanding tasks.
        </div> </ul> <br>



        <label for="Panel256">
        <strong> Offline Pseudo Relevance Feedback for Efficient and Effective Single-pass Dense Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xueru+Wen">Xueru Wen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoyang+Chen">Xiaoyang Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuanang+Chen">Xuanang Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ben+He">Ben He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Le+Sun">Le Sun</a> (2) </u>  <br>
        1:  University of Chinese Academy of Sciences & Institute of Software, 2:  Institute of Software <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592028">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Offline Pseudo Relevance Feedback for Efficient and Effective Single-pass Dense Retrieval">Google Scholar</a></div>
        (256)
        <br>
        <b>概要:　</b> 濃密検索（Dense Retrieval）は、高い効果を維持しながら、単一パス検索プロセス中のオンライン効率を保つことにより、情報検索（IR）において大きな進展を遂げました。しかし、擬似関連フィードバック（PRF）を適用してさらに検索効果を高めることは、オンラインレイテンシーを2倍にする結果引き起こします。この課題に対処するために、本論文では、事前に生成された擬似クエリを活用することでPRFプロセスをオフラインに移行する単一パス濃密検索フレームワークを提案します。その結果、オンライン検索は擬似クエリとの単一マッチングにまで簡略化され、より迅速なオンライン検索が可能となります。提案手法の効果は、標準的なTREC DLおよびHARDデータセットで評価され、その有望性が示されました。コードはhttps://github.com/Rosenberg37/OPRFにて公開されています。
        </label>
        <input type="checkbox" id="Panel256" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Dense retrieval has made significant advancements in information retrieval (IR) by achieving high levels of effectiveness while maintaining online efficiency during a single-pass retrieval process. However, the application of pseudo relevance feedback (PRF) to further enhance retrieval effectiveness results in a doubling of online latency. To address this challenge, this paper presents a single-pass dense retrieval framework that shifts the PRF process offline through the utilization of pre-generated pseudo-queries. As a result, online retrieval is reduced to a single matching with the pseudo-queries, hence providing faster online retrieval. The effectiveness of the proposed approach is evaluated on the standard TREC DL and HARD datasets, and the results demonstrate its promise. Our code is openly available at https://github.com/Rosenberg37/OPRF https://github.com/Rosenberg37/OPRF.
        </div> </ul> <br>



        <label for="Panel257">
        <strong> On Answer Position Bias in Transformers for Question Answering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rafael+Glater">Rafael Glater</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rodrygo+L.+T.+Santos">Rodrygo L. T. Santos</a> (1) </u>  <br>
        1:  Universidade Federal de Minas Gerais <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592029">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=On Answer Position Bias in Transformers for Question Answering">Google Scholar</a></div>
        (257)
        <br>
        <b>概要:　</b> 抽出型のトランスフォーマーモデルは、質問応答（QA）のために候補段落の中で答えの始まりと終わりの位置を予測するように訓練されています。しかし、訓練データにおける答えの位置の分布が大きく偏っている場合、真の答えの位置はこれらのモデルにバイアスを与える可能性があります。つまり、段落の初めに答えがあるデータでのみ訓練されたモデルは、段落の終わりに答えがあるテストインスタンスでは性能が低下します。多くの研究が答えの位置バイアスに対抗することに焦点を当ててきましたが、そのようなバイアスがトランスフォーマーの主要コンポーネントにどのように現れるかについての理解はまだ深まっていません。本論文では、異なるアーキテクチャおよび位置埋め込み戦略を持つ5つのトランスフォーマーベースのモデルの自己注意および埋め込み生成コンポーネントを分析します。我々の分析結果は、モデルが注意行列に位置バイアスをマップし、答えとそのバイアスされた位置を関連付ける埋め込みを生成する傾向があることを示しており、最終的にはモデルの一般化能力を損なうことが明らかになりました。
        </label>
        <input type="checkbox" id="Panel257" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Extractive Transformer-based models for question answering (QA) are trained to predict the start and end position of the answer in a candidate paragraph. However, the true answer position can bias these models when its distribution in the training data is highly skewed. That is, models trained only with the answer at the beginning of the paragraph will perform poorly on test instances with the answer at the end. Many studies have focused on countering answer position bias but have yet to deepen our understanding of how such bias manifests in the main components of the Transformer. In this paper, we analyze the self-attention and embedding generation components of five Transformer-based models with different architectures and position embedding strategies. Our analysis shows that models tend to map position bias in their attention matrices, generating embeddings that correlate the answer and its biased position, ultimately compromising model generalization.
        </div> </ul> <br>



        <label for="Panel258">
        <strong> On the Effects of Regional Spelling Conventions in Retrieval Models </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andreas+Chari">Andreas Chari</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sean+MacAvaney">Sean MacAvaney</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Iadh+Ounis">Iadh Ounis</a> (1) </u>  <br>
        1:  University of Glasgow <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592030">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=On the Effects of Regional Spelling Conventions in Retrieval Models">Google Scholar</a></div>
        (258)
        <br>
        <b>概要:　</b> ニューラルランキングモデルの1つの利点は、同義性の状況、すなわち2つの単語が類似または同一の意味を持つ場合において、良好に一般化することが意図されている点です。本論文では、同義性の明確な事例、すなわち地域差によるスペルの違い（例: color と colour）を持つ単語が異なる表面形で表現される場合において、様々なランキングモデルがどれほど高い性能を示すかを調査および定量化します。まず、ニューラル検索手法の事前学習、訓練、および評価に使用されるデータセットにおけるアメリカ英語とイギリス英語のスペル慣習の普及状況を探り、その結果、アメリカ英語のスペル慣習がはるかに普及していることを発見しました。この訓練データの偏りにもかかわらず、検索モデルはこの同義性の事例において多くの場合良好に一般化することがわかりました。検索における文書スペルの正規化の影響を調査し、すべてのモデルが文書スペルの正規化によって影響を受けることを観察しました。クエリとは異なるスペル慣習に正規化された場合、すべてのモデルが性能低下を経験する一方で、クエリのスペル慣習と共有するように文書を正規化した場合には、モデルによって異なる動作が見られました。具体的には、語彙モデルは改善を示し、密な検索モデルは影響を受けず、再ランカーは矛盾する挙動を示しました。
        </label>
        <input type="checkbox" id="Panel258" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> One advantage of neural ranking models is that they are meant to generalise well in situations of synonymity i.e. where two words have similar or identical meanings. In this paper, we investigate and quantify how well various ranking models perform in a clear-cut case of synonymity: when words are simply expressed in different surface forms due to regional differences in spelling conventions (e.g., color vs colour). We first explore the prevalence of American and British English spelling conventions in datasets used for the pre-training, training and evaluation of neural retrieval methods, and find that American spelling conventions are far more prevalent. Despite these biases in the training data, we find that retrieval models often generalise well in this case of synonymity. We explore the effect of document spelling normalisation in retrieval and observe that all models are affected by normalising the document's spelling. While they all experience a drop in performance when normalised to a different spelling convention than that of the query, we observe varied behaviour when the document is normalised to share the query spelling convention: lexical models show improvements, dense retrievers remain unaffected, and re-rankers exhibit contradictory behaviour.
        </div> </ul> <br>



        <label for="Panel259">
        <strong> On the Impact of Data Quality on Image Classification Fairness </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Aki+Barry">Aki Barry</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Han">Lei Han</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gianluca+Demartini">Gianluca Demartini</a> (1) </u>  <br>
        1:  The University of Queensland <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592031">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=On the Impact of Data Quality on Image Classification Fairness">Google Scholar</a></div>
        (259)
        <br>
        <b>概要:　</b> アルゴリズムによる意思決定が広がる中、これらのシステムへの監視も強化されています。本論文は、教師あり分類の文脈で、トレーニングデータの質とそのデータで訓練されたモデルの公平性の関係を探求します。複数の画像分類データセットにおける様々なアルゴリズムを通じて、主な公平性指標を測定します。これらのデータセットには、ラベルとトレーニングデータ自体の両方に異なるレベルのノイズが含まれています。ラベルのノイズとは、トレーニングセット内のデータのラベリングにおける不正確さを指し、データのノイズとは、トレーニングセット内のデータの歪みを指します。オリジナルのデータセットにノイズを追加することにより、トレーニングデータの質とそのデータで訓練されたモデルの出力の公平性の関係を探ることができます。
        </label>
        <input type="checkbox" id="Panel259" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> With the proliferation of algorithmic decision-making, increased scrutiny has been placed on these systems. This paper explores the relationship between the quality of the training data and the overall fairness of the models trained with such data in the context of supervised classification. We measure key fairness metrics across a range of algorithms over multiple image classification datasets that have a varying level of noise in both the labels and the training data itself. We describe noise in the labels as inaccuracies in the labelling of the data in the training set and noise in the data as distortions in the data, also in the training set. By adding noise to the original datasets, we can explore the relationship between the quality of the training data and the fairness of the output of the models trained on that data.
        </div> </ul> <br>



        <label for="Panel260">
        <strong> One-Shot Labeling for Automatic Relevance Estimation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sean+MacAvaney">Sean MacAvaney</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Luca+Soldaini">Luca Soldaini</a> (2) </u>  <br>
        1:  University of Glasgow, 2:  Allen Institute for AI <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592032">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=One-Shot Labeling for Automatic Relevance Estimation">Google Scholar</a></div>
        (260)
        <br>
        <b>概要:　</b> 関連性評価において未評価の文書（「穴」）に対処することは、オフライン実験で検索システムを評価する際の永続的な問題です。これらの穴は評価中に検索システムの見かけの有効性を低下させ、また不完全なデータで訓練されたモデルにバイアスをもたらすことがあります。本研究では、大規模言語モデルがこうした穴を埋めることでオフライン評価を改善できるかどうかを探ります。評価の設定として極端ではありますが、一般的な評価シナリオである各クエリに対して唯一一つだけ既知の関連文書がある場合を検討します。その上で、クエリおよび既知の関連文書に関して未評価の文書の関連性を予測するための様々なアプローチ（最近傍法、教師あり学習、プロンプティング技術など）を探求します。我々の調査結果によると、これらのOne-Shot Labelers（1SL）の予測は人間の評価としばしば一致しないものの、生成されるラベルは単一のラベルのみの場合に比べてシステムのランキングの信頼性を遥かに高めます。具体的には、最も強力なアプローチでは、様々な評価指標に渡りシステムランキングの相関が0.86以上に達することが一貫して確認されました。また、このアプローチは関連性評価の穴を埋めることでt検定の信頼性を大幅に高め、研究者が重要な結果に対してより自信を持てるようにします。本研究と共に、他のアドホックなコレクションやシステムの評価に1SLを使用できる簡便なソフトウェアパッケージも公開します。
        </label>
        <input type="checkbox" id="Panel260" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Dealing with unjudged documents ("holes") in relevance assessments is a perennial problem when evaluating search systems with offline experiments. Holes can reduce the apparent effectiveness of retrieval systems during evaluation and introduce biases in models trained with incomplete data. In this work, we explore whether large language models can help us fill such holes to improve offline evaluations. We examine an extreme, albeit common, evaluation setting wherein only a single known relevant document per query is available for evaluation. We then explore various approaches for predicting the relevance of unjudged documents with respect to a query and the known relevant document, including nearest neighbor, supervised, and prompting techniques. We find that although the predictions of these One-Shot Labelers (1SL) frequently disagree with human assessments, the labels they produce yield a far more reliable ranking of systems than the single labels do alone. Specifically, the strongest approaches can consistently reach system ranking correlations of over 0.86 with the full rankings over a variety of measures. Meanwhile, the approach substantially increases the reliability of t-tests due to filling holes in relevance assessments, giving researchers more confidence in results they find to be significant. Alongside this work, we release an easy-to-use software package to enable the use of 1SL for evaluation of other ad-hoc collections or systems.
        </div> </ul> <br>



        <label for="Panel261">
        <strong> Optimizing Reciprocal Rank with Bayesian Average for improved Next Item Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangkui+Lu">Xiangkui Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Wu">Jun Wu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianbo+Yuan">Jianbo Yuan</a> (3) </u>  <br>
        1:  Beijing Jiaotong University, 2:  Beijing Jiaotong University & Engineering Research Center of Integration and Application of Digital Learning Technology, 3:  ByteDance <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592033">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Optimizing Reciprocal Rank with Bayesian Average for improved Next Item Recommendation">Google Scholar</a></div>
        (261)
        <br>
        <b>概要:　</b> 次アイテム推薦は、セッションベースの推薦において重要なタスクです。しかし、最適化の目的（バイナリクロスエントロピー）とランキング指標（平均逆順位）の間のギャップは十分に探求されておらず、その結果、最適以下の推薦が行われています。本論文では、平均逆順位を直接最適化するための新しい目的関数、すなわちAdjusted-RRを提案します。具体的に言うと、Adjusted-RRはベイズ平均を採用して、逆順位損失と通常の順位損失を位置認識重みで調整します。Adjusted-RRは様々なモデルに対応可能なプラグアンドプレイ方式の目的関数です。私たちは、二つのベースモデルと二つのデータセットに対してAdjusted-RRを適用し、実験結果から次アイテム推薦において大幅な改善が見られることを示しました。
        </label>
        <input type="checkbox" id="Panel261" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Next item recommendation is a crucial task of session-based recommendation. However, the gap between the optimization objective (Binary Cross Entropy) and the ranking metric (Mean Reciprocal Rank) has not been well-explored, resulting in sub-optimal recommendations. In this paper, we propose a novel objective function, namely Adjusted-RR, to directly optimize Mean Reciprocal Rank. Specifically, Adjusted-RR adopts Bayesian Average to adjust Reciprocal Rank loss with Normal Rank loss by creating position-aware weights between them. Adjusted-RR is a plug-and-play objective that is compatible with various models. We apply Adjusted-RR on two base models and two datasets, and experimental results show that it makes a significant improvement in the next item recommendation.
        </div> </ul> <br>



        <label for="Panel262">
        <strong> Patterns of Gender-Specializing Query Reformulation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Amifa+Raj">Amifa Raj</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bhaskar+Mitra">Bhaskar Mitra</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nick+Craswell">Nick Craswell</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michael+Ekstrand">Michael Ekstrand</a> (1) </u>  <br>
        1:  Boise State University, 2:  Microsoft Research, 3:  Microsoft <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592034">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Patterns of Gender-Specializing Query Reformulation">Google Scholar</a></div>
        (262)
        <br>
        <b>概要:　</b> 検索システムのユーザーは、システムが関連コンテンツを表示しない場合、情報の必要性が進化することに伴い、あるいはより正確に情報の必要性を表現するために、クエリ語を追加してクエリを再形成することがあります。これらのクエリ再形成を分析することで、システムとユーザーの行動についての知見を得ることができます。本研究では、再形成されたクエリの一部として、性別などの人口統計グループの属性を特定するクエリ再形成の特別なカテゴリを研究します（例：「オリンピック2021サッカー結果」->「オリンピック2021女子サッカー結果」）。クエリ、検索結果、および性別のような人口統計属性は多くの方法で関連し得るため、これらの再形成パターンの原因として元の結果ページでの過小表現や言語理論の有標性などを仮定します。本論文では、Bingの大規模な検索ログデータに基づいて、ジェンダーを特定するクエリ再形成の文脈と効果に関する観察研究を報告します。これらの再形成は、元の結果ページのジェンダー表現を補正する場合もあれば、強化する場合もありますが、通常は最終的に選択された結果へのアクセスを向上させます。これらの再形成の普及率や、どのジェンダーに偏るかは、トピックのコンテキストによって異なります。しかし、元の結果ページでのグループの過小表現や有標性理論だけでは、これらの再形成を十分に説明する証拠は見つかりません。将来の研究では、このようなクエリ再形成を使用して、検索結果ページにおけるジェンダー（および他の人口統計）の表現に関するより深い調査を行うことを期待します。
        </label>
        <input type="checkbox" id="Panel262" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Users of search systems often reformulate their queries by adding query terms to reflect their evolving information need or to more precisely express their information need when the system fails to surface relevant content. Analyzing these query reformulations can inform us about both system and user behavior. In this work, we study a special category of query reformulations that involve specifying demographic group attributes, such as gender, as part of the reformulated query (e.g., ''olympic 2021 soccer results'' -> ''olympic 2021 women's soccer results"). There are many ways a query, the search results, and a demographic attribute such as gender may relate, leading us to hypothesize different causes for these reformulation patterns, such as under-representation on the original result page or based on the linguistic theory of markedness. This paper reports on an observational study of gender-specializing query reformulations---their contexts and effects---as a lens on the relationship between system results and gender, based on large-scale search log data from Bing. We find that these reformulations sometimes correct for and other times reinforce gender representation on the original result page, but typically yield better access to the ultimately-selected results. The prevalence of these reformulations---and which gender they skew towards---differ by topical context. However, we do not find evidence that either group under-representation or markedness alone adequately explains these reformulations. We hope that future research will use such reformulations as a probe for deeper investigation into gender (and other demographic) representation on the search result page.
        </div> </ul> <br>



        <label for="Panel263">
        <strong> Personalized Dynamic Recommender System for Investors </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Takehiro+Takayanagi">Takehiro Takayanagi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chung-Chi+Chen">Chung-Chi Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kiyoshi+Izumi">Kiyoshi Izumi</a> (1) </u>  <br>
        1:  The University of Tokyo, 2:  National Institute of Advanced Industrial Science and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592035">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Personalized Dynamic Recommender System for Investors">Google Scholar</a></div>
        (263)
        <br>
        <b>概要:　</b> オンラインプラットフォームの発展により、人々は意見を迅速に共有し取得できるようになりました。それに伴い、他のユーザーから説得力のある意見を受け取ると、個人の好みも速やかに変動するようになっています。アイテムの特徴が固定されているeコマースプラットフォームなどの代表的な推薦研究とは異なり、投資シナリオでは株価などの金融商品の特徴が時間とともに動的に変化します。これらの動的な特徴を捉え、アマチュア投資家に対してよりパーソナライズされた推薦を提供するために、本研究では投資家向けパーソナライズ動的推薦システム（PDRSI）を提案します。提案するPDRSIは投資家の動的な嗜好と過去の興味という2つの個人属性と、ソーシャルメディアプラットフォーム上の最近の議論と最新の市場情報という2つの時系列環境特性を考慮します。実験結果は提案するPDRSIの有用性を支持しており、アブレーションスタディは各モジュールの効果を示しています。再現性のために、Twitterの開発者ポリシーに従い、今後の研究のためにデータセットを共有しています。
        </label>
        <input type="checkbox" id="Panel263" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> With the development of online platforms, people can share and obtain opinions quickly. It also makes individuals' preferences change dynamically and rapidly because they may change their minds when getting convincing opinions from other users. Unlike representative areas of recommendation research such as e-commerce platforms where items' features are fixed, in investment scenarios financial instruments' features such as stock price, also change dynamically over time. To capture these dynamic features and provide a better-personalized recommendation for amateur investors, this study proposes a Personalized Dynamic Recommender System for Investors, PDRSI. The proposed PDRSI considers two investor's personal features: dynamic preferences and historical interests, and two temporal environmental properties: recent discussions on the social media platform and the latest market information. The experimental results support the usefulness of the proposed PDRSI, and the ablation studies show the effect of each module. For reproduction, we follow Twitter's developer policy to share our dataset for future work.
        </div> </ul> <br>



        <label for="Panel264">
        <strong> Personalized Showcases: Generating Multi-Modal Explanations for Recommendations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=An+Yan">An Yan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhankui+He">Zhankui He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiacheng+Li">Jiacheng Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tianyang+Zhang">Tianyang Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Julian+McAuley">Julian McAuley</a> (1) </u>  <br>
        1:  University of California <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592036">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Personalized Showcases: Generating Multi-Modal Explanations for Recommendations">Google Scholar</a></div>
        (264)
        <br>
        <b>概要:　</b> 既存の説明モデルは推奨事項のためにテキストのみを生成しますが、多様なコンテンツを生み出すのには依然として困難が伴っています。本論文では、説明をさらに充実させるために、テキストと視覚情報の両方を提供して推奨事項を説明する新しいタスク「パーソナライズドショーケース」を提案します。具体的には、まずユーザーの興味に最も関連するパーソナライズド画像セットを選びます。その次に、選択した画像を考慮して自然言語の説明を生成します。この新しいタスクのために、Google Mapsから大規模なデータセットを収集し、マルチモーダルな説明を生成するための高品質なサブセットを構築しました。我々は、コントラスト学習を通じて多様で視覚的に一致した説明を生成できるパーソナライズド・マルチモーダル・フレームワークを提案します。実験の結果、我々のフレームワークは異なるモダリティを入力として活用することで、従来の方法と比べてより多様で表現力のある説明を生成できることが示されました。
        </label>
        <input type="checkbox" id="Panel264" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Existing explanation models generate only text for recommendations but still struggle to produce diverse contents. In this paper, to further enrich explanations, we propose a new task named personalized showcases, in which we provide both textual and visual information to explain our recommendations. Specifically, we first select a personalized image set that is the most relevant to a user's interest toward a recommended item. Then, natural language explanations are generated accordingly given our selected images. For this new task, we collect a large-scale dataset from Google Maps and construct a high-quality subset for generating multi-modal explanations. We propose a personalized multi-modal framework which can generate diverse and visually-aligned explanations via contrastive learning. Experiments show that our framework benefits from different modalities as inputs, and is able to produce more diverse and expressive explanations compared to previous methods on a variety of evaluation metrics.
        </div> </ul> <br>



        <label for="Panel265">
        <strong> PersonalTM: Transformer Memory for Personalized Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruixue+Lian">Ruixue Lian</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sixing+Lu">Sixing Lu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Clint+Solomon">Clint Solomon</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gustavo+Aguilar">Gustavo Aguilar</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pragaash+Ponnusamy">Pragaash Ponnusamy</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jialong+Han">Jialong Han</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chengyuan+Ma">Chengyuan Ma</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenlei+Guo">Chenlei Guo</a> (2) </u>  <br>
        1:  University of Wisconsin-Madison, 2:  Amazon Alexa AI <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592037">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=PersonalTM: Transformer Memory for Personalized Retrieval">Google Scholar</a></div>
        (265)
        <br>
        <b>概要:　</b> Transformerメモリを活用するDifferentiable Search Index（DSI）は、新しい情報検索パラダイムとして提案され、類似スコアに基づくデュアルエンコーダー検索フレームワークの限界に対処することを目指しています。DSIフレームワークは、明示的なインデックスに依存せず、クエリから関連する文書識別子を直接生成することで、強力なベースラインを上回ります。DSIフレームワークの記憶能力は、個別化された検索タスクに適しています。そこで、個別化されたテキスト検索のためにPersonal Transformer Memory（PersonalTM）アーキテクチャを提案します。PersonalTMはユーザー固有のプロファイルとコンテクスト的なユーザークリック行動を取り入れ、文書識別子の階層的割り当てに沿うためにデコーディングプロセスで階層的損失を導入します。さらに、PersonalTMはアダプターアーキテクチャを採用することで、インデックスの更新に対するスケーラビリティを向上させ、従来のDSIと比較して計算コストを削減します。実験の結果、PersonalTMは精度@1および10位、平均互換順位（MRR）の観点から、DSIのベースライン、BM25、ファインチューニングされたデュアルエンコーダー、および他の個別化モデルを上回ることが示されました。具体的には、PersonalTMはBM25、デュアルエンコーダー、DSIと比較してp@1をそれぞれ58%、49%、12%向上させます。
        </label>
        <input type="checkbox" id="Panel265" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The Transformer Memory as a Differentiable Search Index (DSI) has been proposed as a new information retrieval paradigm, which aims to address the limitations of dual-encoder retrieval framework based on the similarity score. The DSI framework outperforms strong baselines by directly generating relevant document identifiers from queries without relying on an explicit index. The memorization power of DSI framework makes it suitable for personalized retrieval tasks. Therefore, we propose a Personal Transformer Memory (PersonalTM) architecture for personalized text retrieval. PersonalTM incorporates user-specific profiles and contextual user click behaviors, and introduces hierarchical loss in the decoding process to align with the hierarchical assignment of document identifier. Additionally, PersonalTM also employs an adapter architecture to improve the scalability for index updates and reduce computation costs, compared to the vanilla DSI. Experiments show that PersonalTM outperforms the DSI baseline, BM25, fine-tuned dual-encoder, and other personalized models in terms of precision at top 1st and 10th positions and Mean Reciprocal Rank (MRR). Specifically, PersonalTM improves p@1 by 58%, 49%, and 12% compared to BM25, Dual-encoder, and DSI, respectively.
        </div> </ul> <br>



        <label for="Panel266">
        <strong> PiTL: Cross-modal Retrieval with Weakly-supervised Vision-language Pre-training via Prompting </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zixin+Guo">Zixin Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tzu-Jui+Julius+Wang">Tzu-Jui Julius Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Selen+Pehlivan">Selen Pehlivan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Abduljalil+Radman">Abduljalil Radman</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jorma+Laaksonen">Jorma Laaksonen</a> (1) </u>  <br>
        1:  Aalto University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592038">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=PiTL: Cross-modal Retrieval with Weakly-supervised Vision-language Pre-training via Prompting">Google Scholar</a></div>
        (266)
        <br>
        <b>概要:　</b> ビジョンと言語の事前学習（Vision-language Pre-training；VLP）は、多様な下流タスク、特に異種メディア間の情報検索タスクに対して、汎用的なVLモデルを生成することが示されています。しかし、この手法は大量の画像とテキストのペアに依存しており、その収集には多大な手間と費用がかかります。これに対し、弱教師ありのVLP（Weakly-supervised VLP；W-VLP）は、事前学習された物体検出器（Object Detector；OD）によって生成されたオブジェクトタグを用いる方法を探求します。しかし、依然としてオブジェクトレベルの注釈付きの画像が必要であり、それがODの訓練のための監督信号となります。この監督信号の量をさらに減らすために、私たちはPrompts-in-The-Loop（PiTL）を提案します。これは、大規模言語モデル（Large Language Models；LLMs）から知識を引き出し、画像を説明するものです。具体的には、例えば"製油所"というカテゴリラベルが与えられた場合、LLMsから抽出された「製油所には大きな貯蔵タンクや配管などが見られるといった知識」を言語ペアとして使用します。この知識は、シーン内に最も頻繁に出現するエンティティ間の一般的な関係を補完します。私たちはImageNet21Kから、14,000のカテゴリにおいて900万枚の画像と100万の説明からなる新しいVLデータセットIN14KをPiTLを用いて作成しました。経験的に、PiTLで生成されたペアを用いて事前学習されたVLモデルは、画像からテキスト（I2T）およびテキストから画像（T2I）の情報検索タスクにおいて、他のW-VLP研究に比べて強く支持されています。その結果は、VLPにおいてPiTL生成ペアの有効性を明らかにしています。
        </label>
        <input type="checkbox" id="Panel266" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Vision-language (VL) Pre-training (VLP) has shown to well generalize VL models over a wide range of VL downstream tasks, especially for cross-modal retrieval. However, it hinges on a huge amount of image-text pairs, which requires tedious and costly curation. On the contrary,weakly-supervised VLP (W-VLP) explores means with object tags generated by a pre-trained object detector (OD) from images. Yet, they still require paired information, i.e. images and object-level annotations, as supervision to train an OD. To further reduce the amount of supervision, we propose Prompts-in-The-Loop (PiTL) that prompts knowledge from large language models (LLMs) to describe images. Concretely, given a category label of an image, e.g.refinery, the knowledge, e.g.a refinery could be seen with large storage tanks, pipework, and ..., extracted by LLMs is used as the language counterpart. The knowledge supplements, e.g. the common relations among entities most likely appearing in a scene. We create IN14K, a new VL dataset of 9M images and 1M descriptions of 14K categories from ImageNet21K with PiTL. Empirically, the VL models pre-trained with PiTL-generated pairs are strongly favored over other W-VLP works on image-to-text (I2T) and text-to-image (T2I) retrieval tasks, with less supervision. The results reveal the effectiveness of PiTL-generated pairs for VLP.
        </div> </ul> <br>



        <label for="Panel267">
        <strong> Power Norm Based Lifelong Learning for Paraphrase Generations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dingcheng+Li">Dingcheng Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peng+Yang">Peng Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Zhang">Yue Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ping+Li">Ping Li</a> (2) </u>  <br>
        1:  Baidu Research, 2:  Baidu Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592039">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Power Norm Based Lifelong Learning for Paraphrase Generations">Google Scholar</a></div>
        (267)
        <br>
        <b>概要:　</b> 連続学習に基づくシーケンス間翻訳 (seq2seq) 言語生成モデルは、多領域にわたり、連続学習の形式で訓練されます。各領域のデータはオンライン方式で観測されます。連続学習が直面する問題として、破滅的な忘却 (Catastrophic Forgetting) がよく知られています。この課題に対処するため、従来の研究では、経験再生や動的アーキテクチャを利用して過去の知識を強化してきましたが、これにはメモリ空間の増加または高い計算コストが伴います。本研究では、「パワーノルムに基づく連続学習」（PNLLL）と呼ばれる新しいフレームワークを提案し、NLPトランスフォーマーモデルにおけるパワー正規化を活用して破滅的な忘却の問題を解決することを目指します。具体的には、PNLLLはパワーノルムを利用して、過去の経験のリハーサルと新しい知識の取得のバランスをより良く実現します。これにより、新しいタスクへの知識適応と過去のタスクの経験の記憶が可能となります。我々のパラフレーズ生成タスクの実験結果では、PNLLLがSOTA (最先端) モデルをかなりの差で上回り、忘却も大幅に軽減できることが示されました。
        </label>
        <input type="checkbox" id="Panel267" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Lifelong seq2seq language generation models are trained with multiple domains in a lifelong learning manner, with data from each domain being observed in an online fashion. It is a well-known problem that lifelong learning suffers from the catastrophic forgetting (CF). To handle this challenge, existing works have leveraged experience replay or dynamic architecture to consolidate the past knowledge, which however result in incremental memory space or high computational cost. In this work, we propose a novel framework name "power norm based lifelong learning" (PNLLL), which aims to remedy the catastrophic forgetting issues with a power normalization on NLP transformer models. Specifically, PNLLL leverages power norm to achieve a better balance between past experience rehearsal and new knowledge acquisition. These designs enable the knowledge adaptation onto new tasks while memorizing the experience of past tasks. Our experiments on paraphrase generation tasks show that PNLLL not only outperforms SOTA models by a considerable margin and but also largely alleviates forgetting.
        </div> </ul> <br>



        <label for="Panel268">
        <strong> Prediction then Correction: An Abductive Prediction Correction Method for Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yulong+Huang">Yulong Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Zhang">Yang Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qifan+Wang">Qifan Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenxu+Wang">Chenxu Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuli+Feng">Fuli Feng</a> (1) </u>  <br>
        1:  University of Science and Technology of China, 2:  Meta AI <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592040">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Prediction then Correction: An Abductive Prediction Correction Method for Sequential Recommendation">Google Scholar</a></div>
        (268)
        <br>
        <b>概要:　</b> 逐次推奨モデルは、テスト時に予測を一度に生成し、性能向上のための追加の予測補正を考慮しないのが通常です。これは人間が行うような予測補正の方法とは異なります。このモデルの精度を向上させるため、一部の研究者は訓練データの予測誤差を参照してテストデータの予測を修正する、人間の類推的推論を模倣する手法を試みています。しかし、テストデータと訓練データの間には根本的なギャップがあり、このアプローチは信頼性に欠けることがあります。この問題に対処するために、我々は逐次推薦のためのアブダクティブ予測補正（APC）フレームワークを提案します。我々の手法は、アブダクティブ推論をシミュレートして予測を修正します。具体的には、推奨システムが予測した未来の相互作用から最もありそうな過去の相互作用を推定し、推定された過去の相互作用と実際の過去の相互作用とのずれを最小化しながら予測を調整するアブダクティブ推論タスクを設計します。我々は、ニューラルネットワークの順伝播と逆伝播の方法で、反転した逐次モデルを使用してアブダクティブ推論と調整を行います。我々のAPCフレームワークは、さまざまな微分可能な逐次推薦モデルに適用可能です。我々は、三つの基盤モデルに実装し、その有効性を実証しました。コードはhttps://github.com/zyang1580/APCで公開しています。
        </label>
        <input type="checkbox" id="Panel268" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Sequential recommender models typically generate predictions in a single step during testing, without considering additional prediction correction to enhance performance as humans would. To improve the accuracy of these models, some researchers have attempted to simulate human analogical reasoning to correct predictions for testing data by drawing analogies with the prediction errors of similar training data. However, there are inherent gaps between testing and training data, which can make this approach unreliable. To address this issue, we propose an Abductive Prediction Correction (APC) framework for sequential recommendation. Our approach simulates abductive reasoning to correct predictions. Specifically, we design an abductive reasoning task that infers the most probable historical interactions from the future interactions predicted by a recommender, and minimizes the discrepancy between the inferred and true historical interactions to adjust the predictions. We perform the abductive inference and adjustment using a reversed sequential model in the forward and backward propagation manner of neural networks. Our APC framework is applicable to various differentiable sequential recommender models. We implement it on three backbone models and demonstrate its effectiveness. We release the code at https://github.com/zyang1580/APC.
        </div> </ul> <br>



        <label for="Panel269">
        <strong> Priming and Actions: An Analysis in Conversational Search Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Fu">Xiao Fu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Aldo+Lipani">Aldo Lipani</a> (1) </u>  <br>
        1:  University College London <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592041">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Priming and Actions: An Analysis in Conversational Search Systems">Google Scholar</a></div>
        (269)
        <br>
        <b>概要:　</b> 会話システムにおいてユーザーを正確にシミュレートするためには、ユーザーの行動に影響を与える要因を理解することが不可欠です。これは情報検索（IR）分野にとって重要な課題であり、従来の手法は会話の文脈のインタラクティブかつ独自の逐次構造には適していません。本研究では、心理学文献からプライミング効果の概念を用いて、各化された効果に対する主な刺激を特定しました。次に、これらの刺激を様々なデータセットで検証し、ユーザーの行動との相関を調査しました。最終的に、これらの刺激に基づいてロジスティック回帰（LR）モデルを訓練し、ユーザーの行動を予測しました。我々の研究成果は、ユーザーモデルおよびシミュレーターの現実性を高めるための基礎を提供します。具体的には、ユーザーの行動と強い関連性を持つ刺激のサブセットを特定し、ユーザーの行動を予測できるモデルを構築しました。
        </label>
        <input type="checkbox" id="Panel269" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In order to accurately simulate users in conversational systems, it is essential to comprehend the factors that influence their behaviour. This is a critical challenge for the Information Retrieval (IR) field, as conventional methods are not well-suited for the interactive and unique sequential structure of conversational contexts. In this study, we employed the concept of Priming effects from the Psychology literature to identify core stimuli for each abstracted effect. We then examined these stimuli on various datasets to investigate their correlations with users' actions. Finally, we trained Logistic Regression (LR) models based on these stimuli to anticipate users' actions. Our findings offer a basis for creating more realistic user models and simulators, as we identified the subset of stimuli with strong relationships with users' actions. Additionally, we built a model that can predict users' actions.
        </div> </ul> <br>



        <label for="Panel270">
        <strong> Private Meeting Summarization Without Performance Loss </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Seolhwa+Lee">Seolhwa Lee</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anders+Søgaard">Anders Søgaard</a> (2) </u>  <br>
        1:  Technical University of Darmstadt, 2:  University of Copenhagen <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592042">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Private Meeting Summarization Without Performance Loss">Google Scholar</a></div>
        (270)
        <br>
        <b>概要:　</b> 会議には大きなビジネス可能性がありますが、これは困難な問題であるだけでなく、プライバシーに関する懸念が導入を妨げています。我々は、差分プライバシー制約の下での会議の問題を探求し、驚いたことに、差分プライバシーがインサンプルデータでの性能をわずかに低下させる一方で、未見の会議タイプを評価した場合には性能を向上させることを発見しました。会議システムは、実際の運用シナリオで多様な会議タイプに遭遇するため、この発見により、安全な会議がはるかに現実的であると見なせます。我々は広範なエラー解析を実施し、忠実性分析を含む差分プライバシー下での会議における潜在的なリスクを特定しました。
        </label>
        <input type="checkbox" id="Panel270" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Meeting summarization has an enormous business potential, but in addition to being a hard problem, roll-out is challenged by privacy concerns. We explore the problem of meeting summarization under differential privacy constraints and find, to our surprise, that while differential privacy leads to slightly lower performance on in-sample data, differential privacy improves performance when evaluated on unseen meeting types. Since meeting summarization systems will encounter a great variety of meeting types in practical employment scenarios, this observation makes safe meeting summarization seem much more feasible. We perform extensive error analysis and identify potential risks in meeting summarization under differential privacy, including a faithfulness analysis.
        </div> </ul> <br>



        <label for="Panel271">
        <strong> Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Liu">Lei Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jimmy+Xiangji+Huang">Jimmy Xiangji Huang</a> (1) </u>  <br>
        1:  York University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592043">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation">Google Scholar</a></div>
        (271)
        <br>
        <b>概要:　</b> 非英語圏の対話システムはこれまで十分に研究されていませんでした。本論文では、データが限られた非英語のオープンドメイン対話生成における少数ショットクロス言語遷移学習（FS-XLT）と多タスク学習（MTL）の初歩的な調査を行います。予備実験では、すべての6言語においてFS-XLTとMTLで致命的な忘却現象が観察されました。この問題を緩和するために、Pre-trained multilingual language model (mPLM)の多言語性をFS-XLTおよびMTLで維持するシンプルながら効果的なプロンプト学習アプローチを提案します。具体的には、Fixed-prompt LM Tuningと私たちが手作りしたプロンプトを用いて、事前学習とファインチューニングのギャップを埋めます。自動評価及び人間評価の両方に基づく6言語すべてにおける実験結果が、提案手法の有効性を示しています。我々のコードはhttps://github.com/JeremyLeiLiu/XLinguDialにて公開されています。
        </label>
        <input type="checkbox" id="Panel271" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Dialogue systems for non-English languages have long been under-explored. In this paper, we take the first step to investigate few-shot cross-lingual transfer learning (FS-XLT) and multitask learning (MTL) in the context of open-domain dialogue generation for non-English languages with limited data. We observed catastrophic forgetting in both FS-XLT and MTL for all 6 languages in our preliminary experiments. To mitigate the issue, we propose a simple yet effective prompt learning approach that can preserve the multilinguality of multilingual pre-trained language model (mPLM) in FS-XLT and MTL by bridging the gap between pre-training and fine-tuning with Fixed-prompt LM Tuning and our hand-crafted prompts. Experimental results on all 6 languages in terms of both automatic and human evaluations demonstrate the effectiveness of our approach. Our code is available at https://github.com/JeremyLeiLiu/XLinguDial.
        </div> </ul> <br>



        <label for="Panel272">
        <strong> Quantifying and Leveraging User Fatigue for Interventions in Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hitesh+Sagtani">Hitesh Sagtani</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Madan+Gopal+Jhawar">Madan Gopal Jhawar</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Akshat+Gupta">Akshat Gupta</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rishabh+Mehrotra">Rishabh Mehrotra</a> (1) </u>  <br>
        1:  Sharechat <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592044">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Quantifying and Leveraging User Fatigue for Interventions in Recommender Systems">Google Scholar</a></div>
        (272)
        <br>
        <b>概要:　</b> オンラインプラットフォームにおけるユーザーエンゲージメントを維持するためには、離脱予測と介入戦略の設計が重要です。我々は、離脱予測、すなわちユーザーがシステムから離れ戻らない行動が、しばしば遅れて行われ、システムが介入する時期が手遅れになることが多いと仮定しています。そこで、ユーザーが興味を失う早期兆候を検出し、介入のための時間を確保することを提案します。我々は、短期的不満としてのユーザー疲労の新しい定式化を紹介し、長期的な離脱を予測するための早期シグナルを提供します。さらに、疲労を予測するための行動シグナルを特定し、疲労予測のためのモデルを開発しました。加えて、予測された疲労の推定値を活用し、疲労を考慮した広告負荷バランシングの介入戦略を開発し、離脱を減少させ、短期および長期のユーザー維持を改善しました。80百万人以上のユーザーによる200百万セッション以上にわたる複数のライブA/Bテストと展開された推奨システムの結果は、ユーザーエンゲージメントやプラットフォームの戦略的指標の向上を示しています。
        </label>
        <input type="checkbox" id="Panel272" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Predicting churn and designing intervention strategies are crucial for online platforms to maintain user engagement. We hypothesize that predicting churn, i.e. users leaving from the system without further return, is often a delayed act, and it might get too late for the system to intervene. We propose detecting early signs of users losing interest, allowing time for intervention, and introduce a new formulation ofuser fatigue as short-term dissatisfaction, providing early signals to predict long-term churn. We identify behavioral signals predicting fatigue and develop models for fatigue prediction. Furthermore, we leverage the predicted fatigue estimates to develop fatigue-aware ad-load balancing intervention strategy that reduces churn, improving short- and long-term user retention. Results from deployed recommendation system and multiple live A/B tests across over 80 million users generating over 200 million sessions highlight gains for user engagement and platform strategic metrics.
        </div> </ul> <br>



        <label for="Panel273">
        <strong> Quantifying Ranker Coverage of Different Query Subspaces </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Negar+Arabzadeh">Negar Arabzadeh</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Amin+Bigdeli">Amin Bigdeli</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Radin+Hamidi+Rad">Radin Hamidi Rad</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ebrahim+Bagheri">Ebrahim Bagheri</a> (2) </u>  <br>
        1:  University of Waterloo, 2:  Toronto Metropolitan University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592045">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Quantifying Ranker Coverage of Different Query Subspaces">Google Scholar</a></div>
        (273)
        <br>
        <b>概要:　</b> ニューラルアーキテクチャの導入により、情報検索コミュニティでは様々なタスクにおいて顕著なパフォーマンス向上が観察されています。しかし、そのような向上は全てのクエリに対して均等に起こっているわけではないようです。本論文では実証的に示すように、ニューラルランカーのパフォーマンスは長尾分布に従い、多くのクエリサブセットでは効果的に処理されていません。それにもかかわらず、パフォーマンスは通常、MRRやnDCGといった標準的な検索指標を用いて報告され、これらは全てのクエリに対する平均的なパフォーマンスを捉えています。そのため、報告される改善が、既存の手法で既に良好に機能しているクエリの小さなサブセットに対する漸進的なブーストによるものなのか、それとも困難だったクエリに対する解決策であるのか不明確です。本論文では、タスク部分空間カバレッジ (Task Subspace Coverage, TaSC) 指標を提案します。これは、異なるランカーに対して同様または異なるクエリ部分空間での検索の有効性の改善が、どの程度行われているかを体系的に定量化するものです。我々の実験は、既存のランキング指標と併用したTaSC指標の考慮が、ランカーのパフォーマンスと既存タスクにおける全体的な進展への貢献について、より深い洞察を提供することを示しています。
        </label>
        <input type="checkbox" id="Panel273" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The information retrieval community has observed significant performance improvements over various tasks due to the introduction of neural architectures. However, such improvements do not necessarily seem to have happened uniformly across a range of queries. As we will empirically show in this paper, the performance of neural rankers follow a long-tail distribution where there are many subsets of queries, which are not effectively satisfied by neural methods. Despite this observation, performance is often reported using standard retrieval metrics, such as MRR or nDCG, which capture average performance over all queries. As such, it is not clear whether reported improvements are due to incremental boost on a small subset of already well-performing queries or addressing queries that have been difficult to address by existing methods. In this paper, we propose the Task Subspace Coverage (TaSC /tAHsk/) metric, which systematically quantifies whether and to what extent improvements in retrieval effectiveness happen on similar or disparate query subspaces for different rankers. Our experiments show that the consideration of our proposed TaSC metric in conjunction with existing ranking metrics provides deeper insight into ranker performance and their contribution to overall advances on a given task.
        </div> </ul> <br>



        <label for="Panel274">
        <strong> Query-specific Variable Depth Pooling via Query Performance Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Debasis+Ganguly">Debasis Ganguly</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Emine+Yilmaz">Emine Yilmaz</a> (2) </u>  <br>
        1:  University of Glasgow, 2:  University College London <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592046">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Query-specific Variable Depth Pooling via Query Performance Prediction">Google Scholar</a></div>
        (274)
        <br>
        <b>概要:　</b> テストコレクションの大規模さのため、情報検索（IR）の評価において一般的な手法は、さまざまな検索システムによって取得された上位k件のドキュメントからなる「プール」を構築することです。この手法はdepth-kプーリングと呼ばれています。通常、ベンチマークセットを構成する各クエリに対して深度（k）を一定の値に設定します。しかし、本論文では、プールの深度を各クエリごとに可変にすることで、注釈作業を大幅に削減できると主張します。理由は、情報ニーズに対する関連ドキュメントの数はクエリによって大きく異なることが多いためです。我々の仮説は、関連ドキュメントが少ないクエリに対しては浅い深度を使用し、関連ドキュメントが多いクエリに対しては深い深度を使用することで、IRの効果評価に大きな変化をもたらすことなく、注釈作業を削減できる可能性があるというものです。我々は標準的なクエリ性能予測（QPP）技術を用いて各クエリに対して潜在的に関連するドキュメントの数を推定し、その数を基にプールの深度を決定します。標準的なテストコレクションで行った実験は、クエリごとに変動する深度を採用するこの提案手法が、実質的に少ない注釈作業でIRシステムの相対的な有効性を適切に反映できることを示しています。
        </label>
        <input type="checkbox" id="Panel274" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Due to the massive size of test collections, a standard practice in IR evaluation is to construct a 'pool' of candidate relevant documents comprised of the top-k documents retrieved by a wide range of different retrieval systems - a process called depth-k pooling. A standard practice is to set the depth (k) to a constant value for each query constituting the benchmark set. However, in this paper we argue that the annotation effort can be substantially reduced if the depth of the pool is made a variable quantity for each query, the rationale being that the number of documents relevant to the information need can widely vary across queries. Our hypothesis is that a lower depth for queries with a small number of relevant documents, and a higher depth for those with a larger number of relevant documents can potentially reduce the annotation effort without a significant change in IR effectiveness evaluation.We make use of standard query performance prediction (QPP) techniques to estimate the number of potentially relevant documents for each query, which is then used to determine the depth of the pool. Our experiments conducted on standard test collections demonstrate that this proposed method of employing query-specific variable depths is able to adequately reflect the relative effectiveness of IR systems with a substantially smaller annotation effort.
        </div> </ul> <br>



        <label for="Panel275">
        <strong> RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Honglei+Zhuang">Honglei Zhuang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhen+Qin">Zhen Qin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rolf+Jagerman">Rolf Jagerman</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kai+Hui">Kai Hui</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ji+Ma">Ji Ma</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jing+Lu">Jing Lu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianmo+Ni">Jianmo Ni</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuanhui+Wang">Xuanhui Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michael+Bendersky">Michael Bendersky</a> (1) </u>  <br>
        1:  Google Research, 2:  Google Research, 3:  Google Research, 4:  Google Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592047">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=RankT5: Fine-Tuning T5 for Text Ranking with Ranking Losses">Google Scholar</a></div>
        (275)
        <br>
        <b>概要:　</b> BERTのような事前学習済み言語モデルは、テキストランキングに非常に効果的であることが示されていますが、T5のようなより強力なシーケンス・ツー・シーケンスモデルをどのように活用するかについての研究は限られています。現行の取り組みでは、テキストランキングを分類問題として定式化し、ランク付けリストを得るために後処理に依存しています。本稿では、RankT5を提案し、エンコーダーデコーダー構造とエンコーダーのみの2つのT5ベースのランキングモデル構造を研究します。これらは、各クエリ・ドキュメントペアのランキングスコアを直接出力できるだけでなく、ペアワイズまたはリストワイズのランキング損失で微調整してランキング性能を最適化することもできます。我々の実験では、提案されたモデルがランキング損失と共に用いることで、異なる公開テキストランキングデータセットで実質的なランキング性能向上を達成できることが示されました。さらに、リストワイズランキング損失で微調整されたランキングモデルは、分類損失で微調整されたモデルよりも、未知領域データに対するゼロショットランキング性能が優れています。
        </label>
        <input type="checkbox" id="Panel275" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Pretrained language models such as BERT have been shown to be exceptionally effective for text ranking. However, there are limited studies on how to leverage more powerful sequence-to-sequence models such as T5. Existing attempts usually formulate text ranking as a classification problem and rely on postprocessing to obtain a ranked list. In this paper, we propose RankT5 and study two T5-based ranking model structures, an encoder-decoder and an encoder-only one, so that they not only can directly output ranking scores for each query-document pair, but also can be fine-tuned with pairwise or listwise ranking losses to optimize ranking performance. Our experiments show that the proposed models with ranking losses can achieve substantial ranking performance gains on different public text ranking data sets. Moreover, ranking models fine-tuned with listwise ranking losses have better zero-shot ranking performance on out-of-domain data than models fine-tuned with classification losses.
        </div> </ul> <br>



        <label for="Panel276">
        <strong> Rating Prediction in Conversational Task Assistants with Behavioral and Conversational-Flow Features </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rafael+Ferreira">Rafael Ferreira</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=David+Semedo">David Semedo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=João+Magalhães">João Magalhães</a> (1) </u>  <br>
        1:  NOVA University of Lisbon <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592048">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Rating Prediction in Conversational Task Assistants with Behavioral and Conversational-Flow Features">Google Scholar</a></div>
        (276)
        <br>
        <b>概要:　</b> 会話型タスクアシスタント（Conversational Task Assistants, CTA）の成功を予測することは、ユーザーの行動を理解し、それに応じた対応をする上で不可欠です。本論文では、CTAシナリオにおいてユーザーの評価を予測するために、会話の流れに関する特徴とユーザー行動の特徴を組み合わせたTransformerモデルであるTB-Raterを提案します。特に、Alexa TaskBotチャレンジで収集されたリアルな人間とエージェントの会話と評価を用います。このチャレンジは新しいマルチモーダルおよびマルチターンの会話文脈です。結果から、会話の流れと行動の両側面を単一のモデルでオフライン評価予測に取り込むことの利点が示されました。さらに、CTAに特有の行動特徴の分析は、この環境に関する洞察を提供し、将来のシステムの立ち上げに活用できる可能性があります。
        </label>
        <input type="checkbox" id="Panel276" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Predicting the success of Conversational Task Assistants (CTA) can be critical to understand user behavior and act accordingly. In this paper, we propose TB-Rater, a Transformer model which combines conversational-flow features with user behavior features for predicting user ratings in a CTA scenario. In particular, we use real human-agent conversations and ratings collected in the Alexa TaskBot challenge, a novel multimodal and multi-turn conversational context. Our results show the advantages of modeling both the conversational-flow and behavioral aspects of the conversation in a single model for offline rating prediction. Additionally, an analysis of the CTA-specific behavioral features brings insights into this setting and can be used to bootstrap future systems.
        </div> </ul> <br>



        <label for="Panel277">
        <strong> Read it Twice: Towards Faithfully Interpretable Fact Verification by Revisiting Evidence </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuming+Hu">Xuming Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaochen+Hong">Zhaochen Hong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhijiang+Guo">Zhijiang Guo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lijie+Wen">Lijie Wen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philip+Yu">Philip Yu</a> (3) </u>  <br>
        1:  Tsinghua University, 2:  University of Cambridge, 3:  University of Illinois at Chicago <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592049">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Read it Twice: Towards Faithfully Interpretable Fact Verification by Revisiting Evidence">Google Scholar</a></div>
        (277)
        <br>
        <b>概要:　</b> 実世界の事実検証のタスクは、情報元の文書から証拠を取得することで、主張の事実性を検証することを目的としています。取得された証拠の質は、主張検証において重要な役割を果たします。理想的には、取得された証拠は信頼性（主張検証の過程を反映したものであること）と説得力（人間にとって納得できるものであること）を備え、検証タスクの精度を向上させるべきです。既存のアプローチは、主張と文書間の意味的または表面的な類似性の尺度を利用して証拠を取得しますが、それらすべては特定のヒューリスティックスに依存しており、これら三つの要件を全て満たすことはできません。この観点から、我々はReReadという事実検証モデルを提案します。このモデルは、以下のステップを踏んで証拠を取得し、主張を検証します：（1）証拠取得器を訓練して、解釈可能な証拠（すなわち信頼性と説得力の基準）を取得させる。（2）最適化された証拠取得器によって取得された証拠を再訪し、主張検証器を訓練することによって精度を向上させる。提案されたシステムは、異なる設定において報告されている最良のモデルに対して有意な改善を達成することができます。
        </label>
        <input type="checkbox" id="Panel277" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Real-world fact verification task aims to verify the factuality of a claim by retrieving evidence from the source document. The quality of the retrieved evidence plays an important role in claim verification. Ideally, the retrieved evidence should be faithful (reflecting the model's decision-making process in claim verification) and plausible (convincing to humans), and can improve the accuracy of verification task. Although existing approaches leverage the similarity measure of semantic or surface form between claims and documents to retrieve evidence, they all rely on certain heuristics that prevent them from satisfying all three requirements. In light of this, we propose a fact verification model named ReRead to retrieve evidence and verify claim that: (1) Train the evidence retriever to obtain interpretable evidence (i.e., faithfulness and plausibility criteria); (2) Train the claim verifier to revisit the evidence retrieved by the optimized evidence retriever to improve the accuracy. The proposed system is able to achieve significant improvements upon best-reported models under different settings.
        </div> </ul> <br>



        <label for="Panel278">
        <strong> Reducing Spurious Correlations for Relation Extraction by Feature Decomposition and Semantic Augmentation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tianshu+Yu">Tianshu Yu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Min+Yang">Min Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chengming+Li">Chengming Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruifeng+Xu">Ruifeng Xu</a> (3) </u>  <br>
        1:  SIAT, 2:  Shenzhen MSU-BIT University, 3:  Harbin Institute of Technology (Shenzhen) <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592050">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Reducing Spurious Correlations for Relation Extraction by Feature Decomposition and Semantic Augmentation">Google Scholar</a></div>
        (278)
        <br>
        <b>概要:　</b> 深層ニューラルモデルは関係抽出（RE）の分野で主流となり、最先端の性能を発揮しています。しかし、既存の多くのニューラルモデルは入力特徴と予測ラベルの間の偽相関に陥りやすく、これによりモデルのロバスト性や汎化性能が低下します。本論文では、特徴分解とセマンティック強化（FDSAと表現）の手法を用いて、REにおける偽相関を低減する方法を提案します。まず、元の文章表現をクラス関連の特徴と文脈関連の特徴に分解します。より良い文脈関連の特徴を得るために、コントラスト学習法を考案し、アンカー文とその強化文の文脈関連特徴を引き寄せ、異なるアンカー文の文脈関連特徴を遠ざけます。さらに、REモデルのロバスト性を向上させるために、文脈関連の特徴に対する勾配ベースのセマンティック強化を提案します。4つのデータセットに関する実験では、我々のモデルが強力な競合モデルを上回る性能を示しました。
        </label>
        <input type="checkbox" id="Panel278" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Deep neural models have become mainstream in relation extraction (RE), yielding state-of-the-art performance. However, most existing neural models are prone to spurious correlations between input features and prediction labels, making the models suffer from low robustness and generalization.In this paper, we propose a spurious correlation reduction method for RE via feature decomposition and semantic augmentation (denoted as FDSA). First, we decompose the original sentence representation into class-related features and context-related features. To obtain better context-related features, we devise a contrastive learning method to pull together the context-related features of the anchor sentence and its augmented sentences, and push away the context-related features of different anchor sentences. In addition, we propose gradient-based semantic augmentation on context-related features in order to improve the robustness of the RE model. Experiments on four datasets show that our model outperforms the strong competitors.
        </div> </ul> <br>



        <label for="Panel279">
        <strong> Representation Sparsification with Hybrid Thresholding for Fast SPLADE-based Document Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yifan+Qiao">Yifan Qiao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yingrui+Yang">Yingrui Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shanxiu+He">Shanxiu He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tao+Yang">Tao Yang</a> (1) </u>  <br>
        1:  University of California <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592051">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Representation Sparsification with Hybrid Thresholding for Fast SPLADE-based Document Retrieval">Google Scholar</a></div>
        (279)
        <br>
        <b>概要:　</b> Transformerベースのニューラルモデルを用いたスパース文書表現は、関連性の効果と時間効率の両面で魅力的であることが示されています。本論文では、SPLADEベースの文書検索を高速化するための反転インデックス近似を用いたハードおよびソフト閾値処理に基づく表現のスパース化手法について記述します。この学習可能なハイブリッド閾値処理手法の影響について、分析および実験結果を提供します。
        </label>
        <input type="checkbox" id="Panel279" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Learned sparse document representations using a transformer-based neural model has been found to be attractive in both relevance effectiveness and time efficiency. This paper describes a representation sparsification scheme based on hard and soft thresholding with an inverted index approximation for faster SPLADE-based document retrieval. It provides analytical and experimental results on the impact of this learnable hybrid thresholding scheme.
        </div> </ul> <br>



        <label for="Panel280">
        <strong> Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Donghan+Yu">Donghan Yu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiming+Yang">Yiming Yang</a> (1) </u>  <br>
        1:  Carnegie Mellon University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592052">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion">Google Scholar</a></div>
        (280)
        <br>
        <b>概要:　</b> 知識グラフ補完（KGC）の課題は非常に重要です。大規模な知識グラフを処理する際の拡張性を達成するために、最近の研究ではKGCをシーケンス・ツー・シーケンスのプロセスとして定式化しており、不完全な三項（入力）と欠けているエンティティ（出力）の両方をテキストシーケンスとして言語化しています。しかし、これらの方法による推論はモデルのパラメータのみに依存して暗黙的な推論を行うため、知識グラフ自体の利用を怠っており、モデルが大量の三項を記憶する能力に欠けているため、性能が制限されます。この問題に対処するために、我々はReSKGC（Retrieval-enhanced Seq2seq KGC）モデルを紹介します。このモデルは、知識グラフから意味的に関連する三項を選択し、それらを証拠として使用して明示的な推論で出力生成を導きます。我々の方法は、約500万と9000万のエンティティを含むベンチマークデータセットWikidata5MおよびWikiKG90Mv2で最先端の性能を示しました。
        </label>
        <input type="checkbox" id="Panel280" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The task of knowledge graph completion (KGC) is of great importance. To achieve scalability when dealing with large-scale knowledge graphs, recent works formulate KGC as a sequence-to-sequence process, where the incomplete triplet (input) and the missing entity (output) are both verbalized as text sequences. However, inference with these methods relies solely on the model parameters for implicit reasoning and neglects the use of KG itself, which limits the performance since the model lacks the capacity to memorize a vast number of triplets. To tackle this issue, we introduce ReSKGC, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning. Our method has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2, which contain about 5M and 90M entities, respectively.
        </div> </ul> <br>



        <label for="Panel281">
        <strong> Review-based Multi-intention Contrastive Learning for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Yang">Wei Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tengfei+Huo">Tengfei Huo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Liu">Zhiqiang Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chi+Lu">Chi Lu</a> (3) </u>  <br>
        1:  Institute of Automation, 2:  Institute of Computing Technology, 3:  Kuaishou Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592053">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Review-based Multi-intention Contrastive Learning for Recommendation">Google Scholar</a></div>
        (281)
        <br>
        <b>概要:　</b> 実際のレコメンデーションシステムには、多数の特徴量が存在し、それらは多くの場合、高次元でスパースな上に、効果的に学習するのが難しいです。数値的な特徴量に加えて、ユーザーレビューにはユーザーの好みを含むリッチなセマンティック情報が含まれており、研究者はこれを補助的な特徴量として利用しています。レビューに基づいてデータ特徴を補完する方法には一定の効果がありますが、ほとんどの場合、レビューの表現と他の特徴を単純に連結するだけであり、テキスト表現には多くのノイズ情報が含まれている点を考慮していません。さらに、ユーザーレビューに含まれる重要な意図が効果的にモデル化されていません。これらの問題を解決するために、我々は新しいレビュー基盤の多意図対比学習（RMCL）方法を提案します。具体的には、RMCLは混合ガウス分布仮説に基づく意図表現方法を提案します。さらに、RMCLは多意図対比戦略を採用し、ユーザーレビューとアイテムレビュー間の詳細な接続を確立します。5つの現実世界のデータセットにおける広範な実験結果は、提案するRMCLモデルが最新の方法に比べて顕著な改善を示すことを実証しています。
        </label>
        <input type="checkbox" id="Panel281" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Real recommendation systems contain various features, which are often high-dimensional, sparse, and difficult to learn effectively. In addition to numerical features, user reviews contain rich semantic information including user preferences, which are used as auxiliary features by researchers. The methods of supplementing data features based on reviews have certain effects. However, most of them simply concatenate review representations and other features together, without considering that the text representation contains a lot of noise information. In addition, the important intentions contained in user reviews are not modeled effectively. In order to solve the above problems, we propose a novel Review-based Multi-intention Contrastive Learning (RMCL) method. In detail, RMCL proposes an intention representation method based on mixed Gaussian distribution hypothesis. Further, RMCL adopts a multi-intention contrastive strategy, which establishes a fine-grained connection between user reviews and item reviews. Extensive experiments on five real-world datasets demonstrate significant improvements of our proposed RMCL model over the state-of-the-art methods.
        </div> </ul> <br>



        <label for="Panel282">
        <strong> RewardTLG: Learning to Temporally Language Grounding from Flexible Reward </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yawen+Zeng">Yawen Zeng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Keyu+Pan">Keyu Pan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ning+Han">Ning Han</a> (2) </u>  <br>
        1:  ByteDance AI Lab, 2:  Xiangtan University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592054">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=RewardTLG: Learning to Temporally Language Grounding from Flexible Reward">Google Scholar</a></div>
        (282)
        <br>
        <b>概要:　</b> ユーザーが提供したテキスト文に基づいて、Temporal Language Grounding (TLG) タスクはトリミングされていないビデオから意味的に関連する瞬間やクリップを見つけるプロセスとして定義されます。近年、強化学習を用いてビデオからクリップを特定するローカリゼーションベースのTLG手法が研究されています。しかし、強化学習の確率的探索メカニズムにより、これらの手法は報酬に対して敏感であり、十分に安定していません。そのため、より柔軟で合理的な報酬を提供することが、学界および産業界の注目点となっています。ChatGPTのトレーニングプロセスに触発されて、我々は視覚と言語の事前学習（VLP）モデルを報酬モデルとして革新的に採用し、ローカリゼーションベースのTLGタスクを収束させるために柔軟な報酬を提供します。具体的には、強化学習ベースのローカリゼーションモジュールを導入し、マルチモーダルなシナリオで開始と終了のタイムスタンプを予測します。その後、VLPモデルに基づいた報酬モデルを微調整し、場合によっては人間のフィードバックも取り入れて、ローカリゼーションモジュールに柔軟な報酬スコアを提供します。この方法により、我々のモデルはトリミングされていないビデオの微妙な違いを捉えることができます。2つのデータセットでの広範な実験により、我々の提案するソリューションの有効性が十分に検証されました。
        </label>
        <input type="checkbox" id="Panel282" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Given a textual sentence provided by a user, the Temporal Language Grounding (TLG) task is defined as the process of finding a semantically relevant video moment or clip from an untrimmed video. In recent years, localization-based TLG methods have been explored, which adopt reinforcement learning to locate a clip from the video. However, these methods are not stable enough due to the stochastic exploration mechanism of reinforcement learning, which is sensitive to the reward. Therefore, providing a more flexible and reasonable reward has become a focus of attention for both academia and industry. Inspired by the training process of chatGPT, we innovatively adopt a vision-language pre-training (VLP) model as a reward model, which provides flexible rewards to help the localization-based TLG task converge. Specifically, a reinforcement learning-based localization module is introduced to predict the start and end timestamps in multi-modal scenarios. Thereafter, we fine-tune a reward model based on a VLP model, even introducing some human feedback, which provides a flexible reward score for the localization module. In this way, our model is able to capture subtle differences of the untrimmed video. Extensive experiments on two datasets have well verified the effectiveness of our proposed solution.
        </div> </ul> <br>



        <label for="Panel283">
        <strong> Robust Causal Inference for Recommender System to Overcome Noisy Confounders </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiheng+Zhang">Zhiheng Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Quanyu+Dai">Quanyu Dai</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xu+Chen">Xu Chen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenhua+Dong">Zhenhua Dong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruiming+Tang">Ruiming Tang</a> (2) </u>  <br>
        1:  Institute for Interdisciplinary Information Sciences (IIIS), 2:  Huawei Noah's Ark Lab, 3:  Gaoling School of Artificial Intelligence <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592055">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Robust Causal Inference for Recommender System to Overcome Noisy Confounders">Google Scholar</a></div>
        (283)
        <br>
        <b>概要:　</b> 近年、因果推論をレコメンダーシステムに統合し、「ユーザーに製品が推薦された場合の潜在的なフィードバックは何か？」という仮説的質問に答えることへの関心が高まっています。これに対処するために、逆傾向スコア（IPS）や二重ロバスト性（DR）など、さまざまな偏りのない推定器が提案されています。しかし、これらの推定器はしばしば、交絡因子が正確に観測可能であるという前提に依存しており、実際のシナリオでは必ずしもそうではありません。この課題に対処するため、我々はノイズのある交絡因子を取り扱うための対抗訓練ベースの新しい手法であるAT-IPS（Adversarial Training-based IPS）を提案します。提案手法では、交絡因子のための実現可能領域を定義し、その領域内で最悪のケースとなるノイズ（対抗ノイズ）を取得し、そのノイズに対して傾向モデルと予測モデルを共同訓練してロバスト性を向上させます。我々は、AT-IPSの精度とロバスト性のトレードオフに関する理論的な分析を提供し、実世界および半合成データセットにおいて他の一般的な推定器に比べて優れた性能を実証します。
        </label>
        <input type="checkbox" id="Panel283" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recently, there has been growing interest in integrating causal inference into recommender systems to answer the hypothetical question: "what would be the potential feedback when a user is recommended a product?" Various unbiased estimators, including Inverse Propensity Score (IPS) and Doubly Robust (DR), have been proposed to address this question. However, these estimators often assume that confounders are precisely observable, which is not always the case in real-world scenarios. To address this challenge, we propose a novel method called Adversarial Training-based IPS (AT-IPS), which uses adversarial training to handle noisy confounders. The proposed method defines a feasible region for the confounders, obtains the worst-case noise (adversarial noise) within the region, and jointly trains the propensity model and the prediction model against such noise to improve their robustness. We provide a theoretical analysis of the accuracy-robustness tradeoff of AT-IPS and demonstrate its superior performance compared to other popular estimators on both real-world and semi-synthetic datasets.
        </div> </ul> <br>



        <label for="Panel284">
        <strong> Rows or Columns? Minimizing Presentation Bias When Comparing Multiple Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Patrik+Dokoupil">Patrik Dokoupil</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ladislav+Peska">Ladislav Peska</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ludovico+Boratto">Ludovico Boratto</a> (2) </u>  <br>
        1:  Faculty of Mathematics and Physics, 2:  University of Cagliari <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592056">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Rows or Columns? Minimizing Presentation Bias When Comparing Multiple Recommender Systems">Google Scholar</a></div>
        (284)
        <br>
        <b>概要:　</b> レコメンダーシステムの評価において、正確度を超えて評価することがますます注目されるようになっています。多くの考慮すべき視点の中で、提示バイアスの影響は中心的な重要性を持ちます。提示バイアスの下では、ユーザーが推薦リスト内のアイテムに対する注意が変わり、それによってそれらが考慮される可能性やモデルの効果に影響を与えます。ページ単位の被験者内研究はレコメンダーシステムの文献で広く使用されており、アルゴリズムを平行に比較するためにその結果を表示します。しかし、この文脈における提示バイアスの影響を評価する研究はこれまで行われていません。本論文では、提示バイアスが列または行という異なるレイアウトオプションにどのように影響するかを特徴づけます。具体的には、6つのレイアウトバリアントをユーザーに提示し、ページ単位の被験者内設定で推薦結果の認識を評価するユーザー研究を紹介します。結果は、提示バイアスがユーザーのクリック行動（低レベルのフィードバック）には影響を与えるが、レコメンダーシステムの知覚性能（高レベルのフィードバック）にはあまり影響を与えないことを示しています。ソースコードと生データは、https://tinyurl.com/PresBiasSIGIR2023 で利用可能です。
        </label>
        <input type="checkbox" id="Panel284" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Going beyond accuracy in the evaluation of a recommender system is an aspect that is receiving more and more attention. Among the many perspectives that can be considered, the impact of presentation bias is of central importance. Under presentation bias, the attention of the users to the items in a recommendation list changes, thus affecting their possibility to be considered and the effectiveness of a model. Page-wise within-subject studies are widely employed in the recommender systems literature to compare algorithms by displaying their results in parallel. However, no study has ever been performed to assess the impact of presentation bias in this context. In this paper, we characterize how presentation bias affects different layout options, which present the results in column- or row-wise fashion. Concretely, we present a user study where six layout variants are proposed to the users in a page-wise within-subject setting, so as to evaluate their perception of the displayed recommendations. Results show that presentation bias impacts users clicking behavior (low-level feedback), but not so much the perceived performance of a recommender system (high-level feedback). Source codes and raw results are available at https://tinyurl.com/PresBiasSIGIR2023.
        </div> </ul> <br>



        <label for="Panel285">
        <strong> Searching for Products in Virtual Reality: Understanding the Impact of Context and Result Presentation on User Experience </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Austin+Ward">Austin Ward</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sandeep+Avula">Sandeep Avula</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao-Fei+Cheng">Hao-Fei Cheng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sheikh+Muhammad+Sarwar">Sheikh Muhammad Sarwar</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Vanessa+Murdock">Vanessa Murdock</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Eugene+Agichtein">Eugene Agichtein</a> (2) </u>  <br>
        1:  UNC Chapel Hill, 2:  Amazon <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592057">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Searching for Products in Virtual Reality: Understanding the Impact of Context and Result Presentation on User Experience">Google Scholar</a></div>
        (285)
        <br>
        <b>概要:　</b> バーチャルリアリティ（VR）やヘッドマウントディスプレイ（HMD）などの没入技術は、近年普及が進んでいます。本研究では、音声クエリを通じてVRでのショッピング体験に影響を与える2つの要因、すなわち（1）検索環境のコンテキスト整合性と（2）検索エンジン結果ページ（SERP）の詳細度、を調査しました。この目的のために、我々はVR用の検索システムを開発し、被験者内探索研究（N=18）を実施して、2つの実験条件の影響を理解しました。我々の結果は、コンテキスト整合性とSERPの両方がVRにおける情報探索において重要な要素であり、独自の機会と課題を提示することを示唆しています。具体的には、我々の発見に基づき、VR用の検索システムは次の点を重視すべきことを提案します：（1）VR環境とSERPの両方での情報探索の手掛かりを提供する、（2）VR環境と検索インターフェースの間での注意を分散させる、（3）VR環境内の気を散らす要素を減少させる、（4）VR環境での検索に「コントロール感」を提供する。
        </label>
        <input type="checkbox" id="Panel285" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Immersive technologies such as virtual reality (VR) and head-mounted displays (HMD) have seen increased adoption in recent years. In this work, we study two factors that influence users' experience when shopping in VR through voice queries: (1) context alignment of the search environment and (2) the level of detail on the Search Engine Results Page (SERP). To this end, we developed a search system for VR and conducted a within-subject exploratory study (N=18) to understand the impact of the two experimental conditions. Our results suggest that both context alignment and SERP are important factors for information-seeking in VR, which present unique opportunities and challenges. More specifically, based on our findings, we suggest that search systems for VR must be able to: (1) provide cues for information-seeking in both the VR environment and SERP, (2) distribute attention between the VR environment and the search interface, (3) reduce distractions in the VR environment and (4) provide a ''sense of control'' to search in the VR environment.
        </div> </ul> <br>



        <label for="Panel286">
        <strong> SelfLRE: Self-refining Representation Learning for Low-resource Relation Extraction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuming+Hu">Xuming Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junzhe+Chen">Junzhe Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shiao+Meng">Shiao Meng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lijie+Wen">Lijie Wen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philip+S.+Yu">Philip S. Yu</a> (2) </u>  <br>
        1:  Tsinghua University, 2:  University of Illinois at Chicago <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592058">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SelfLRE: Self-refining Representation Learning for Low-resource Relation Extraction">Google Scholar</a></div>
        (286)
        <br>
        <b>概要:　</b> 低リソース関係抽出（LRE）は、人間のアノテーションが少ない問題を解決するために、限られたラベル付きコーパスから潜在的な関係を抽出することを目指しています。従来の研究は主に以下の2つの方法に分けられます：(1) 自己学習法: モデルの予測を通じて自身を改善しますが、予測が間違っている場合には確認バイアスの問題に悩まされます。(2) 自己アンサンブリング法: タスク非依存の表現を学習しようとしますが、特定のタスクにはあまり適しません。本研究では、新しいLREアーキテクチャ「SelfLRE」を提案します。これは2つの補完的なモジュールを活用しており、一つのモジュールは自己学習を用いて未ラベルデータに対する疑似ラベルを取得し、もう一つのモジュールは自己アンサンブリング学習を用いてタスク非依存の表現を取得し、既存の疑似ラベルを活用して未ラベルデータにおけるより良いタスク固有の表現を洗練させます。これらの2つのモジュールはマルチタスク学習を通じて共同で訓練され、LREタスクの効果を反復的に向上させます。3つの公開データセットで行った実験では、SelfLREがSOTAベースラインに対して1.81％のパフォーマンス向上を達成しました。ソースコードは以下のリンクにて公開されています：https://github.com/THU-BPM/SelfLRE。
        </label>
        <input type="checkbox" id="Panel286" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Low-resource relation extraction (LRE) aims to extract potential relations from limited labeled corpus to handle the problem of scarcity of human annotations. Previous works mainly consist of two categories of methods: (1) Self-training methods, which improve themselves through the models' predictions, thus suffering from confirmation bias when the predictions are wrong. (2) Self-ensembling methods, which learn task-agnostic representations, therefore, generally do not work well for specific tasks. In our work, we propose a novel LRE architecture named SelfLRE, which leverages two complementary modules, one module uses self-training to obtain pseudo-labels for unlabeled data, and the other module uses self-ensembling learning to obtain the task-agnostic representations, and leverages the existing pseudo-labels to refine the better task-specific representations on unlabeled data. The two models are jointly trained through multi-task learning to iteratively improve the effect of LRE task. Experiments on three public datasets show that SelfLRE achieves 1.81% performance gain over the SOTA baseline. Source code is available at: https://github.com/THU-BPM/SelfLRE.
        </div> </ul> <br>



        <label for="Panel287">
        <strong> Sharpness-Aware Graph Collaborative Filtering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huiyuan+Chen">Huiyuan Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chin-Chia+Michael+Yeh">Chin-Chia Michael Yeh</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yujie+Fan">Yujie Fan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yan+Zheng">Yan Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junpeng+Wang">Junpeng Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Vivian+Lai">Vivian Lai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mahashweta+Das">Mahashweta Das</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Yang">Hao Yang</a> (1) </u>  <br>
        1:  Visa Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592059">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Sharpness-Aware Graph Collaborative Filtering">Google Scholar</a></div>
        (287)
        <br>
        <b>概要:　</b> グラフニューラルネットワーク（GNNs）は、協調フィルタリングにおいて優れた性能を発揮しています。しかし、最近の研究では、トレーニングデータとテストデータの分布がうまく一致していない場合、GNNsは性能が低下する傾向があることが示されています。さらに、GNNsのトレーニングには非凸ニューラルネットワークの最適化が必要であり、その中には局所的およびグローバルな極小値が多数存在し、テスト時の性能に大きな違いが出る可能性があります。したがって、未見データに対して強い一般化性能を発揮する極小値を慎重に選択できる最適化戦略を開発することが重要です。本研究では、鋭い極小値よりも平坦な極小値の方が一般化能力が優れているという原則に基づき、有効なトレーニングスキーマ「gSAM」を提案します。この目標を達成するために、gSAMは、重み損失のランドスケープの平坦性を規制する二層最適化を形成します。外層問題では標準的なモデルトレーニングを行い、内層問題ではモデルが鋭い極小値から抜け出すことを支援します。実験結果は、我々のgSAMの優位性を示しています。
        </label>
        <input type="checkbox" id="Panel287" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Graph Neural Networks (GNNs) have achieved impressive performance in collaborative filtering. However, recent studies show that GNNs tend to yield inferior performance when the distributions of training and test data are not aligned well. Moreover, training GNNs often requires optimizing non-convex neural networks with an abundance of local and global minima, which may differ widely in their performance at test time. Thus, it is essential to develop an optimization strategy that can choose the minima carefully, which can yield strong generalization performance on unseen data. Here we propose an effective training schema, called gSAM, under the principle that theflatter minima has a better generalization ability than thesharper ones. To achieve this goal, gSAM regularizes the flatness of the weight loss landscape by forming a bi-level optimization: the outer problem conducts the standard model training while the inner problem helps the model jump out of the sharp minima. Experimental results show the superiority of our gSAM.
        </div> </ul> <br>



        <label for="Panel288">
        <strong> Simple Approach for Aspect Sentiment Triplet Extraction Using Span-Based Segment Tagging and Dual Extractors </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongxu+Li">Dongxu Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhihao+Yang">Zhihao Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuquan+Lan">Yuquan Lan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunqi+Zhang">Yunqi Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hui+Zhao">Hui Zhao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gang+Zhao">Gang Zhao</a> (3) </u>  <br>
        1:  East China Normal University, 2:  Shanghai Key Laboratory of Trustworthy Computing, 3:  Microsoft <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592060">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Simple Approach for Aspect Sentiment Triplet Extraction Using Span-Based Segment Tagging and Dual Extractors">Google Scholar</a></div>
        (288)
        <br>
        <b>概要:　</b> アスペクト感情三重項抽出（ASTE）は、レビューの文章からアスペクト項目、意見項目、および感情の極性を三重項として抽出するタスクです。従来のアプローチでは、項目の相互作用のために双方向構造を開発してきました。感情の極性はアスペクト-意見ペアからその後に抽出されます。しかし、これらの解決策は以下の問題に苦しんでいます：1) カスタム双方向構造への高い依存度、2) 既存のタグ付け方式による情報の不十分な表現、および3) 利用可能な感情データの不十分な利用。これらの問題に対処するために、セグメントタグ付けとデュアルエクストラクタを備えたシンプルなスパンベースのソリューションであるSimSTAR（Segment Tagging And dual extRactors）を提案します。SimSTAR は追加の双方向メカニズムを導入しません。セグメントタグ付け方式は、すべての可能なスパンのケースを示すことができ、ネガティブラベルを通じてより多くの情報を明らかにします。デュアルエクストラクタを使用して、感情抽出を項目抽出から独立させます。私たちは4つのASTEデータセットでモデルを評価しました。実験結果は、我々のシンプルな方法が最先端の性能を達成することを示しています。
        </label>
        <input type="checkbox" id="Panel288" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Aspect sentiment triplet extraction (ASTE) is a task which extracts aspect terms, opinion terms, and sentiment polarities as triplets from review sentences. Existing approaches have developed bidirectional structures for term interaction. Sentiment polarities are subsequently extracted from aspect-opinion pairs. These solutions suffer from: 1) high dependency on custom bidirectional structures, 2) inadequate representation of the information through existing tagging schemes, and 3) insufficient usage of all available sentiment data. To address the above issues, we propose a simple span-based solution named SimSTAR with Segment Tagging And dual extRactors. SimSTAR does not introduce any additional bidirectional mechanism. The segment tagging scheme is capable to indicate all possible cases of spans and reveals more information through negative labels. Dual extractors are employed to make the sentiment extraction independent of the term extraction. We evaluate our model on four ASTE datasets. The experimental results show that our simple method achieves state-of-the-art performance.
        </div> </ul> <br>



        <label for="Panel289">
        <strong> Simpler is Much Faster: Fair and Independent Inner Product Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kazuyoshi+Aoyama">Kazuyoshi Aoyama</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daichi+Amagata">Daichi Amagata</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sumio+Fujita">Sumio Fujita</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Takahiro+Hara">Takahiro Hara</a> (1) </u>  <br>
        1:  Osaka University, 2:  Osaka University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592061">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Simpler is Much Faster: Fair and Independent Inner Product Search">Google Scholar</a></div>
        (289)
        <br>
        <b>概要:　</b> 内積検索（IPS）の問題は多くの分野で重要です。最大内積検索（MIPS）がしばしば考慮されますが、その結果は通常偏っており、静的です。そのため、ユーザーはMIPS問題を使用して多様で新しいアイテムを取得するのが難しいです。これに動機付けられ、私たちは新たな問題、すなわち公平で独立したIPS問題を定式化しました。クエリ、閾値、および出力サイズkが与えられた場合、この問題はクエリとアイテムの内積が閾値以上となるアイテム集合からランダムにk個のアイテムをサンプリングします。この問題は、閾値を満たす各アイテムの出力確率が他のアイテムと同等であるため、公平です。この公平性は多様性と新規性をもたらす可能性がありますが、この問題は計算上の課題に直面します。既存の（M）IPS技術はこの問題に適用可能ですが、それらはO(n)またはo(n)の時間を要し、nはデータセットのサイズです。大規模なデータセットに対応するために、私たちはO(log n + k)の期待時間で動作する、シンプルで効率的なアルゴリズムを提案します。実データセットを使用して実験を行った結果、我々のアルゴリズムがベースラインと比較して最大330倍高速であることを示しました。
        </label>
        <input type="checkbox" id="Panel289" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The problem of inner product search (IPS) is important in many fields. Although maximum inner product search (MIPS) is often considered, its result is usually skewed and static. Users are hence hard to obtain diverse and/or new items by using the MIPS problem. Motivated by this, we formulate a new problem, namely the fair and independent IPS problem. Given a query, a threshold, and an output size k, this problem randomly samples k items from a set of items such that the inner product of the query and item is not less than the threshold. For each item that satisfies the threshold, this problem is fair, because the probability that such an item is outputted is equal to that for each other item. This fairness can yield diversity and novelty, but this problem faces a computational challenge. Some existing (M)IPS techniques can be employed in this problem, but they require O(n) or o(n) time, where n is the dataset size. To scale well to large datasets, we propose a simple yet efficient algorithm that runs in O(log n + k) expected time. We conduct experiments using real datasets, and the results demonstrate that our algorithm is up to 330 times faster than baselines.
        </div> </ul> <br>



        <label for="Panel290">
        <strong> Simplifying Content-Based Neural News Recommendation: On User Modeling and Training Objectives </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andreea+Iana">Andreea Iana</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Goran+Glavas">Goran Glavas</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Heiko+Paulheim">Heiko Paulheim</a> (1) </u>  <br>
        1:  University of Mannheim, 2:  CAIDAS <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592062">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Simplifying Content-Based Neural News Recommendation: On User Modeling and Training Objectives">Google Scholar</a></div>
        (290)
        <br>
        <b>概要:　</b> パーソナライズされたニュース推薦の登場により、ますます複雑なレコメンダーアーキテクチャが生み出されました。ほとんどのニューラルニュースレコメンダーはユーザーのクリック行動に依存しており、通常、クリックされたニュースの内容を集約してユーザー埋め込みを形成する専用のユーザーエンコーダを導入します（早期融合）。これらのモデルは主に標準的なポイントワイズ分類目的で訓練されています。既存の研究には主に二つの欠点があります：（1）設計の一般的な均質性にもかかわらず、評価データセットやプロトコルの違いによりモデルの直接比較が困難であること、（2）代替モデル設計や訓練目的が大幅に未探索であることです。本研究では、ニュース推薦の統一的なフレームワークを提案し、ユーザーモデリングにおける候補認識、クリック行動の融合、訓練目的といういくつかの重要な設計次元にわたるニュースレコメンダーの体系的かつ公平な比較を可能にします。我々の発見は、ニューラルニュース推薦における現状に一石を投じます。大規模なユーザーエンコーダを、候補ニュースとクリックされたニュースの埋め込み間のパラメータ効率の良いドット積（後期融合）に置き換えることで、多くの場合、パフォーマンスが大幅に向上することを示します。さらに、コントラスト学習はポイントワイズ分類目的に対する実行可能な代替手段となることも示されました。
        </label>
        <input type="checkbox" id="Panel290" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The advent of personalized news recommendation has given rise to increasingly complex recommender architectures. Most neural news recommenders rely on user click behavior and typically introduce dedicated user encoders that aggregate the content of clicked news into user embeddings (early fusion). These models are predominantly trained with standard point-wise classification objectives. The existing body of work exhibits two main shortcomings: (1) despite general design homogeneity, direct comparisons between models are hindered by varying evaluation datasets and protocols; (2) it leaves alternative model designs and training objectives vastly unexplored. In this work, we present a unified framework for news recommendation, allowing for a systematic and fair comparison of news recommenders across several crucial design dimensions: (i) candidate-awareness in user modeling, (ii) click behavior fusion, and (iii) training objectives. Our findings challenge the status quo in neural news recommendation. We show that replacing sizable user encoders with parameter-efficient dot products between candidate and clicked news embeddings (late fusion) often yields substantial performance gains. Moreover, our results render contrastive training a viable alternative to point-wise classification objectives.
        </div> </ul> <br>



        <label for="Panel291">
        <strong> SimTDE: Simple Transformer Distillation for Sentence Embeddings </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jian+Xie">Jian Xie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xin+He">Xin He</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiyang+Wang">Jiyang Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zimeng+Qiu">Zimeng Qiu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ali+Kebarighotbi">Ali Kebarighotbi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Farhad+Ghassemi">Farhad Ghassemi</a> (3) </u>  <br>
        1:  University of Central Florida, 2:  Amazon Alexa, 3:  Amazon Alexa <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592063">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SimTDE: Simple Transformer Distillation for Sentence Embeddings">Google Scholar</a></div>
        (291)
        <br>
        <b>概要:　</b> 本論文では、性能の損失を最小限に抑え、サイズと遅延を大幅に削減するための簡易な知識蒸留フレームワークであるSimTDEを紹介します。SimTDEは、大規模および小規模なトランスフォーマーモデルを、コンパクトなトークン埋め込みブロックと浅いエンコーディングブロックを介して効果的に蒸留し、射影層で接続することで次元一致要件を緩和します。SimTDEは、トークン埋め込みと文埋め込みのみに焦点を当てる蒸留損失を簡素化します。標準的なセマンティックテキスト類似性（STS）タスクおよびエンティティ解決（ER）タスクで評価を行いました。STSタスクでは、最先端（SOTA）のSimCSE-Bert-Base性能の99.94%を達成し、サイズを3倍縮小し、サイズを12倍縮小してSOTA性能の96.99%を達成しました。また、マルチリンガルERデータでは、わずか1.4Mパラメータと5.7MBのサイズの小さなトランスフォーマースチューデントモデルで教師モデルの性能の99.57%を達成しました。さらに、他の蒸留トランスフォーマーと比較して、SimTDEは同等のサイズで推論時に2倍高速であり、33%小さいモデル（例えばMiniLM）よりも1.17倍高速です。SimTDEの容易に採用できるフレームワーク、強力な精度および低遅延により、最先端の文埋め込みのランタイム展開が広く可能になります。
        </label>
        <input type="checkbox" id="Panel291" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this paper we introduce SimTDE, a simple knowledge distillation framework to compress sentence embeddings transformer models with minimal performance loss and significant size and latency reduction. SimTDE effectively distills large and small transformers via a compact token embedding block and a shallow encoding block, connected with a projection layer, relaxing dimension match requirement. SimTDE simplifies distillation loss to focus only on token embedding and sentence embedding. We evaluate on standard semantic textual similarity (STS) tasks and entity resolution (ER) tasks. It achieves 99.94% of the state-of-the-art (SOTA) SimCSE-Bert-Base performance with 3 times size reduction and 96.99% SOTA performance with 12 times size reduction on STS tasks. It also achieves 99.57% of teacher's performance on multi-lingual ER data with a tiny transformer student model of 1.4M parameters and 5.7MB size. Moreover, compared to other distilled transformers SimTDE is 2 times faster at inference given similar size and still 1.17 times faster than a model 33% smaller (e.g. MiniLM). The easy-to-adopt framework, strong accuracy and low latency of SimTDE can widely enable runtime deployment of SOTA sentence embeddings.
        </div> </ul> <br>



        <label for="Panel292">
        <strong> Sinkhorn Transformations for Single-Query Postprocessing in Text-Video Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Konstantin+Yakovlev">Konstantin Yakovlev</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gregory+Polyakov">Gregory Polyakov</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ilseyar+Alimova">Ilseyar Alimova</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alexander+Podolskiy">Alexander Podolskiy</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrey+Bout">Andrey Bout</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sergey+Nikolenko">Sergey Nikolenko</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Irina+Piontkovskaya">Irina Piontkovskaya</a> (1) </u>  <br>
        1:  Huawei Noah's Ark Lab, 2:  Ivannikov Institute for System Programming of the RAS & St. Petersburg Department of the Steklov Institute of Mathematics <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592064">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Sinkhorn Transformations for Single-Query Postprocessing in Text-Video Retrieval">Google Scholar</a></div>
        (292)
        <br>
        <b>概要:　</b> マルチモーダル検索における最近のトレンドとして、デュアルソフトマックス損失（DSL）を用いたテストセット結果の後処理があります。このアプローチは大きな改善をもたらすことができますが、通常はDSLの入力としてテストサンプル全体の行列が利用可能であることを前提としています。本研究では、DSLを上回るSinkhorn変換に基づく新しい後処理アプローチを紹介します。さらに、複数のテストクエリにアクセスしなくてもよい新しい後処理設定を提案します。我々のアプローチは、CLIP4Clip、BLIP、X-CLIP、およびDRLなどの最先端モデルの結果を大幅に向上させることができ、テストセット全体へのアクセスがある場合とシングルクエリ設定の両方で、いくつかの標準的なテキスト-ビデオ検索データセットで新たな最先端を達成しました。
        </label>
        <input type="checkbox" id="Panel292" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> A recent trend in multimodal retrieval is related to postprocessing test set results via the dual-softmax loss (DSL). While this approach can bring significant improvements, it usually presumes that an entire matrix of test samples is available as DSL input. This work introduces a new postprocessing approach based on Sinkhorn transformations that outperforms DSL. Further, we propose a new postprocessing setting that does not require access to multiple test queries. We show that our approach can significantly improve the results of state of the art models such as CLIP4Clip, BLIP, X-CLIP, and DRL, thus achieving a new state-of-the-art on several standard text-video retrieval datasets both with access to the entire test set and in the single-query setting.
        </div> </ul> <br>



        <label for="Panel293">
        <strong> SparseEmbed: Learning Sparse Lexical Representations with Contextual Embeddings for Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weize+Kong">Weize Kong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jeffrey+M.+Dudek">Jeffrey M. Dudek</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cheng+Li">Cheng Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mingyang+Zhang">Mingyang Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michael+Bendersky">Michael Bendersky</a> (1) </u>  <br>
        1:  Google Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592065">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SparseEmbed: Learning Sparse Lexical Representations with Contextual Embeddings for Retrieval">Google Scholar</a></div>
        (293)
        <br>
        <b>概要:　</b> 密な情報検索において、先行研究は主にColBERTのようなマルチベクターの密な表現を用いて情報検索の効果を大幅に向上させてきました。一方、疎な情報検索では、最近のSPLADEのような研究が、疎な語彙表現を学習することで、同等の効果を保ちつつ、より良い解釈性を享受できることを示しました。本研究では、第一段階の情報検索において、疎な表現と密な表現の両方の強みを組み合わせることを目的としています。具体的には、SparseEmbedと呼ばれる新しい検索モデルを提案します。このモデルは、コンテクスト埋め込みを用いた疎な語彙表現を学習します。SPLADEと比較して、我々のモデルはコンテクスト埋め込みを活用してモデルの表現力を向上させています。ColBERTと比較して、我々の疎な表現は効率性と効果を最適化するためにエンドツーエンドでトレーニングされています。
        </label>
        <input type="checkbox" id="Panel293" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In dense retrieval, prior work has largely improved retrieval effectiveness using multi-vector dense representations, exemplified by ColBERT. In sparse retrieval, more recent work, such as SPLADE, demonstrated that one can also learn sparse lexical representations to achieve comparable effectiveness while enjoying better interpretability. In this work, we combine the strengths of both the sparse and dense representations for first-stage retrieval. Specifically, we propose SparseEmbed - a novel retrieval model that learns sparse lexical representations with contextual embeddings. Compared with SPLADE, our model leverages the contextual embeddings to improve model expressiveness. Compared with ColBERT, our sparse representations are trained end-to-end to optimize both efficiency and effectiveness.
        </div> </ul> <br>



        <label for="Panel294">
        <strong> Surprise: Result List Truncation via Extreme Value Theory </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dara+Bahri">Dara Bahri</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Che+Zheng">Che Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Tay">Yi Tay</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Donald+Metzler">Donald Metzler</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrew+Tomkins">Andrew Tomkins</a> (1) </u>  <br>
        1:  Google Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592066">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Surprise: Result List Truncation via Extreme Value Theory">Google Scholar</a></div>
        (294)
        <br>
        <b>概要:　</b> 情報検索の研究は主にランキングと関連性に焦点を当ててきました。特定のクエリに対して、ユーザーにとっての関連性に基づいて結果を順に並べたリストを返すというものです。しかし、結果リストの切り捨て、つまりランク付けされた結果リストをどこで切り捨てるかという問題は、様々な応用において重要であるにもかかわらず、あまり注目されてきませんでした。この切り捨ては、結果の全体的な関連性や有用性と、ユーザーがより多くの結果を処理するコストとの間のバランスをとる行為です。結果リストの切り捨ては、関連性スコアがよくキャリブレーションされていないことが多いため、困難を伴います。これは特に、文書とクエリが同じメトリック空間に埋め込まれ、クエリの最も近い文書の近隣が推論中に返される大規模なIRシステムにおいて顕著です。ここで、関連性はクエリと候補文書の間の距離に反比例しますが、関連性を構成する距離はクエリごとに異なり、インデックスにドキュメントが追加されるにつれて動的に変化します。本研究では、極値理論における一般化パレート分布を利用して、ランク付けされたスコアだけを用い、クエリ時間において解釈可能でキャリブレーションされた関連性スコアを生成する統計的手法「Surpriseスコアリング」を提案します。画像、テキスト、IRデータセットにおける結果リスト切り捨てのタスクにおいてその有効性を実証し、古典的および最近のベースラインと比較します。また、仮説検定とp値への関連性も議論します。
        </label>
        <input type="checkbox" id="Panel294" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Work in information retrieval has largely been centered around ranking and relevance: given a query, return some number of results ordered by relevance to the user. The problem of result list truncation, or where to truncate the ranked list of results, however, has received less attention despite being crucial in a variety of applications. Such truncation is a balancing act between the overall relevance, or usefulness of the results, with the user cost of processing more results. Result list truncation can be challenging because relevance scores are often not well-calibrated. This is particularly true in large-scale IR systems where documents and queries are embedded in the same metric space and a query's nearest document neighbors are returned during inference. Here, relevance is inversely proportional to the distance between the query and candidate document, but what distance constitutes relevance varies from query to query and changes dynamically as more documents are added to the index. In this work, we propose Surprise scoring, a statistical method that leverages the Generalized Pareto Distribution that arises in extreme value theory to produce interpretable and calibrated relevance scores at query time using nothing more than the ranked scores. We demonstrate its effectiveness on the result list truncation task across image, text, and IR datasets and compare it to both classical and recent baselines. We draw connections to hypothesis testing and p-values.
        </div> </ul> <br>



        <label for="Panel295">
        <strong> ExaRanker: Synthetic Explanations Improve Neural Rankers </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fernando+Ferraretto">Fernando Ferraretto</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Thiago+Laitz">Thiago Laitz</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Roberto+Lotufo">Roberto Lotufo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rodrigo+Nogueira">Rodrigo Nogueira</a> (1) </u>  <br>
        1:  UNICAMP <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592067">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=ExaRanker: Synthetic Explanations Improve Neural Rankers">Google Scholar</a></div>
        (295)
        <br>
        <b>概要:　</b> 最近の研究により、大規模言語モデル（LLMs）が生成する出力に説明を組み込むことで、幅広い推論タスクにおける性能が大幅に向上することが示されています。本研究は、この知見をさらに発展させ、ニューラルランカーにおける説明の利点を実証します。GPT-3.5などのLLMを用いてリトリーバルデータセットを説明付きで充実させることで、シーケンス・ツー・シーケンスのランキングモデル「ExaRanker」を訓練し、クエリ-ドキュメントペアに対して関連性ラベルと説明を生成しました。ExaRankerモデルは、少数の例と合成説明でファインチューニングされており、説明なしで3倍の例でファインチューニングされたモデルに匹敵する性能を示します。さらに、説明を組み込むことは、再ランキングステップに追加の計算負荷をかけることなく、オンデマンドの説明生成を可能にします。本研究で使用したコードベースとデータセットは、以下のURLで公開予定です：https://github.com/unicamp-dl/ExaRanker
        </label>
        <input type="checkbox" id="Panel295" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recent work has shown that incorporating explanations into the output generated by large language models (LLMs) can significantly enhance performance on a broad spectrum of reasoning tasks. Our study extends these findings by demonstrating the benefits of explanations for neural rankers. By utilizing LLMs such as GPT-3.5 to enrich retrieval datasets with explanations, we trained a sequence-to-sequence ranking model, dubbed ExaRanker, to generate relevance labels and explanations for query-document pairs. The ExaRanker model, finetuned on a limited number of examples and synthetic explanations, exhibits performance comparable to models finetuned on three times more examples, but without explanations. Moreover, incorporating explanations imposes no additional computational overhead into the reranking step and allows for on-demand explanation generation. The codebase and datasets used in this study will be available at https://github.com/unicamp-dl/ExaRanker
        </div> </ul> <br>



        <label for="Panel296">
        <strong> TAML: Time-Aware Meta Learning for Cold-Start Problem in News Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingyuan+Li">Jingyuan Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Zhang">Yue Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuan+Lin">Xuan Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinxing+Yang">Xinxing Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ge+Zhou">Ge Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Longfei+Li">Longfei Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hong+Chen">Hong Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (1) </u>  <br>
        1:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592068">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=TAML: Time-Aware Meta Learning for Cold-Start Problem in News Recommendation">Google Scholar</a></div>
        (296)
        <br>
        <b>概要:　</b> メタラーニングは、類似した学習タスクから学び、新しいタスクにその知識を転移できるため、推薦システムにおけるユーザーのコールドスタート問題に広く利用されている方法です。しかし、既存のほとんどのメタラーニング手法は、ユーザーの好みの時間的要素を考慮しておらず、ニュース推薦システムのシナリオでは、この要素が非常に重要です。ニュースストリームが時間と共に動的に変化するためです。本論文では、ニュース推薦システムにおけるコールドスタートユーザーに焦点を当てた新しいフレームワークであるTime-Aware Meta-Learning (TAML) を提案します。TAMLは、ユーザーの好みを時間特有の表現と時間変動の表現に因数分解し、これらが共同でユーザーのニュースの好みに影響を与えるというものです。これらの時間的要因をメタラーニングフレームワークに組み込むことで、正確かつ適時なコールドスタート推薦を実現します。実世界の2つのデータセットに対して広範な実験を行い、TAMLが最新の手法よりも優れた性能を示すことを実証しました。
        </label>
        <input type="checkbox" id="Panel296" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Meta-learning has become a widely used method for the user cold-start problem in recommendation systems, as it allows the model to learn from similar learning tasks and transfer the knowledge to new tasks. However, most existing meta-learning methods do not consider the temporal factor of users' preferences, which is crucial for news recommendation scenarios where news streams change dynamically over time. In this paper, we propose Time-Aware Meta-Learning (TAML), a novel framework that focuses on cold-start users in news recommendation systems. TAML factorizes user preferences into time-specifc and time-shift representations that jointly affect users' news preferences. These temporal factors are further incorporated into the meta-learning framework to achieve accurate and timely cold-start recommendations. Extensive experiments are conducted on two real-world datasets, demonstrating the superior performance of TAML over state-of-the-art methods.
        </div> </ul> <br>



        <label for="Panel297">
        <strong> Text-to-Motion Retrieval: Towards Joint Understanding of Human Motion Data and Natural Language </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nicola+Messina">Nicola Messina</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jan+Sedmidubsky">Jan Sedmidubsky</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fabrizio+Falchi">Fabrizio Falchi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tomás+Rebok">Tomás Rebok</a> (2) </u>  <br>
        1:  ISTI-CNR, 2:  Masaryk University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592069">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Text-to-Motion Retrieval: Towards Joint Understanding of Human Motion Data and Natural Language">Google Scholar</a></div>
        (297)
        <br>
        <b>概要:　</b> 最近のポーズ推定技術の進歩により、一般的なビデオから3Dスケルトンシーケンスとして人間の動作を抽出することが可能になりました。これにより素晴らしい応用機会が生まれましたが、大量の時空間スケルトンデータに基づく効果的かつ効率的なコンテンツ検索は未だに困難な課題です。本論文では、指定された自然言語のテキスト記述に基づいて関連する動作を検索する新しいコンテンツベースのテキストから動作への検索タスクを提案します。この未踏のタスクに対するベースラインを定義するために、BERTおよびCLIPの言語表現を使用してテキストモダリティをエンコードし、成功した時空間モデルを使用して動作モダリティをエンコードします。さらに、空間と時間の異なるスケルトンジョイントを効果的に集約するために分離された時空間アテンションを採用する、Motion Transformer（MoT）と呼ばれる我々のトランスフォーマーベースのアプローチを紹介します。テキストから画像やビデオへのマッチングにおける最近の進展に着想を得て、広く採用されている二つのメトリックラーニングの損失関数を用いて実験を行います。最後に、最近導入されたKIT Motion-LanguageおよびHumanML3Dデータセットを対象に、検索された動作の品質を評価するための定性的指標を定義し、共通の評価プロトコルを設定します。再現性のためのコードはこちらで公開しています：https://github.com/mesnico/text-to-motion-retrieval。
        </label>
        <input type="checkbox" id="Panel297" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Due to recent advances in pose-estimation methods, human motion can be extracted from a common video in the form of 3D skeleton sequences. Despite wonderful application opportunities, effective and efficient content-based access to large volumes of such spatio-temporal skeleton data still remains a challenging problem. In this paper, we propose a novel content-based text-to-motion retrieval task, which aims at retrieving relevant motions based on a specified natural-language textual description. To define baselines for this uncharted task, we employ the BERT and CLIP language representations to encode the text modality and successful spatio-temporal models to encode the motion modality. We additionally introduce our transformer-based approach, called Motion Transformer (MoT), which employs divided space-time attention to effectively aggregate the different skeleton joints in space and time. Inspired by the recent progress in text-to-image/video matching, we experiment with two widely-adopted metric-learning loss functions. Finally, we set up a common evaluation protocol by defining qualitative metrics for assessing the quality of the retrieved motions, targeting the two recently-introduced KIT Motion-Language and HumanML3D datasets. The code for reproducing our results is available here: https://github.com/mesnico/text-to-motion-retrieval.
        </div> </ul> <br>



        <label for="Panel298">
        <strong> The Dark Side of Explanations: Poisoning Recommender Systems with Counterfactual Examples </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ziheng+Chen">Ziheng Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fabrizio+Silvestri">Fabrizio Silvestri</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jia+Wang">Jia Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongfeng+Zhang">Yongfeng Zhang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gabriele+Tolomei">Gabriele Tolomei</a> (2) </u>  <br>
        1:  Stony Brook University, 2:  Sapienza University of Rome, 3:  Xi'an Jiaotong-Liverpool University, 4:  Rutgers University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592070">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=The Dark Side of Explanations: Poisoning Recommender Systems with Counterfactual Examples">Google Scholar</a></div>
        (298)
        <br>
        <b>概要:　</b> ディープラーニングに基づくレコメンダーシステムは、いくつかのオンラインプラットフォームの不可欠な部分となっています。しかし、そのブラックボックス的な性質により、特定のアイテムが特定のユーザーに推薦される理由を人間が理解できる形で提供するための説明可能な人工知能（XAI）アプローチの必要性が強調されています。その一つの方法として反事実説明（CF）があります。CFはユーザーやシステム設計者にとって非常に有益である一方、悪意のあるアクターがこれらの説明を利用してシステムのセキュリティを損なう可能性もあります。本研究では、CFを通じてレコメンダーシステムを攻撃する新しい戦略であるH-CARSを提案します。具体的には、まず反事実説明から得たトレーニングデータに基づいて論理推論ベースの代理モデルを訓練します。次に、推薦モデルの学習プロセスを逆転させることで、前述の代理モデルに対して偽のユーザープロフィールとそれに関連するインタラクション記録を生成する熟練したグリーディーアルゴリズムを開発します。よく知られたCF生成方法を使用し、2つの異なるデータセットで実施した実験では、H-CARSが高い攻撃性能を示し、成功した結果を得ました。
        </label>
        <input type="checkbox" id="Panel298" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Deep learning-based recommender systems have become an integral part of several online platforms. However, their black-box nature emphasizes the need for explainable artificial intelligence (XAI) approaches to provide human-understandable reasons why a specific item gets recommended to a given user. One such method is counterfactual explanation (CF). While CFs can be highly beneficial for users and system designers, malicious actors may also exploit these explanations to undermine the system's security. In this work, we propose H-CARS, a novel strategy to poison recommender systems via CFs. Specifically, we first train a logical-reasoning-based surrogate model on training data derived from counterfactual explanations. By reversing the learning process of the recommendation model, we thus develop a proficient greedy algorithm to generate fabricated user profiles and their associated interaction records for the aforementioned surrogate model. Our experiments, which employ a well-known CF generation method and are conducted on two distinct datasets, show that H-CARS yields significant and successful attack performance.
        </div> </ul> <br>



        <label for="Panel299">
        <strong> The Tale of Two MSMARCO - and Their Unfair Comparisons </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Carlos+Lassance">Carlos Lassance</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Stephane+Clinchant">Stephane Clinchant</a> (1) </u>  <br>
        1:  Naver Labs Europe <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592071">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=The Tale of Two MSMARCO - and Their Unfair Comparisons">Google Scholar</a></div>
        (299)
        <br>
        <b>概要:　</b> MS MARCOパッセージデータセットはIRコミュニティにとって主要な大規模データセットであり、これにより新しいニューラル検索モデルの開発が成功してきました。しかし、文献の中で公式のコーパスと、Tevatronコードベースの導入によりパッセージがタイトルで拡張された別のコーパスの2つが使われていることが判明しています。しかし、タイトルの追加は関連情報の漏洩を引き起こし、MS MARCOパッセージデータセットの元々のガイドラインを破っています。本研究では、これら2つのコーパスの違いを調査し、新しい方法を評価する際にそれらが大きな違いをもたらすことを実証的に示します。つまり、使用されているバージョンを適切に報告しない場合、公正に結果を再現することは基本的に不可能であることを示します。さらに、最新の結果を監視することが非常に重要な現在のレビュー状況を考えると、2つの異なるバージョンのデータセットが存在することは大きな問題です。したがって、本論文はこの問題の重要性を報告し、研究者がこの問題を認識し、適切に結果を報告できるようにすることを目的としています。
        </label>
        <input type="checkbox" id="Panel299" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The MS MARCO-passage dataset has been the main large-scale dataset open to the IR community and it has fostered successfully the development of novel neural retrieval models over the years. But, it turns out that two different corpora of MS MARCO are used in the literature, the official one and a second one where passages were augmented with titles, mostly due to the introduction of the Tevatron code base. However, the addition of titles actually leaks relevance information, while breaking the original guidelines of the MS MARCO-passage dataset. In this work, we investigate the differences between the two corpora and demonstrate empirically that they make a significant difference when evaluating a new method. In other words, we show that if a paper does not properly report which version is used, reproducing fairly its results is basically impossible. Furthermore, given the current status of reviewing, where monitoring state-of-the-art results is of great importance, having two different versions of a dataset is a large problem. This is why this paper aims to report the importance of this issue so that researchers can be made aware of this problem and appropriately report their results.
        </div> </ul> <br>



        <label for="Panel300">
        <strong> Think Rationally about What You See: Continuous Rationale Extraction for Relation Extraction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuming+Hu">Xuming Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaochen+Hong">Zhaochen Hong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenwei+Zhang">Chenwei Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Irwin+King">Irwin King</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philip+Yu">Philip Yu</a> (4) </u>  <br>
        1:  Tsinghua University, 2:  Amazon, 3:  The Chinese University of Hong Kong, 4:  University of Illinois at Chicago <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592072">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Think Rationally about What You See: Continuous Rationale Extraction for Relation Extraction">Google Scholar</a></div>
        (300)
        <br>
        <b>概要:　</b> 関係抽出 (Relation Extraction, RE) は、2つのエンティティの文脈に基づいて潜在的な関係を抽出することを目的としており、したがって、文から合理的な文脈を導き出すことが重要な役割を果たします。従来の研究は、エンティティ情報（例：エンティティのタイプ、エンティティの言語化）を利用して関係を推論する方法に焦点を当てているか、文脈に焦点を当てた内容を無視するか、または反事実的思考を使用してエンティティ内の潜在的な関係に対するモデルのバイアスを除去するが、関係推論プロセスが無関係な内容によって妨げられる多く、どちらかに傾いている傾向があります。したがって、関連する内容を保持しつつ、文からノイズの多い部分を除去することが重要な課題です。さらに、保持された内容が意味的に連続して解釈可能である必要があります。本研究では、連続性と疎性の2つの因子を活用して、文から関連性のある首尾一貫したラショナルを抽出する新しい枠組みRE2を提案します。ゴールドラショナルがラベル付けされていない問題を解決するために、RE2は文中の各トークンに対して最適化可能なバイナリマスクを適用し、関係ラベルに応じて選択する必要があるラショナルを調整します。4つのデータセットで行った実験では、RE2がベースラインを上回る成果を上げました。
        </label>
        <input type="checkbox" id="Panel300" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Relation extraction (RE) aims to extract potential relations according to the context of two entities, thus, deriving rational contexts from sentences plays an important role. Previous works either focus on how to leverage the entity information (e.g., entity types, entity verbalization) to inference relations, but ignore context-focused content, or use counterfactual thinking to remove the model's bias of potential relations in entities, but the relation reasoning process will still be hindered by irrelevant content. Therefore, how to preserve relevant content and remove noisy segments from sentences is a crucial task. In addition, retained content needs to be fluent enough to maintain semantic coherence and interpretability. In this work, we propose a novel rationale extraction framework named RE2, which leverages two continuity and sparsity factors to obtain relevant and coherent rationales from sentences. To solve the problem that the gold rationales are not labeled, RE2 applies an optimizable binary mask to each token in the sentence, and adjust the rationales that need to be selected according to the relation label. Experiments on four datasets show that RE2 surpasses baselines.
        </div> </ul> <br>



        <label for="Panel301">
        <strong> Towards Robust Knowledge Tracing Models via k-Sparse Attention </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuyan+Huang">Shuyan Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zitao+Liu">Zitao Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyu+Zhao">Xiangyu Zhao</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weiqi+Luo">Weiqi Luo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jian+Weng">Jian Weng</a> (2) </u>  <br>
        1:  TAL Education Group, 2:  Jinan University, 3:  City University of Hong Kong <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592073">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Towards Robust Knowledge Tracing Models via k-Sparse Attention">Google Scholar</a></div>
        (301)
        <br>
        <b>概要:　</b> 知識追跡（Knowledge Tracing, KT）は、学生の過去のインタラクションシーケンスに基づいて将来の成績を予測する問題です。文脈的な長期依存関係を捉える能力が進化したことで、注意メカニズムは多くの深層学習ベースKT（DLKT）モデルにとって重要な要素の一つとなっています。これらの注意メカニズムを持つDLKTモデルは優れた性能を達成している一方で、小規模な教育データセットに対して過学習のリスクがしばしば問題となります。そこで、本論文では、注意メカニズムを使用したDLKTアプローチの頑健性と汎化能力を向上させるための簡潔かつ効果的なフレームワークである sparseKT を提案します。具体的には、k-セレクションモジュールを取り入れ、最高の注意スコアを持つ項目のみを選択します。我々は２つのスパース化のヒューリスティックスを提案します：(1) ソフトしきい値スパース注意と (2) トップKスパース注意です。我々の sparseKT が、注意メカニズムを持つKTモデルが無関係な学生のインタラクションを排除し、3つの公開されている実世界の教育データセットにおいて11の最先端KTモデルと比較して予測性能を向上させることを示します。再現可能な研究を促進するために、我々はデータとコードを https://github.com/pykt-team/pykt-toolkit1 で公開しています。
        </label>
        <input type="checkbox" id="Panel301" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge tracing (KT) is the problem of predicting students' future performance based on their historical interaction sequences. With the advanced capability of capturing contextual long-term dependency, attention mechanism becomes one of the essential components in many deep learning based KT (DLKT) models. In spite of the impressive performance achieved by these attentional DLKT models, many of them are often vulnerable to run the risk of overfitting, especially on small-scale educational datasets. Therefore, in this paper, we propose sparseKT, a simple yet effective framework to improve the robustness and generalization of the attention based DLKT approaches. Specifically, we incorporate a k-selection module to only pick items with the highest attention scores. We propose two sparsification heuristics: (1) soft-thresholding sparse attention and (2) top-K sparse attention. We show that our sparseKT is able to help attentional KT models get rid of irrelevant student interactions and improve the predictive performance when compared to 11 state-of-the-art KT models on three publicly available real-world educational datasets. To encourage reproducible research, we make our data and code publicly available at https://github.com/pykt-team/pykt-toolkit1..
        </div> </ul> <br>



        <label for="Panel302">
        <strong> TripSafe: Retrieving Safety-related Abnormal Trips in Real-time with Trajectory Data </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yueyang+Su">Yueyang Su</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Di+Yao">Di Yao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaolei+Zhou">Xiaolei Zhou</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuxuan+Zhang">Yuxuan Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunxia+Fan">Yunxia Fan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lu+Bai">Lu Bai</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingping+Bi">Jingping Bi</a> (1) </u>  <br>
        1:  Institute of Computing Technology Chinese Academy of Sciences, 2:  DiDi Global Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592074">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=TripSafe: Retrieving Safety-related Abnormal Trips in Real-time with Trajectory Data">Google Scholar</a></div>
        (302)
        <br>
        <b>概要:　</b> 近年、ライドハイリングサービスにおいて安全性が最も重要な要素の一つとなっています。ライドハイリングプラットフォームは、異常な乗車、例えば暴力や性的暴行のリスクを最小限に抑えるために、ドライバーの背景調査を徹底的に行ってきました。しかし、現在の方法は労力がかかり、ドライバーの個人情報に大きく依存しているため、オーダー配車システムの公平性を損なう可能性があります。本論文では、乗車経路を入力として活用し、異常な安全事象の確率を推定するための二重変分オートエンコーダ(VAE)フレームワーク「TripSafe」を提案します。具体的には、TripSafeは移動行動とルート情報を二つの独立した要素としてモデル化し、通常の乗車データに対して生成モデルを事前学習するためにVAEを使用します。その後、いくつかのラベル付きサンプルを用いて全体のモデルを微調整するために、融合ネットワークを採用します。実際には、TripSafeはデータの更新を監視し、部分的に観察された乗車の異常スコアをリアルタイムで計算します。実際のライドハイリングデータに基づく実験では、TripSafeが最新のベースラインと比較してF1スコアで約14.2%〜28.9%の改善を示す優位性があることが確認されました。
        </label>
        <input type="checkbox" id="Panel302" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Nowadays safety has become one of the most critical factors for ride-hailing service. Ride-hailing platforms have conducted meticulous background checks for drivers to minimize the risk of abnormal trips, e.g. violence and sexual assault. However, current methods are labor-consuming and highly rely on the personal information of drivers, which may harm the fairness of the order dispatching system. In this paper, we utilize the trip trajectories as inputs and propose a dual variational auto-encoder(VAE) framework, namely TripSafe, to estimate the probability of abnormal safety incidents. Specifically, TripSafe models the moving behavior and route information, as two independent components and employs VAEs to pre-train generative models for normal trips. Then, a fusion network is adopted to fine-tune the whole model with a few labeled samples. In practice, TripSafe monitors the data update and calculate the anomaly score of partial-observed trips in real-time. Experiments on real ridehailing data show that TripSafe is superior to the state-of-the-art baselines with about 14.2%~28.9% improvements on F1 score.
        </div> </ul> <br>



        <label for="Panel303">
        <strong> TrustSGCN: Learning Trustworthiness on Edge Signs for Effective Signed Graph Convolutional Networks </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Min-Jeong+Kim">Min-Jeong Kim</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yeon-Chang+Lee">Yeon-Chang Lee</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sang-Wook+Kim">Sang-Wook Kim</a> (1) </u>  <br>
        1:  Hanyang University, 2:  Georgia Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592075">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=TrustSGCN: Learning Trustworthiness on Edge Signs for Effective Signed Graph Convolutional Networks">Google Scholar</a></div>
        (303)
        <br>
        <b>概要:　</b> 符号付きネットワーク埋め込み（Signed Network Embedding, SNE）の問題は、与えられた符号付きネットワーク内のノードを低次元のベクトルとして表現することを目的としています。グラフ畳み込みネットワーク（Graph Convolutional Network, GCN）に基づくいくつかのSNE手法が提案されていますが、これらは現実世界では常に成り立つわけではない古くからの平衡理論に大きく依存しているという点に注意が必要です。この制約を克服するために、我々は新しいGCNベースのSNEアプローチであるTrustSGCNを提案します。このアプローチは、平衡理論によって推測される高次の関係に対するエッジの符号の信頼性を測定し、その信頼性に基づいて誤った埋め込み伝播を修正します。4つの実世界の符号付きネットワークデータセットに対する実験により、TrustSGCNは一貫して5つの最先端のGCNベースのSNE手法を上回る性能を示しました。コードはhttps://github.com/kmj0792/TrustSGCNにて公開されています。
        </label>
        <input type="checkbox" id="Panel303" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The problem of signed network embedding (SNE) aims to represent nodes in a given signed network as low-dimensional vectors. While several SNE methods based on graph convolutional networks (GCN) have been proposed, we point out that they significantly rely on the assumption that the decades-old balance theory always holds in the real world. To address this limitation, we propose a novel GCN-based SNE approach, named as TrustSGCN, which measures the trustworthiness on edge signs for high-order relationships inferred by balance theory and corrects incorrect embedding propagation based on the trustworthiness. The experiments on four real-world signed network datasets demonstrate that TrustSGCN consistently outperforms five state-of-the-art GCN-based SNE methods. The code is available at https://github.com/kmj0792/TrustSGCN.
        </div> </ul> <br>



        <label for="Panel304">
        <strong> uCTRL: Unbiased Contrastive Representation Learning via Alignment and Uniformity for Collaborative Filtering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jae-woong+Lee">Jae-woong Lee</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Seongmin+Park">Seongmin Park</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mincheol+Yoon">Mincheol Yoon</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jongwuk+Lee">Jongwuk Lee</a> (1) </u>  <br>
        1:  Sungkyunkwan University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592076">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=uCTRL: Unbiased Contrastive Representation Learning via Alignment and Uniformity for Collaborative Filtering">Google Scholar</a></div>
        (304)
        <br>
        <b>概要:　</b> 協調フィルタリング（CF）モデルのためのインプット型のユーザーフィードバックは人気のあるアイテムに偏りがあるため、CFモデルは人気バイアスを持つ推奨リストを生成する傾向があります。これまでの研究では、この問題を緩和するために逆傾向スコア（IPW）または因果推論を利用してきました。しかし、それらの研究はポイントワイズまたはペアワイズの損失関数のみを使用し、ユーザーおよびアイテムの意味のある表現を学習するためのコントラスト損失関数を採用していません。本論文では、CFモデル用に情報エンコーディング対比損失（InfoNCE）から導出されたアライメントと均一性の関数を最適化する、偏りのないコントラスト学習（uCTRL）を提案します。具体的には、uCTRLに使用される偏りのないアライメント関数を定式化しました。また、ユーザーとアイテムのバイアスを同時に除去する新しいIPW推定方法を考案しました。uCTRLはその簡便さにもかかわらず、既存のCFモデルと組み合わせることで、4つのベンチマークデータセットで最先端の偏りのない推奨モデルを一貫して上回り、Recall@20で最大12.22%、NDCG@20で最大16.33%の向上を実現しました。
        </label>
        <input type="checkbox" id="Panel304" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Because implicit user feedback for the collaborative filtering (CF) models is biased toward popular items, CF models tend to yield recommendation lists with popularity bias. Previous studies have utilized inverse propensity weighting (IPW) or causal inference to mitigate this problem. However, they solely employ pointwise or pairwise loss functions and neglect to adopt a contrastive loss function for learning meaningful user and item representations. In this paper, we propose Unbiased ConTrastive Representation Learning (uCTRL), optimizing alignment and uniformity functions derived from the InfoNCE loss function for CF models. Specifically, we formulate an unbiased alignment function used in uCTRL. We also devise a novel IPW estimation method that removes the bias of both users and items. Despite its simplicity, uCTRL equipped with existing CF models consistently outperforms state-of-the-art unbiased recommender models, up to 12.22% for Recall@20 and 16.33% for NDCG@20 gains, on four benchmark datasets.
        </div> </ul> <br>



        <label for="Panel305">
        <strong> Unbiased Pairwise Learning from Implicit Feedback for Recommender Systems without Biased Variance Control </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Ren">Yi Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongyan+Tang">Hongyan Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiangpeng+Rong">Jiangpeng Rong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siwen+Zhu">Siwen Zhu</a> (1) </u>  <br>
        1:  Tencent <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592077">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Unbiased Pairwise Learning from Implicit Feedback for Recommender Systems without Biased Variance Control">Google Scholar</a></div>
        (305)
        <br>
        <b>概要:　</b> 一般に推奨システムのモデル訓練は、明示的フィードバックと暗黙的フィードバックの2種類のデータに基づいて行うことができます。さらに、暗黙的フィードバックデータ（例えばクリック信号）の一般的な利用可能性のため、これが広く採用されています。暗黙的フィードバックの応用には主に二つの課題があります。第一に、暗黙的データは正のフィードバックのみを含んでおり、非インタラクション項目が実際に否定的か、または肯定的だが対応するユーザに表示されていないかを判断することができません。さらに、稀少項目の関連性は、人気のある項目と比較して収集される正のフィードバックがはるかに少ないため、通常過小評価されます。このような困難に対処するために、ポイントワイズおよびペアワイズの両方の解決策が以前から提案されています。ペアワイズ学習はランキングタスクに適しており、以前提案されたバイアスのないペアワイズ学習アルゴリズムは最先端の性能を達成しています。それにもかかわらず、既存のバイアスのないペアワイズ学習法は高い分散に悩まされています。満足のいく性能を得るためには、実践的な分散の制御のため非負推定量が利用されますが、追加のバイアスを導入します。本研究では、真にバイアスのない推奨モデルを学習するために、より低い分散を持つバイアスのないペアワイズ学習法（UPLと命名）を提案します。実世界のデータセットにおける広範なオフライン実験やオンラインのA/Bテストにより、提案手法の優れた性能が実証されました。
        </label>
        <input type="checkbox" id="Panel305" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Generally speaking, the model training for recommender systems can be based on two types of data, namely explicit feedback and implicit feedback. Moreover, because of its general availability, we see wide adoption of implicit feedback data, such as click signal. There are mainly two challenges for the application of implicit feedback. First, implicit data just includes positive feedback. Therefore, we are not sure whether the non-interacted items are really negative or positive but not displayed to the corresponding user. Moreover, the relevance of rare items is usually underestimated since much fewer positive feedback of rare items is collected compared with popular ones. To tackle such difficulties, both pointwise and pairwise solutions are proposed before for unbiased relevance learning. As pairwise learning suits well for the ranking tasks, the previously proposed unbiased pairwise learning algorithm already achieves state-of-the-art performance. Nonetheless, the existing unbiased pairwise learning method suffers from high variance. To get satisfactory performance, non-negative estimator is utilized for practical variance control but introduces additional bias. In this work, we propose an unbiased pairwise learning method, named UPL, with much lower variance to learn a truly unbiased recommender model. Extensive offline experiments on real world datasets and online A/B testing demonstrate the superior performance of our proposed method.
        </div> </ul> <br>



        <label for="Panel306">
        <strong> Uncertainty-aware Consistency Learning for Cold-Start Item Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Taichi+Liu">Taichi Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chen+Gao">Chen Gao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenyu+Wang">Zhenyu Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dong+Li">Dong Li</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianye+Hao">Jianye Hao</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Depeng+Jin">Depeng Jin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yong+Li">Yong Li</a> (1) </u>  <br>
        1:  Tsinghua University, 2:  Tsinghua University & Huawei Noah's Ark Lab, 3:  Huawei Noah's Ark Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592078">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Uncertainty-aware Consistency Learning for Cold-Start Item Recommendation">Google Scholar</a></div>
        (306)
        <br>
        <b>概要:　</b> グラフニューラルネットワーク（GNN）ベースのモデルは、レコメンダーシステムの主要手法となっている。効果的であるにもかかわらず、これらのモデルは依然としてコールドスタート問題、すなわち、少ないインタラクションしかないアイテムに対する推薦の課題を抱えている。既存のGNNベースの推薦モデルは、主にユーザーやアイテムの補助的な特徴を利用することに焦点を当てており、ユーザー-アイテム間のインタラクションが十分に活用されていない。しかし、コールドアイテムとウォームアイテムの埋め込み分布は大きく異なる。コールドアイテムの埋め込みは低い人気度のインタラクションから学習される一方、ウォームアイテムの埋め込みは高い人気度のインタラクションから学習されるためである。その結果、コールドアイテムとウォームアイテムの推薦性能を同時に向上させることが困難なシーソー現象が発生する。この問題に対して、ユーザー-アイテム間のインタラクションのみに基づくコールドスタートアイテム推薦のための不確実性認識コンシステンシー学習フレームワーク（UCC）を提案する。このフレームワークでは、教示モデル（生成器）と学習モデル（レコメンダー）をコンシステンシー学習で訓練し、追加的に生成された低不確実性インタラクションを用いてコールドアイテムがウォームアイテムと同様の分布を持つようにする。これにより、コールドアイテムとウォームアイテムの推奨性能が同時に向上し、どちらの性能も損なわれない。ベンチマークデータセットを用いた広範な実験により、提案手法がウォームアイテムおよびコールドアイテムの両方で最先端の手法を大幅に上回り、平均27.6%の性能向上を実現することが示された。
        </label>
        <input type="checkbox" id="Panel306" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Graph Neural Network (GNN)-based models have become the mainstream approach for recommender systems. Despite the effectiveness, they are still suffering from the cold-start problem, i.e., recommend for few-interaction items. Existing GNN-based recommendation models to address the cold-start problem mainly focus on utilizing auxiliary features of users and items, leaving the user-item interactions under-utilized. However, embeddings distributions of cold and warm items are still largely different, since cold items' embeddings are learned from lower-popularity interactions, while warm items' embeddings are from higher-popularity interactions. Thus, there is a seesaw phenomenon, where the recommendation performance for the cold and warm items cannot be improved simultaneously. To this end, we proposed a Uncertainty-aware Consistency learning framework for Cold-start item recommendation (shorten as UCC) solely based on user-item interactions. Under this framework, we train the teacher model (generator) and student model (recommender) with consistency learning, to ensure the cold items with additionally generated low-uncertainty interactions can have similar distribution with the warm items. Therefore, the proposed framework improves the recommendation of cold and warm items at the same time, without hurting any one of them. Extensive experiments on benchmark datasets demonstrate that our proposed method significantly outperforms state-of-the-art methods on both warm and cold items, with an average performance improvement of 27.6%.
        </div> </ul> <br>



        <label for="Panel307">
        <strong> Uncertainty-based Heterogeneous Privileged Knowledge Distillation for Recommendation System </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ang+Li">Ang Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jian+Hu">Jian Hu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ke+Ding">Ke Ding</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaolu+Zhang">Xiaolu Zhang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yong+He">Yong He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xu+Min">Xu Min</a> (3) </u>  <br>
        1:  Ant Group, 2:  Queen Mary University of London, 3:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592079">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Uncertainty-based Heterogeneous Privileged Knowledge Distillation for Recommendation System">Google Scholar</a></div>
        (307)
        <br>
        <b>概要:　</b> 産業用推薦システムにおいて、データサイズや計算資源はシナリオにより異なります。データが限られているシナリオでは、データのスパース性によりモデルの性能が低下することがあります。異種の知識蒸留に基づく転移学習を用いて、データ豊富なドメインから知識を転移することができます。しかし、推薦システムにおいて、ターゲットドメインにはモデルに大きく貢献する特定の特権的な特徴が存在します。既存の知識蒸留法はこれらの特徴を考慮しておらず、その結果、最適ではない転移重みが設定されます。この限界を克服するために、我々は「不確実性に基づく異種特権知識蒸留 (Uncertainty-based Heterogeneous Privileged Knowledge Distillation: UHPKD)」という新しいアルゴリズムを提案します。我々の手法は、モデルの不確実性を表すソースドメインとターゲットドメインの知識を定量化することを目指しています。このアプローチにより、ソースドメインとターゲットドメイン間の知識の差を捉えた知識増加に基づく転移重みを導出できます。公共および産業データセットを用いた実験により、我々のUHPKDアルゴリズムが他の最先端手法と比較して優れていることが示されました。
        </label>
        <input type="checkbox" id="Panel307" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In industrial recommendation systems, both data sizes and computational resources vary across different scenarios. For scenarios with limited data, data sparsity can lead to a decrease in model performance. Heterogeneous knowledge distillation-based transfer learning can be used to transfer knowledge from models in data-rich domains. However, in recommendation systems, the target domain possesses specific privileged features that significantly contribute to the model. While existing knowledge distillation methods have not taken these features into consideration, leading to suboptimal transfer weights. To overcome this limitation, we propose a novel algorithm called Uncertainty-based Heterogeneous Privileged Knowledge Distillation (UHPKD). Our method aims to quantify the knowledge of both the source and target domains, which represents the uncertainty of the models. This approach allows us to derive transfer weights based on the knowledge gain, which captures the difference in knowledge between the source and target domains. Experiments conducted on both public and industrial datasets demonstrate the superiority of our UHPKD algorithm compared to other state-of-the-art methods.
        </div> </ul> <br>



        <label for="Panel308">
        <strong> Unsupervised Dense Retrieval Training with Web Anchors </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiqing+Xie">Yiqing Xie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Liu">Xiao Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenyan+Xiong">Chenyan Xiong</a> (2) </u>  <br>
        1:  Carnegie Mellon University, 2:  Microsoft <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592080">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Unsupervised Dense Retrieval Training with Web Anchors">Google Scholar</a></div>
        (308)
        <br>
        <b>概要:　</b> 本研究では、Webアンカーに対する対比学習を用いた教師なし検索手法を提案します。アンカーテキストはリンク先ページの内容を記述しており、これは関連する文書から有益な情報を取得する検索クエリと類似性を持っています。この共通点に基づき、アンカーテキストとリンクされた文書を一致させる対比学習タスクを通じて教師なしの密な検索エンジン「Anchor-DR」を訓練します。機能的なアンカー（例："homepage"など）を除外するために、検索クエリと同様の情報を含むアンカーのみを選択する新しいフィルタリング技術を導入しました。実験の結果、Anchor-DRはMSMARCOにおけるNDCG@10で5.3%の向上を示すなど、教師なしの密な検索の最先端手法を大幅に上回ることが示されました。我々の手法の利点は、特に検索および質問応答タスクで顕著です。さらに分析により、アンカー－文書ペアのパターンが検索クエリ－文書ペアのパターンと類似していることが明らかになりました。コードはhttps://github.com/Veronicium/AnchorDRで公開されています。
        </label>
        <input type="checkbox" id="Panel308" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this work, we present an unsupervised retrieval method with contrastive learning on web anchors. The anchor text describes the content that is referenced from the linked page. This shows similarities to search queries that aim to retrieve pertinent information from relevant documents. Based on their commonalities, we train an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document. To filter out uninformative anchors (such as "homepage" or other functional anchors), we present a novel filtering technique to only select anchors that contain similar types of information as search queries. Experiments show that Anchor-DR outperforms state-of-the-art methods on unsupervised dense retrieval by a large margin (e.g., by 5.3% NDCG@10 on MSMARCO). The gain of our method is especially significant for search and question answering tasks. Our analysis further reveals that the pattern of anchor-document pairs is similar to that of search query-document pairs. Code available at https://github.com/Veronicium/AnchorDR.
        </div> </ul> <br>



        <label for="Panel309">
        <strong> Unsupervised Dialogue Topic Segmentation with Topic-aware Contrastive Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haoyu+Gao">Haoyu Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rui+Wang">Rui Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ting-En+Lin">Ting-En Lin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuchuan+Wu">Yuchuan Wu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Min+Yang">Min Yang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Huang">Fei Huang</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongbin+Li">Yongbin Li</a> (2) </u>  <br>
        1:  University of Science and Technology of China & Shenzhen Institute of Advanced Technology, 2:  Alibaba Group, 3:  Shenzhen Institute of Advanced Technology, 4:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592081">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Unsupervised Dialogue Topic Segmentation with Topic-aware Contrastive Learning">Google Scholar</a></div>
        (309)
        <br>
        <b>概要:　</b> 対話トピックのセグメンテーション（DTS）は、さまざまな対話モデリングタスクにおいて重要な役割を果たします。従来のDTS手法は、非監督対話セグメンテーションのためにトピックの類似性を評価する際に、意味的類似性または対話の一貫性に焦点を当てていました。しかし、トピックの類似性は意味的類似性または対話の一貫性だけでは完全に把握することができません。さらに、発話間の関係に関する有益な手がかりを含むラベルなし対話データは十分に活用されていません。本論文では、近隣の発話のマッチングと疑似セグメンテーションを通じて、ラベルなし対話データからトピック認識の発話表現を学習する新しい非監督DTSフレームワークを提案します。二つのベンチマークデータセット（DialSeg711およびDoc2Dial）における大規模な実験により、我々の方法は強力なベースライン手法を大幅に上回ることが示されました。再現性のために、コードとデータを以下で提供しています: https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial-start.
        </label>
        <input type="checkbox" id="Panel309" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Dialogue Topic Segmentation (DTS) plays an essential role in a variety of dialogue modeling tasks. Previous DTS methods either focus on semantic similarity or dialogue coherence to assess topic similarity for unsupervised dialogue segmentation. However, the topic similarity cannot be fully identified via semantic similarity or dialogue coherence. In addition, the unlabeled dialogue data, which contains useful clues of utterance relationships, remains underexploited. In this paper, we propose a novel unsupervised DTS framework, which learns topic-aware utterance representations from unlabeled dialogue data through neighboring utterance matching and pseudo-segmentation. Extensive experiments on two benchmark datasets (i.e., DialSeg711 and Doc2Dial) demonstrate that our method significantly outperforms the strong baseline methods. For reproducibility, we provide our code and data at: https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial-start.
        </div> </ul> <br>



        <label for="Panel310">
        <strong> Unsupervised Query Performance Prediction for Neural Models with Pairwise Rank Preferences </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ashutosh+Singh">Ashutosh Singh</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Debasis+Ganguly">Debasis Ganguly</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Suchana+Datta">Suchana Datta</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Craig+McDonald">Craig McDonald</a> (1) </u>  <br>
        1:  University of Glasgow, 2:  University College Dublin <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592082">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Unsupervised Query Performance Prediction for Neural Models with Pairwise Rank Preferences">Google Scholar</a></div>
        (310)
        <br>
        <b>概要:　</b> クエリパフォーマンス予測（QPP）法は、特定のクエリに対する情報検索（IR）システムの有効性を予測します。従来の非監督学習アプローチは、統計的IRモデルに対しては良好な性能を示していますが、ニューラルランキングモデル（NRM）に対しては効果が限定的であると考えられます。これは、これらのモデルの検索スコアが短い範囲に収まるからです。本研究では、ペアワイズ推論に基づくNRM（具体的にはDuoT5）の出力を利用し、一つの文書が他の文書よりも上位にランク付けされるというペアワイズの信念を蓄積することを提案します。これらのペアワイズ確率が一貫しているほど、検索結果の質が高くなる可能性が高まり、QPPスコアが上昇するという仮説を立てます。我々は、TREC-DLデータセットで補助モデルDuoT5からのペアワイズ確率を活用して実験を行いました。実験の結果、提案手法であるペアワイズランキング優先型QPP（QPP-PRP）は、いくつかのNRMにおいて標準的な非監督QPPベースラインよりも有意に優れた結果を示しました。
        </label>
        <input type="checkbox" id="Panel310" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> A query performance prediction (QPP) method predicts the effectiveness of an IR system for a given query. While unsupervised approaches have been shown to work well for statistical IR models, it is likely that these approaches would yield limited effectiveness for neural ranking models (NRMs) because the retrieval scores of these models lie within a short range unlike their statistical counterparts. In this work, we propose to leverage a pairwise inference-based NRM's (specifically, DuoT5) output to accumulate evidences on the pairwise believes of one document ranked above the other. We hypothesize that the more consistent these pairwise likelihoods are, the higher is the likelihood of the retrieval to be of better quality, thus yielding a higher QPP score. We conduct our experiments on the TREC-DL dataset leveraging pairwise likelihoods from an auxiliary model DuoT5. Our experiments demonstrate that the proposed method called Pairwise Rank Preference-based QPP (QPP-PRP) leads to significantly better results than a number of standard unsupervised QPP baselines on several NRMs.
        </div> </ul> <br>



        <label for="Panel311">
        <strong> User-Dependent Learning to Debias for Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fangyuan+Luo">Fangyuan Luo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Wu">Jun Wu</a> (1) </u>  <br>
        1:  Beijing Jiaotong University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592083">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=User-Dependent Learning to Debias for Recommendation">Google Scholar</a></div>
        (311)
        <br>
        <b>概要:　</b> レコメンダシステム（RS）において、逆傾向スコア（IPS）は、ユーザーとアイテム間の相互作用をモデル化する際に、人気アイテムの貢献度を減少させることで人気バイアスを緩和する重要な技術です。しかし、従来のIPSは全てのユーザーを同等に扱うため、人気に敏感でない（PI）ユーザーを過度にデバイアスし、人気に敏感な（PS）ユーザーを十分にデバイアスできない傾向があります。その上、この方法ではデバイアスされたテストではほぼ良好な性能を発揮しますが、通常のバイアスがかかったテストでは効果を発揮しません。この問題を解決するために、我々はユーザー依存型IPS（UDIPS）を提案します。この方法は、各ユーザーのアイテム人気への感受性に基づいて各ユーザー・アイテムペアの傾向推定を適応的に行います。IPSと同様に、我々の理論解析によりUDIPSの無バイアス性が検証されています。特筆すべきは、我々のソリューションがモデルに依存せず、現在の無バイアスレコメンダを容易にアップグレードできる点です。我々は、4つの最先端モデルに実装し、2つのベンチマークデータセットでの実験結果により、無バイアスおよび通常のバイアスがかかったテストの両方での我々の手法の有効性を示しています。
        </label>
        <input type="checkbox" id="Panel311" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In recommender systems (RSs), inverse propensity score (IPS) has been a key technique to mitigate popularity bias by decreasing the contribution of popular items in modeling user-item interactions. However, conventional IPS treats all users equally, which tends to over-debias the popularity-insensitive (PI) users and under-debias the popularity-sensitive (PS) users. Furthermore, in such a treatment, IPS only performs slightly well on the debiased test while does not work on the normal biased test. To this end, we propose a user-dependent IPS (UDIPS in short) method, which adaptively conducts propensity estimation for each user-item pair based on the user's sensitivity to item popularity. Like IPS, our theoretical analysis validates the unbiasedness of UDIPS. Remarkably, our solution is model-agnostic and can be easily used to upgrade current unbiased recommenders. We implemented it in four state-of-the-art models for unbiased recommendation, and experimental results on two benchmark datasets demonstrate the effectiveness of our method in both unbiased and normal biased test.
        </div> </ul> <br>



        <label for="Panel312">
        <strong> Using Entropy for Group Sampling in Pairwise Ranking from implicit feedback </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yujie+Chen">Yujie Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Runlong+Yu">Runlong Yu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qi+Liu">Qi Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Enhong+Chen">Enhong Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenya+Huang">Zhenya Huang</a> (1) </u>  <br>
        1:  University of Science and Technology of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592084">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Using Entropy for Group Sampling in Pairwise Ranking from implicit feedback">Google Scholar</a></div>
        (312)
        <br>
        <b>概要:　</b> 近年、ベイジアンパーソナライズドランキング（Bayesian Personalized Ranking, BPR）などのペアワイズ手法は、推薦システムにおける協調フィルタリングの分野で大きな注目を集めています。Group BPRは、BPRを拡張し、ユーザー間の独立性の厳しい仮定を緩和するためにユーザーグループを組み込んだものです。しかし、Group BPRのユーザーグループは、いくつかの行動の類似性にのみ焦点を当てるため、その信頼性が損なわれる可能性があります。本研究では、この問題に対処するために、2人のユーザー間の関係性を定量化し、志向が類似するユーザーグループをサンプリングするための新しいエントロピー重み付け類似度尺度を提案します。まず、グループの嗜好をいくつかのペアワイズランク付けアルゴリズムに導入し、その後、エントロピー重み付け類似度を用いてグループをサンプリングし、これらのアルゴリズムを更に改善します。他のアプローチが共通アイテム評価にのみ依存するのに対し、我々の手法は類似度尺度にグローバル情報を組み込み、より信頼性の高いグループサンプリング手法を提供します。実世界の2つのデータセットで実験を行い、異なるメトリクスを用いて我々の手法を評価しました。結果は、我々の手法が疎なデータからより良いユーザーグループを構築し、より正確な推薦を生成できることを示しています。我々のアプローチは広範な推薦システムに適用可能であり、ペアワイズランク付けアルゴリズムの性能を大幅に改善し、ペアワイズランク付けの効果的なツールとなることができます。
        </label>
        <input type="checkbox" id="Panel312" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In recent years, pairwise methods, such as Bayesian Personalized Ranking (BPR), have gained significant attention in the field of collaborative filtering for recommendation systems. Group BPR is an extension of BPR that incorporates user groups to relax the strict assumption of independence between two users. However, the reliability of its user groups may be compromised as they only focus on a few behavioral similarities. To address this problem, this paper proposes a new entropy-weighted similarity measure for implicit feedback to quantify the relation between two users and sample like-minded user groups. We first introduce the group preference into several pairwise ranking algorithms and then utilize the entropy-weighted similarity to sample groups to further improve these algorithms. Unlike other approaches that rely solely on common item ratings, our method incorporates global information into the similarity measure, resulting in a more reliable approach to group sampling. We conducted experiments on two real-world datasets and evaluated our method using different metrics. The results show that our method can construct better user groups from sparse data and produce more accurate recommendations. Our approach can be applied to a wide range of recommendation systems, and this can significantly improve the performance of pairwise ranking algorithms, making it an effective tool for pairwise ranking.
        </div> </ul> <br>



        <label for="Panel313">
        <strong> Weakly-Supervised Scientific Document Classification via Retrieval-Augmented Multi-Stage Training </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ran+Xu">Ran Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Yu">Yue Yu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Joyce+Ho">Joyce Ho</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Carl+Yang">Carl Yang</a> (1) </u>  <br>
        1:  Emory University, 2:  Georgia Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592085">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Weakly-Supervised Scientific Document Classification via Retrieval-Augmented Multi-Stage Training">Google Scholar</a></div>
        (313)
        <br>
        <b>概要:　</b> 科学文書分類は多岐にわたる応用において重要なタスクですが、人手でラベル付けされたデータを収集するコストは高くつきます。我々は、ラベル名のみを使用して科学文書の分類を研究します。科学の分野では、ラベル名にはしばしば文書コーパスに現れないドメイン固有の概念が含まれているため、ラベルと文書を正確に一致させることが難しいです。この問題に対処するために、我々はWanDeRを提案します。WanDeRは、密な検索を活用して埋め込み空間でのマッチングを行い、ラベル名の意味を捉えます。さらに、ラベル名拡張モジュールを設計してその表現力を豊かにします。最後に、自己訓練ステップを使用して予測を洗練させます。3つのデータセットでの実験により、WanDeRは最良のベースラインを11.9%上回る性能を示しました。我々のコードはhttps://github.com/ritaranx/wanderで公開される予定です。
        </label>
        <input type="checkbox" id="Panel313" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Scientific document classification is a critical task for a wide range of applications, but the cost of collecting human-labeled data can be prohibitive. We study scientific document classification using label names only. In scientific domains, label names often include domain-specific concepts that may not appear in the document corpus, making it difficult to match labels and documents precisely. To tackle this issue, we propose WanDeR, which leverages dense retrieval to perform matching in the embedding space to capture the semantics of label names. We further design the label name expansion module to enrich its representations. Lastly, a self-training step is used to refine the predictions. The experiments on three datasets show that WanDeR outperforms the best baseline by 11.9%. Our code will be published at https://github.com/ritaranx/wander.
        </div> </ul> <br>



        <label for="Panel314">
        <strong> When the Music Stops: Tip-of-the-Tongue Retrieval for Music </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Samarth+Bhargav">Samarth Bhargav</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anne+Schuth">Anne Schuth</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Claudia+Hauff">Claudia Hauff</a> (2) </u>  <br>
        1:  University of Amsterdam, 2:  Spotify <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592086">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=When the Music Stops: Tip-of-the-Tongue Retrieval for Music">Google Scholar</a></div>
        (314)
        <br>
        <b>概要:　</b> タイトル: 音楽における舌の先現象（ToT）検索の研究本研究では、音楽に関する舌の先現象（Tip-of-the-tongue、ToT）検索について検討します。これは、検索者が既存の音楽エンティティを見つけようとするものの、重要な識別情報を正確に思い出せないために成功しない場合です。ToT情報のニーズは、複雑さ、多弁さ、不確実性、および誤った記憶の可能性によって特徴づけられます。本研究では以下の4つの貢献を行います。<br><br>(1) 2,278件の情報ニーズとそれに対する真実の答えを含むデータセット「TOTMUSIC」を収集しました。<br>(2) これらの情報ニーズに対するスキーマを導入し、歌詞検索、オーディオベースの検索、オーディオフィンガープリンティング、テキスト検索など、複数の音楽情報検索（Music IR）サブタスクを含む複数のモダリティが関与することを示しました。<br>(3) このタスクの困難さを強調するために、このデータセットに対して標準のテキスト検索アプローチをベンチマークしました。<br>(4) 大規模言語モデル（LLM）によって生成されたクエリ再構成の有効性を調査し、単に全情報ニーズをクエリとして用いるよりも効果的でないことを示しました。この結果は将来の研究に対する多くの未解決問題を残します。
        </label>
        <input type="checkbox" id="Panel314" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> We present a study of Tip-of-the-tongue (ToT) retrieval for music, where a searcher is trying to find an existing music entity, but is unable to succeed as they cannot accurately recall important identifying information. ToT information needs are characterized by complexity, verbosity, uncertainty, and possible false memories. We make four contributions. (1) We collect a dataset - TOTMUSIC--of 2,278 information needs and ground truth answers. (2) We introduce a schema for these information needs and show that they often involve multiple modalities encompassing several Music IR sub-tasks such as lyric search, audio-based search, audio fingerprinting, and text search. (3) We underscore the difficulty of this task by benchmarking a standard text retrieval approach on this dataset. (4) We investigate the efficacy of query reformulations generated by a Large Language Model (LLM), and show that they are not as effective as simply employing the entire information need as a query--leaving several open questions for future research.
        </div> </ul> <br>



        <label for="Panel315">
        <strong> Where Does Your News Come From? Predicting Information Pathways in Social Media </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alexander+K.+Taylor">Alexander K. Taylor</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nuan+Wen">Nuan Wen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Po-Nien+Kung">Po-Nien Kung</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiaao+Chen">Jiaao Chen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Violet+Peng">Violet Peng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Wang">Wei Wang</a> (1) </u>  <br>
        1:  University of California, 2:  University Southern California, 3:  Georgia Tech <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592087">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Where Does Your News Come From? Predicting Information Pathways in Social Media">Google Scholar</a></div>
        (315)
        <br>
        <b>概要:　</b> 現代社会においてソーシャルネットワークがますます定着する中で、情報（例：特定の出来事に関するニュース報道）がソーシャルメディア上でどのように広がるか（つまり、情報の経路）を理解し、予測することがますます重要になっています。これにより、現実の情報の影響を理解する助けとなります。したがって、本論文では、新しいタスクである情報経路予測（IPP）を提案します。IPPは、特定の文章の伝播経路をコミュニティツリー（情報源を根とする）として示します。このツリーは、個々のユーザーをニュースソースや影響力のあるユーザーを中心に形成されたコミュニティに集約し、そうしたコミュニティノードに基づいてメディア全体の情報伝播パターンを明らかにします。我々は、このタスクが重要かつ有用であると論じます。一方で、コミュニティレベルの相互作用はユーザーレベルのものよりも安定しており、他方で、個々のユーザーはしばしばコミュニティに影響されるため、コミュニティレベルの情報伝播をモデル化することは、従来のリンク予測問題にも寄与するからです。IPPタスクに取り組むために、我々は新しいコンテンツ認識リンク予測GNNモデルであるLightningを紹介し、大規模なTwitterデータセット（COVID関連のツイートすべてを含む）を用いて、Lightningが最先端のリンク予測ベースラインを大幅に上回る性能を示すことを実証します。
        </label>
        <input type="checkbox" id="Panel315" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> As social networks become further entrenched in modern society, it becomes increasingly important to understand and predict how information (e.g., news coverage of a given event) is propagated across social media (i.e., information pathway), which helps the understandings of the impact of real-world information. Thus, in this paper, we propose a novel task, Information Pathway Prediction (IPP), which depicts the propagation paths of a given passage as a community tree (rooted at the information source) on constructed community interaction graphs where we first aggregate individual users into communities formed around news sources and influential users, and then elucidate the patterns of information dissemination across media based on such community nodes. We argue that this is an important and useful task because, on one hand, community-level interactions offer more stability than those at the user level; on the other hand, individual users are often influenced by their community, and modeling community-level information propagation will help the traditional link-prediction problem. To tackle the IPP task, we introduce Lightning, a novel content-aware link prediction GNN model and demonstrate using a large Twitter dataset consisting of all COVID related tweets that Lightning outperforms state-of-the-art link prediction baselines by a significant margin.
        </div> </ul> <br>



        <label for="Panel316">
        <strong> Which Matters Most in Making Fund Investment Decisions? A Multi-granularity Graph Disentangled Learning Framework </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chunjing+Gan">Chunjing Gan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Binbin+Hu">Binbin Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Huang">Bo Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tianyu+Zhao">Tianyu Zhao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yingru+Lin">Yingru Lin</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenliang+Zhong">Wenliang Zhong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Zhang">Zhiqiang Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chuan+Shi">Chuan Shi</a> (2) </u>  <br>
        1:  Ant Group, 2:  Beijing University of Posts and Telecommunications, 3:  Ant Group, 4:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592088">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Which Matters Most in Making Fund Investment Decisions? A Multi-granularity Graph Disentangled Learning Framework">Google Scholar</a></div>
        (316)
        <br>
        <b>概要:　</b> 本論文では、投資信託の意思決定において、個人的な興味に加えて、同調性とリスク選好が重要であることを強調し、これらの側面を区別して特徴付けることを目指しています。その結果、ファンド投資商品のインテリジェントなマッチングを効果的に行うための新しい多粒度グラフ識別学習フレームワーク（MGDL）を開発しました。確立されたファンドグラフとアテンションモジュールの恩恵を受けて、履歴行動から多粒度のユーザー表現が導き出され、個人的な興味、同調性、リスク選好をきめ細かく表現します。特定の意味を持つより強力な識別表現を得るために、MGDLは自己監視信号として、ファンドタイプに基づくコントラストとファンド人気を明示的に取り入れています。オフラインとオンラインの環境での広範な実験により、MGDLの有効性が検証されました。
        </label>
        <input type="checkbox" id="Panel316" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this paper, we highlight that both conformity and risk preference matter in making fund investment decisions beyond personal interest and seek to jointly characterize these aspects in a disentangled manner. Consequently, we develop a novel Multi-granularity Graph Disentangled Learning framework named MGDL to effectively perform intelligent matching of fund investment products. Benefiting from the well-established fund graph and the attention module, multi-granularity user representations are derived from historical behaviors to separately express personal interest, conformity and risk preference in a fine-grained way. To attain stronger disentangled representations with specific semantics, MGDL explicitly involve two self-supervised signals, ie fund type based contrasts and fund popularity. Extensive experiments in offline and online environments verify the effectiveness of MGDL.
        </div> </ul> <br>



        <label for="Panel317">
        <strong> WSFE: Wasserstein Sub-graph Feature Encoder for Effective User Segmentation in Collaborative Filtering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yankai+Chen">Yankai Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yifei+Zhang">Yifei Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Menglin+Yang">Menglin Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zixing+Song">Zixing Song</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chen+Ma">Chen Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Irwin+King">Irwin King</a> (1) </u>  <br>
        1:  The Chinese University of Hong Kong <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592089">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=WSFE: Wasserstein Sub-graph Feature Encoder for Effective User Segmentation in Collaborative Filtering">Google Scholar</a></div>
        (317)
        <br>
        <b>概要:　</b> ユーザーとアイテムのエンゲージメントをベクトル化された埋め込みに基づいて最大化することは、最近のレコメンダーモデルの標準手法です。しかし、アイテム推奨の性能が優れているにもかかわらず、これらの方法は埋め込み空間でユーザー間の類似性のモデリングを暗黙のうちに優先しないため、似たユーザーの識別が不十分であり、追加の処理手法が通常必要となります。徹底的なモデル再学習を避けるために、WSFEを提案します。これは、柔軟に使用できる、モデル非依存でトレーニング不要の表現エンコーダーです。最適輸送理論に基づき、WSFEから得られるエンコードされた表現は、実際の空間と埋め込み空間の間で一致したユーザー間の類似性・距離の測定を提供します。WSFEを6つの最先端レコメンダーモデルに組み込み、6つの実世界のデータセットで広範な実験を行いました。実証的分析により、WSFEの優位性と汎用性が示され、レコメンデーションにおける多様な下流タスクに対する効果が明らかになりました。
        </label>
        <input type="checkbox" id="Panel317" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Maximizing the user-item engagement based on vectorized embeddings is a standard procedure of recent recommender models. Despite the superior performance for item recommendations, these methods however implicitly deprioritize the modeling of user-wise similarity in the embedding space; consequently, identifying similar users is underperforming, and additional processing schemes are usually required otherwise. To avoid thorough model re-training, we propose WSFE, a model-agnostic and training-free representation encoder, to be flexibly employed on the fly for effective user segmentation. Underpinned by the optimal transport theory, the encoded representations from WSFE present a matched user-wise similarity/distance measurement between the realistic and embedding space. We incorporate WSFE into six state-of-the-art recommender models and conduct extensive experiments on six real-world datasets. The empirical analyses well demonstrate the superiority and generality of WSFE to fuel multiple downstream tasks with diverse underlying targets in recommendation.
        </div> </ul> <br>



        <label for="Panel318">
        <strong> EmoUS: Simulating User Emotions in Task-Oriented Dialogues </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hsien-Chin+Lin">Hsien-Chin Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shutong+Feng">Shutong Feng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Christian+Geishauser">Christian Geishauser</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nurul+Lubis">Nurul Lubis</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Carel+van+Niekerk">Carel van Niekerk</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michael+Heck">Michael Heck</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Benjamin+Ruppik">Benjamin Ruppik</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Renato+Vukovic">Renato Vukovic</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Milica+Gasić">Milica Gasić</a> (1) </u>  <br>
        1:  Heinrich-Heine-Universität Düsseldorf <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3592092">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=EmoUS: Simulating User Emotions in Task-Oriented Dialogues">Google Scholar</a></div>
        (318)
        <br>
        <b>概要:　</b> 既存のタスク指向対話システム用のユーザーシミュレーター（US）は、ユーザーのペルソナや感情を考慮せず、セマンティックおよび自然言語レベルでのユーザー行動のみをモデル化しています。多様な感情状態に基づくユーザー行動をモデル化できない一般的なユーザーポリシーを最適化することで、実際に展開された際に高い離脱率を引き起こす可能性があります。そこで、我々はユーザーの感情と行動を同時にシミュレートするユーザーシミュレーターEmoUSを提案します。EmoUSは、ユーザーの目標、対話履歴、ペルソナに基づいてユーザーの感情、セマンティックアクション、および自然言語応答を生成します。システムのどのような行動がどのようなユーザーの感情を引き起こすかを分析することで、EmoUSを様々な対話システムの評価、特にユーザーの感情状態に与える影響の評価に利用できることを示しました。このような手法の開発は、大規模言語モデルを用いたチャットボットの時代と、倫理的懸念が高まる中で重要です。
        </label>
        <input type="checkbox" id="Panel318" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Existing user simulators (USs) for task-oriented dialogue systems only model user behaviour on semantic and natural language levels without considering the user persona and emotions. Optimising dialogue systems with generic user policies, which cannot model diverse user behaviour driven by different emotional states, may result in a high drop-off rate when deployed in the real world. Thus, we present EmoUS, a user simulator that learns to simulate user emotions alongside user behaviour. EmoUS generates user emotions, semantic actions, and natural language responses based on the user goal, the dialogue history, and the user persona. By analysing what kind of system behaviour elicits what kind of user emotions, we show that EmoUS can be used as a probe to evaluate a variety of dialogue systems and in particular their effect on the user's emotional state. Developing such methods is important in the age of large language model chat-bots and rising ethical concerns.
        </div> </ul> <br>



        <label for="Panel319">
        <strong> Repetition and Exploration in Sequential Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ming+Li">Ming Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ali+Vardasbi">Ali Vardasbi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrew+Yates">Andrew Yates</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (1) </u>  <br>
        1:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591914">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Repetition and Exploration in Sequential Recommendation">Google Scholar</a></div>
        (319)
        <br>
        <b>概要:　</b> 複数のレコメンデーションシナリオ、特に次のバスケット推奨において、重複と探索の重要性が明らかにされ、研究されてきました。シーケンシャルレコメンダー（Sequential Recommenders、SR）は、ユーザーの履歴的なインタラクションシーケンスに基づいて次にインタラクトするアイテムを推測・推薦することを目指しています。しかし、重複と探索の観点からシーケンシャルレコメンダーを体系的に分析した研究はありません。その結果、通常は精度の最適化を目指すこれらのモデルが、重複と探索の観点からどう機能するのか、また実際のアプリケーションに導入した際の潜在的な欠点については不明です。本論文では、シーケンシャルレコメンデーションシナリオにおける重複と探索が重要な次元であるかどうかを検討します。ユーザー中心およびアイテム中心の両視点からこの一般化の問題を考察します。後者に向けて、アイテムのリピートエクスポージャーとアイテムのエクスプロエクスポージャーを定義し、シーケンシャルレコメンデーションモデルの精度と露出性を重複と探索の観点から分析します。その結果、(i) SRシナリオにおける重複と探索の精度と難易度には不均衡が存在し、(ii) 従来の平均総合精度と有意差検定ではモデルの推薦精度を完全には表せず、(iii) 精度重視のシーケンシャルレコメンデーションモデルは項目のエクスプロエクスポージャーが少ない/ゼロとなり、アイテムが主にリピートユーザーにのみ推薦され、新規ユーザーに届かない問題があることがわかりました。発見を分析するために、データセットからリピートサンプルを除去し、純粋な探索SRシナリオに焦点を当てます。以下のことが判明しました。(i) リピートショートカットを除去することで推薦の新規性が増し、次に新規アイテムを消費したいユーザーに役立つ、(ii) ニューラルベースのモデルはこの純粋な探索シナリオの基本特性を学習できず、固有の反復バイアス問題を抱える、(iii) 予測層で共有アイテム埋め込みを使用すると推薦がリピートアイテムに偏る可能性がある、(iv) 推薦結果の後処理としてすべてのリピートアイテムを除去することで、いくつかのSRメソッドの上で大幅な改善が得られる。
        </label>
        <input type="checkbox" id="Panel319" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In several recommendation scenarios, including next basket recommendation, the importance of repetition and exploration has been discovered and studied. Sequential recommenders (SR) aim to infer a user's preferences and suggest the next item for them to interact with based on their historical interaction sequences. There has not been a systematic analysis of sequential recommenders from the perspective of repetition and exploration. As a result, it is unclear how these models, that are typically optimized for accuracy, perform in terms of repetition and exploration, as well as the potential drawbacks of deploying them in real applications. In this paper, we examine whether repetition and exploration are important dimensions in the sequential recommendation scenario. We consider this generalizability question both from a user-centered and an item-centered perspective. Towards the latter, we define item repeat exposure and item explore exposure and examine the recommendation performance of sequential recommendation models in terms of both accuracy and exposure from the perspective of repetition and exploration. We find that (i) there is an imbalance in accuracy and difficulty w.r.t. repetition and exploration in SR scenarios, (ii) using the conventional average overall accuracy with a significance test does not fully represent a model's recommendation accuracy, and (iii) accuracy-oriented sequential recommendation models may suffer from less/zero item explore exposure issue, where items are mostly (or even only) recommended to their repeat users and fail to reach their potential new users. To analyze our findings, we remove repeat samples from the dataset, that often act as easy shortcuts, and focus on a pure exploration SR scenario. We find that (i) removing the repetition shortcut increases the recommendation novelty and helps users who prefer to consume novel items next, (ii) neural-based models fail to learn the basic characteristics of this pure exploration scenario and suffer from an inherent repetitive bias issue, (iii) using shared item embeddings in the prediction layer may skew recommendations to repeat items, and (iv) removing all repeat items to post-processing recommendation results leads to a substantial improvement on top of several SR methods.
        </div> </ul> <br>



        <label for="Panel320">
        <strong> Balanced Topic Aware Sampling for Effective Dense Retriever: A Reproducibility Study </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuai+Wang">Shuai Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guido+Zuccon">Guido Zuccon</a> (1) </u>  <br>
        1:  The University of Queensland <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591915">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Balanced Topic Aware Sampling for Effective Dense Retriever: A Reproducibility Study">Google Scholar</a></div>
        (320)
        <br>
        <b>概要:　</b> 知識蒸留は、事前学習型言語モデル（PLMs）に基づくランカーの効果を高める上で重要な役割を果たします。これは、効果的ではあるものの効率が悪い大規模モデルを使用して、より効率的な学生モデルを教えることによって実現されます。学生用の高密度パッセージリトリーバーの知識蒸留の文脈において、バランスの取れたトピック認識サンプリング法が最先端の効果を提供することが示されています。この方法は、同じトピックからのポジティブ・ネガティブペアのパッセージを含むバッチを作成し、ポジティブおよびネガティブパッセージのペア間マージンを均等にすることで、トレーニングバッチの作成に介入します。本研究では、オリジナルの評価に使用されたデータセット（MS MARCO）と異なるドメインのデータセットである商品検索（Amazonショッピングクエリデータセット）の両方において、バランスの取れたトピック認識サンプリング法を再現し、元の結果が異なる文脈に一般化されるかどうかを検証します。我々は、オリジナルの論文の正確な結果を再現することはできませんでしたが、傾向に関してはオリジナルの発見を確認しました。バランスの取れたトピック認識サンプリングは確かに非常に効果的な高密度リトリーバーをもたらします。これらの結果は、商品検索という別の検索タスクに部分的に一般化されますが、MS MARCOに比べて改善の度合いはより少ないことを観察しました。オリジナルの結果を再現し、方法が異なるデータセットにどのように一般化されるかを調査することに加えて、方法の有効性に影響を与える重要な側面、すなわちネガティブサンプリングのためのハードマージン閾値の使用についても調査します。この側面はオリジナルの論文では研究されていませんでした。ハードマージンについては、異なるハードマージン値を設定することにより学生モデルの有効性に大きく影響を与えることがわかりましたが、この影響はデータセットに依存します。実際、リトリーバーモデルがデータセットで示すスコア分布によって決まります。我々の再現性コードはhttps://github.com/ielab/TAS-B-Reproductionで利用可能です。
        </label>
        <input type="checkbox" id="Panel320" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge distillation plays a key role in boosting the effectiveness of rankers based on pre-trained language models (PLMs); this is achieved using an effective but inefficient large model to teach a more efficient student model. In the context of knowledge distillation for a student dense passage retriever, the balanced topic-aware sampling method has been shown to provide state-of-the-art effectiveness. This method intervenes in the creation of the training batches by creating batches that contain positive-negative pairs of passages from the same topic, and balancing the pairwise margins of the positive and negative passages. In this paper, we reproduce the balanced topic-aware sampling method; we do so for both the dataset used for evaluation in the original work (MS MARCO) and for a dataset in a different domain, that of product search (Amazon shopping queries dataset) to study whether the original results generalize to a different context. We show that while we could not replicate the exact results from the original paper, we do confirm the original findings in terms of trends: balanced topic-aware sampling indeed leads to highly effective dense retrievers. These results partially generalize to the other search task we investigate, product search: although we observe the improvements are less significant compared to MS MARCO. In addition to reproducing the original results and studying how the method generalizes to a different dataset, we also investigate a key aspect that influences the effectiveness of the method: the use of a hard margin threshold for negative sampling. This aspect was not studied in the original paper. With respect to hard margins, we find that while setting different hard margin values significantly influences the effectiveness of the student model, this impact is dataset-dependent -- and indeed, it does depend on the score distributions exhibited by retrieval models on the dataset at hand. Our reproducibility code is available at https://github.com/ielab/TAS-B-Reproduction.
        </div> </ul> <br>



        <label for="Panel321">
        <strong> Reproducibility, Replicability, and Insights into Dense Multi-Representation Retrieval Models: from ColBERT to Col* </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Wang">Xiao Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Craig+Macdonald">Craig Macdonald</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nicola+Tonellotto">Nicola Tonellotto</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Iadh+Ounis">Iadh Ounis</a> (1) </u>  <br>
        1:  University of Glasgow, 2:  University of Pisa <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591916">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Reproducibility, Replicability, and Insights into Dense Multi-Representation Retrieval Models: from ColBERT to Col*">Google Scholar</a></div>
        (321)
        <br>
        <b>概要:　</b> ColBERTに代表される高密度マルチリプレゼンテーション検索モデルは、クエリとドキュメントの関連性を文脈化されたトークンレベルの埋め込みの類似性に基づいて評価します。実際、文脈化されたトークンの埋め込みを使用することで、高密度検索は正確なマッチングや意味的なマッチングとして行われ、ドメイン内およびドメイン外両方の検索タスクで効果を高めることができます。これは、重要なモデルであることを示しています。しかし、これらの意味的マッチングが果たす正確な役割はまだ十分に調査されていません。例えば、トークン化は様々な事前学習言語モデルにおいて重要な設計選択肢の一つですが、そのマッチング動作への影響は詳しく検討されていません。本研究では、ColBERTをCol⋆に拡張することにより、文脈化された遅延相互作用メカニズムの再現性と再現可能性を検証します。この拡張により、様々な事前学習モデルと異なるタイプのトークナイザーを実装します。異なるトークン化方式が遅延相互作用メカニズム内でのマッチング動作に直接影響を与える可能性があるため、不同のCol⋆モデルで発生するマッチの性質を研究し、さらに検索効果に対する語彙と意味のマッチングの寄与を定量化します。全体として、我々の実験は様々なクエリセットでのColBERTのパフォーマンスを成功裏に再現し、異なるトークナイザーを持つ異なる事前学習モデルに遅延相互作用メカニズムを再現しました。加えて、以下のような新しい洞察が得られました：(i) 意味のマッチング動作は異なるトークナイザーによって異なる；(ii) より具体的には、高頻度トークンは他のトークンファミリーよりも意味のマッチングを行う傾向がある；(iii) 遅延相互作用メカニズムは意味のマッチングよりも語彙のマッチングからの恩恵を受ける；(iv) [CLS]のような特殊トークンは遅延相互作用において非常に重要な役割を果たす。
        </label>
        <input type="checkbox" id="Panel321" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Dense multi-representation retrieval models, exemplified as ColBERT, estimate the relevance between a query and a document based on the similarity of their contextualised token-level embeddings. Indeed, by using contextualised token embeddings, dense retrieval, conducted as either exact or semantic matches, can result in increased effectiveness for both in-domain and out-of-domain retrieval tasks, indicating that it is an important model to study. However, the exact role that these semantic matches play is not yet well investigated. For instance, although tokenisation is one of the crucial design choices for various pretrained language models, its impact on the matching behaviour has not been examined in detail. In this work, we inspect the reproducibility and replicability of the contextualised late interaction mechanism by extending ColBERT to Col⋆ which implements the late interaction mechanism across various pretrained models and different types of tokenisers. As different tokenisation methods can directly impact the matching behaviour within the late interaction mechanism, we study the nature of matches occurring in different Col⋆ models, and further quantify the contribution of lexical and semantic matching on retrieval effectiveness. Overall, our experiments successfully reproduce the performance of ColBERT on various query sets, and replicate the late interaction mechanism upon different pretrained models with different tokenisers. Moreover, our experimental results yield new insights, such as: (i) semantic matching behaviour varies across different tokenisers; (ii) more specifically, high-frequency tokens tend to perform semantic matching than other token families; (iii) late interaction mechanism benefits more from lexical matching than semantic matching; (iv) special tokens, such as [CLS], play a very important role in late interaction.
        </div> </ul> <br>



        <label for="Panel322">
        <strong> On Stance Detection in Image Retrieval for Argumentation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Miriam+Louise+Carnot">Miriam Louise Carnot</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lorenz+Heinemann">Lorenz Heinemann</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jan+Braker">Jan Braker</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tobias+Schreieder">Tobias Schreieder</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Johannes+Kiesel">Johannes Kiesel</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maik+Fröbe">Maik Fröbe</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Martin+Potthast">Martin Potthast</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Benno+Stein">Benno Stein</a> (3) </u>  <br>
        1:  Leipzig University and ScaDS.AI, 2:  Leipzig University, 3:  Bauhaus-Universität Weimar, 4:  Martin-Luther-Universität Halle Wittenberg <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591917">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=On Stance Detection in Image Retrieval for Argumentation">Google Scholar</a></div>
        (322)
        <br>
        <b>概要:　</b> 論争的なトピックに関するテキストクエリが与えられた場合、論証のための画像検索のタスクは、そのトピックの議論を支援するためにどれだけうまく使えるかに基づいて画像をランク付けすることです。その中で重要なサブタスクは、取得された画像の立場、すなわち画像がトピックの賛成または反対のどちらを支持するかを判断することです。本論文では、CLEF'22 Touchéラボとそれを基にした社内拡張により代表される最新技術の包括的な再現性研究を行います。提出されたアプローチに基づいて、統一かつモジュール化された検索プロセスを開発し、このプロセスに従って提出されたアプローチを再実装しました。この統一された再現（以前考慮されていなかったモデルも含まれる）を通じて、議論的な画像検出の効果性が最大で0.832 precision@10まで向上することを達成しました。しかし、再現の成功にもかかわらず、我々の研究はこれまで知られていなかった否定的な結果も明らかにしました。すなわち、立場検出では、再現されたアプローチや新しいアプローチのいずれもランダムなベースラインを説得力を持って上回ることができないということです。画像の立場検出に内在すると思われる課題を理解するために、徹底的なエラー分析を行い、このタスクにアプローチする新たな方法の可能性について洞察を提供します。
        </label>
        <input type="checkbox" id="Panel322" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Given a text query on a controversial topic, the task of Image Retrieval for Argumentation is to rank images according to how well they can be used to support a discussion on the topic. An important subtask therein is to determine the stance of the retrieved images, i.e., whether an image supports the pro or con side of the topic. In this paper, we conduct a comprehensive reproducibility study of the state of the art as represented by the CLEF'22 Touché lab and an in-house extension of it. Based on the submitted approaches, we developed a unified and modular retrieval process and reimplemented the submitted approaches according to this process. Through this unified reproduction (which also includes models not previously considered), we achieve an effectiveness improvement in argumentative image detection of up to 0.832 precision@10. However, despite this reproduction success, our study also revealed a previously unknown negative result: for stance detection, none of the reproduced or new approaches can convincingly beat a random baseline. To understand the apparent challenges inherent to image stance detection, we conduct a thorough error analysis and provide insight into potential new ways to approach this task.
        </div> </ul> <br>



        <label for="Panel323">
        <strong> Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Joakim+Edin">Joakim Edin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alexander+Junge">Alexander Junge</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jakob+D.+Havtorn">Jakob D. Havtorn</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lasse+Borgholt">Lasse Borgholt</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maria+Maistro">Maria Maistro</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tuukka+Ruotsalo">Tuukka Ruotsalo</a> (6), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lars+Maaløe">Lars Maaløe</a> (3) </u>  <br>
        1:  University of Copenhagen & Corti, 2:  Corti, 3:  Technical University of Denmark & Corti, 4:  University of Aalborg & Corti, 5:  University of Copenhagen, 6:  University of Copenhagen & University of Helsinki <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591918">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study">Google Scholar</a></div>
        (323)
        <br>
        <b>概要:　</b> 医療コーディングは、臨床の自由形式文書に医療コードを割り当てる作業です。医療専門家は、患者の診断や治療を追跡するために、手作業でこれらのコードを割り当てます。自動化された医療コーディングは、この事務的負担をかなり軽減することができます。本論文では、最先端の自動医療コーディング機械学習モデルを再現、比較、分析します。いくつかのモデルは、設定が不適切であったり、訓練とテストの分割が不均等であったり、評価が不十分であるため、期待通りの性能を発揮しないことを示します。先行研究では、マクロF1スコアの計算が最適ではなく、我々の修正により、このスコアは2倍に向上します。層別抽出法と同一の実験設定（ハイパーパラメータおよび決定境界の調整を含む）を使用した修正版のモデル比較を提案します。予測誤差を分析し、先行研究の仮定を検証および反証します。この分析は、すべてのモデルが稀なコードに苦戦する一方、長い文書にはほとんど影響がないことを確認しています。最後に、再現されたモデルを用いて、新しく公開されたMIMIC-IVデータセットに関する最初の包括的な結果を提示します。我々のコード、モデルパラメータ、および新しいMIMIC-IIIおよびMIMIC-IVの訓練と評価のパイプラインを提供し、公平な将来比較を促進します。
        </label>
        <input type="checkbox" id="Panel323" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Medical coding is the task of assigning medical codes to clinical free-text documentation. Healthcare professionals manually assign such codes to track patient diagnoses and treatments. Automated medical coding can considerably alleviate this administrative burden. In this paper, we reproduce, compare, and analyze state-of-the-art automated medical coding machine learning models. We show that several models underperform due to weak configurations, poorly sampled train-test splits, and insufficient evaluation. In previous work, the macro F1 score has been calculated sub-optimally, and our correction doubles it. We contribute a revised model comparison using stratified sampling and identical experimental setups, including hyperparameters and decision boundary tuning. We analyze prediction errors to validate and falsify assumptions of previous works. The analysis confirms that all models struggle with rare codes, while long documents only have a negligible impact. Finally, we present the first comprehensive results on the newly released MIMIC-IV dataset using the reproduced models. We release our code, model parameters, and new MIMIC-III and MIMIC-IV training and evaluation pipelines to accommodate fair future comparisons.
        </div> </ul> <br>



        <label for="Panel324">
        <strong> Query Performance Prediction: From Ad-hoc to Conversational Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chuan+Meng">Chuan Meng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Negar+Arabzadeh">Negar Arabzadeh</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mohammad+Aliannejadi">Mohammad Aliannejadi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (1) </u>  <br>
        1:  University of Amsterdam, 2:  University of Waterloo <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591919">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Query Performance Prediction: From Ad-hoc to Conversational Search">Google Scholar</a></div>
        (324)
        <br>
        <b>概要:　</b> クエリパフォーマンス予測（QPP）は、情報検索の重要な課題です。QPPの課題は、関連性判断なしに検索システムのクエリに対する検索品質を予測することです。研究は、アドホック検索におけるQPPの有効性と有用性を示しています。近年、会話型検索（CS）においても著しい進展が見られます。効果的なQPPは、CSシステムが次のターンで取るべき適切なアクションを決定するのに役立ちます。潜在的な可能性にも関わらず、CSのためのQPPの研究は少ないです。我々は、既存のQPP手法をCSの文脈で再現および評価することで、この研究のギャップに対処します。2つの設定におけるパッセージ検索のタスクは同じままである一方、CSではユーザークエリが対話履歴に依存するため、新たなQPPの課題が生じます。特に、アドホック検索のQPP手法の知見がどの程度CSの3つの設定に一般化されるかを探索します：(i)異なるクエリリライトベースの検索手法の検索品質の推定、(ii)会話型高密度検索手法の検索品質の推定、(iii)上位ランクと下位ランクのリストの検索品質の推定。我々の発見は次のようにされます：(i)教師ありのQPP手法は、大規模な訓練データセットが利用可能な場合にのみ、教師なし手法を明確に上回ります；(ii)ポイントワイズの教師ありQPP手法は、ほとんどの場合リストワイズのカウンターパートを上回ります；(iii)検索スコアベースの教師なしQPP手法は、CSの高密度検索手法であるConvDRを評価する上で高い有効性を示します。
        </label>
        <input type="checkbox" id="Panel324" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Query performance prediction (QPP) is a core task in information retrieval. The QPP task is to predict the retrieval quality of a search system for a query without relevance judgments. Research has shown the effectiveness and usefulness of QPP for ad-hoc search. Recent years have witnessed considerable progress in conversational search (CS). Effective QPP could help a CS system to decide an appropriate action to be taken at the next turn. Despite its potential, QPP for CS has been little studied. We address this research gap by reproducing and studying the effectiveness of existing QPP methods in the context of CS. While the task of passage retrieval remains the same in the two settings, a user query in CS depends on the conversational history, introducing novel QPP challenges. In particular, we seek to explore to what extent findings from QPP methods for ad-hoc search generalize to three CS settings: (i) estimating the retrieval quality of different query rewriting-based retrieval methods, (ii) estimating the retrieval quality of a conversational dense retrieval method, and (iii) estimating the retrieval quality for top ranks vs. deeper-ranked lists. Our findings can be summarized as follows: (i) supervised QPP methods distinctly outperform unsupervised counterparts only when a large-scale training set is available; (ii) point-wise supervised QPP methods outperform their list-wise counterparts in most cases; and (iii) retrieval score-based unsupervised QPP methods show high effectiveness in assessing the conversational dense retrieval method, ConvDR.
        </div> </ul> <br>



        <label for="Panel325">
        <strong> An Empirical Comparison of Web Content Extraction Algorithms </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Janek+Bevendorff">Janek Bevendorff</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sanket+Gupta">Sanket Gupta</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Johannes+Kiesel">Johannes Kiesel</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Benno+Stein">Benno Stein</a> (1) </u>  <br>
        1:  Bauhaus-Universität Weimar <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591920">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=An Empirical Comparison of Web Content Extraction Algorithms">Google Scholar</a></div>
        (325)
        <br>
        <b>概要:　</b> ウェブページから主要コンテンツを抽出する方法—時には「ボイラープレート除去」とも呼ばれる—は、過去20年間にわたる研究課題である。ウェブページが機械可読なマークアップ形式で提供されているにもかかわらず、その実際のコンテンツを抽出することは依然として難題である。多くのセマンティック要素を定義する最新のHTML5規格でさえ、ウェブページの著者がセマンティックマークアップを正しく、または十分に利用しないことがあり、それが自動システムによる関連情報の抽出を困難にしている。高精度かつ高再現性のコンテンツ抽出は、検索エンジンやAI言語ツール、ユーザーブラウザの集中読み取りモード、その他の汎用支援技術といった下流アプリケーションにとって極めて重要である。しかし、このような基本的なタスクに対して、驚くべきことに公開されている抽出システムやトレーニング・ベンチマークデータセットは非常に少ない。さらに、既存の数少ない抽出システムの厳密な評価や真正な比較研究もほとんど行われていない。そこで、本研究では、現在の最先端の状況をより深く理解するために、既存の8つの人間がラベル付けしたウェブコンテンツ抽出データセットを統合し、クリーンアップを実施する。この統合データセット上で、14の競争力のある主要コンテンツ抽出システムと5つのベースライン手法を評価する。最終的に、新しい最先端抽出ベースラインとなる3つのアンサンブルを構築する。本研究では、既存システムの性能がジャンルによって非常に依存すること、そしてどのタイプのウェブページにおいても単一の抽出器が最適に機能するわけではないことを明らかにする。
        </label>
        <input type="checkbox" id="Panel325" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Main content extraction from web pages-sometimes also called boilerplate removal-has been a research topic for over two decades. Yet despite web pages being delivered in a machine-readable markup format, extracting the actual content is still a challenge today. Even with the latest HTML5 standard, which defines many semantic elements to mark content areas, web page authors do not always use semantic markup correctly or to its full potential, making it hard for automated systems to extract the relevant information. A high-precision, high-recall content extraction is crucial for downstream applications such as search engines, AI language tools, distraction-free reader modes in users' browsers, and other general assistive technologies. For such a fundamental task, however, surprisingly few openly available extraction systems or training and benchmarking datasets exist. Even less research has gone into the rigorous evaluation and a true apples-to-apples comparison of the few extraction systems that do exist. To get a better grasp on the current state of the art in the field, we combine and clean eight existing human-labeled web content extraction datasets. On the combined dataset, we evaluate 14~competitive main content extraction systems and five baseline approaches. Finally, we build three ensembles as new state-of-the-art extraction baselines. We find that the performance of existing systems is quite genre-dependent and no single extractor performs best on all types of web pages.
        </div> </ul> <br>



        <label for="Panel326">
        <strong> Multimodal Neural Databases </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Giovanni+Trappolini">Giovanni Trappolini</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrea+Santilli">Andrea Santilli</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Emanuele+Rodolà">Emanuele Rodolà</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alon+Halevy">Alon Halevy</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fabrizio+Silvestri">Fabrizio Silvestri</a> (3) </u>  <br>
        1:  Sapienza University, 2:  Meta AI, 3:  Sapienza University & ISTI-CNR <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591930">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multimodal Neural Databases">Google Scholar</a></div>
        (326)
        <br>
        <b>概要:　</b> テキスト、画像、およびその他のモダリティを通じて入手可能な構造化されていないデータの増加により、それらを問い合わせる新しい方法が求められています。マルチメディア情報検索はこのギャップを埋め、近年エキサイティングな進展を遂げています。広範なマルチメディアアーカイブの検索や取得などのタスクは、主にマルチモーダルディープラーニングの最近の進展により、パフォーマンスが大幅に向上しました。しかし、この分野の手法はサポートするクエリの種類、特にデータベースのようなクエリに対する回答能力に限界があります。そこで、ニューラルデータベースに関する最近の研究に触発されて、私たちは新しい枠組み「マルチモーダルニューラルデータベース（MMNDB）」を提案します。MMNDBは、テキストや画像などの異なる入力モダリティに対する推論を伴う、複雑なデータベースのようなクエリに対応できるものです。本論文では、これらの要件を満たす初のアーキテクチャを紹介し、いくつかのベースラインとテストを行い、現在利用可能なモデルの限界を示します。その結果、これらの新技術が異なるモダリティから来る非構造化データを処理する可能性を示し、この分野における今後の研究の道を開くことが明らかになりました。
        </label>
        <input type="checkbox" id="Panel326" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The rise in loosely-structured data available through text, images, and other modalities has called for new ways of querying them. Multimedia Information Retrieval has filled this gap and has witnessed exciting progress in recent years. Tasks such as search and retrieval of extensive multimedia archives have undergone massive performance improvements, driven to a large extent by recent developments in multimodal deep learning. However, methods in this field remain limited in the kinds of queries they support and, in particular, their inability to answer database-like queries. For this reason, inspired by recent work on neural databases, we propose a new framework, which we name Multimodal Neural Databases (MMNDBs). MMNDBs can answer complex database-like queries that involve reasoning over different input modalities, such as text and images, at scale. In this paper, we present the first architecture able to fulfill this set of requirements and test it with several baselines, showing the limitations of currently available models. The results show the potential of these new techniques to process unstructured data coming from different modalities, paving the way for future research in the area.
        </div> </ul> <br>



        <label for="Panel327">
        <strong> Take a Fresh Look at Recommender Systems from an Evaluation Standpoint </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Aixin+Sun">Aixin Sun</a> (1) </u>  <br>
        1:  Nanyang Technological University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591931">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Take a Fresh Look at Recommender Systems from an Evaluation Standpoint">Google Scholar</a></div>
        (327)
        <br>
        <b>概要:　</b> 推奨は、情報検索（IR）分野において重要な研究分野の一つとなっています。一方で、評価もこのコミュニティにおける伝統的な研究テーマの一つです。最近の研究で報告されたいくつかの直感に反する観察結果に動機付けられ、本稿では評価の観点からレコメンダーシステムを新たに検討します。再現率、ヒット率、NDCG といったメトリクスや、新規性、幅広さといった観点を調べるのではなく、ここでの主な焦点は、レコメンダーアルゴリズムを評価する際にこれらのメトリクスがどのように計算されるかにあります。具体的には、一般的に使用される訓練/テストデータの分割方法とそれに伴う結果を再検討します。まず、ランダムスプリットや留出法といった一般的なデータ分割方法を検討し、なぜ人気基準がそのような分割の下で不十分に定義されるかを論じます。次に、評価時にグローバルな時間軸を無視した場合の二つの影響、すなわちデータ漏洩とユーザーの嗜好モデリングの過度な単純化について探ります。その後、より現実世界のシナリオを正確に反映するアルゴリズム性能の評価技術や、ユーザーの嗜好モデリングにおける意思決定コンテクストを考慮するための可能なアプローチを含む、新しいレコメンダーシステムに関する見解を提示します。
        </label>
        <input type="checkbox" id="Panel327" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recommendation has become a prominent area of research in the field of Information Retrieval (IR). Evaluation is also a traditional research topic in this community. Motivated by a few counter-intuitive observations reported in recent studies, this perspectives paper takes a fresh look at recommender systems from an evaluation standpoint. Rather than examining metrics like recall, hit rate, or NDCG, or perspectives like novelty and diversity, the key focus here is on how these metrics are calculated when evaluating a recommender algorithm. Specifically, the commonly used train/test data splits and their consequences are re-examined. We begin by examining common data splitting methods, such as random split or leave-one-out, and discuss why the popularity baseline is poorly defined under such splits. We then move on to explore the two implications of neglecting a global timeline during evaluation: data leakage and oversimplification of user preference modeling. Afterwards, we present new perspectives on recommender systems, including techniques for evaluating algorithm performance that more accurately reflect real-world scenarios, and possible approaches to consider decision contexts in user preference modeling.
        </div> </ul> <br>



        <label for="Panel328">
        <strong> Where to Go Next for Recommender Systems? ID- vs. Modality-based Recommender Models Revisited </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zheng+Yuan">Zheng Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fajie+Yuan">Fajie Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yu+Song">Yu Song</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Youhua+Li">Youhua Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junchen+Fu">Junchen Fu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Yang">Fei Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunzhu+Pan">Yunzhu Pan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongxin+Ni">Yongxin Ni</a> (1) </u>  <br>
        1:  Westlake University, 2:  Zhejiang Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591932">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Where to Go Next for Recommender Systems? ID- vs. Modality-based Recommender Models Revisited">Google Scholar</a></div>
        (328)
        <br>
        <b>概要:　</b> 異なるユーザーやアイテムを識別するための一意のID（以下、ID）を利用する推薦モデルは、過去10年以上にわたり最先端（SOTA）の地位を占め、推薦システム（RS）分野の文献を席巻してきました。一方で、BERT [9] や Vision Transformer [11] などの事前学習済みモダリティエンコーダーは、テキストや画像などのアイテムの生のモダリティ特徴をモデル化する力がますます強力になっています。このことから、自然な疑問が生じます。それは、SOTAモダリティエンコーダーを用いてアイテムID埋め込みを置き換えた場合、純粋なモダリティベースの推薦モデル（MoRec）が純粋なIDベースのモデル（IDRec）を超えるかまたは匹敵することができるかというものです。実際、この疑問は10年前にIDRecが推薦精度と効率の両方でMoRecを大差で上回ったときに解決されました。我々はこの「古い」疑問を再考し、MoRecをいくつかの側面から体系的に研究することを目指します。具体的には、以下のサブクエスチョンを研究します：（i）実際のシナリオで、特にIDRecが強みを持つ一般的な設定や温暖なアイテムのシナリオで、どの推薦パラダイムがより良い性能を示すか、これは異なるモダリティ特徴を持つアイテムにも当てはまるか？（ii）自然言語処理やコンピュータビジョンなど、他のコミュニティの最新技術的進歩はMoRecにおける精度向上に寄与するか？（iii）アイテムのモダリティ表現を効率的に活用する方法、直接使用できるか、または新しいデータで調整する必要があるか？（iv）MoRecが実際のアプリケーションで取り組むべき重要な課題は何か？これらの質問に答えるために、テキストとビジョンという2つの一般的なモダリティでアイテム推薦に関する厳密な実験を行います。高価なエンドツーエンドのトレーニング方法を用いても、すでにMoRecが温暖なアイテム推薦においてもIDRecに匹敵することを示す初めての実証的証拠を提供します。我々の結果は、RS分野におけるIDRecの優位性が将来的に大きく挑戦される可能性があることを示唆しています。我々のコードとその他の資料をhttps://github.com/westlake-repl/IDvs.MoRec.で公開しています。
        </label>
        <input type="checkbox" id="Panel328" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recommendation models that utilize unique identities (IDs for short) to represent distinct users and items have been state-of-the-art (SOTA) and dominated the recommender systems (RS) literature for over a decade. Meanwhile, the pre-trained modality encoders, such as BERT [9] and Vision Transformer [11], have become increasingly powerful in modeling the raw modality features of an item, such as text and images. Given this, a natural question arises: can a purely modality-based recommendation model (MoRec) outperforms or matches a pure ID-based model (IDRec) by replacing the itemID embedding with a SOTA modality encoder? In fact, this question was answered ten years ago when IDRec beats MoRec by a strong margin in both recommendation accuracy and efficiency. We aim to revisit this 'old' question and systematically study MoRec from several aspects. Specifically, we study several sub-questions: (i) which recommendation paradigm, MoRec or IDRec, performs better in practical scenarios, especially in the general setting and warm item scenarios where IDRec has a strong advantage? does this hold for items with different modality features? (ii) can the latest technical advances from other communities (i.e., natural language processing and computer vision) translate into accuracy improvement for MoRec? (iii) how to effectively utilize item modality representation, can we use it directly or do we have to adjust it with new data? (iv) are there any key challenges that MoRec needs to address in practical applications? To answer them, we conduct rigorous experiments for item recommendations with two popular modalities, i.e., text and vision. We provide the first empirical evidence that MoRec is already comparable to its IDRec counterpart with an expensive end-to-end training method, even for warm item recommendation. Our results potentially imply that the dominance of IDRec in the RS field may be greatly challenged in the future. We release our code and other materials at https://github.com/westlake-repl/IDvs.MoRec.
        </div> </ul> <br>



        <label for="Panel329">
        <strong> The Role of Relevance in Fair Ranking </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Aparna+Balagopalan">Aparna Balagopalan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Abigail+Z.+Jacobs">Abigail Z. Jacobs</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Asia+J.+Biega">Asia J. Biega</a> (3) </u>  <br>
        1:  Massachusetts Institute of Technology, 2:  University of Michigan, 3:  Max Planck Institute for Security and Privacy <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591933">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=The Role of Relevance in Fair Ranking">Google Scholar</a></div>
        (329)
        <br>
        <b>概要:　</b> オンラインプラットフォームは機会へのアクセスを仲介します。リレバンスに基づくランキングは、求人プラットフォームにおける求人情報や候補者、または市場における売り手への露出を割り当てることで、選択肢を生み出し制約します。このような社会的に重要なシステムが責任ある運用を行うために、さまざまな公平性の指標や介入が導入されています。その多くは“価値”に基づいて露出を割り当てることを目指しています。しかし、これらの概念は通常、直接観察することができないため、プラットフォームはリレバンスといった代理スコアを用い、検索者のクリックといった行動信号から推定する必要があります。しかし、リレバンスが高リスクの公平なランキングにおいて“価値”スコアとしての役割を果たすかどうかは依然として未解決の問題です。本論文では、社会科学、情報検索、機械学習の公平性の観点とツールを組み合わせ、公平性の介入を有意義に導くためにリレバンススコアが満たすべき一連の望ましい基準を導き出します。次に、バイアスのあるユーザクリックデータから推定されたリレバンスのケーススタディにおいて、これらの基準のすべてが満たされていないことを実証的に示します。これらの違反がシステムの推定公平性に与える影響を評価し、既存の公平性介入が特定された問題を軽減できるかどうかを分析します。我々の分析と結果は、公平なランキングに適した新しいリレバンスの収集と生成方法の緊急な必要性を浮き彫りにします。
        </label>
        <input type="checkbox" id="Panel329" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Online platforms mediate access to opportunity: relevance-based rankings create and constrain options by allocating exposure to job openings and job candidates in hiring platforms, or sellers in a marketplace. In order to do so responsibly, these socially consequential systems employ various fairness measures and interventions, many of which seek to allocate exposure based on worthiness. Because these constructs are typically not directly observable, platforms must instead resort to using proxy scores such as relevance and infer them from behavioral signals such as searcher clicks. Yet, it remains an open question whether relevance fulfills its role as %a deservedness score such a worthiness score in high-stakes fair rankings. In this paper, we combine perspectives and tools from the social sciences, information retrieval, and fairness in machine learning to derive a set of desired criteria that relevance scores should satisfy in order to meaningfully guide fairness interventions. We then empirically show that not all of these criteria are met in a case study of relevance inferred from biased user click data. We assess the impact of these violations on the estimated system fairness and analyze whether existing fairness interventions may mitigate the identified issues. Our analyses and results surface the pressing need for new approaches to relevance collection and generation that are suitable for use in fair ranking.
        </div> </ul> <br>



        <label for="Panel330">
        <strong> How Important is Periodic Model update in Recommender System? </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hyunsung+Lee">Hyunsung Lee</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sungwook+Yoo">Sungwook Yoo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongjun+Lee">Dongjun Lee</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jaekwang+Kim">Jaekwang Kim</a> (2) </u>  <br>
        1:  Kakao Corporation, 2:  Sungkyunkwan University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591934">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=How Important is Periodic Model update in Recommender System?">Google Scholar</a></div>
        (330)
        <br>
        <b>概要:　</b> 現実世界のレコメンダーモデル配備において、モデルは通常、再トレーニングおよび再配備が繰り返し行われます。レコメンダーモデルを定期的に再トレーニングして最新のユーザー行動やアイテムのトレンドを捕捉することが経験則となっています。しかし、モデルの更新が遅れることによる悪影響はまだ十分に調査されていません。本展望論文では、モデル更新の遅延問題を定式化し、遅延モデル更新が実際にモデル性能に有害であることを定量的に示します。具体的には、冷却ユーザーと冷却アイテムの数が増加し、全体的なモデル性能が低下することを示します。これらの影響は、異なる特性を持つ異なるドメインにおいて異なります。これらの発見に基づき、遅延モデル更新がオンラインレコメンダーモデル配備において負の影響を与えるにもかかわらず、研究コミュニティから十分な注意を集めていないと主張します。我々の検証により、モデル更新サイクルとモデル性能の関係が明らかになったことで、より迅速なモデルトレーニングや、より効率的なデータパイプラインの研究が必要であると訴えます。これにより、モデルを最新のユーザー行動やアイテムのトレンドにより適応させることが可能となります。
        </label>
        <input type="checkbox" id="Panel330" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In real-world recommender model deployments, the models are typically retrained and deployed repeatedly. It is the rule-of-thumb to periodically retrain recommender models to capture up-to-date user behavior and item trends. However, the harm caused by delayed model updates has not been investigated extensively yet. in this perspective paper, we formulate the delayed model update problem and quantitatively demonstrate the delayed model update actually harms the model performance by increasing the number of cold users and cold items increase and decreasing overall model performances. These effects vary across different domains having different characteristics. Upon these findings, we further argue that although the delayed model update has negative effects on online recommender model deployment, yet it has not gathered enough attention from research communities. We argue our verification of the relationship between the model update cycle and model performance calls for further research such as faster model training, and more efficient data pipelines to keep the model more up-to-date with the latest user behaviors and item trends.
        </div> </ul> <br>



        <label for="Panel331">
        <strong> Metric-agnostic Ranking Optimization </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qingyao+Ai">Qingyao Ai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuanhui+Wang">Xuanhui Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michael+Bendersky">Michael Bendersky</a> (2) </u>  <br>
        1:  Tsinghua University, 2:  Google Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591935">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Metric-agnostic Ranking Optimization">Google Scholar</a></div>
        (331)
        <br>
        <b>概要:　</b> ランキングは情報検索の中心にあります。従来のランキング最適化研究では、ランキングを個々のアイテムの有用性に基づいて並べ替える問題と見なし、最も良いパフォーマンスはその方法で達成されるとの前提があります。その結果、多くのランキング指標が開発され、それを最適化するための学習アルゴリズムが現代の情報検索システムで広く使用されています。しかし、アプリケーションが進化するにつれて、人々の情報検索に対するニーズは単に関連する文書を取得することから、より複雑な業務や娯楽のニーズを満たす高度な情報サービスへとシフトしています。したがって、ユーザーの満足度やエンゲージメントといったより複雑でユーザー中心の目標が、現代の情報検索システムの評価に採用されています。残念ながら、これらの目標は、既存の学習アルゴリズムの枠組みの中では最適化が困難です。なぜなら、これらは大きな分散や複雑な構造を持ち、単純な数式で明示的に説明や定式化することが難しいからです。このような問題に対し、複雑なランキング指標の内部構造を知らずに結果を最適化する方法は何かという研究問題が生じます。この問題に対処するため、既存のランキング最適化技術の限界について形式的な分析を行い、メトリック無関係ランキング最適化に関する3つの研究課題を提示します。(1) オフラインデータにおいて複雑なオンラインランキング指標をシミュレートする代理指標モデルの開発、(2) 詳細な監督信号なしでリストやセッションレベルのパフォーマンス指標を最適化するための微分可能なランキング最適化フレームワークの開発、(3) メトリック無関係なシナリオにおけるランキング最適化のための効率的なパラメータ探索および活用技術の開発です。これらの課題に対する潜在的な解決策の議論を通じて、複雑な検索およびレコメンデーションシナリオにおけるランキング最適化の問題に対する関心が高まることを期待しています。
        </label>
        <input type="checkbox" id="Panel331" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Ranking is at the core of Information Retrieval. Classic ranking optimization studies often treat ranking as a sorting problem with the assumption that the best performance of ranking would be achieved if we rank items according to their individual utility. Accordingly, considerable ranking metrics have been developed and learning-to-rank algorithms that have been designed to optimize these simple performance metrics have been widely used in modern IR systems. As applications evolve, however, people's need for information retrieval have shifted from simply retrieving relevant documents to more advanced information services that satisfy their complex working and entertainment needs. Thus, more complicated and user-centric objectives such as user satisfaction and engagement have been adopted to evaluate modern IR systems today. Those objectives, unfortunately, are difficult to be optimized under existing learning-to-rank frameworks as they are subject to great variance and complicated structures that cannot be explicitly explained or formulated with math equations like those simple performance metrics. This leads to the following research question -- how to optimize result ranking for complex ranking metrics without knowing their internal structures? To address this question, we conduct formal analysis on the limitation of existing ranking optimization techniques and describe three research tasks in Metric-agnostic Ranking Optimization: (1) develop surrogate metric models to simulate complex online ranking metrics on offline data; (2) develop differentiable ranking optimization frameworks for list or session level performance metrics without fine-grained supervision signals; and (3) develop efficient parameter exploration and exploitation techniques for ranking optimization in metric-agnostic scenarios. Through the discussion of potential solutions to these tasks, we hope to encourage more people to look into the problem of ranking optimization in complex search and recommendation scenarios.
        </div> </ul> <br>



        <label for="Panel332">
        <strong> T2Ranking: A Large-scale Chinese Benchmark for Passage Ranking </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaohui+Xie">Xiaohui Xie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qian+Dong">Qian Dong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bingning+Wang">Bingning Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Feiyang+Lv">Feiyang Lv</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ting+Yao">Ting Yao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weinan+Gan">Weinan Gan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhijing+Wu">Zhijing Wu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangsheng+Li">Xiangsheng Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haitao+Li">Haitao Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiqun+Liu">Yiqun Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jin+Ma">Jin Ma</a> (2) </u>  <br>
        1:  Tsinghua University, 2:  Tencent Inc., 3:  Beijing Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591874">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=T2Ranking: A Large-scale Chinese Benchmark for Passage Ranking">Google Scholar</a></div>
        (332)
        <br>
        <b>概要:　</b> パッセージランキングは、パッセージ検索とパッセージの再ランキングという2つの段階を含み、情報検索（IR）の分野において、学術界および産業界にとって重要かつ挑戦的なトピックです。しかし、パッセージランキングに一般的に使用されるデータセットは、通常英語に焦点を当てています。例えば中国語のような非英語のシナリオにおいては、既存のデータセットはデータ規模、詳細な関連性アノテーション、および偽陰性問題の点で限定されています。この問題を解決するために、我々はパッセージランキングのための大規模な中国語ベンチマークであるT2Rankingを紹介します。T2Rankingは、実際の検索エンジンから得られた30万以上のクエリと200万以上のユニークなパッセージを含んでいます。専門のアノテーターがクエリとパッセージのペアに対して、バイナリ関連性判断（粗い判断）ではなく、4段階の詳細な関連性スコア（詳細な判断）を提供するように招かれています。偽陰性問題を軽減するために、特にテストセットにおいて、多様性の高いパッセージを関連性アノテーションの際に考慮し、より正確な評価を確保します。テキストベースのクエリとパッセージデータに加えて、さらなる研究を容易にするため、クエリタイプやパッセージの元となる文書のXMLファイルなどの補助資源も提供されています。データセットを評価するために、一般的に使用されるランキングモデルがT2Ranking上でベースラインとして実装およびテストされました。実験結果は、T2Rankingが挑戦的であり、まだ改善の余地があることを示しています。全データおよびすべてのコードは、https://github.com/THUIR/T2Ranking/ で利用可能です。
        </label>
        <input type="checkbox" id="Panel332" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Passage ranking involves two stages: passage retrieval and passage re-ranking, which are important and challenging topics for both academics and industries in the area of Information Retrieval (IR). However, the commonly-used datasets for passage ranking usually focus on the English language. For non-English scenarios, such as Chinese, the existing datasets are limited in terms of data scale, fine-grained relevance annotation and false negative issues. To address this problem, we introduce T2Ranking, a large-scale Chinese benchmark for passage ranking. T2Ranking comprises more than 300K queries and over 2M unique passages from real-world search engines. Expert annotators are recruited to provide 4-level graded relevance scores (fine-grained) for query-passage pairs instead of binary relevance judgments (coarse-grained). To ease the false negative issues, more passages with higher diversities are considered when performing relevance annotations, especially in the test set, to ensure a more accurate evaluation. Apart from the textual query and passage data, other auxiliary resources are also provided, such as query types and XML files of documents which passages are generated from, to facilitate further studies. To evaluate the dataset, commonly used ranking models are implemented and tested on T2Ranking as baselines. The experimental results show that T2Ranking is challenging and there is still scope for improvement. The full data and all codes are available at https://github.com/THUIR/T2Ranking/.
        </div> </ul> <br>



        <label for="Panel333">
        <strong> BizGraphQA: A Dataset for Image-based Inference over Graph-structured Diagrams from Business Domains </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Petr+Babkin">Petr Babkin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=William+Watson">William Watson</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Ma">Zhiqiang Ma</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lucas+Cecchi">Lucas Cecchi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Natraj+Raman">Natraj Raman</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Armineh+Nourbakhsh">Armineh Nourbakhsh</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sameena+Shah">Sameena Shah</a> (2) </u>  <br>
        1:  J.P. Morgan AI Research, 2:  J.P. Morgan AI Research, 3:  J.P. Morgan AI Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591875">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=BizGraphQA: A Dataset for Image-based Inference over Graph-structured Diagrams from Business Domains">Google Scholar</a></div>
        (333)
        <br>
        <b>概要:　</b> 企業の所有権チャートや管理階層のようなグラフ構造を持つ図は、言語と空間関係のモデリング能力だけでなく、エンティティ間のリンクのトポロジーや、それらのリンクが表す様々な意味合いを含めて理解する必要があるため、ディープラーニングモデルにとって挑戦的な媒体です。このような図を自動的に処理し、理解することができる質問応答モデルを開発することは、多くの企業分野における広範な応用が可能であり、マルチモーダルな文書理解の最先端を新たな領域へと前進させる可能性があります。これらのモデルを訓練するための実世界データセットを作成することは、これらの図を含む文書の希少性や機密性のために困難です。最近リリースされた合成データセットは、繰り返しの構造に陥りがちで、記憶やヒューリスティクスに依存することが多いです。本論文では、四つのビジネスドメインの実際のグラフの特性を忠実に反映し、異なるスタイルとレイアウトでPDFドキュメント内に現実的にレンダリングされた、10,000の合成グラフのコレクションを紹介します。加えて、各ドメイン固有の複雑なグラフィカル関係をターゲットとした130,000以上の質問インスタンスを生成しました。このチャレンジが、ビジネスや科学の各分野で広く見られるグラフ構造の画像について、堅牢な推論が可能なモデルの開発を促進することを期待しています。
        </label>
        <input type="checkbox" id="Panel333" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Graph-structured diagrams, such as enterprise ownership charts or management hierarchies, are a challenging medium for deep learning models as they not only require the capacity to model language and spatial relations but also the topology of links between entities and the varying semantics of what those links represent. Devising Question Answering models that automatically process and understand such diagrams have vast applications to many enterprise domains, and can move the state-of-the-art on multimodal document understanding to a new frontier. Curating real-world datasets to train these models can be difficult, due to scarcity and confidentiality of the documents where such diagrams are included. Recently released synthetic datasets are often prone to repetitive structures that can be memorized or tackled using heuristics. In this paper, we present a collection of 10,000 synthetic graphs that faithfully reflect properties of real graphs in four business domains, and are realistically rendered within a PDF document with varying styles and layouts. In addition, we have generated over 130,000 question instances that target complex graphical relationships specific to each domain. We hope this challenge will encourage the development of models capable of robust reasoning about graph structured images, which are ubiquitous in numerous sectors in business and across scientific disciplines.
        </div> </ul> <br>



        <label for="Panel334">
        <strong> Towards Building Voice-based Conversational Recommender Systems: Datasets, Potential Solutions and Prospects </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinghua+Qu">Xinghua Qu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongyang+Liu">Hongyang Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhu+Sun">Zhu Sun</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Yin">Xiang Yin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yew+Soon+Ong">Yew Soon Ong</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lu+Lu">Lu Lu</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zejun+Ma">Zejun Ma</a> (6) </u>  <br>
        1:  Bytedance AI Lab, 2:  Bytedance AI Lab, 3:  Institute of High Performance Computing, 4:  A*STAR Centre for Frontier AI Research & Nanyang Technological University, 5:  Bytedance AI Lab, 6:  Bytedance AI Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591876">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Towards Building Voice-based Conversational Recommender Systems: Datasets, Potential Solutions and Prospects">Google Scholar</a></div>
        (334)
        <br>
        <b>概要:　</b> 対話型推薦システム（CRS）は、対話を通じてユーザーの好みを明示的に取得し、推薦理由を明示するという自然な利点を持つため、推薦システムの分野において注目される研究テーマとなっている。しかし、現在のCRSの大部分はテキストベースであり、視覚障害者や読写能力が限られたユーザーにとって使い勝手が悪い場合がある。そこで本研究では、初めて音声ベースの対話型推薦システム（VCRS）の可能性を探り、自然で直感的、便利でアクセスしやすい形で推薦システムとユーザーが対話する革新的な方法を提案する。これを支えるため、徹底的な文献レビューを通じてこれらのデータセットの欠如を認識し、eコマースと映画分野で2つのVCRSベンチマークデータセットを作成した。具体的には、まずこれらのデータセットを作成する利点と必要性を実証的に確認した。その後、ユーザーとアイテムのインタラクションをテキストベースの対話に変換し、ChatGPTによるプロンプトを使用して多様で自然なテンプレートを生成し、テキストから音声への変換モデルを用いて対応する音声を合成した。また、声の対話の自然さと高品質を確保するためのいくつかの戦略が慎重に設計された。これに基づき、音声ベースの入力をシームレスに抽出および統合し、性能が向上し自己説明可能でユーザーフレンドリーなVCRSを構築するための潜在的な解決策と方向性をさらに検討した。本研究は、VCRSの新興分野における基盤を確立し、さらに先駆的な研究を動機付けることを目的としている。これは、説明可能なAIと社会的善のためのAIの原則、すなわち公正、持続可能、公平な世界を創造するための技術の潜在力を活用することに一致する。我々のコードとデータセットはGitHub (https://github.com/hyllll/VCRS) で入手可能である。
        </label>
        <input type="checkbox" id="Panel334" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Conversational recommender systems (CRSs) have become crucial emerging research topics in the field of RSs, thanks to their natural advantages of explicitly acquiring user preferences via interactive conversations and revealing the reasons behind recommendations. However, the majority of current CRSs are text-based, which is less user-friendly and may pose challenges for certain users, such as those with visual impairments or limited writing and reading abilities. Therefore,for the first time, this paper investigates the potential of voice-based CRS (VCRSs) to revolutionize the way users interact with RSs in a natural, intuitive, convenient, and accessible fashion. To support such studies, we create two VCRSs benchmark datasets in the e-commerce and movie domains, after realizing the lack of such datasets through an exhaustive literature review. Specifically, we first empirically verify the benefits and necessity of creating such datasets. Thereafter, we convert the user-item interactions to text-based conversations through the ChatGPT-driven prompts for generating diverse and natural templates, and then synthesize the corresponding audios via the text-to-speech model. Meanwhile, a number of strategies are delicately designed to ensure the naturalness and high quality of voice conversations. On this basis, we further explore the potential solutions and point out possible directions to build end-to-end VCRSs by seamlessly extracting and integrating voice-based inputs, thus delivering performance-enhanced, self-explainable, and user-friendly VCRSs. Our study aims to establish the foundation and motivate further pioneering research in the emerging field of VCRSs. This aligns with the principles of explainable AI and AI for social good, viz., utilizing technology's potential to create a fair, sustainable, and just world. Our codes and datasets are available on GitHub (https://github.com/hyllll/VCRS ).
        </div> </ul> <br>



        <label for="Panel335">
        <strong> SocialDial: A Benchmark for Socially-Aware Dialogue Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haolan+Zhan">Haolan Zhan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhuang+Li">Zhuang Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yufei+Wang">Yufei Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linhao+Luo">Linhao Luo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tao+Feng">Tao Feng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoxi+Kang">Xiaoxi Kang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuncheng+Hua">Yuncheng Hua</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lizhen+Qu">Lizhen Qu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lay-Ki+Soon">Lay-Ki Soon</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Suraj+Sharma">Suraj Sharma</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ingrid+Zukerman">Ingrid Zukerman</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaleh+Semnani-Azad">Zhaleh Semnani-Azad</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gholamreza+Haffari">Gholamreza Haffari</a> (1) </u>  <br>
        1:  Monash University, 2:  Monash University, 3:  California State University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591877">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SocialDial: A Benchmark for Socially-Aware Dialogue Systems">Google Scholar</a></div>
        (335)
        <br>
        <b>概要:　</b> 内容警告：本論文には攻撃的または動揺を引き起こす内容を含む場合があります。対話システムは多くのシナリオで広く応用されており、現在ではこれまで以上に強力で普及しています。大規模なニューラルモデルと大量に利用できるデータにより、現在の対話システムは人間が生涯で得られる以上の知識にアクセスできます。しかし、現在の対話システムは依然として人間レベルのパフォーマンスを達成していません。対話エージェントと人間の間の主なギャップの一つが、社会的規範に対する認識能力にあります。社会的に認識力のある対話システムの開発は、リソースの不足により妨げられています。本論文では、初めての社会的に認識力のある対話コーパスであるSocialDialを紹介します。SocialDialは、中国の社会文化に基づいています。SocialDialは二つの部分から構成されており、人間のスピーカー間での1,563のマルチターン対話に細かいラベルを付けたものと、ChatGPTによって生成された4,870の合成対話です。人間によるコーパスは、社会的規範の5つのカテゴリをカバーしており、合計で14のサブカテゴリがあります。具体的には、社会的関係、コンテキスト、社会的距離、社会的規範などの社会的要因の注釈が含まれています。しかし、十分な社会的認識力を持つ対話を収集することは高コストです。したがって、我々はChatGPTの力を活用し、オントロジーに基づく合成データ生成フレームワークを考案しました。このフレームワークは大規模な合成データを生成することができます。合成対話の品質を確保するために、データ収集中にいくつかの品質管理メカニズムを設計しました。最後に、BERTやRoBERTaなどのいくつかの事前訓練されたモデルを使用して我々のデータセットを評価しました。最先端のニューラルモデルに基づく包括的な実証結果は、対話システムの社会的規範のモデリングが有望な研究方向であることを示しています。我々の知る限り、SocialDialは複数の社会的要因をカバーし、細かいラベルが付けられた初めての社会的に認識力のある対話データセットです。
        </label>
        <input type="checkbox" id="Panel335" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Content Warning: this paper may contain content that is offensive or upsetting. Dialogue systems have been widely applied in many scenarios and are now more powerful and ubiquitous than ever before. With large neural models and massive available data, current dialogue systems have access to more knowledge than any people in their life. However, current dialogue systems still do not perform at a human level. One major gap between conversational agents and humans lies in their abilities to be aware of social norms. The development of socially-aware dialogue systems is impeded due to the lack of resources. In this paper, we present the first socially-aware dialogue corpus -- SocialDial based on Chinese social culture. SocialDial consists of two parts: 1,563 multi-turn dialogues between two human speakers with fine-grained labels, and 4,870 synthetic conversations generated by ChatGPT. The human corpus covers five categories of social norms, which have 14 sub-categories in total. Specifically, it contains social factor annotations including social relation, context, social distance, and social norms. However, collecting sufficient socially-aware dialogues is costly. Thus, we harness the power of ChatGPT and devise an ontology-based synthetic data generation framework. This framework is able to generate synthetic data at scale. To ensure the quality of synthetic dialogues, we design several mechanisms for quality control during data collection. Finally, we evaluate our dataset using several pre-trained models, such as BERT and RoBERTa. Comprehensive empirical results based on state-of-the-art neural models demonstrate that modeling of social norms for dialogue systems is a promising research direction. To the best of our knowledge, SocialDial is the first socially-aware dialogue dataset that covers multiple social factors and has fine-grained labels.
        </div> </ul> <br>



        <label for="Panel336">
        <strong> U-NEED: A Fine-grained Dataset for User Needs-Centric E-commerce Conversational Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuanxing+Liu">Yuanxing Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weinan+Zhang">Weinan Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Baohua+Dong">Baohua Dong</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yan+Fan">Yan Fan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hang+Wang">Hang Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fan+Feng">Fan Feng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yifan+Chen">Yifan Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ziyu+Zhuang">Ziyu Zhuang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hengbin+Cui">Hengbin Cui</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yongbin+Li">Yongbin Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wanxiang+Che">Wanxiang Che</a> (1) </u>  <br>
        1:  Independent, 2:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591878">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=U-NEED: A Fine-grained Dataset for User Needs-Centric E-commerce Conversational Recommendation">Google Scholar</a></div>
        (336)
        <br>
        <b>概要:　</b> 対話型推薦システム（CRS）は、ユーザーに適切なアイテムを推奨するために、対話で表現される情報ニーズや好みを理解することを目的としています。既存の対話型推薦データセットの多くは、クラウドソーシングによって合成またはシミュレーションされたものであり、現実のシナリオとは大きなギャップがあります。このギャップを埋めるために、以前の研究は、Eコマースシナリオにおけるユーザーとカスタマーサービススタッフ間のプレセールス対話に基づいたデータセットE-ConvRecを提供しました。しかし、E-ConvRecは粗粒度のアノテーションと一般的なタスクしか提供しておらず、プレセールス対話での推奨に限定されています。それとは異なり、私たちは実際のユーザーニーズを手がかりにして、複雑なプレセールス対話におけるEコマース対話型推薦、すなわちユーザーニーズ中心のEコマース対話型推薦（UNECR）を探求します。本論文では、現実のEコマースシナリオからユーザーニーズ中心のEコマース対話型推薦データセット（U-NEED）を構築しました。U-NEEDは以下の3タイプのリソースで構成されています。(i) 5つの主要カテゴリーにおける7,698の細粒度のアノテーション付きプレセールス対話、(ii) 333,879のユーザー行動、(iii) 332,148の製品知識トリプル。UNECRの研究を促進するために、5つの重要なタスクを提案します。(i) プレセールス対話の理解、(ii) ユーザーニーズの引き出し、(iii) ユーザーニーズに基づく推薦、(iv) プレセールス対話の生成、(v) プレセールス対話の評価。各タスクに対するベースライン手法と評価指標を確立しました。U-NEEDにおける5つのタスクの実験結果を報告します。また、3つの典型的なカテゴリーにおける結果も報告します。実験結果は、さまざまなカテゴリーにおけるUNECRの課題が異なることを示しています。
        </label>
        <input type="checkbox" id="Panel336" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Conversational recommender systems ( CRS s) aim to understand the information needs and preferences expressed in a dialogue to recommend suitable items to the user. Most of the existing conversational recommendation datasets are synthesized or simulated with crowdsourcing, which has a large gap with real-world scenarios. To bridge the gap, previous work contributes a dataset E-ConvRec, based on pre-sales dialogues between users and customer service staff in E-commerce scenarios. However, E-ConvRec only supplies coarse-grained annotations and general tasks for making recommendations in pre-sales dialogues. Different from it, we use real user needs as a clue to explore the E-commerce conversational recommendation in complex pre-sales dialogues, namely user needs-centric E-commerce conversational recommendation (UNECR). In this paper, we construct a user needs-centric E-commerce conversational recommendation dataset (U-NEED ) from real-world E-commerce scenarios. U-NEED consists of 3 types of resources: (i) 7,698 fine-grained annotated pre-sales dialogues in 5 top categories (ii) 333,879 user behaviors and (iii) 332,148 product knowledge tuples. To facilitate the research of UNECR, we propose 5 critical tasks: (i) pre-sales dialogue understanding (ii) user needs elicitation (iii) user needs-based recommendation (iv) pre-sales dialogue generation and (v) pre-sales dialogue evaluation. We establish baseline methods and evaluation metrics for each task. We report experimental results of 5 tasks on U-NEED . We also report results on 3 typical categories. Experimental results indicate that the challenges of UNECR in various categories are different.
        </div> </ul> <br>



        <label for="Panel337">
        <strong> End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Barry+Menglong+Yao">Barry Menglong Yao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Aditya+Shah">Aditya Shah</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lichao+Sun">Lichao Sun</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jin-Hee+Cho">Jin-Hee Cho</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lifu+Huang">Lifu Huang</a> (1) </u>  <br>
        1:  Virginia Tech, 2:  Lehigh University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591879">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models">Google Scholar</a></div>
        (337)
        <br>
        <b>概要:　</b> 我々は、エンドツーエンドのマルチモーダル事実確認と説明生成を提案します。この手法では、入力として主張と、大量のウェブソース（記事、画像、動画、ツイートを含む）を用い、関連する証拠を検索し、真実性ラベル（例：支持する、反駁する、情報不足）を予測することにより、主張の真実性を評価します。また、推論および判定プロセスをし、説明する文を生成します。この研究を支援するために、MOCHEGという大規模データセットを構築しました。MOCHEGは、各主張が真実性ラベルと判定文で注釈付けされた合計15,601件の主張、および33,880のテキスト段落と12,112の画像を証拠として含んでいます。MOCHEGにおけるベースラインパフォーマンスを確立するために、マルチモーダル証拠検索、主張検証、説明生成という3つの段階において、いくつかの最先端のニューラルアーキテクチャを実験しました。その結果、最先端のエンドツーエンドのマルチモーダル事実確認では満足のいく結果が得られないことが分かりました。我々の知る限り、エンドツーエンドのマルチモーダル事実確認と説明生成のためのベンチマークデータセットとソリューションを構築したのは、我々が初めてです。このデータセット、ソースコード、およびモデルチェックポイントは、https://github.com/VT-NLP/Mocheg で入手可能です。
        </label>
        <input type="checkbox" id="Panel337" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> We propose end-to-end multimodal fact-checking and explanation generation, where the input is a claim and a large collection of web sources, including articles, images, videos, and tweets, and the goal is to assess the truthfulness of the claim by retrieving relevant evidence and predicting a truthfulness label (e.g., support, refute or not enough information), and to generate a statement to summarize and explain the reasoning and ruling process. To support this research, we construct MOCHEG, a large-scale dataset consisting of 15,601 claims where each claim is annotated with a truthfulness label and a ruling statement, and 33,880 textual paragraphs and 12,112 images in total as evidence. To establish baseline performances on MOCHEG, we experiment with several state-of-the-art neural architectures on the three pipelined subtasks: multimodal evidence retrieval, claim verification, and explanation generation, and demonstrate that the performance of the state-of-the-art end-to-end multimodal fact-checking does not provide satisfactory outcomes. To the best of our knowledge, we are the first to build the benchmark dataset and solutions for end-to-end multimodal fact-checking and explanation generation. The dataset, source code and model checkpoints are available at https://github.com/VT-NLP/Mocheg.
        </div> </ul> <br>



        <label for="Panel338">
        <strong> Recipe-MPR: A Test Collection for Evaluating Multi-aspect Preference-based Natural Language Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haochen+Zhang">Haochen Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anton+Korikov">Anton Korikov</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Parsa+Farinneya">Parsa Farinneya</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mohammad+Mahdi+Abdollah+Pour">Mohammad Mahdi Abdollah Pour</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Manasa+Bharadwaj">Manasa Bharadwaj</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ali+Pesaranghader">Ali Pesaranghader</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xi+Yu+Huang">Xi Yu Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Xin+Lok">Yi Xin Lok</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaoqi+Wang">Zhaoqi Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nathan+Jones">Nathan Jones</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Scott+Sanner">Scott Sanner</a> (3) </u>  <br>
        1:  University of Toronto, 2:  LG Electronics, 3:  University of Toronto & Vector Institute of Artificial Intelligence <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591880">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Recipe-MPR: A Test Collection for Evaluating Multi-aspect Preference-based Natural Language Retrieval">Google Scholar</a></div>
        (338)
        <br>
        <b>概要:　</b> インタラクティブな推薦アシスタントの隆盛に伴い、自然言語（NL）での推薦が新たな領域として注目されています。この領域では、NLによる好みの表現に基づいて関連アイテムを取得するための多面的な推論が必要とされています。たとえば、「肉のラザニアが食べたいが、体重も気になる」といった好みの表現には、複数の側面が絡んでいます。しかし、この分野の進展は、注釈付きデータの不足によって遅れています。このギャップを埋めるために、我々は多面的なNLベースの好みのクエリと、複数の選択肢からなる多面項アイテム説明に対して論理的推論ができる新たなデータセットを作成しました。我々は、人間の食事の複雑性から多面的な好みが頻繁に見られるレシピの領域に焦点を当てています。このデータセットの公開目的は、次の3つの主要な領域における共同進展のベンチマークを提供することです：1）特定の水準、否定の存在、常識・類推・時間的推論の必要性など様々な特性を持つ構造化された多面的なNL推論、2）NLの好み表現に応じた推薦システムの対応能力、3）側面抽出と推論を通じて促進される説明可能なNL推薦。我々は、モノリシック設定（完全なクエリを使用）と側面ベース設定（個々のクエリ側面を分離し結果を集約）という2つの設定で、さまざまな方法（スパース・デンスな情報検索、大規模言語モデルによるゼロショット・少ショット推論）を用いて実験を行いました。GPT-3は、モノリシック設定において、ゼロショット性能73%、少ショット性能83%という他の方法よりもずっと優れたパフォーマンスを示しました。また、構造化された説明を促進する側面ベースのGPT-3も、ゼロショット性能68%と有望な結果を示しました。これらの結果は、多面的な好みに基づくNL推論を通じた説明可能な推薦研究のための基準を確立します。
        </label>
        <input type="checkbox" id="Panel338" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The rise of interactive recommendation assistants has led to a novel domain of natural language (NL) recommendation that would benefit from improved multi-aspect reasoning to retrieve relevant items based on NL statements of preference. Such preference statements often involve multiple aspects, e.g., "I would like meat lasagna but I'm watching my weight". Unfortunately, progress in this domain is slowed by the lack of annotated data. To address this gap, we curate a novel dataset which captures logical reasoning over multi-aspect, NL preference-based queries and a set of multiple-choice, multi-aspect item descriptions. We focus on the recipe domain in which multi-aspect preferences are often encountered due to the complexity of the human diet. The goal of publishing our dataset is to provide a benchmark for joint progress in three key areas: 1) structured, multi-aspect NL reasoning with a variety of properties (e.g., level of specificity, presence of negation, and the need for commonsense, analogical, and/or temporal inference), 2) the ability of recommender systems to respond to NL preference utterances, and 3) explainable NL recommendation facilitated by aspect extraction and reasoning. We perform experiments using a variety of methods (sparse and dense retrieval, zero- and few-shot reasoning with large language models) in two settings: a monolithic setting which uses the full query and an aspect-based setting which isolates individual query aspects and aggregates the results. GPT-3 results in much stronger performance than other methods with 73% zero-shot accuracy and 83% few-shot accuracy in the monolithic setting. Aspect-based GPT-3, which facilitates structured explanations, also shows promise with 68% zero-shot accuracy. These results establish baselines for future research into explainable recommendations via multi-aspect preference-based NL reasoning.
        </div> </ul> <br>



        <label for="Panel339">
        <strong> Beyond Single Items: Exploring User Preferences in Item Sets with the Conversational Playlist Curation Dataset </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Arun+Tejasvi+Chaganty">Arun Tejasvi Chaganty</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Megan+Leszczynski">Megan Leszczynski</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shu+Zhang">Shu Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ravi+Ganti">Ravi Ganti</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Krisztian+Balog">Krisztian Balog</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Filip+Radlinski">Filip Radlinski</a> (4) </u>  <br>
        1:  Google Research, 2:  Stanford University, 3:  Google Research, 4:  Google Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591881">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Beyond Single Items: Exploring User Preferences in Item Sets with the Conversational Playlist Curation Dataset">Google Scholar</a></div>
        (339)
        <br>
        <b>概要:　</b> 音楽などの消費ドメインにおけるユーザーは、単一項目（例：楽曲）よりも一連の項目（例：プレイリストやラジオ）に対して効率的に好みを提供できるケースが多い。しかしながら、この領域に関する研究は十分に進んでおらず、既存のレコメンデーションシステムの大半は単一項目の好みを理解することに限られている。項目セットを選定することは、レコメンデーションシステムが考慮すべき検索空間を指数関数的に増加させる（全ての部分集合!）。これに対処するためには、ユーザーが明示的に好みを述べたり修正したりし、システムが自然言語で好みを引き出す会話型アプローチが、ユーザーのニーズを理解するための効率的な方法として求められる。このタスクを会話型アイテムセット選定と呼び、アイテムレベルおよびセットレベル双方のフィードバックを観察することにより、会話型設定で現実的な好みを効率的に収集する新たなデータ収集方法を提案する。この方法論を音楽推薦に適用し、会話型プレイリスト選定データセット（CPCD）を構築したところ、評価者が通常では表現しないような好みを表現することが示された。最後に、このタスクの基準モデルとして広範な会話型検索モデルを提案し、データセット上で評価した結果を報告する。
        </label>
        <input type="checkbox" id="Panel339" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Users in consumption domains, like music, are often able to more efficiently provide preferences over a set of items (e.g. a playlist or radio) than over single items (e.g. songs). Unfortunately, this is an underexplored area of research, with most existing recommendation systems limited to understanding preferences over single items. Curating an item set exponentiates the search space that recommender systems must consider (all subsets of items!): this motivates conversational approaches-where users explicitly state or refine their preferences and systems elicit preferences in natural language-as an efficient way to understand user needs. We call this task conversational item set curation and present a novel data collection methodology that efficiently collects realistic preferences about item sets in a conversational setting by observing both item-level and set-level feedback. We apply this methodology to music recommendation to build the Conversational Playlist Curation Dataset (CPCD), where we show that it leads raters to express preferences that would not be otherwise expressed. Finally, we propose a wide range of conversational retrieval models as baselines for this task and evaluate them on the dataset.
        </div> </ul> <br>



        <label for="Panel340">
        <strong> Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Martin+Wessel">Martin Wessel</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tomás+Horych">Tomás Horych</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Terry+Ruas">Terry Ruas</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Akiko+Aizawa">Akiko Aizawa</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bela+Gipp">Bela Gipp</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Timo+Spinde">Timo Spinde</a> (3) </u>  <br>
        1:  University of Konstanz, 2:  Czech Technical University, 3:  University of Göttingen, 4:  National Institute of Informatics <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591882">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Introducing MBIB - The First Media Bias Identification Benchmark Task and Dataset Collection">Google Scholar</a></div>
        (340)
        <br>
        <b>概要:　</b> メディアバイアス検出は複雑なマルチタスク問題ですが、これらの評価タスクを一括して取り扱う統一ベンチマークはこれまで存在しませんでした。私たちは、メディアバイアス同定ベンチマーク（Media Bias Identification Benchmark, MBIB）を紹介します。これは、メディアバイアスのさまざまなタイプ（例：言語的、認知的、政治的）を共通の枠組みの下でグループ化し、将来的な検出技術の汎用性をテストする包括的なベンチマークです。115のデータセットを検討した結果、9つのタスクを選び、メディアバイアス検出技術を評価するための22の関連データセットを慎重に提案しました。最先端のTransformer技術（例：T5、BART）を用いてMBIBを評価したところ、ヘイトスピーチ、人種バイアス、性別バイアスは比較的検出しやすい一方で、認知的および政治的バイアスなどの特定のバイアスの取り扱いには苦戦することが示されました。しかし、いかなる技術も他の全てを大幅に上回ることはないという結果も得られました。また、メディアバイアスの個々のタスクに対する研究関心およびリソースの配分が不均等であることもわかりました。統一ベンチマークは、より堅牢なシステムの開発を促進し、現在のメディアバイアス検出評価のパラダイムを、一つではなく複数のメディアバイアスのタイプを同時に扱うソリューションへとシフトさせます。
        </label>
        <input type="checkbox" id="Panel340" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Although media bias detection is a complex multi-task problem, there is, to date, no unified benchmark grouping these evaluation tasks. We introduce the Media Bias Identification Benchmark (MBIB), a comprehensive benchmark that groups different types of media bias (e.g., linguistic, cognitive, political) under a common framework to test how prospective detection techniques generalize. After reviewing 115 datasets, we select nine tasks and carefully propose 22 associated datasets for evaluating media bias detection techniques. We evaluate MBIB using state-of-the-art Transformer techniques (e.g., T5, BART). Our results suggest that while hate speech, racial bias, and gender bias are easier to detect, models struggle to handle certain bias types, e.g., cognitive and political bias. However, our results show that no single technique can outperform all the others significantly.We also find an uneven distribution of research interest and resource allocation to the individual tasks in media bias. A unified benchmark encourages the development of more robust systems and shifts the current paradigm in media bias detection evaluation towards solutions that tackle not one but multiple media bias types simultaneously.
        </div> </ul> <br>



        <label for="Panel341">
        <strong> MG-ShopDial: A Multi-Goal Conversational Dataset for e-Commerce </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nolwenn+Bernard">Nolwenn Bernard</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Krisztian+Balog">Krisztian Balog</a> (1) </u>  <br>
        1:  University of Stavanger <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591883">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MG-ShopDial: A Multi-Goal Conversational Dataset for e-Commerce">Google Scholar</a></div>
        (341)
        <br>
        <b>概要:　</b> 会話型システムは、進化する情報ニーズを伴う複雑な情報検索シナリオにおいて非常に効果的です。例えば、eコマースプラットフォームで適切な商品を見つける場合がその一例で、会話エージェントは商品カタログに対する検索機能を提供し、ユーザーの嗜好に基づいて推奨を行い、商品およびその使用方法に関する様々な質問に答える必要があります。しかし、現存する会話データセットは、異なる会話の目標（検索、推奨、質問応答など）を混在させるアイデアを十分にサポートしておらず、単一の目標に焦点を当てています。これを解決するために、我々はMG-ShopDialを紹介します。これはeコマースの領域において異なる目標を混在させた会話のデータセットです。具体的には、以下の貢献を行います。第一に、各対話参加者に具体的なスクリプトや選択肢を与えるのではなく、一連の指示を与えるコーチ型の人間対人間データ収集プロトコルを開発しました。第二に、上記のプロトコルを用いて、ウェブチャットインターフェースを通じたマルチゴール会話の収集を容易にするデータ収集ツールを実装しました。第三に、MG-ShopDialコレクションを作成し、異なる複雑さのeコマースシナリオに関する合計2,196の発話を含む64の高品質な対話を収録しました。このデータセットには、発話レベルでの意図と目標もアノテートされています。最後に、このデータセットの分析を行い、マルチゴール会話のパターンを特定しました。
        </label>
        <input type="checkbox" id="Panel341" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Conversational systems can be particularly effective in supporting complex information seeking scenarios with evolving information needs. Finding the right products on an e-commerce platform is one such scenario, where a conversational agent would need to be able to provide search capabilities over the item catalog, understand and make recommendations based on the user's preferences, and answer a range of questions related to items and their usage. Yet, existing conversational datasets do not fully support the idea of mixing different conversational goals (i.e., search, recommendation, and question answering) and instead focus on a single goal. To address this, we introduce MG-ShopDial: a dataset of conversations mixing different goals in the domain of e-commerce. Specifically, we make the following contributions. First, we develop a coached human-human data collection protocol where each dialogue participant is given a set of instructions, instead of a specific script or answers to choose from. Second, we implement a data collection tool to facilitate the collection of multi-goal conversations via a web chat interface, using the above protocol. Third, we create the MG-ShopDial collection, which contains 64 high-quality dialogues with a total of 2,196 utterances for e-commerce scenarios of varying complexity. The dataset is additionally annotated with both intents and goals on the utterance level. Finally, we present an analysis of this dataset and identify multi-goal conversational patterns.
        </div> </ul> <br>



        <label for="Panel342">
        <strong> Towards Explainable Conversational Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuyu+Guo">Shuyu Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuo+Zhang">Shuo Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weiwei+Sun">Weiwei Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pengjie+Ren">Pengjie Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhumin+Chen">Zhumin Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaochun+Ren">Zhaochun Ren</a> (1) </u>  <br>
        1:  Shandong University, 2:  Bloomberg <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591884">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Towards Explainable Conversational Recommender Systems">Google Scholar</a></div>
        (342)
        <br>
        <b>概要:　</b> 従来のレコメンダーシステムにおける説明は、推薦の合理性を理解するのを助け、システムの効率性、透明性、および信用性を向上させる効果があることが示されています。しかし、対話型環境では、複数の文脈に即した説明を生成する必要があり、説明に対してさらなる挑戦が必要となります。CRS（Conversational Recommender Systems）の説明可能性をより良く評価するために、従来のレコメンダーシステムの概念とCRSの特性を基にした10の評価指標を提案します。この指標を用いて5つの既存のCRSベンチマークデータセットを評価した結果、CRSの説明の質を向上させる必要性が確認されました。これを達成するために、手作業および自動的な手法でこれらの対話を拡張し、新たなCRSデータセット「Explainable Recommendation Dialogues（E-ReDial）」を構築しました。このデータセットには、756の対話および2,000以上の高品質な書き直した説明が含まれています。我々は、E-ReDialを基に説明生成を行う2つのベースライン手法を比較しました。実験結果によれば、E-ReDialで訓練されたモデルは説明可能性を大幅に改善でき、モデルに知識を導入することで性能をさらに向上させることが示唆されました。GPT-3は文脈学習設定において、より現実的で多様な映画説明を生成できる一方で、T5はE-Redialで訓練することで、ユーザーの嗜好に基づいた推薦理由をより明確に生成できます。E-ReDialはhttps://github.com/Superbooming/E-ReDialで利用可能です。
        </label>
        <input type="checkbox" id="Panel342" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Explanations in conventional recommender systems have demonstrated benefits in helping the user understand the rationality of the recommendations and improving the system's efficiency, transparency, and trustworthiness. In the conversational environment, multiple contextualized explanations need to be generated, which poses further challenges for explanations. To better measure explainability in CRS, we propose ten evaluation perspectives based on the concepts from conventional recommender systems together with the characteristics of CRS. We assess five existing CRS benchmark datasets using these metrics and observe the necessity of improving the explanation quality of CRS. To achieve this, we conduct manual and automatic approaches to extend these dialogues and construct a new CRS dataset, namely Explainable Recommendation Dialogues (E-ReDial). It includes 756 dialogues with over 2,000 high-quality rewritten explanations. We compare two baseline approaches to perform explanation generation based on E-ReDial. Experimental results suggest that models trained on E-ReDial can significantly improve explainability while introducing knowledge into the models can further improve the performance. GPT-3 in the in-context learning setting can generate more realistic and diverse movie descriptions. In contrast, T5 training on E-Redial can better generate clear reasons for recommendations based on user preferences. E-ReDial is available at https://github.com/Superbooming/E-ReDial.
        </div> </ul> <br>



        <label for="Panel343">
        <strong> The JOKER Corpus: English-French Parallel Data for Multilingual Wordplay Recognition </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liana+Ermakova">Liana Ermakova</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anne-Gwenn+Bosser">Anne-Gwenn Bosser</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Adam+Jatowt">Adam Jatowt</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tristan+Miller">Tristan Miller</a> (4) </u>  <br>
        1:  Université de Bretagne Occidentale, 2:  École Nationale d'Ingénieurs de Brest, 3:  University of Innsbruck, 4:  Austrian Research Institute for Artificial Intelligence <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591885">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=The JOKER Corpus: English-French Parallel Data for Multilingual Wordplay Recognition">Google Scholar</a></div>
        (343)
        <br>
        <b>概要:　</b> 情報検索と自然言語処理の分野における最近の進歩にもかかわらず、曖昧さを利用したり、言語規則を逸脱する修辞技法は依然としてこれらのシステムにとって困難な課題です。しかし、コーパスに基づく語呂合わせの分析は、人文学（文学批評、語学教育、翻訳研究など）の分野で長年にわたり研究されています。これらの研究に必要な膨大なデータ収集の努力は、専門的なテキスト検索および分類技術の必要性を示しており、それに伴い適切なテストコレクションも求められています。本論文では、語呂合わせの検索と処理の研究および応用のための新しいデータセットを紹介し、分析します。このコーパスは、CLEF 2023でのJOKERトラックのために開発され、過去の英語語呂合わせ検出データセットをいくつかの点で拡張・改良しています。まず、何百もの語呂合わせの陽性例を追加し、次にそれらの例のフランス語訳を提供し、さらに語呂合わせではない否定例を、陽性例の特徴に密接に一致させた形で提供しています。この最後の機能は、AIモデルが単にテキストの長さ、スタイル、語彙の違いではなく、語呂合わせを効果的に区別する学習を保証するのに役立ちます。我々のテストコレクションは、語呂合わせに対応した多言語情報検索への一歩を示しています。
        </label>
        <input type="checkbox" id="Panel343" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Despite recent advances in information retrieval and natural language processing, rhetorical devices that exploit ambiguity or subvert linguistic rules remain a challenge for such systems. However, corpus-based analysis of wordplay has been a perennial topic of scholarship in the humanities, including literary criticism, language education, and translation studies. The immense data-gathering effort required for these studies points to the need for specialized text retrieval and classification technology, and consequently for appropriate test collections. In this paper, we introduce and analyze a new dataset for research and applications in the retrieval and processing of wordplay. Developed for the JOKER track at CLEF 2023, our annotated corpus extends and improves upon past English wordplay detection datasets in several ways. First, we introduce hundreds of additional positive examples of wordplay; second, we provide French translations for the examples; and third, we provide negative examples of non-wordplay with characteristics closely matching those of the positive examples. This last feature helps ensure that AI models learn to effectively distinguish wordplay from non-wordplay, and not simply texts differing in length, style, or vocabulary. Our test collection represents then a step towards wordplay-aware multilingual information retrieval.
        </div> </ul> <br>



        <label for="Panel344">
        <strong> Form-NLU: Dataset for the Form Natural Language Understanding </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yihao+Ding">Yihao Ding</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siqu+Long">Siqu Long</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiabin+Huang">Jiabin Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kaixuan+Ren">Kaixuan Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xingxiang+Luo">Xingxiang Luo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hyunsuk+Chung">Hyunsuk Chung</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Soyeon+Caren+Han">Soyeon Caren Han</a> (3) </u>  <br>
        1:  The University of Sydney, 2:  FortifyEdge, 3:  The University of Western Australia <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591886">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Form-NLU: Dataset for the Form Natural Language Understanding">Google Scholar</a></div>
        (344)
        <br>
        <b>概要:　</b> の日本語訳<br>一般的な文書解析タスクと比較して、フォーム文書の構造理解と検索は困難です。フォーム文書は通常、フォームの構造とキーを設計するフォームデザイナーと、提供されたキーに基づいて値を入力するフォームユーザーの二種類の著者によって作成されます。そのため、フォームユーザーが混乱すると、フォームデザイナーの意図（構造とキー）とフォームの値が一致しない可能性があります。本論文では、フォーム構造の理解とそのキーおよび値情報の抽出、さらにはフォームデザイナーの意図とユーザーが書いた値の整合性を解釈するための初めてのデータセット「Form-NLU」を紹介します。このデータセットは857枚のフォーム画像、6,000個のフォームキーと値、さらに4,000個のテーブルキーと値を含んでいます。データセットにはデジタル、印刷、手書きの3種類のフォームが含まれ、さまざまな形式とレイアウトをカバーしています。私たちは位置関係と論理的関係に基づく強力なフォームキー値情報抽出フレームワークを提案します。このデータセット「Form-NLU」を使用して、まず強力な物体検出モデルでフォームレイアウトの理解を検証し、次にキー情報抽出タスクをデータセット上で評価し、フォームとキーの種類ごとに詳細な結果を提供します。さらに、市販のPDFレイアウト抽出ツールとこのデータセットを用いて検証し、実際のケースでの実現可能性を証明します。
        </label>
        <input type="checkbox" id="Panel344" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Compared to general document analysis tasks, form document structure understanding and retrieval are challenging. Form documents are typically made by two types of authors; A form designer, who develops the form structure and keys, and a form user, who fills out form values based on the provided keys. Hence, the form values may not be aligned with the form designer's intention (structure and keys) if a form user gets confused. In this paper, we introduce Form-NLU, the first novel dataset for form structure understanding and its key and value information extraction, interpreting the form designer's intent and the alignment of user-written value on it. It consists of 857 form images, 6k form keys and values, and 4k table keys and values. Our dataset also includes three form types: digital, printed, and handwritten, which cover diverse form appearances and layouts. We propose a robust positional and logical relation-based form key-value information extraction framework. Using this dataset, Form-NLU, we first examine strong object detection models for the form layout understanding, then evaluate the key information extraction task on the dataset, providing fine-grained results for different types of forms and keys. Furthermore, we examine it with the off-the-shelf pdf layout extraction tool and prove its feasibility in real-world cases.
        </div> </ul> <br>



        <label for="Panel345">
        <strong> MMEAD: MS MARCO Entity Annotations and Disambiguations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chris+Kamphuis">Chris Kamphuis</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Aileen+Lin">Aileen Lin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siwen+Yang">Siwen Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jimmy+Lin">Jimmy Lin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Arjen+P.+de+Vries">Arjen P. de Vries</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Faegheh+Hasibi">Faegheh Hasibi</a> (1) </u>  <br>
        1:  Radboud University, 2:  University of Waterloo <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591887">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MMEAD: MS MARCO Entity Annotations and Disambiguations">Google Scholar</a></div>
        (345)
        <br>
        <b>概要:　</b> MMEAD、すなわち MS MARCO Entity Annotations and Disambiguations は、MS MARCO データセットのエンティティリンクのためのリソースです。本研究では、MS MARCO の文書およびパッセージコレクションのリンクを保存および共有するためのフォーマットを指定します。この仕様に従い、MS MARCO コレクション（v1 および v2）の文書およびパッセージへの Wikipedia へのエンティティリンクを公開します。エンティティリンクは REL および BLINK システムによって生成されました。MMEAD は簡単にインストールできる Python パッケージで、ユーザーはリンクデータとエンティティ埋め込みを簡単に読み込むことができます。MMEAD を使用するには、数行のコードしか必要ありません。最後に、エンティティ情報を使用した IR 研究に MMEAD をどのように利用できるかを示します。具体的には、このリソースを使用することで、MS MARCO v1 パッセージデータセットにおけるより複雑なクエリの recall@1000 および MRR@10 を向上させる方法を説明します。さらに、対話型検索アプリケーションのためのエンティティ拡張の使用方法も示します。
        </label>
        <input type="checkbox" id="Panel345" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> MMEAD, or MS MARCO Entity Annotations and Disambiguations, is a resource for entity links for the MS MARCO datasets. We specify a format to store and share links for both document and passage collections of MS MARCO. Following this specification, we release entity links to Wikipedia for documents and passages in both MS MARCO collections (v1 and v2). Entity links have been produced by the REL and BLINK systems. MMEAD is an easy-to-install Python package, allowing users to load the link data and entity embeddings effortlessly. Using MMEAD takes only a few lines of code. Finally, we show how MMEAD can be used for IR research that uses entity information. We show how to improve recall@1000 and MRR@10 on more complex queries on the MS MARCO v1 passage dataset by using this resource. We also demonstrate how entity expansions can be used for interactive search applications.
        </div> </ul> <br>



        <label for="Panel346">
        <strong> The Information Retrieval Experiment Platform </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maik+Fröbe">Maik Fröbe</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jan+Heinrich+Reimer">Jan Heinrich Reimer</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sean+MacAvaney">Sean MacAvaney</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Niklas+Deckers">Niklas Deckers</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Simon+Reich">Simon Reich</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Janek+Bevendorff">Janek Bevendorff</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Benno+Stein">Benno Stein</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Matthias+Hagen">Matthias Hagen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Martin+Potthast">Martin Potthast</a> (3) </u>  <br>
        1:  Friedrich-Schiller-Universität Jena, 2:  University of Glasgow, 3:  Leipzig University and ScaDS.AI, 4:  Leipzig University, 5:  Bauhaus-Universität Weimar <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591888">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=The Information Retrieval Experiment Platform">Google Scholar</a></div>
        (346)
        <br>
        <b>概要:　</b> 私たちは情報検索実験プラットフォーム（TIREx）において、再現性、スケーラビリティ、標準化、さらにはブラインド（盲検）検索実験を促進するために、irdatasets、ir_measures、およびPyTerrierをTIRAと統合しました。標準化は、検索アプローチがPyTerrierのインターフェースを実装し、実験の入力と出力がir_datasetsとir_measuresに互換性を持つときに達成されます。ただし、再現性とスケーラビリティのための要件ではなく、TIRAはあらゆるドッカー化されたソフトウェアをローカルまたはクラウドネイティブな実行環境でリモートに実行できます。バージョン管理とキャッシングは効率的な（再）実行を保証します。実験が実験者の管理下にないリモートサーバーやクラウドで実行される場合、TIRAはブラインド評価を可能にします。この場合、テストデータと地上真理データは公開アクセスから隠され、検索ソフトウェアはデータ漏洩を防ぐサンドボックス内で処理しなければなりません。現在、私たちは32の共有検索タスクに基づく15のコーパス（19億件のドキュメント）を含むTIRExのインスタンスをホストしています。50の標準検索アプローチのDockerイメージを使用して、これらすべてのタスクに対して自動的に全てのアプローチを評価しました（50 ⋅ 32 = 1,600回の実行）し、中規模クラスター（1,620コアと24 GPU）で1週間以内に完了しました。このTIRExのインスタンスは現在投稿を受け付けており、IR Anthologyと統合されるとともに、オープンソースとして公開される予定です。
        </label>
        <input type="checkbox" id="Panel346" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> We integrate irdatasets, ir_measures, and PyTerrier with TIRA in the Information Retrieval Experiment Platform (TIREx) to promote more standardized, reproducible, scalable, and even blinded retrieval experiments. Standardization is achieved when a retrieval approach implements PyTerrier's interfaces and the input and output of an experiment are compatible with ir_datasets and ir_measures. However, none of this is a must for reproducibility and scalability, as TIRA can run any dockerized software locally or remotely in a cloud-native execution environment. Version control and caching ensure efficient (re)execution. TIRA allows for blind evaluation when an experiment runs on a remote server or cloud not under the control of the experimenter. The test data and ground truth are then hidden from public access, and the retrieval software has to process them in a sandbox that prevents data leaks. We currently host an instance of TIREx with 15 corpora (1.9~billion documents) on which 32 shared retrieval tasks are based. Using Docker images of 50~standard retrieval approaches, we automatically evaluated all approaches on all tasks (50 ⋅ 32 = 1,600 runs) in less than a week on a midsize cluster (1,620 cores and 24 GPUs). This instance of TIREx is open for submissions and will be integrated with the IR Anthology, as well as released open source.
        </div> </ul> <br>



        <label for="Panel347">
        <strong> Towards a More User-Friendly and Easy-to-Use Benchmark Library for Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lanling+Xu">Lanling Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhen+Tian">Zhen Tian</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gaowei+Zhang">Gaowei Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junjie+Zhang">Junjie Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Wang">Lei Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bowen+Zheng">Bowen Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yifan+Li">Yifan Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiakai+Tang">Jiakai Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zeyu+Zhang">Zeyu Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yupeng+Hou">Yupeng Hou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xingyu+Pan">Xingyu Pan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wayne+Xin+Zhao">Wayne Xin Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xu+Chen">Xu Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ji-Rong+Wen">Ji-Rong Wen</a> (1) </u>  <br>
        1:  Renmin University of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591889">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Towards a More User-Friendly and Easy-to-Use Benchmark Library for Recommender Systems">Google Scholar</a></div>
        (347)
        <br>
        <b>概要:　</b> 近年、レコメンデーションモデルの再現性はレコメンダーシステムにおいて深刻な懸念事項となっています。この課題を踏まえ、私たちは以前、統一的で包括的かつ効率的なレコメンデーションライブラリ「RecBole」をリリースし、研究コミュニティから大きな注目を集めました。利用者の増加に伴い、多くの提案や更新要求が寄せられました。これにより、ユーザーの要望に応え、研究コミュニティに貢献するために、ライブラリのさらなる改良を行う動機が生まれました。本論文では、RecBoleの重要なアップデートを紹介し、よりユーザーフレンドリーで使いやすい包括的なベンチマークライブラリとして改良しました。具体的には、このアップデートのハイライトは次の通りです：(1) より多くのベンチマークモデルやデータセットを含め、データ処理、トレーニング、評価の面でベンチマークフレームワークを改善し、レコメンデーションモデルのベンチマークに再現可能な設定をリリースしました。(2) より詳細なドキュメントや整理されたFAQを提供することで、ユーザーフレンドリネスを向上させました。(3) オープンソースライブラリ開発者向けの開発ガイドラインを提案しました。これらの拡張により、ベンチマーク結果の再現が容易になり、レコメンダーシステムの最新の進化を追跡しやすくなります。アップデート内容は次のリンクからご覧いただけます: https://github.com/RUCAIBox/RecBole。
        </label>
        <input type="checkbox" id="Panel347" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In recent years, the reproducibility of recommendation models has become a severe concern in recommender systems. In light of this challenge, we have previously released a unified, comprehensive and efficient recommendation library called RecBole, attracting much attention from the research community. With the increasing number of users, we have received a number of suggestions and update requests. This motivates us to make further improvements on our library, so as to meet the user requirements and contribute to the research community. In this paper, we present a significant update of RecBole, making it more user-friendly and easy-to-use as a comprehensive benchmark library for recommendation. More specifically, the highlights of this update are summarized as: (1) we include more benchmark models and datasets, improve the benchmark framework in terms of data processing, training and evaluation, and release reproducible configurations to benchmark the recommendation models; (2) we upgrade the user friendliness of our library by providing more detailed documentation and well-organized frequently asked questions, and (3) we propose several development guidelines for the open-source library developers. These extensions make it much easier to reproduce the benchmark results and stay up-to-date with the recent advances on recommender systems. Our update is released at the link: https://github.com/RUCAIBox/RecBole.
        </div> </ul> <br>



        <label for="Panel348">
        <strong> The Archive Query Log: Mining Millions of Search Result Pages of Hundreds of Search Engines from 25 Years of Web Archives </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jan+Heinrich+Reimer">Jan Heinrich Reimer</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sebastian+Schmidt">Sebastian Schmidt</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maik+Fröbe">Maik Fröbe</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lukas+Gienapp">Lukas Gienapp</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Harrisen+Scells">Harrisen Scells</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Benno+Stein">Benno Stein</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Matthias+Hagen">Matthias Hagen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Martin+Potthast">Martin Potthast</a> (3) </u>  <br>
        1:  Friedrich-Schiller-Universität Jena, 2:  Leipzig University, 3:  Leipzig University and ScaDS.AI, 4:  Bauhaus-Universität Weimar <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591890">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=The Archive Query Log: Mining Millions of Search Result Pages of Hundreds of Search Engines from 25 Years of Web Archives">Google Scholar</a></div>
        (348)
        <br>
        <b>概要:　</b> アーカイブクエリログ（AQL）は、過去25年間にわたりインターネットアーカイブで収集された、これまで未使用の包括的なクエリログである。その初版には、356百万のクエリ、137百万の検索結果ページ、1.4十億の検索結果が550の検索プロバイダにわたって含まれている。多くのクエリログがこれまで文献で研究されてきたが、それらを所有する検索プロバイダはユーザープライバシーと重要なビジネスデータを保護するために一般にログを公開しない。公開されている少数のクエリログの中で、サイズ、範囲、そして多様性を併せ持つものはない。AQLはそれを初めて実現し、新しい検索モデルや（斉時的）検索エンジン分析に関する研究を可能にする。プライバシー保護の手法で提供されているため、オープンな研究を促進し、検索業界の透明性と責任性を向上させる。
        </label>
        <input type="checkbox" id="Panel348" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The Archive Query Log (AQL) is a previously unused, comprehensive query log collected at the Internet Archive over the last 25 years. Its first version includes 356 million queries, 137 million search result pages, and 1.4 billion search results across 550 search providers. Although many query logs have been studied in the literature, the search providers that own them generally do not publish their logs to protect user privacy and vital business data. Of the few query logs publicly available, none combines size, scope, and diversity. The AQL is the first to do so, enabling research on new retrieval models and (diachronic) search engine analyses. Provided in a privacy-preserving manner, it promotes open research as well as more transparency and accountability in the search industry.
        </div> </ul> <br>



        <label for="Panel349">
        <strong> GammaGL: A Multi-Backend Library for Graph Neural Networks </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yaoqi+Liu">Yaoqi Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cheng+Yang">Cheng Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tianyu+Zhao">Tianyu Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hui+Han">Hui Han</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siyuan+Zhang">Siyuan Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jing+Wu">Jing Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guangyu+Zhou">Guangyu Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hai+Huang">Hai Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hui+Wang">Hui Wang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chuan+Shi">Chuan Shi</a> (4) </u>  <br>
        1:  Beijing University of Posts and Telecommunications, 2:  Beijing University of Posts and Telecommunications & Peng Cheng Laboratory, 3:  Peng Cheng Laboratory, 4:  Beijing University of Posts and Telecommunications & Peng Cheng Laboratory <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591891">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=GammaGL: A Multi-Backend Library for Graph Neural Networks">Google Scholar</a></div>
        (349)
        <br>
        <b>概要:　</b> グラフニューラルネットワーク（GNN）は、グラフ構造データのモデル化において優れた性能を示し、過去5年間で大きな注目を集めています。TensorFlowやPyTorchといった従来のディープラーニングフレームワークは、ニューラルネットワークアルゴリズムを実装するための便利なツールを提供しますが、メッセージパッシングの計算など、GNNの主要な操作を十分にサポートしていません。この問題に対処するために、PyGなどのGNNライブラリが、GNNに特化した豊富なアプリケーションプログラミングインターフェイス（API）を導入して提案されました。しかし、現在のほとんどのGNNライブラリは、特定のディープラーニングフレームワークをバックエンドとしてサポートしているだけであり、たとえばPyGはPyTorchと結びついています。実際には、ユーザーはしばしば、同僚や異なるディープラーニングバックエンドを持つオープンソースのコードから来た他のニューラルネットワークコンポーネントとGNNを組み合わせる必要があります。その結果、ユーザーはさまざまなGNNライブラリに精通し、それぞれのAPIでGNNを再実装する必要があります。より便利なユーザー体験を提供するために、私たちは複数のディープラーニングフレームワークをバックエンドとしてサポートするGNNライブラリ、Gamma Graph Library（GammaGL）を提案します。GammaGLはフレームワークに依存しない設計を採用しており、既存のコンポーネントの上でディープラーニングバックエンドを一行のコード変更で簡単に切り替えることができます。テンサー中心の設計理念に従い、GammaGLはグラフデータをいくつかの主要なテンソルに分割し、GNNの計算プロセス（メッセージパッシングやグラフのミニバッチ操作など）をいくつかの主要な関数に化します。私たちはGammaGL内で多くの効率的なオペレーターを開発し、アクセラレーションを実現しました。これまでに、GammaGLは多様な下流タスクに適用できる40以上のGNN例を提供しています。さらに、GammaGLはヘテロジニアスグラフニューラルネットワークやレコメンデーションのためのツールも提供し、関連分野の研究を促進します。GammaGLで実装されたモデルの性能と最適化されたオペレーターの時間消費を示し、その効率性を示します。私たちのライブラリは https://github.com/BUPT-GAMMA/GammaGL で入手可能です。
        </label>
        <input type="checkbox" id="Panel349" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Graph Neural Networks (GNNs) have shown their superiority in modeling graph-structured data, and gained much attention over the last five years. Though traditional deep learning frameworks such as TensorFlow and PyTorch provide convenient tools for implementing neural network algorithms, they do not support the key operations of GNNs well, e.g., the message passing computation based on sparse matrices. To address this issue, GNN libraries such as PyG are proposed by introducing rich Application Programming Interfaces (APIs) specialized for GNNs. However, most current GNN libraries only support a specific deep learning framework as the backend, e.g., PyG is tied up with PyTorch. In practice, users usually need to combine GNNs with other neural network components, which may come from their co-workers or open-source codes with different deep-learning backends. Consequently, users have to be familiar with various GNN libraries, and rewrite their GNNs with corresponding APIs. To provide a more convenient user experience, we present Gamma Graph Library (GammaGL), a GNN library that supports multiple deep learning frameworks as backends. GammaGL uses a framework-agnostic design that allows users to easily switch between deep learning backends on top of existing components with a single line of code change. Following the tensor-centric design idea, GammaGL splits the graph data into several key tensors, and abstracts GNN computational processes (such as message passing and graph mini-batch operations) into a few key functions. We develop many efficient operators in GammaGL for acceleration. So far, GammaGL has provided more than 40 GNN examples that can be applied to a variety of downstream tasks. GammaGL also provides tools for heterogeneous graph neural networks and recommendations to facilitate research in related fields. We present the performance of models implemented by GammaGL and the time consumption of our optimized operators to show the efficiency. Our library is available at https://github.com/BUPT-GAMMA/GammaGL.
        </div> </ul> <br>



        <label for="Panel350">
        <strong> tieval: An Evaluation Framework for Temporal Information Extraction Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hugo+Sousa">Hugo Sousa</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ricardo+Campos">Ricardo Campos</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alípio+Mário+Jorge">Alípio Mário Jorge</a> (1) </u>  <br>
        1:  INESC TEC & University of Porto, 2:  INESC TEC & Polytechnic Institute of Tomar; Ci2 - Smart Cities Research Center <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591892">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=tieval: An Evaluation Framework for Temporal Information Extraction Systems">Google Scholar</a></div>
        (350)
        <br>
        <b>概要:　</b> 時間情報抽出（TIE）は、過去20年間で大きな関心を集めてきました。この取り組みにより、多くのデータセットが開発されましたが、その恩恵にもかかわらず、大量のコーパスへのアクセスはTIEシステムのベンチマークを困難にしています。一方で、異なるデータセットが異なるアノテーション方式を持っているため、異なるコーパス間での比較が妨げられます。さらに、それぞれのコーパスが異なる形式で配布されているため、研究者や実務者がすべてのコーパスのパーサーを開発するためにはかなりのエンジニアリング努力が必要です。これらの制約により、研究者はシステム評価のために限られた数のデータセットを選ばざるを得ず、その結果、システムの比較可能性が制限されます。さらに、TIEシステムの比較可能性を妨げるもう一つの障害は、使用される評価指標です。ほとんどの研究が精度、再現率、F1などの伝統的な指標を採用する一方、一部の研究はテンポラルアウェアネスという、時間システムの評価に特化した指標を好みます。多くのシステムの評価にテンポラルアウェアネスが欠如している理由は明確ではありませんが、その決定に影響を与える要因の一つは、実装が簡単でないテンポラルクローズアルゴリズムを必要とすることでしょう。これらの問題に対処するために、私たちはtievalを開発しました。これは、異なるコーパスを取り込むための簡潔なインターフェースを提供し、システム評価を容易にするドメイン固有の操作を備えたPythonライブラリです。本論文では、tievalの最初の公開リリースを紹介し、その最も関連性の高い機能を強調します。このライブラリは、MITライセンスのもとで、PyPIおよびGitHubでオープンソースとして利用可能です。
        </label>
        <input type="checkbox" id="Panel350" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Temporal information extraction (TIE) has attracted a great deal of interest over the last two decades. Such endeavors have led to the development of a significant number of datasets. Despite its benefits, having access to a large volume of corpora makes it difficult to benchmark TIE systems. On the one hand, different datasets have different annotation schemes, which hinders the comparison between competitors across different corpora. On the other hand, the fact that each corpus is disseminated in a different format requires a considerable engineering effort for a researcher/practitioner to develop parsers for all of them. These constraints force researchers to select a limited amount of datasets to evaluate their systems which consequently limits the comparability of the systems. Yet another obstacle to the comparability of TIE systems is the evaluation metric employed. While most research works adopt traditional metrics such as precision, recall, and F1, a few others prefer temporal awareness -- a metric tailored to be more comprehensive on the evaluation of temporal systems. Although the reason for the absence of temporal awareness in the evaluation of most systems is not clear, one of the factors that certainly weighs on this decision is the need to implement the temporal closure algorithm, which is neither straightforward to implement nor easily available. All in all, these problems have limited the fair comparison between approaches and consequently, the development of TIE systems. To mitigate these problems, we have developed tieval, a Python library that provides a concise interface for importing different corpora and is equipped with domain-specific operations that facilitate system evaluation. In this paper, we present the first public release of tieval and highlight its most relevant features. The library is available as open source, under MIT License, at PyPI and GitHub.
        </div> </ul> <br>



        <label for="Panel351">
        <strong> HC3: A Suite of Test Collections for CLIR Evaluation over Informal Text </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dawn+Lawrie">Dawn Lawrie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=James+Mayfield">James Mayfield</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Douglas+W.+Oard">Douglas W. Oard</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Eugene+Yang">Eugene Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Suraj+Nair">Suraj Nair</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Petra+Galuščáková">Petra Galuščáková</a> (4) </u>  <br>
        1:  Johns Hopkins University, 2:  University of Maryland, 3:  University of Maryland, 4:  Université Grenoble Alpes <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591893">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=HC3: A Suite of Test Collections for CLIR Evaluation over Informal Text">Google Scholar</a></div>
        (351)
        <br>
        <b>概要:　</b> クロスランゲージ情報検索（CLIR）には多くのテストコレクションがありますが、大規模な公的テストコレクションの中には短い非正式なテキストドキュメントに焦点を当てたものは存在しません。本論文では、新しいペアのCLIRテストコレクションを紹介します。これらのコレクションは、数百万規模の中国語またはペルシャ語のツイートやツイートスレッドをドキュメントとし、英語とそれぞれのドキュメント言語で記述された60のイベント駆動トピック、そしてインタラクティブ検索とアクティブラーニングを使用して構築された3点尺度の関連性判断を含んでいます。これらの新しいテストコレクションの設計および構築方法について説明し、システム評価のためのコレクションの有用性を示すベースライン結果を提示します。シャロープーリングを使用して、判断のためにドキュメントを選択するアクティブラーニングの有効性を評価します。
        </label>
        <input type="checkbox" id="Panel351" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> While there are many test collections for Cross-Language Information Retrieval (CLIR), none of the large public test collections focus on short informal text documents. This paper introduces a new pair of CLIR test collections with millions of Chinese or Persian Tweets or Tweet threads as documents, sixty event-motivated topics written both in English and in each of the two document languages, and three-point graded relevance judgments constructed using interactive search and active learning. The design and construction of these new test collections are described, and baseline results are presented that demonstrate the utility of the collections for system evaluation. Shallow pooling is used to assess the efficacy of active learning to select documents for judgment.
        </div> </ul> <br>



        <label for="Panel352">
        <strong> RecStudio: Towards a Highly-Modularized Recommender System </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Defu+Lian">Defu Lian</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xu+Huang">Xu Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaolong+Chen">Xiaolong Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jin+Chen">Jin Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xingmei+Wang">Xingmei Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yankai+Wang">Yankai Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haoran+Jin">Haoran Jin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rui+Fan">Rui Fan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zheng+Liu">Zheng Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Le+Wu">Le Wu</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Enhong+Chen">Enhong Chen</a> (1) </u>  <br>
        1:  University of Science and Technology of China, 2:  University of Electronics Science and Technology of China, 3:  Huawei, 4:  Hefei University of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591894">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=RecStudio: Towards a Highly-Modularized Recommender System">Google Scholar</a></div>
        (352)
        <br>
        <b>概要:　</b> 近年、人気のある推薦アルゴリズムの再現性を高めるために、多くの推薦ライブラリが開発されました。しかし、それらのライブラリはほとんどがアルゴリズムの単なる集まりに過ぎず、推薦アルゴリズムのモジュール化や実際のシナリオでの使用を見落としています。アルゴリズムのモジュール化には以下の利点があります：1) 各アルゴリズムの有効性を理解しやすくします。2) ドラッグアンドドロップによるプログラミングや自動機械学習を通じて、性能の良いモジュールを用いた新しいアルゴリズムを容易に組み立てることができます。3) 一つのアルゴリズムが他のアルゴリズムのモジュールとして機能することにより、アルゴリズム間の強化が可能になります。この目的のために、私たちは高度にモジュール化された推薦システムであるRecStudioを開発しました。このシステムでは、任意の推薦アルゴリズムがランカーかリトリーバーのいずれかに分類されます。RecStudioライブラリでは、他のライブラリに見られる一般的なアルゴリズムから、複数の推薦モデルを含む複雑なアルゴリズムまで、純粋なPytorchで90の推薦アルゴリズムを実装しています。RecStudioは、インデックスをサポートした効率的な推薦と評価、GPU加速によるネガティブサンプリング、検証に基づくハイパーパラメータ学習、リトリーバーとランカーの連携など、いくつかの視点から特徴付けられています。また、RecStudioはウェブサービスも備えており、推薦パイプラインを迅速に確立し、選択したデータセットで視覚的に評価することができます。評価結果は自動的にアーカイブされ、リーダーボードで視覚化されます。プロジェクトとドキュメントはhttp://recstudio.org.cnで公開されています。
        </label>
        <input type="checkbox" id="Panel352" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> A dozen recommendation libraries have recently been developed to accommodate popular recommendation algorithms for reproducibility. However, they are almost simply a collection of algorithms, overlooking the modularization of recommendation algorithms and their usage in practical scenarios. Algorithmic modularization has the following advantages: 1) helps to understand the effectiveness of each algorithm; 2) easily assembles new algorithms with well-performed modules by either drag-and-drop programming or automatic machine learning; 3) enables reinforcement between algorithms since one algorithm may act as a module of another algorithm. To this end, we develop a highly-modularized recommender system -- RecStudio, in which any recommendation algorithm is categorized into either a ranker or a retriever. In the RecStudio library, we implement 90 recommendation algorithms with the pure Pytorch, covering both common algorithms in other libraries and complex algorithms involving multiple recommendation models. RecStudio is featured from several perspectives, such as index-supported efficient recommendation and evaluation, GPU-accelerated negative sampling, hyperparameter learning on the validation, and cooperation between the retriever and ranker. RecStudio is also equipped with a web service, where the recommendation pipeline can be quickly established and visually evaluated on selected datasets, and the evaluation results are automatically archived and visualized in a leaderboard. The project and documents are released at http://recstudio.org.cn.
        </div> </ul> <br>



        <label for="Panel353">
        <strong> MR2: A Benchmark for Multimodal Retrieval-Augmented Rumor Detection in Social Media </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuming+Hu">Xuming Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhijiang+Guo">Zhijiang Guo</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junzhe+Chen">Junzhe Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lijie+Wen">Lijie Wen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philip+S.+Yu">Philip S. Yu</a> (3) </u>  <br>
        1:  Tsinghua University, 2:  University of Cambridge, 3:  University of Illinois at Chicago <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591896">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MR2: A Benchmark for Multimodal Retrieval-Augmented Rumor Detection in Social Media">Google Scholar</a></div>
        (353)
        <br>
        <b>概要:　</b> ソーシャルメディアプラットフォームがテキストベースのフォーラムからマルチモーダル環境へと進化する中で、ソーシャルメディアにおける誤情報の性質もそれに応じて変化しています。誤情報の拡散者は最近、テキストや画像などのモダリティ間の文脈的なつながりをターゲットにしています。しかし、噂検出のための既存のデータセットは主に単一のモダリティ、すなわちテキストに焦点を当てています。このギャップを埋めるために、私たちは噂検出のためのマルチモーダル多言語リトリーバル強化データセットであるMR2を構築しました。このデータセットは、画像とテキストを含む噂をカバーし、インターネットから取得した両方のモダリティからの証拠を提供します。さらに、確立されたベースラインを開発し、データセットで評価されたシステムの詳細な分析を行いました。広範な実験により、MR2がソーシャルメディア投稿を検索し、推論するために設計された噂検出システムを開発するための挑戦的なテストベッドを提供することが示されました。ソースコードとデータは次のリンクから入手できます: https://github.com/THU-BPM/MR2。
        </label>
        <input type="checkbox" id="Panel353" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> As social media platforms are evolving from text-based forums into multi-modal environments, the nature of misinformation in social media is also transforming accordingly. Misinformation spreaders have recently targeted contextual connections between the modalities e.g., text and image. However, existing datasets for rumor detection mainly focus on a single modality i.e., text. To bridge this gap, we construct MR2, a multimodal multilingual retrieval-augmented dataset for rumor detection. The dataset covers rumors with images and texts, and provides evidence from both modalities that are retrieved from the Internet. Further, we develop established baselines and conduct a detailed analysis of the systems evaluated on the dataset. Extensive experiments show that MR2 will provide a challenging testbed for developing rumor detection systems designed to retrieve and reason over social media posts. Source code and data are available at: https://github.com/THU-BPM/MR2.
        </div> </ul> <br>



        <label for="Panel354">
        <strong> BioSift: A Dataset for Filtering Biomedical Abstracts for Drug Repurposing and Clinical Meta-Analysis </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=David+Kartchner">David Kartchner</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Irfan+Al-Hussaini">Irfan Al-Hussaini</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haydn+Turner">Haydn Turner</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jennifer+Deng">Jennifer Deng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shubham+Lohiya">Shubham Lohiya</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Prasanth+Bathala">Prasanth Bathala</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cassie+Mitchell">Cassie Mitchell</a> (1) </u>  <br>
        1:  Georgia Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591897">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=BioSift: A Dataset for Filtering Biomedical Abstracts for Drug Repurposing and Clinical Meta-Analysis">Google Scholar</a></div>
        (354)
        <br>
        <b>概要:　</b> 本研究では、薬の再利用のための研究の初期選定とラベリングを迅速化するために、新しいオリジナルの文書分類データセットであるBioSiftを提案します。このデータセットは、PubMedに掲載された科学論文の10,000件のを人間が注釈したものから構成されています。それぞれのは、人気のある患者—介入—比較対象—結果（PICO）法を使用したメタアナリシスを行うために必要な8つの属性でラベル付けされています：人間の被験者がいる、臨床試験/コホートである、集団の規模が記載されている、対象疾患が記載されている、研究薬が記載されている、比較群が記載されている、定量的な結果が記載されている、そして「総合」ラベルが付与されています。各は、3人の異なる注釈者（すなわち、医学部の学生）によって注釈され、ランダムにサンプリングされたは、品質を確保するために上級注釈者によってレビューされました。レビュアーの一致率、ラベルの同時出現、および信頼性などのデータ統計が示されています。堅牢なベンチマーク結果は、PubMedの高度なフィルターや最先端の文書分類スキーム（例：アクティブラーニング、弱い監督、完全な監督）が人間の注釈を効率的に置き換えることができないことを示しています。要するに、BioSiftは薬の再利用を迅速化するための重要でありながら挑戦的な文書分類タスクです。完全な注釈付きデータセットは公開されており、薬の再利用を強化するための文書分類アルゴリズムの研究開発を可能にします。
        </label>
        <input type="checkbox" id="Panel354" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This work presents a new, original document classification dataset, BioSift, to expedite the initial selection and labeling of studies for drug repurposing. The dataset consists of 10,000 human-annotated abstracts from scientific articles in PubMed. Each abstract is labeled with up to eight attributes necessary to perform meta-analysis utilizing the popular patient-intervention-comparator-outcome (PICO) method: has human subjects, is clinical trial/cohort, has population size, has target disease, has study drug, has comparator group, has a quantitative outcome, and an "aggregate" label. Each abstract was annotated by 3 different annotators (i.e., biomedical students) and randomly sampled abstracts were reviewed by senior annotators to ensure quality. Data statistics such as reviewer agreement, label co-occurrence, and confidence are shown. Robust benchmark results illustrate neither PubMed advanced filters nor state-of-the-art document classification schemes (e.g., active learning, weak supervision, full supervision) can efficiently replace human annotation. In short, BioSift is a pivotal but challenging document classification task to expedite drug repurposing. The full annotated dataset is publicly available and enables research development of algorithms for document classification that enhance drug repurposing.
        </div> </ul> <br>



        <label for="Panel355">
        <strong> MoocRadar: A Fine-grained and Multi-aspect Knowledge Repository for Improving Cognitive Student Modeling in MOOCs </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jifan+Yu">Jifan Yu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mengying+Lu">Mengying Lu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qingyang+Zhong">Qingyang Zhong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zijun+Yao">Zijun Yao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shangqing+Tu">Shangqing Tu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhengshan+Liao">Zhengshan Liao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoya+Li">Xiaoya Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Manli+Li">Manli Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Hou">Lei Hou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hai-Tao+Zheng">Hai-Tao Zheng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Juanzi+Li">Juanzi Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jie+Tang">Jie Tang</a> (1) </u>  <br>
        1:  Tsinghua University, 2:  Tsinghua University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591898">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MoocRadar: A Fine-grained and Multi-aspect Knowledge Repository for Improving Cognitive Student Modeling in MOOCs">Google Scholar</a></div>
        (355)
        <br>
        <b>概要:　</b> 学生モデル化とは、コースワークとの相互作用を通じて学生の学習特性を推測する課題であり、インテリジェント教育において基本的な問題です。知識トレーシングや認知診断からの最近の試みは、現在のモデルの使いやすさと効果を向上させるためのいくつかの有望な方向性を提案していますが、既存の公開データセットは、完全な演習コンテキスト、きめ細かい概念、および認知ラベルの無視により、これらの潜在的な解決策のニーズを満たすには不十分です。本論文では、2,513の練習問題、5,600の知識概念、および1,200万を超える行動記録からなるきめ細かく多面的な知識リポジトリであるMoocRadarを提案します。具体的には、きめ細かい概念と認知ラベルの高品質で包括的なアノテーションを保証するためのフレームワークを提案します。統計的および実験的結果は、我々のデータセットが既存の方法の将来の改善の基礎を提供することを示しています。さらに、研究者が便利に使用できるよう、データクエリ、モデル適応、さらにはリポジトリの拡張のための一連のツールを公開し、https://github.com/THU-KEG/MOOC-Radar で利用可能にしました。
        </label>
        <input type="checkbox" id="Panel355" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Student modeling, the task of inferring a student's learning characteristics through their interactions with coursework, is a fundamental issue in intelligent education. Although the recent attempts from knowledge tracing and cognitive diagnosis propose several promising directions for improving the usability and effectiveness of current models, the existing public datasets are still insufficient to meet the need for these potential solutions due to their ignorance of complete exercising contexts, fine-grained concepts, and cognitive labels. In this paper, we present MoocRadar, a fine-grained, multi-aspect knowledge repository consisting of 2,513 exercise questions, 5,600 knowledge concepts, and over 12 million behavioral records. Specifically, we propose a framework to guarantee a high-quality and comprehensive annotation of fine-grained concepts and cognitive labels. The statistical and experimental results indicate that our dataset provides the basis for the future improvements of existing methods. Moreover, to support the convenient usage for researchers, we release a set of tools for data querying, model adaption, and even the extension of our repository, which are now available at https://github.com/THU-KEG/MOOC-Radar.
        </div> </ul> <br>



        <label for="Panel356">
        <strong> RL4RS: A Real-World Dataset for Reinforcement Learning based Recommender System </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kai+Wang">Kai Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhene+Zou">Zhene Zou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Minghao+Zhao">Minghao Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qilin+Deng">Qilin Deng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Shang">Yue Shang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yile+Liang">Yile Liang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Runze+Wu">Runze Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xudong+Shen">Xudong Shen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tangjie+Lyu">Tangjie Lyu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Changjie+Fan">Changjie Fan</a> (1) </u>  <br>
        1:  NetEase Fuxi AI Lab <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591899">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=RL4RS: A Real-World Dataset for Reinforcement Learning based Recommender System">Google Scholar</a></div>
        (356)
        <br>
        <b>概要:　</b> 強化学習に基づくレコメンダシステム（RLベースのRS）は、収集されたデータのバッチから良好な方策を学習し、マルチステップの意思決定タスクへの推奨を行うことを目指しています。しかし、現在のRLベースのRS研究には、現実との大きな隔たりが一般的に存在します。本論文では、RLベースのRS分野におけるリソースの制約により、従来の研究が使用していた人工データセットや半シミュレーションRSデータセットに代わる、初のオープンソースの実世界データセットであるRL4RSを紹介します。学術的なRL研究とは異なり、RLベースのRSは導入前の十分な検証が困難です。我々は環境シミュレーションの評価、環境に対する評価、および反事実方策評価を含む、新しい体系的な評価フレームワークの提案を試みます。まとめると、現実とのギャップに特別な配慮を持つ新しいリソースであるRL4RS（Reinforcement Learning for Recommender Systems）は、二つの実世界データセット、データ理解ツール、調整されたシミュレーション環境、関連する先進的なRLベースライン、バッチRLベースライン、および反事実方策評価アルゴリズムを含みます。RL4RS統合スイートはhttps://github.com/fuxiAIlab/RL4RSで見つけることができます。
        </label>
        <input type="checkbox" id="Panel356" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Reinforcement learning based recommender systems (RL-based RS) aim at learning a good policy from a batch of collected data, by casting recommendations to multi-step decision-making tasks. However, current RL-based RS research commonly has a large reality gap. In this paper, we introduce the first open-source real-world dataset, RL4RS, hoping to replace the artificial datasets and semi-simulated RS datasets previous studies used due to the resource limitation of the RL-based RS domain. Unlike academic RL research, RL-based RS suffers from the difficulties of being well-validated before deployment. We attempt to propose a new systematic evaluation framework, including evaluation of environment simulation, evaluation on environments, and counterfactual policy evaluation. In summary, the RL4RS (Reinforcement Learning for Recommender Systems), a new resource with special concerns on the reality gaps, contains two real-world datasets, data understanding tools, tuned simulation environments, related advanced RL baselines, batch RL baselines, and counterfactual policy evaluation algorithms. The RL4RS suite can be found at https://github.com/fuxiAIlab/RL4RS.
        </div> </ul> <br>



        <label for="Panel357">
        <strong> JDsearch: A Personalized Product Search Dataset with Real Queries and Full Interactions </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiongnan+Liu">Jiongnan Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhicheng+Dou">Zhicheng Dou</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guoyu+Tang">Guoyu Tang</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sulong+Xu">Sulong Xu</a> (3) </u>  <br>
        1:  Renmin University of China, 2:  Engineering Research Center of Next-Generation Intelligent Search and Recommendation, 3:  JD.com <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591900">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=JDsearch: A Personalized Product Search Dataset with Real Queries and Full Interactions">Google Scholar</a></div>
        (357)
        <br>
        <b>概要:　</b> 近年、個人化された製品検索が大きな注目を集めており、多くのモデルが提案されています。これらのモデルの有効性を評価するために、従来の研究では主にシミュレーションされたAmazonの推薦データセットを利用していますが、このデータセットは自動生成されたクエリを含み、冷遇ユーザーやテイルプロダクトを除外しています。我々は、このようなデータセットで評価することは信頼性の低い結果や結論をもたらし、実際のユーザー満足度から逸脱する可能性があると主張します。この問題を克服するために、本研究ではJD.comという人気の中国のオンラインショッピングプラットフォームから収集された実際のユーザークエリと多様なユーザー-製品間のインタラクションタイプ（クリック、カートへの追加、フォロー、購入）を含む個人化された製品検索データセットを公開します。具体的には、特定の日に約170,000人のアクティブユーザーをサンプルし、彼らが1年間にインタラクトしたすべての製品と発行したクエリを記録し、どのテイルユーザーやテイルプロダクトも除外していません。最終的に約12,000,000個の製品、9,400,000件の実際の検索、26,000,000件のユーザー-製品間インタラクションが集まりました。様々な視点からこのデータセットの特性を研究し、代表的なパーソナライゼーションモデルを評価して、その実行可能性を検証します。このデータセットはGithub（https://github.com/rucliujn/JDsearch）で公開されています。
        </label>
        <input type="checkbox" id="Panel357" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recently, personalized product search attracts great attention and many models have been proposed. To evaluate the effectiveness of these models, previous studies mainly utilize the simulated Amazon recommendation dataset, which contains automatically generated queries and excludes cold users and tail products. We argue that evaluating with such a dataset may yield unreliable results and conclusions, and deviate from real user satisfaction. To overcome these problems, in this paper, we release a personalized product search dataset comprised of real user queries and diverse user-product interaction types (clicking, adding to cart, following, and purchasing) collected from JD.com, a popular Chinese online shopping platform. More specifically, we sample about 170,000 active users on a specific date, then record all their interacted products and issued queries in one year, without removing any tail users and products. This finally results in roughly 12,000,000 products, 9,400,000 real searches, and 26,000,000 user-product interactions. We study the characteristics of this dataset from various perspectives and evaluate representative personalization models to verify its feasibility. The dataset can be publicly accessed at Github: https://github.com/rucliujn/JDsearch.
        </div> </ul> <br>



        <label for="Panel358">
        <strong> iQPP: A Benchmark for Image Query Performance Prediction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Eduard+Poesina">Eduard Poesina</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Radu+Tudor+Ionescu">Radu Tudor Ionescu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Josiane+Mothe">Josiane Mothe</a> (2) </u>  <br>
        1:  University of Bucharest, 2:  INSPE <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591901">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=iQPP: A Benchmark for Image Query Performance Prediction">Google Scholar</a></div>
        (358)
        <br>
        <b>概要:　</b> これまで、コンテンツベースの画像検索におけるクエリパフォーマンス予測（QPP）は、特にクエリバイエグザンプルシナリオ（クエリが画像である場合）においてあまり研究されていません。画像検索におけるQPPタスクの探求を促進するために、私たちは画像クエリパフォーマンス予測（iQPP）のための初のベンチマークを提案します。まず、PASCAL VOC 2012、Caltech-101、ROxford5k、RParis6kの4つのデータセットを用いて、2つの最新の画像検索モデルを基に各クエリの真の難易度を平均精度またはprecision@kとして推定します。次に、新しい事前・事後検索クエリパフォーマンス予測子を提案し、既存の予測子やテキストから画像に適応した予測子と比較評価します。実証結果は、ほとんどの予測子が評価シナリオを通じて一般化しないことを示しています。私たちの包括的な実験は、iQPPが重要な研究のギャップを明らかにする難しいベンチマークであることを示しており、今後の研究で対応する必要があることを明らかにしました。将来の研究を促進するために、コードとデータをhttps://github.com/Eduard6421/iQPPでオープンソースとして公開します。
        </label>
        <input type="checkbox" id="Panel358" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> To date, query performance prediction (QPP) in the context of content-based image retrieval remains a largely unexplored task, especially in the query-by-example scenario, where the query is an image. To boost the exploration of the QPP task in image retrieval, we propose the first benchmark for image query performance prediction (iQPP). First, we establish a set of four data sets (PASCAL VOC 2012, Caltech-101, ROxford5k and RParis6k) and estimate the ground-truth difficulty of each query as the average precision or the precision@k, using two state-of-the-art image retrieval models. Next, we propose and evaluate novel pre-retrieval and post-retrieval query performance predictors, comparing them with existing or adapted (from text to image) predictors. The empirical results show that most predictors do not generalize across evaluation scenarios. Our comprehensive experiments indicate that iQPP is a challenging benchmark, revealing an important research gap that needs to be addressed in future work. We release our code and data as open source at https://github.com/Eduard6421/iQPP, to foster future research.
        </div> </ul> <br>



        <label for="Panel359">
        <strong> SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nandan+Thakur">Nandan Thakur</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kexin+Wang">Kexin Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Iryna+Gurevych">Iryna Gurevych</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jimmy+Lin">Jimmy Lin</a> (1) </u>  <br>
        1:  University of Waterloo, 2:  Technical University of Darmstadt <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591902">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval">Google Scholar</a></div>
        (359)
        <br>
        <b>概要:　</b> 従来、スパース検索システムは、BM25のような語彙表現に依存して文書を検索し、情報検索タスクを支配してきました。BERTのような事前訓練済みトランスフォーマーモデルの出現により、ニューラルスパース検索は検索の新たなパラダイムを導入しました。しかしながら、この成功にもかかわらず、異なるスパースリトリーバーが統一された共通環境で動作するソフトウェアのサポートは限定的です。これにより、実務者が異なるスパースモデルを公正に比較し、現実的な評価結果を得ることが妨げられています。もう1つの欠けている要素は、これまでの研究の大半が、単一のデータセット（MS MARCO）に対するインドメイン検索モデルの評価に焦点を当てていることです。しかし、実際の検索システムでは、未見のアウトオブドメイン、すなわちゼロショット検索タスクに対してもよく一般化できるモデルが必要とされています。この研究において、我々は統一されたPythonツールキットであるSPRINTを提供します。PyseriniとLuceneを基盤にしており、ニューラルスパース検索の評価を行うための共通インターフェイスをサポートしています。このツールキットには現在、uniCOIL、DeepImpact、SPARTA、TILDEv2、SPLADEv2の5つの組み込みモデルが含まれています。ユーザーは独自の重み付け方法を定義することで、簡単にカスタマイズモデルを追加できます。我々のツールキットを使用して、よく知られたベンチマークであるBEIRにおいて、強力かつ再現性のあるゼロショットスパース検索のベースラインを確立しました。我々の結果は、SPLADEv2がBEIRにおけるすべてのニューラルスパースリトリーバーの中で、最高平均スコアである0.470のnDCG@10を達成することを示しています。本研究では、そのパフォーマンス向上の理由も明らかにしています。SPLADEv2は、元のクエリ及び文書外のトークンを多数含むスパース表現を生成し、それがパフォーマンス向上にとって重要であることを示しています、すなわち他のスパースモデルには限界があるということです。我々はSPRINTツールキット、モデルおよび実験に使用したデータを以下で公開しています: https://github.com/thakur-nandan/sprint.
        </label>
        <input type="checkbox" id="Panel359" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Traditionally, sparse retrieval systems relied on lexical representations to retrieve documents, such as BM25, dominated information retrieval tasks. With the onset of pre-trained transformer models such as BERT, neural sparse retrieval has led to a new paradigm within retrieval. Despite the success, there has been limited software supporting different sparse retrievers running in a unified, common environment. This hinders practitioners from fairly comparing different sparse models and obtaining realistic evaluation results. Another missing piece is, that a majority of prior work evaluates sparse retrieval models on in-domain retrieval, i.e. on a single dataset: MS MARCO. However, a key requirement in practical retrieval systems requires models that can generalize well to unseen out-of-domain, i.e. zero-shot retrieval tasks. In this work, we provide SPRINT, a unified python toolkit based on Pyserini and Lucene, supporting a common interface for evaluating neural sparse retrieval. The toolkit currently includes five built-in models: uniCOIL, DeepImpact, SPARTA, TILDEv2 and SPLADEv2. Users can also easily add customized models by defining their term weighting method. Using our toolkit, we establish strong and reproducible zero-shot sparse retrieval baselines across the well-acknowledged benchmark, BEIR. Our results demonstrate that SPLADEv2 achieves the best average score of 0.470 nDCG@10 on BEIR amongst all neural sparse retrievers. In this work, we further uncover the reasons behind its performance gain. We show that SPLADEv2 produces sparse representations with a majority of tokens outside of the original query and document which is often crucial for its performance gains, i.e. a limitation among its other sparse counterparts. We provide our SPRINT toolkit, models, and data used in our experiments publicly here: https://github.com/thakur-nandan/sprint.
        </div> </ul> <br>



        <label for="Panel360">
        <strong> AToMiC: An Image/Text Retrieval Test Collection to Support Multimedia Content Creation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jheng-Hong+Yang">Jheng-Hong Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Carlos+Lassance">Carlos Lassance</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rafael+Sampaio+De+Rezende">Rafael Sampaio De Rezende</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Krishna+Srinivasan">Krishna Srinivasan</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Miriam+Redi">Miriam Redi</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Stéphane+Clinchant">Stéphane Clinchant</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jimmy+Lin">Jimmy Lin</a> (1) </u>  <br>
        1:  University of Waterloo, 2:  Naver Labs Europe, 3:  Google Research, 4:  Wikimedia Foundation <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591903">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=AToMiC: An Image/Text Retrieval Test Collection to Support Multimedia Content Creation">Google Scholar</a></div>
        (360)
        <br>
        <b>概要:　</b> :<br>本論文では、画像とテキストのクロスモーダル検索の研究を進展させるために設計されたAToMiC（Authoring Tools for Multi media Content）データセットを紹介します。ビジョンとランゲージの事前学習済みトランスフォーマーは検索効率を大幅に向上させている一方で、既存の研究は簡素な画像とテキストの関係性や具体性に欠けるユーザーモデルに依存してきました。こうした過度に単純化された設定と、マルチメディアコンテンツ作成の現実的な応用とのギャップを埋めるために、新たな検索テストコレクションの構築アプローチを導入します。私たちは階層構造、多様なドメインのテキスト、スタイル、および画像のタイプ、そしてWikipediaに埋め込まれた大規模な画像と文書の関連性を活用しました。現実的なユーザーモデルに基づいた2つのタスクを定式化し、ベースラインモデルを用いた検索実験を通じてデータセットの妥当性を検証しました。AToMiCはスケーラブルで多様性と再現性のあるマルチメディア検索研究のためのテストベッドを提供します。最後に、本データセットは2023年テキスト検索会議（TREC）の専用トラックの基盤を提供し、https://github.com/TREC-AToMiC/AToMiC で公開されています。
        </label>
        <input type="checkbox" id="Panel360" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This paper presents the AToMiC (Authoring Tools for Multi media Content) dataset, designed to advance research in image/text cross-modal retrieval. While vision--language pretrained transformers have led to significant improvements in retrieval effectiveness, existing research has relied on image-caption datasets that feature only simplistic image--text relationships and underspecified user models of retrieval tasks. To address the gap between these oversimplified settings and real-world applications for multimedia content creation, we introduce a new approach for building retrieval test collections. We leverage hierarchical structures and diverse domains of texts, styles, and types of images, as well as large-scale image--document associations embedded in Wikipedia. We formulate two tasks based on a realistic user model and validate our dataset through retrieval experiments using baseline models. AToMiC offers a testbed for scalable, diverse, and reproducible multimedia retrieval research. Finally, our dataset provides the basis for a dedicated track at the 2023 Text Retrieval Conference (TREC), and is publicly available at https://github.com/TREC-AToMiC/AToMiC.
        </div> </ul> <br>



        <label for="Panel361">
        <strong> DICE: a Dataset of Italian Crime Event news </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Giovanni+Bonisoli">Giovanni Bonisoli</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maria+Pia+Di+Buono">Maria Pia Di Buono</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Laura+Po">Laura Po</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Federica+Rollo">Federica Rollo</a> (1) </u>  <br>
        1:  University of Modena and Reggio Emilia, 2:  University of Napoli <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591904">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=DICE: a Dataset of Italian Crime Event news">Google Scholar</a></div>
        (361)
        <br>
        <b>概要:　</b> ニュース記事からイベントを抽出することは、質問応答、ニュース推薦、ニュースなどのいくつかの自然言語処理(NLP)アプリケーションの目的として重要ですが、その複雑さから簡単な作業ではありません。自然言語の複雑さに加え、ニュース報道はジャーナリズムのスタイルや規範によって特徴付けられているためです。これらの要因は、イベントの説明が1つの文書内(または複数の文書に分散すること)に数文の中に分散されることを意味し、段階的にイベント関連情報を具体化する仕組みを適用します。そのため、共参照関係を広範に使用し、非線形の時間情報を伝えます。これに加えて、いくつかのタスクで最先端の結果が達成されているにもかかわらず、非英語圏の言語向けの高品質なトレーニングデータセットはほとんど利用可能ではありません。本稿では、イタリアの犯罪ニュースの注釈付きデータセット(DICE: Dataset for Italian Crime Event news)を開発するための予備的な研究を紹介します。本稿の貢献は以下のとおりです：(1) 10,395件の犯罪ニュースのコーパスの作成；(2) 注釈スキーマ；(3) 自動注釈付きの10,395件のニュースデータセット；(4) 提案スキーマを用いた1,000件の文書の予備的な手動注釈。DICEに対する初期のテストでは、手動注釈者の性能とシングルスパンおよびマルチスパンの質問応答モデルの性能を比較し、特に複雑な注釈タスクや限られたトレーニングデータを扱う際に依然としてモデルにギャップがあることが示されました。これは、DICEのような高品質の注釈付きデータセットの作成に投資する重要性を強調するものであり、広範なNLPモデルの訓練およびテストに堅固な基盤を提供することができます。
        </label>
        <input type="checkbox" id="Panel361" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Extracting events from news stories as the aim of several Natural Language Processing (NLP) applications (e.g., question answering, news recommendation, news summarization) is not a trivial task, due to the complexity of natural language and the fact that news reporting is characterized by journalistic style and norms. Those aspects entail scattering an event description over several sentences within one document (or more documents), applying a mechanism of gradual specification of event-related information. This implies a widespread use of co-reference relations among the textual elements, conveying non-linear temporal information. In addition to this, despite the achievement of state-of-the-art results in several tasks, high-quality training datasets for non-English languages are rarely available. This paper presents our preliminary study to develop an annotated Dataset for Italian Crime Event news (DICE). The contribution of the paper are: (1) the creation of a corpus of 10,395 crime news; (2) the annotation schema; (3) a dataset of 10,395 news with automatic annotations; (4) a preliminary manual annotation using the proposed schema of 1000 documents. The first tests on DICE have compared the performance of a manual annotator with that of single-span and multi-span question answering models and shown there is still a gap in the models, especially when dealing with more complex annotation tasks and limited training data. This underscores the importance of investing in the creation of high-quality annotated datasets like DICE, which can provide a solid foundation for training and testing a wide range of NLP models.
        </div> </ul> <br>



        <label for="Panel362">
        <strong> BDI-Sen: A Sentence Dataset for Clinical Symptoms of Depression </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anxo+Pérez">Anxo Pérez</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Javier+Parapar">Javier Parapar</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Álvaro+Barreiro">Álvaro Barreiro</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Silvia+Lopez-Larrosa">Silvia Lopez-Larrosa</a> (1) </u>  <br>
        1:  Universidade da Coruña <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591905">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=BDI-Sen: A Sentence Dataset for Clinical Symptoms of Depression">Google Scholar</a></div>
        (362)
        <br>
        <b>概要:　</b> 人々はソーシャルプラットフォームを、関心事や感情の苦悩を表現するための便利なメディアと見なす傾向があります。その広範な使用により、研究者は精神状態に関連するユーザー生成コンテンツにアクセスして分析することができます。このデータを活用する計算モデルは、設計された特徴量や深層学習モデルに基づいて、リスクのあるユーザーを検出する上で有望な結果を示しています。しかし、最近の研究は、臨床の設定を考慮した場合、これらのアプローチが一般化と解釈の能力に限界があることを明らかにしました。モデルの判断を臨床的かつ認識された症状に基づけることが、これらの制約を克服するのに役立ちます。本稿では、うつ病性障害のための症状注釈付き文データセットBDI-Senを紹介します。BDI-Senは、うつ病の検出と測定に使用される信頼性のある質問票であるBeck Depression Inventory-II（BDI-II）に含まれるすべての症状を網羅しています。このコレクションの注釈は、特定の症状に関する発言が情報提供的であるかどうか（すなわち、その症状に関する個人の状態についての痕跡を示すかどうか）を反映しています。我々はこのリソースを徹底的に分析し、言語スタイル、感情の付与、その他の心理言語学的指標を探ります。さらに、BDI-Senの有用性を検出や症状の重症度分類などのさまざまなタスクにおいて調査する一連の実験を行います。また、他の精神疾患の症状を考慮した場合の一般化についても検討します。BDI-Senは、信頼性が高く価値のあるうつ病マーカーを考慮する将来のモデルの開発に貢献する可能性があります。
        </label>
        <input type="checkbox" id="Panel362" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> People tend to consider social platforms as convenient media for expressing their concerns and emotional struggles. With their widespread use, researchers could access and analyze user-generated content related to mental states. Computational models that exploit that data show promising results in detecting at-risk users based on engineered features or deep learning models. However, recent works revealed that these approaches have a limited capacity for generalization and interpretation when considering clinical settings. Grounding the models' decisions on clinical and recognized symptoms can help to overcome these limitations. In this paper, we introduce BDI-Sen, a symptom-annotated sentence dataset for depressive disorder. BDI-Sen covers all the symptoms present in the Beck Depression Inventory-II (BDI-II), a reliable questionnaire used for detecting and measuring depression. The annotations in the collection reflect whether a statement about the specific symptom is informative (i.e., exposes traces about the individual's state regarding that symptom). We thoroughly analyze this resource and explore linguistic style, emotional attribution, and other psycholinguistic markers. Additionally, we conduct a series of experiments investigating the utility of BDI-Sen for various tasks, including the detection and severity classification of symptoms. We also examine their generalization when considering symptoms from other mental diseases. BDI-Sen may aid the development of future models that consider trustworthy and valuable depression markers.
        </div> </ul> <br>



        <label for="Panel363">
        <strong> MobileRec: A Large Scale Dataset for Mobile Apps Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=M.+H.+Maqbool">M. H. Maqbool</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Umar+Farooq">Umar Farooq</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Adib+Mosharrof">Adib Mosharrof</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=A.+B.+Siddique">A. B. Siddique</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hassan+Foroosh">Hassan Foroosh</a> (1) </u>  <br>
        1:  University of Central Florida, 2:  Independent Researcher, 3:  University of Kentucky <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591906">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MobileRec: A Large Scale Dataset for Mobile Apps Recommendation">Google Scholar</a></div>
        (363)
        <br>
        <b>概要:　</b> レコメンダーシステムは、eコマースサイトでの商品推奨からストリーミングプラットフォームでの映画や音楽の提案まで、私たちのデジタル生活に不可欠な存在となっています。Amazon商品レビューやMovieLensなどの既存の推薦データセットは、それぞれのドメインにおけるレコメンダーシステムの研究と開発を大いに促進しました。しかし、過去10年間でモバイルユーザーとアプリケーション（通称アプリ）の数が指数関数的に増加している一方で、モバイルアプリのレコメンダーシステムの研究は、高品質なベンチマークデータセットの不足により大幅に制約を受けてきました。これに対して、製品や映画、ニュースの推薦ではそのような制約は少なかったのです。アプリ推薦システムの研究を促進するために、我々はMobileRecと呼ばれる大規模なデータセットを導入します。MobileRecはGoogle Playストアにおけるユーザーの活動から構築されており、19.3百万件のユーザーインタラクション（すなわち、アプリに関するユーザーレビュー）を含んでいます。このデータセットには、48カテゴリにわたる10K以上のユニークなアプリが存在し、総計0.7百万の異なるユーザーの連続的な活動記録が含まれています。これらのユーザーはそれぞれ少なくとも5つの異なるアプリとインタラクションを持っており、これまでのモバイルアプリに関するデータセットがユーザー1人あたり1回のインタラクションしか記録していなかった点と対照的です。さらに、MobileRecはインストールされたアプリに関するユーザーの評価や感情も提供し、各アプリにはアプリ名、カテゴリ、説明、総合評価などの豊富なメタデータが含まれています。MobileRecがアプリ推薦のための優れたテストベッドとなることを、いくつかの最先端の推薦手法の比較研究を通じて示しています。MobileRecデータセットは、https://huggingface.co/datasets/recmeapp/mobilerec で利用可能です。
        </label>
        <input type="checkbox" id="Panel363" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recommender systems have become ubiquitous in our digital lives, from recommending products on e-commerce websites to suggesting movies and music on streaming platforms. Existing recommendation datasets, such as Amazon Product Reviews and MovieLens, greatly facilitated the research and development of recommender systems in their respective domains. While the number of mobile users and applications (aka apps) has increased exponentially over the past decade, research in mobile app recommender systems has been significantly constrained, primarily due to the lack of high-quality benchmark datasets, as opposed to recommendations for products, movies, and news. To facilitate research for app recommendation systems, we introduce a large-scale dataset, called MobileRec. We constructed MobileRec from users' activity on the Google play store. MobileRec contains 19.3 million user interactions (i.e., user reviews on apps) with over 10K unique apps across 48 categories. MobileRec records the sequential activity of a total of 0.7 million distinct users. Each of these users has interacted with no fewer than five distinct apps, which stands in contrast to previous datasets on mobile apps that recorded only a single interaction per user. Furthermore, MobileRec presents users' ratings as well as sentiments on installed apps, and each app contains rich metadata such as app name, category, description, and overall rating, among others. We demonstrate that MobileRec can serve as an excellent testbed for app recommendation through a comparative study of several state-of-the-art recommendation approaches. The MobileRec dataset is available at https://huggingface.co/datasets/recmeapp/mobilerec.
        </div> </ul> <br>



        <label for="Panel364">
        <strong> MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Question Answering </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Bai">Yang Bai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anthony+Colas">Anthony Colas</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daisy+Zhe+Wang">Daisy Zhe Wang</a> (1) </u>  <br>
        1:  The University of Florida <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591907">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through Multi-Answer Open-Domain Question Answering">Google Scholar</a></div>
        (364)
        <br>
        <b>概要:　</b> チェックに値する主張の検出は、下流のファクトチェックシステムや人間の専門家によって確かめられる可能性のある誤情報を提供することを目指しています。これはファクトチェックのプロセスを加速するための重要なステップです。これまで、あらかじめ収集された少量の主張からチェックに値する主張を特定する取り組みが行われてきましたが、Twitterのような大規模な情報源からチェックに値する主張を効率的に検出する方法は十分に研究されていません。このギャップを埋めるために、我々はMythQAを紹介します。MythQAは、クエリベースの大規模なチェックに値する主張検出のために、矛盾するスタンスのマイニングを含む新しいマルチアンサーのオープンドメイン質問応答(QA)タスクです。このアイデアの背後には、矛盾する主張が適切な当局によって精査されるべき誤情報の強力な指標であるという考えがあります。このタスクを研究するため、我々は論争のあるトピックに基づいた522のファクトイドマルチアンサー質問を含む評価データセットTweetMythQAを構築しました。それぞれの質問には複数の回答が注釈されています。さらに、各異なる回答に対して関係するツイートを収集し、「サポート」、「反論」、「中立」の3つのカテゴリーに分類します。合計で5,300のツイートに注釈付けを行いました。データセット内の全ての回答に対して矛盾する証拠が収集されています。最後に、MythQAのベースラインシステムを提示し、TweetMythQAデータセットを使用して各システムコンポーネントに対する既存のNLPモデルを評価します。初期のベンチマークを提供し、将来のモデルが改善すべき主要な課題を特定します。コードとデータは以下のリンクで利用可能です: https://github.com/TonyBY/Myth-QA
        </label>
        <input type="checkbox" id="Panel364" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Check-worthy claim detection aims at providing plausible misinformation to the downstream fact-checking systems or human experts to check. This is a crucial step toward accelerating the fact-checking process. Many efforts have been put into how to identify check-worthy claims from a small scale of pre-collected claims, but how to efficiently detect check-worthy claims directly from a large-scale information source, such as Twitter, remains underexplored. To fill this gap, we introduce MythQA, a new multi-answer open-domain question answering(QA) task that involves contradictory stance mining for query-based large-scale check-worthy claim detection. The idea behind this is that contradictory claims are a strong indicator of misinformation that merits scrutiny by the appropriate authorities. To study this task, we construct TweetMythQA, an evaluation dataset containing 522 factoid multi-answer questions based on controversial topics. Each question is annotated with multiple answers. Moreover, we collect relevant tweets for each distinct answer, then classify them into three categories: "Supporting", "Refuting", and "Neutral". In total, we annotated 5.3K tweets. Contradictory evidence is collected for all answers in the dataset. Finally, we present a baseline system for MythQA and evaluate existing NLP models for each system component using the TweetMythQA dataset. We provide initial benchmarks and identify key challenges for future models to improve upon. Code and data are available at: https://github.com/TonyBY/Myth-QA
        </div> </ul> <br>



        <label for="Panel365">
        <strong> RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gabriel+Iturra-Bocaz">Gabriel Iturra-Bocaz</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Felipe+Bravo-Marquez">Felipe Bravo-Marquez</a> (1) </u>  <br>
        1:  University of Chile <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591908">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams">Google Scholar</a></div>
        (365)
        <br>
        <b>概要:　</b> 単語埋め込みは、ランキング、文書分類、質疑応答など、さまざまな情報検索および自然言語処理タスクにおいて不可欠なコンポーネントになっています。しかし、その広範な使用にもかかわらず、従来の単語埋め込みモデルは静的であるという制約があり、ソーシャルメディアやウェブのような情報源で発生する新しいハッシュタグやブランド名など、絶えず進化する言語パターンに適応する能力が妨げられます。この問題を解決するために、増分単語埋め込みアルゴリズムが導入され、新しい言語パターンに応じて動的に単語表現を更新し、連続データストリームを処理できるようにします。本論文では、テキストデータストリームから増分単語埋め込みを学習および評価するためのPythonライブラリであるRiverTextを紹介します。我々のツールは、ソーシャルメディアの解析のようなストリーミングシナリオで単語埋め込みを使用する情報検索および自然言語処理コミュニティにとってのリソースです。このライブラリは、Skip-gram、連続バグ・オブ・ワーズ（Continuous Bag of Words）、単語文脈行列（Word Context Matrix）などの異なる増分単語埋め込み技術を標準化されたフレームワークで実装しています。さらに、神経ネットワークの訓練にはPyTorchをバックエンドとして使用しています。また、単語の類似性および単語のカテゴリ化といった既存の静的単語埋め込み評価タスクをストリーミング環境に適応させるモジュールを実装しました。最後に、異なるハイパーパラメータ設定で実装された方法を比較し、結果を検討しています。我々のオープンソースライブラリはhttps://github.com/dccuchile/rivertext で入手可能です。
        </label>
        <input type="checkbox" id="Panel365" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Word embeddings have become essential components in various information retrieval and natural language processing tasks, such as ranking, document classification, and question answering. However, despite their widespread use, traditional word embedding models present a limitation in their static nature, which hampers their ability to adapt to the constantly evolving language patterns that emerge in sources such as social media and the web (e.g., new hashtags or brand names). To overcome this problem, incremental word embedding algorithms are introduced, capable of dynamically updating word representations in response to new language patterns and processing continuous data streams. This paper presents RiverText, a Python library for training and evaluating incremental word embeddings from text data streams. Our tool is a resource for the information retrieval and natural language processing communities that work with word embeddings in streaming scenarios, such as analyzing social media. The library implements different incremental word embedding techniques, such as Skip-gram, Continuous Bag of Words, and Word Context Matrix, in a standardized framework. In addition, it uses PyTorch as its backend for neural network training. We have implemented a module that adapts existing intrinsic static word embedding evaluation tasks for word similarity and word categorization to a streaming setting. Finally, we compare the implemented methods with different hyperparameter settings and discuss the results. Our open-source library is available at https://github.com/dccuchile/rivertext.
        </div> </ul> <br>



        <label for="Panel366">
        <strong> FedAds: A Benchmark for Privacy-Preserving CVR Estimation with Vertical Federated Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Penghui+Wei">Penghui Wei</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongjian+Dou">Hongjian Dou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shaoguo+Liu">Shaoguo Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rongjun+Tang">Rongjun Tang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Li+Liu">Li Liu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liang+Wang">Liang Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bo+Zheng">Bo Zheng</a> (1) </u>  <br>
        1:  Alibaba Group, 2:  The Chinese University of Hong Kong, 3:  The Hong Kong University of Science and Technology (Guangzhou) <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591909">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=FedAds: A Benchmark for Privacy-Preserving CVR Estimation with Vertical Federated Learning">Google Scholar</a></div>
        (366)
        <br>
        <b>概要:　</b> コンバージョン率（CVR）の推定は、ユーザーが広告をクリックした後のコンバージョンイベントの確率を予測することを目的としています。通常、オンラインパブリッシャーはユーザーの閲覧興味とクリックフィードバックを持ち、デマンドサイド広告プラットフォームはユーザーのクリック後の行動（滞在時間やコンバージョン決定など）を収集します。CVRを正確に推定し、データのプライバシーをより良く保護するためには、垂直連合学習（vFL）が最適な解決策であり、生データを交換せずに両側の利点を組み合わせてモデルを訓練します。CVRの推定と適用されたvFLアルゴリズムは増加する研究の注目を集めていますが、標準化された体系的な評価は欠如しています。標準化されたデータセットが不足しているため、既存の研究は手作りの特徴分割によってvFL環境をシミュレートするために公開されたデータセットを採用し、公正な比較に挑戦をもたらします。我々は、vFLを用いたCVR推定のための初のベンチマークであるFedAdsを導入し、vFLアルゴリズムの標準化された体系的な評価を促進します。このベンチマークには、アリババの広告プラットフォームから収集された大規模な実世界のデータセットと、さまざまなvFLアルゴリズムの有効性とプライバシーの観点からの体系的な評価が含まれています。また、効果を高めるためにvFLに非整列データを組み込むことを探求し、プライバシーを十分に保護するために攪乱操作を開発します。我々は、将来のvFLとCVR推定に関する研究がFedAdsベンチマークから利益を得ることを期待しています。
        </label>
        <input type="checkbox" id="Panel366" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Conversion rate (CVR) estimation aims to predict the probability of conversion event after a user has clicked an ad. Typically, online publisher has user browsing interests and click feedbacks, while demand-side advertising platform collects users' post-click behaviors such as dwell time and conversion decisions. To estimate CVR accurately and protect data privacy better, vertical federated learning (vFL) is a natural solution to combine two sides' advantages for training models, without exchanging raw data. Both CVR estimation and applied vFL algorithms have attracted increasing research attentions. However, standardized and systematical evaluations are missing: due to the lack of standardized datasets, existing studies adopt public datasets to simulate a vFL setting via hand-crafted feature partition, which brings challenges to fair comparison. We introduce FedAds, the first benchmark for CVR estimation with vFL, to facilitate standardized and systematical evaluations for vFL algorithms. It contains a large-scale real world dataset collected from Alibaba's advertising platform, as well as systematical evaluations for both effectiveness and privacy aspects of various vFL algorithms. Besides, we also explore to incorporate unaligned data in vFL to improve effectiveness, and develop perturbation operations to protect privacy well. We hope that future research work in vFL and CVR estimation benefits from the FedAds benchmark.
        </div> </ul> <br>



        <label for="Panel367">
        <strong> The BETTER Cross-Language Datasets </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ian+Soboroff">Ian Soboroff</a> (1) </u>  <br>
        1:  National Institute of Standards and Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591910">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=The BETTER Cross-Language Datasets">Google Scholar</a></div>
        (367)
        <br>
        <b>概要:　</b> IARPA BETTER（Better Extraction from Text Through Enhanced Retrieval）プログラムは、情報検索（IR）および情報抽出（IE）の三つの評価を実施しました。これらのタスクにおいて、利用可能な訓練データは英語のみでしたが、システムはアラビア語、ペルシア語、中国語、ロシア語、および韓国語からのクロスランゲージ検索と抽出を行う必要がありました。プール評価および情報抽出アノテーションが用いられ、再利用可能なIRテストコレクションが作成されました。これらのデータセットは、クロスランゲージ検索、情報抽出、またはIRとIEの結合を研究する研究者に無償で提供されます。本論文では、これらのデータセットの説明、作成方法、および研究者による利用方法について述べています。
        </label>
        <input type="checkbox" id="Panel367" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The IARPA BETTER (Better Extraction from Text Through Enhanced Retrieval) program held three evaluations of information retrieval (IR) and information extraction (IE). For both tasks, the only training data available was in English, but systems had to perform cross-language retrieval and extraction from Arabic, Farsi, Chinese, Russian, and Korean. Pooled assessment and information extraction annotation were used to create reusable IR test collections. These datasets are freely available to researchers working in cross-language retrieval, information extraction, or the conjunction of IR and IE. This paper describes the datasets, how they were constructed, and how they might be used by researchers.
        </div> </ul> <br>



        <label for="Panel368">
        <strong> REFinD: Relation Extraction Financial Dataset </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Simerjot+Kaur">Simerjot Kaur</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Charese+Smiley">Charese Smiley</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Akshat+Gupta">Akshat Gupta</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Joy+Sain">Joy Sain</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dongsheng+Wang">Dongsheng Wang</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Suchetha+Siddagangappa">Suchetha Siddagangappa</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Toyin+Aguda">Toyin Aguda</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sameena+Shah">Sameena Shah</a> (3) </u>  <br>
        1:  JPMorgan Chase and Co, 2:  JPMorgan Chase and Co, 3:  JPMorgan Chase and Co, 4:  Wright State University, 5:  JPMorgan Chase and Co <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591911">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=REFinD: Relation Extraction Financial Dataset">Google Scholar</a></div>
        (368)
        <br>
        <b>概要:　</b> 関係抽出（RE）のための多数のデータセットが、情報検索、セマンティック検索、質問応答、テキスト含意などの下流タスクを支援するために作成されてきました。しかし、これらのデータセットは、ウィキペディア、ウェブ上のテキスト、ニュース記事などの一般的な知識源を使用して作成されているため、金融分野特有の課題を捉えることができず、現実の金融分野での進展と採用の妨げとなっています。この限界を克服するために、我々は金融文書全体から生成された、8種類のエンティティペア間の22の関係を含む約2万9千のインスタンスからなる、関係の大規模注釈付きデータセットとして初めてのREFinDを提案します。また、REタスクのベンチマークとして、さまざまな最新のモデルを用いた実証評価を提供し、我々のデータセットが提起する課題を強調します。我々の観察によると、多数の最新の深層学習モデルが数値推論、関係の曖昧さ、方向性の曖昧さに苦戦しています。この分野でのさらなる研究を奨励するために、REFinDはhttps://www.jpmorgan.com/technology/artificial-intelligence/initiatives/refind-dataset/problem-motivation-outcomeで利用可能です。
        </label>
        <input type="checkbox" id="Panel368" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> A number of datasets for Relation Extraction (RE) have been created to aide downstream tasks such as information retrieval, semantic search, question answering and textual entailment. However, these datasets fail to capture financial-domain specific challenges since most of these datasets are compiled using general knowledge sources such as Wikipedia, web-based text and news articles, hindering real-life progress and adoption within the financial world. To address this limitation, we propose REFinD, the first large-scale annotated dataset of relations, with ~29K instances and 22 relations amongst 8 types of entity pairs, generated entirely over financial documents. We also provide an empirical evaluation with various state-of-the-art models as benchmarks for the RE task and highlight the challenges posed by our dataset. We observed that various state-of-the-art deep learning models struggle with numeric inference, relational and directional ambiguity. To encourage further research in this direction, REFinD is available at https://www.jpmorgan.com/technology/artificial-intelligence/initiatives/refind-dataset/problem-motivation-outcome.
        </div> </ul> <br>



        <label for="Panel369">
        <strong> Linked-DocRED - Enhancing DocRED with Entity-Linking to Evaluate End-To-End Document-Level Information Extraction Pipelines </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pierre-Yves+Genest">Pierre-Yves Genest</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pierre-Edouard+Portier">Pierre-Edouard Portier</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Elöd+Egyed-Zsigmond">Elöd Egyed-Zsigmond</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Martino+Lovisetto">Martino Lovisetto</a> (3) </u>  <br>
        1:  Alteca & Univ Lyon, 2:  Univ Lyon, 3:  Alteca <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591912">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Linked-DocRED - Enhancing DocRED with Entity-Linking to Evaluate End-To-End Document-Level Information Extraction Pipelines">Google Scholar</a></div>
        (369)
        <br>
        <b>概要:　</b> 情報抽出（Information Extraction, IE）パイプラインは、文書から意味のあるエンティティや関係を抽出し、それらを知識グラフに構造化することを目指します。この知識グラフは、その後のアプリケーションで利用されることを想定しています。このようなパイプラインの訓練および評価には、エンティティ、共参照、関係、エンティティリンクのラベルが付与されたデータセットが必要です。しかし、既存のデータセットはエンティティリンクのラベルが欠如しているか、サイズが小さすぎる、多様性に欠ける、または自動的に注釈が付与されたもの（つまり、注釈の正確性が強く保証されていない）です。そこで、我々はLinked-DocREDを提案します。これは、我々の知る限り、初の手動で注釈を付けられた大規模な文書レベルのIEデータセットです。我々は既存で広く使用されているDocREDデータセットをエンティティリンクのラベルで拡張しました。これらのラベルは、高品質な注釈を保証する半自動プロセスによって生成されます。具体的には、Wikipediaの記事中のハイパーリンクを用いて曖昧性解消の候補を提供します。また、エンドツーエンドのIEパイプラインをベンチマークするための完全な指標フレームワークを提案し、エンティティリンクを評価するためのエンティティ中心の指標を定義します。ベースラインの評価は有望な結果を示しつつ、エンドツーエンドのIEパイプラインの課題も浮き彫りにしました。Linked-DocRED、エンティティリンクのためのソースコード、ベースラインおよび指標はオープンソースライセンスの下で配布されており、公開リポジトリからダウンロードできます。
        </label>
        <input type="checkbox" id="Panel369" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Information Extraction (IE) pipelines aim to extract meaningful entities and relations from documents and structure them into a knowledge graph that can then be used in downstream applications. Training and evaluating such pipelines requires a dataset annotated with entities, coreferences, relations, and entity-linking. However, existing datasets either lack entity-linking labels, are too small, not diverse enough, or automatically annotated (that is, without a strong guarantee of the correction of annotations). Therefore, we propose Linked-DocRED, to the best of our knowledge, the first manually-annotated, large-scale, document-level IE dataset. We enhance the existing and widely-used DocRED dataset with entity-linking labels that are generated thanks to a semi-automatic process that guarantees high-quality annotations. In particular, we use hyperlinks in Wikipedia articles to provide disambiguation candidates. We also propose a complete framework of metrics to benchmark end-to-end IE pipelines, and we define an entity-centric metric to evaluate entity-linking. The evaluation of a baseline shows promising results while highlighting the challenges of an end-to-end IE pipeline. Linked-DocRED, the source code for the entity-linking, the baseline, and the metrics are distributed under an open-source license and can be downloaded from a public repository.
        </div> </ul> <br>



        <label for="Panel370">
        <strong> DECAF: A Modular and Extensible Conversational Search Framework </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Marco+Alessio">Marco Alessio</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guglielmo+Faggioli">Guglielmo Faggioli</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nicola+Ferro">Nicola Ferro</a> (1) </u>  <br>
        1:  University of Padova <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591913">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=DECAF: A Modular and Extensible Conversational Search Framework">Google Scholar</a></div>
        (370)
        <br>
        <b>概要:　</b> 会話型検索（CS）パラダイムは、ユーザーとシステムの間で自然言語文を通じた直感的な対話を可能にし、さまざまなシナリオでますます採用されています。しかし、その広範な実験により、カスタム実装や情報検索（IR）モデルのバリエーションを持つ多数の会話型検索システムが誕生しました。これにより、IRを含むいくつかの研究分野で既に観察されている再現性の危機が悪化しています。この問題に対処するために、迅速なプロトタイピングと会話エージェントの開発用に設計されたモジュラーで拡張可能な会話型検索フレームワーク、DECAFを提案します。我々のフレームワークは、現代の会話型検索システムを特徴付けるすべてのコンポーネントを統合し、機械学習（ML）および大規模言語モデル（LLMs）ベースの技術のシームレスな統合を可能にします。さらに、その統一されたインターフェースのおかげで、DECAFは高い再現性を特徴とする実験を可能にします。DECAFには、クエリ再書き込み、BoWおよび密パラダイム下での検索機能、再ランキング機能を含む、いくつかの最新のコンポーネントが含まれています。我々のフレームワークは、TREC CAsT 2019およびTREC CAsT 2020という2つのよく知られた会話コレクションでテストされ、その結果は将来の実務者にベースラインとして使用され得るものです。我々の貢献は、会話型検索タスクのための一連の最新コンポーネントの識別とその実装のためのモジュラーフレームワークの定義を含みます。
        </label>
        <input type="checkbox" id="Panel370" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The Conversational Search (CS) paradigm allows for an intuitive interaction between the user and the system through natural language sentences and it is increasingly being adopted in various scenarios. However, its widespread experimentation has led to the birth of a multitude of conversational search systems with custom implementations and variants of information retrieval models. This exacerbates the reproducibility crisis already observed in several research areas, including Information Retrieval (IR). To address this issue, we propose DECAF: a modular and extensible conversational search framework designed for fast prototyping and development of conversational agents. Our framework integrates all the components that characterize a modern conversational search system and allows for the seamless integration of Machine Learning (ML) and Large Language Models (LLMs)-based techniques. Furthermore, thanks to its uniform interface, DECAF allows for experiments characterized by a high degree of reproducibility. DECAF contains several state-of-the-art components including query rewriting, search functions under BoW and dense paradigms, and re-ranking functions. Our framework is tested on two well-known conversational collections: TREC CAsT 2019 and TREC CAsT 2020 and the results can be used by future practitioners as baselines. Our contributions include the identification of a series of state-of-the-art components for the conversational search task and the definition of a modular framework for its implementation.
        </div> </ul> <br>



        <label for="Panel371">
        <strong> LongEval-Retrieval: French-English Dynamic Test Collection for Continuous Web Search Evaluation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Petra+Galuscáková">Petra Galuscáková</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Romain+Deveaud">Romain Deveaud</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gabriela+González+Sáez">Gabriela González Sáez</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philippe+Mulhem">Philippe Mulhem</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lorraine+Goeuriot">Lorraine Goeuriot</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Florina+Piroi">Florina Piroi</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Martin+Popel">Martin Popel</a> (4) </u>  <br>
        1:  Université Grenoble Alpes, 2:  Qwant, 3:  Research Studios Austria, 4:  Charles University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591921">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=LongEval-Retrieval: French-English Dynamic Test Collection for Continuous Web Search Evaluation">Google Scholar</a></div>
        (371)
        <br>
        <b>概要:　</b> LongEval-Retrievalは、連続的な検索評価に焦点を当てたWebドキュメント検索ベンチマークです。このテストコレクションは、情報検索システムの時間的持続性を研究するために使用され、CLEF 2023のモデルパフォーマンスの縦断的評価トラック（LongEval）で使用されます。このベンチマークは、Web検索エンジンが操作するような進化する情報システム環境をシミュレートし、ドキュメントコレクション、クエリ分布、関連性が連続的に変動しながら、オフライン評価のためのCranfieldパラダイムに従います。これを実現するために、情報システムの状態を時系列に沿った各タイムステップで表す連続サブコレクションから構成される動的なテストコレクションの概念を導入します。LongEval-Retrievalでは、各サブコレクションにクエリセット、ドキュメント、およびクリックモデルから構築されたソフト関連評価が含まれています。データは、主にフランスマーケットに焦点を当てたプライバシー重視のWeb検索エンジンQwantから提供されます。LongEval-Retrievalは、Qwantのトラフィックの大部分を活用するためにフランス語で初期構築された「ミラー」コレクションも提供し、それを英語に翻訳しています。本論文では、LongEval-Retrievalの作成プロセスを紹介し、ベースラインランと分析を提供します。
        </label>
        <input type="checkbox" id="Panel371" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> LongEval-Retrieval is a Web document retrieval benchmark that focuses on continuous retrieval evaluation. This test collection is intended to be used to study the temporal persistence of Information Retrieval systems and will be used as the test collection in the Longitudinal Evaluation of Model Performance Track (LongEval) at CLEF 2023. This benchmark simulates an evolving information system environment - such as the one a Web search engine operates in - where the document collection, the query distribution, and relevance all move continuously, while following the Cranfield paradigm for offline evaluation. To do that, we introduce the concept of a dynamic test collection that is composed of successive sub-collections each representing the state of an information system at a given time step. In LongEval-Retrieval, each sub-collection contains a set of queries, documents, and soft relevance assessments built from click models. The data comes from Qwant, a privacy-preserving Web search engine that primarily focuses on the French market. LongEval-Retrieval also provides a 'mirror' collection: it is initially constructed in the French language to benefit from the majority of Qwant's traffic, before being translated to English. This paper presents the creation process of LongEval-Retrieval and provides baseline runs and analysis.
        </div> </ul> <br>



        <label for="Panel372">
        <strong> LibVQ: A Toolkit for Optimizing Vector Quantization and Efficient Neural Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaofan+Li">Chaofan Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zheng+Liu">Zheng Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shitao+Xiao">Shitao Xiao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yingxia+Shao">Yingxia Shao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Defu+Lian">Defu Lian</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhao+Cao">Zhao Cao</a> (1) </u>  <br>
        1:  Huawei <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591799">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=LibVQ: A Toolkit for Optimizing Vector Quantization and Efficient Neural Retrieval">Google Scholar</a></div>
        (372)
        <br>
        <b>概要:　</b> ベクトル量子化は、リアルタイムアプリケーションのための高密度検索を可能にする重要な技術の一つです。最近の研究によれば、FAISS [8] で実装されているような従来のベクトル量子化手法は損失が大きく、高速化比率が大きくなると検索性能が制限される傾向があります[14, 16, 18]。加えて、この損失を緩和するために、リトリーバーとベクトル量子化をより良く協働させる複数のアルゴリズムも提案されています。これらの進展を踏まえ、我々は高効率の高密度検索のためのベクトル量子化を最適化するツールキットであるLibVQを開発しました。我々のツールキットはいくつかの利点を持ちます。1. 効果性。標準的なVQ実装に比べて検索品質が大きく向上します。2. 単純性。最適化は少ないコードで実行可能で、最適化結果は簡単にANNインデックスにロードされ、下流のアプリケーションをサポートします。3. 普遍性。最適化は埋め込みの学習プロセスには依存せず、異なる入力条件やANNバックエンドにも多少のワークフロー変更で対応可能です。LibVQは高密度検索を超えて、多様なアプリケーション（例: 埋め込み圧縮、トピックモデリング、重複排除）もサポートできます。このデモでは、LibVQの包括的な実例と評価を提供します。ツールキットは公開されています: https://github.com/staoxiao/LibVQ/tree/demo.
        </label>
        <input type="checkbox" id="Panel372" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Vector quantization is one of the critical techniques which enables dense retrieval for realtime applications. The recent study shows that vanilla vector quantization methods, like those implemented by FAISS [8], are lossy and prone to limited retrieval performances when large acceleration ratios are needed [14, 16, 18]. Besides, there have also been multiple algorithms which make the retriever and VQ better collaborated to alleviate such a loss. On top of these progresses, we develop LibVQ, which optimizes vector quantization for efficient dense retrieval. Our toolkit is highlighted for three advantages. 1. Effectiveness. The retrieval quality can be substantially improved over the vanilla implementations of VQ. 2. Simplicity. The optimization can be conducted in a lowcode fashion, and the optimization results can be easily loaded to ANN indexes to support downstream applications. 3. Universality. The optimization is agnostic to the embedding's learning process, and may accommodate different input conditions and ANN back-ends with little modification of the workflow. LibVQ may also support rich applications beyond dense retrieval, e.g., embedding compression, topic modeling, and de-duplication. In this demo, we provide comprehensive hand-on examples and evaluations for LibVQ. The toolkit is publicly released at: https://github.com/staoxiao/LibVQ/tree/demo.
        </div> </ul> <br>



        <label for="Panel373">
        <strong> A Preference Judgment Tool for Authoritative Assessment </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mahsa+Seifikar">Mahsa Seifikar</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linh+Nhi+Phan+Minh">Linh Nhi Phan Minh</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Negar+Arabzadeh">Negar Arabzadeh</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Charles+L.+A.+Clarke">Charles L. A. Clarke</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mark+D.+Smucker">Mark D. Smucker</a> (1) </u>  <br>
        1:  University of Waterloo <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591801">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Preference Judgment Tool for Authoritative Assessment">Google Scholar</a></div>
        (373)
        <br>
        <b>概要:　</b> 情報検索システムのオフライン評価において、評価判断はグレードやバイナリの関連性判断に対して効果的な方法であることが確立されています。グレード判断では各文書に事前定義されたグレードレベルを割り当てる一方で、評価判断では並べられた２つの項目を比較し、どちらが優れているかを示します。しかし、評価判断を活用するにはより多くの判断が必要となる可能性があり、評価手法に関しても制約があります。本研究では、専門家や研究者向けに設計された新しい評価判断ツール「JUDGO」を紹介します。このツールは推移性を仮定し、同点を許容する新しいヒープライクな評価判断アルゴリズムにより支えられています。ツールの初期バージョンは、NISTがTREC 2022 Health Misinformationトラックの38のトピックにおいてトップ10のベストアイテムを決定するために使用し、2,200件以上の評価を収集しました。現在のバージョンは別の研究でも使用され、約10,000件の評価が収集され、その各トピックで複数の評価者が判断を行いました。コードおよびリソースはhttps://judgo-system.github.ioで入手可能です。
        </label>
        <input type="checkbox" id="Panel373" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Preference judgments have been established as an effective method for offline evaluation of information retrieval systems with advantages to graded or binary relevance judgments. Graded judgments assign each document a pre-defined grade level, while preference judgments involve assessing a pair of items presented side by side and indicating which is better. However, leveraging preference judgments may require a more extensive number of judgments, and there are limitations in terms of evaluation measures. In this study, we present a new preference judgment tool called JUDGO, designed for expert assessors and researchers. The tool is supported by a new heap-like preference judgment algorithm that assumes transitivity and allows for ties. An earlier version of the tool was employed by NIST to determine up to the top-10 best items for each of the 38 topics for the TREC 2022 Health Misinformation track, with over 2,200 judgments collected. The current version has been applied in a separate research study to collect almost 10,000 judgments, with multiple assessors completing each topic. The code and resources are available at https://judgo-system.github.io.
        </div> </ul> <br>



        <label for="Panel374">
        <strong> VoMBaT: A Tool for Visualising Evaluation Measure Behaviour in High-Recall Search Tasks </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wojciech+Kusa">Wojciech Kusa</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Aldo+Lipani">Aldo Lipani</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Petr+Knoth">Petr Knoth</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Allan+Hanbury">Allan Hanbury</a> (1) </u>  <br>
        1:  TU Wien, 2:  University College London, 3:  The Open University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591802">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=VoMBaT: A Tool for Visualising Evaluation Measure Behaviour in High-Recall Search Tasks">Google Scholar</a></div>
        (374)
        <br>
        <b>概要:　</b> 高再現率情報検索 (HRIR) の目的は、特定の検索トピックに対してできるだけ多くの関連文書を検索することです。HRIR の一つのアプローチは、テクノロジー支援レビュー (TAR) であり、大量の文書コレクションのレビューを支援するために情報検索および機械学習技術を利用します。TAR システムは、法的な eDiscovery や体系的な文献レビューで一般的に使用されます。成功した TAR システムは、最小限の評価数で多数の関連文書を発見することができます。一般的に使われる遡及的評価法では、システムがまず特定の固定再現率レベルを達成し、その後に精度や省力効果（例: r% 再現率での精度）を測定します。このアプローチは、固定再現率設定での評価指標の挙動の理解に関連する問題を引き起こすことがあります。また、テクノロジー支援レビュー中の時間とコストの節約を推定する際にも問題となります。本論文では、再現率レベルに依存する評価指標の動態を探るための新しいビジュアル分析ツールを紹介します。我々は、一般的な情報検索タスクおよび TAR に特化したコンフュージョンマトリックスの用語に基づく18の評価指標を実装しました。このツールは、固定再現率評価設定でのこれらの指標の挙動を比較することができます。また、異なるデータセットにおいてモデルの品質に依存し、時間とコストの節約および手動評価と自動評価の数をシミュレーションすることも可能です。このツールはオープンソースであり、デモは以下のURLで利用可能です: https://vombat.streamlit.app。
        </label>
        <input type="checkbox" id="Panel374" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The objective of High-Recall Information Retrieval (HRIR) is to retrieve as many relevant documents as possible for a given search topic. One approach to HRIR is Technology-Assisted Review (TAR), which uses information retrieval and machine learning techniques to aid the review of large document collections. TAR systems are commonly used in legal eDiscovery and systematic literature reviews. Successful TAR systems are able to find the majority of relevant documents using the least number of assessments. Commonly used retrospective evaluation assumes that the system achieves a specific, fixed recall level first, and then measures the precision or work saved (e.g., precision at r% recall). This approach can cause problems related to understanding the behaviour of evaluation measures in a fixed recall setting. It is also problematic when estimating time and money savings during technology-assisted reviews. This paper presents a new visual analytics tool to explore the dynamics of evaluation measures depending on recall level. We implemented 18 evaluation measures based on the confusion matrix terms, both from general IR tasks and specific to TAR. The tool allows for a comparison of the behaviour of these measures in a fixed recall evaluation setting. It can also simulate savings in time and money and a count of manual vs automatic assessments for different datasets depending on the model quality. The tool is open-source, and the demo is available under the following URL: https://vombat.streamlit.app.
        </div> </ul> <br>



        <label for="Panel375">
        <strong> Searching the ACL Anthology with Math Formulas and Text </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bryan+Amador">Bryan Amador</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Matt+Langsenkamp">Matt Langsenkamp</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Abhisek+Dey">Abhisek Dey</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ayush+Kumar+Shah">Ayush Kumar Shah</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Richard+Zanibbi">Richard Zanibbi</a> (1) </u>  <br>
        1:  Rochester Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591803">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Searching the ACL Anthology with Math Formulas and Text">Google Scholar</a></div>
        (375)
        <br>
        <b>概要:　</b> 数学表記法は、科学と技術における重要な分析リソースです。しかし、現在の数式対応検索エンジンは、数式の構築にLATEXやテンプレートパレットを必要とするため、非専門家には難しい場合があります。また、これらの検索エンジンがインデックスしているコレクションは主にウェブページであり、それらの数式は機械可読フォーマット（例：LATEX、Presentation MathML）で明示的に表現されています。新しいMathDeckシステムは、ACL Anthologyの一部のPDFドキュメントを数式およびテキストの両方で検索し、一致した単語や数式、および他の抽出された数式をコンテキストとともに表示します。PDFでは数式が区切られていないため、新しいインデックス作成モジュールではPDFベクトルグラフィックス情報とコンピュータビジョン技術を使用して数式を抽出します。非専門家ユーザーと視覚的な編集のために、MathDeckのインターフェイスの中心的な設計特徴は、数式の作成、検索、再利用、カードでのタイトルと説明による注釈に使用できる数式「チップス」です。専門家向けには、テキストクエリボックスおよび視覚的数式エディタでLATEXがサポートされています。MathDeckはオープンソースであり、オンラインでデモを利用可能です。
        </label>
        <input type="checkbox" id="Panel375" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Mathematical notation is a key analytical resource for science and technology. Unfortunately, current math-aware search engines require LATEX or template palettes to construct formulas, which can be challenging for non-experts. Also, their indexed collections are primarily web pages where formulas are represented explicitly in machine-readable formats (e.g., LATEX, Presentation MathML). The new MathDeck system searches PDF documents in a portion of the ACL Anthology using both formulas and text, and shows matched words and formulas along with other extracted formulas in-context. In PDF, formulas are not demarcated: a new indexing module extracts formulas using PDF vector graphics information and computer vision techniques. For non-expert users and visual editing, a central design feature of MathDeck's interface is formula 'chips' usable in formula creation, search, reuse, and annotation with titles and descriptions in cards. For experts, LATEX is supported in the text query box and the visual formula editor. MathDeck is open-source, and our demo is available online.
        </div> </ul> <br>



        <label for="Panel376">
        <strong> One Stop Shop for Question-Answering Dataset Selection </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chang+Nian+Chuy">Chang Nian Chuy</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qinmin+Vivian+Hu">Qinmin Vivian Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chen+Ding">Chen Ding</a> (1) </u>  <br>
        1:  Toronto Metropolitan University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591804">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=One Stop Shop for Question-Answering Dataset Selection">Google Scholar</a></div>
        (376)
        <br>
        <b>概要:　</b> 本論文では、新しい可視化ツールである「Dataset Statistical View (DSV)」を提案し、リサーチエントリーのハードルを下げることで研究者が利用できる質疑応答(QA)データセットへの簡単なアクセスを提供することを目的としています。対象ユーザーはQA領域に新たに参入した研究者で、前提知識やプログラミングスキルを持たない方を含みます。本システムには多様なQAデータセットが収録されており、広範なQAタスクを網羅しています。研究者は、ワンストップのウェブサイトで既存のQAデータセットを探索および比較することができます。各QAデータセットについて統計グラフを表示し、データセット間のと視覚的な比較を提供します。本論文は主に構文レベルでの比較に焦点を当てていますが、バイアスおよび意味レベルの分析を統合することも進行中の作業です。DSVシステムは、新しい研究者や実務者にとって堅実な出発点を提供することで、QA分野の発展に貢献するものであると信じています。本論文ではフレームワークのを示し、アプリケーションシステムの詳細についてはhttps://cnchuy.github.io/images/demo.mp4で紹介しています。
        </label>
        <input type="checkbox" id="Panel376" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this paper, we offer a new visualization tool -- Dataset Statistical View (DSV), to lower the barrier of research entry by providing easy access to the question-answering (QA) datasets that researchers can build their work upon. Our target users are new researchers to the QA domain with no prior knowledge nor programming skills. The system is populated with multiple QA datasets, which covers a wide range of QA tasks. It allows researchers to explore and compare existing QA datasets at a one-stop website. The system shows statistical graphs for each QA dataset to offer an overview and a visual comparison between datasets. Although this paper focuses mainly at the syntactic level comparison, integrating bias and semantic level analysis is our ongoing work. We believe our DSV system is a valuable contribution to the advancement of the QA field, as it provides a solid starting point for new researchers and practitioners. An overview of the framework is demonstrated in this paper and the introduction of the application system is available at https://cnchuy.github.io/images/demo.mp4.
        </div> </ul> <br>



        <label for="Panel377">
        <strong> Tevatron: An Efficient and Flexible Toolkit for Neural Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Luyu+Gao">Luyu Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xueguang+Ma">Xueguang Ma</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jimmy+Lin">Jimmy Lin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jamie+Callan">Jamie Callan</a> (1) </u>  <br>
        1:  Carnegie Mellon University, 2:  University of Waterloo <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591805">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Tevatron: An Efficient and Flexible Toolkit for Neural Retrieval">Google Scholar</a></div>
        (377)
        <br>
        <b>概要:　</b> 最近、大規模なデータセットの導入と深層事前学習言語モデルの急速な進展により、埋め込みベースのニューラル検索に関する研究が活発化しています。数多くの優れた研究論文が発表されていますが、それらのほとんどは特定の研究目標に最適化された独自の実装を伴っており、効率性やコードの組織化を重視していないことが多いです。本論文では、効率性、柔軟性、およびコードの簡潔さに最適化されたニューラル検索ツールキットであるTevatronを紹介します。Tevatronは密な検索、疎な検索、および再ランク付けなど、さまざまなランキングコンポーネントのモデル訓練と評価を可能にします。また、テキスト処理、モデル訓練、コーパス／クエリのエンコーディング、検索を含む標準化されたパイプラインを提供します。さらに、Tevatronはハードネガティブマイニングや知識蒸留など、検索精度を向上させるためのよく研究された方法を組み込んでいます。本論文では、複数の情報検索（IR）および質問応答（QA）データセットにおけるTevatronの有効性と効率性を実証し、その柔軟な設計により、データセット、モデルアーキテクチャ、ハードウェアアクセラレータ（GPUおよびTPU）間での容易な一般化を可能にすることを強調します。総じて、Tevatronはニューラル検索システムの設計、モデリング、および最適化に関する研究のための堅固なソフトウェア基盤となり得ると信じています。
        </label>
        <input type="checkbox" id="Panel377" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recent rapid advances in deep pre-trained language models and the introduction of large datasets have powered research in embedding-based neural retrieval. While many excellent research papers have emerged, most of them come with their own implementations, which are typically optimized for some particular research goals instead of efficiency or code organization. In this paper, we introduce Tevatron, a neural retrieval toolkit that is optimized for efficiency, flexibility, and code simplicity. Tevatron enables model training and evaluation for a variety of ranking components such as dense retrievers, sparse retrievers, and rerankers. It also provides a standardized pipeline that includes text processing, model training, corpus/query encoding, and search. In addition, Tevatron incorporates well-studied methods for improving retriever effectiveness such as hard negative mining and knowledge distillation. We provide an overview of Tevatron in this paper, demonstrating its effectiveness and efficiency on multiple IR and QA datasets. We highlight Tevatron's flexible design, which enables easy generalization across datasets, model architectures, and accelerator platforms (GPUs and TPUs). Overall, we believe that Tevatron can serve as a solid software foundation for research on neural retrieval systems, including their design, modeling, and optimization.
        </div> </ul> <br>



        <label for="Panel378">
        <strong> Profiling and Visualizing Dynamic Pruning Algorithms </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhixuan+Li">Zhixuan Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Joel+Mackenzie">Joel Mackenzie</a> (1) </u>  <br>
        1:  The University of Queensland <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591806">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Profiling and Visualizing Dynamic Pruning Algorithms">Google Scholar</a></div>
        (378)
        <br>
        <b>概要:　</b> 与えられたクエリに対する上位k件のドキュメントを効率的に検索することは、多くの検索アプリケーションにおいて基本操作です。動的プルーニングアルゴリズムは、反転インデックスを介した上位k件の検索を加速させ、現在の結果セットに入れないドキュメントをスキップします。しかし、これらのアルゴリズムの性能は、ランキング関数、インデックス内のドキュメントの順序、および検索対象のドキュメント数などの変数に依存します。本論文では、動的プルーニングアルゴリズムの性能をプロファイリングおよび視覚化するための診断フレームワーク「Dyno」を提案します。我々のフレームワークは、検索中の処理トレースをキャプチャし、インデックストラバーサルアルゴリズムの操作を視覚化します。これらの視覚化はクエリレベルおよびシステム間の比較をサポートし、異なるシステムの性能特性を容易に理解することができます。Dynoは、動的プルーニングアルゴリズムの動作理解を深めることで、実験や展開時の設計選択を改善し、学術研究者や実務者の双方に利益をもたらします。
        </label>
        <input type="checkbox" id="Panel378" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Efficiently retrieving the top-k documents for a given query is a fundamental operation in many search applications. Dynamic pruning algorithms accelerate top-k retrieval over inverted indexes by skipping documents that are not able to enter the current set of results. However, the performance of these algorithms depends on a number of variables such as the ranking function, the order of documents within the index, and the number of documents to be retrieved. In this paper, we propose a diagnostic framework, Dyno, for profiling and visualizing the performance of dynamic pruning algorithms. Our framework captures processing traces during retrieval, allowing the operations of the index traversal algorithm to be visualized. These visualizations support both query-level and system-to-system comparisons, enabling performance characteristics to be readily understood for different systems. Dyno benefits both academics and practitioners by furthering our understanding of the behavior of dynamic pruning algorithms, allowing better design choices to be made during experimentation and deployment.
        </div> </ul> <br>



        <label for="Panel379">
        <strong> MetroScope: An Advanced System for Real-Time Detection and Analysis of Metro-Related Threats and Events via Twitter </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianfeng+He">Jianfeng He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Syuan-Ying+Wu">Syuan-Ying Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Abdulaziz+Alhamadani">Abdulaziz Alhamadani</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chih-Fang+Chen">Chih-Fang Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wen-Fang+Lu">Wen-Fang Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chang-Tien+Lu">Chang-Tien Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=David+Solnick">David Solnick</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yanlin+Li">Yanlin Li</a> (2) </u>  <br>
        1:  Virginia Tech, 2:  Washington Metropolitan Area Transit Authority <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591807">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MetroScope: An Advanced System for Real-Time Detection and Analysis of Metro-Related Threats and Events via Twitter">Google Scholar</a></div>
        (379)
        <br>
        <b>概要:　</b> 地下鉄システムは私たちの日常生活に欠かせない存在ですが、犯罪行為やインフラの障害など、安全性や信頼性に関する課題に直面しています。これらの安全性や信頼性を確保するためには、リアルタイムの脅威検出と分析が不可欠です。現在の多くのシステムは、Twitterを用いて地下鉄関連の脅威やイベントをリアルタイムで検出しますが、イベントの分析やシステムの維持において限界があります。具体的には、イベントの展開を分析したり、膨大なツイートから優先度の高いイベントを選別したりすることができません。また、ユーザーはシステムの通知を継続的に監視し、非効率的なコンテンツ検索方法を使用し、詳細なシステムメンテナンスを行う必要があります。これらの問題を解決するために、ワシントンD.C.の地下鉄システムに適用されたリアルタイムの脅威/イベント検出システム「MetroScope」を開発しました。MetroScopeは、イベントの展開を自動的に分析し、緊急度に基づいてイベントに優先順位を付け、緊急通知をメールで送信し、効率的なコンテンツ検索を提供し、システムを自己維持します。私たちのMetroScopeシステムは、http://orion.nvc.cs.vt.edu:5000/ で利用可能であり、その機能と使い方を紹介するビデオ（https://www.youtube.com/watch?v=vKIK9M60-J8）も用意しています。MetroScopeは、地下鉄システムの安全性と信頼性を向上させるための重要な進歩です。
        </label>
        <input type="checkbox" id="Panel379" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Metro systems are vital to our daily lives, but they face safety or reliability challenges, such as criminal activities or infrastructure disruptions, respectively. Real-time threat detection and analysis are crucial to ensure their safety and reliability. Although many existing systems use Twitter to detect metro-related threats or events in real-time, they have limitations in event analysis and system maintenance. Specifically, they cannot analyze event development, or prioritize events from numerous tweets. Besides, their users are required to continuously monitor system notifications, use inefficient content retrieval methods, and perform detailed system maintenance. We addressed those issues by developing the MetroScope system, a real-time threat/event detection system applied to Washington D.C. metro system. MetroScope can automatically analyze event development, prioritize events based on urgency, send emergency notifications via emails, provide efficient content retrieval, and self-maintain the system. Our MetroScope system is now available at http://orion.nvc.cs.vt.edu:5000/, with a video (https://www.youtube.com/watch?v=vKIK9M60-J8) introducing its features and instructions. MetroScope is a significant advancement in enhancing the safety and reliability of metro systems.
        </div> </ul> <br>



        <label for="Panel380">
        <strong> SciHarvester: Searching Scientific Documents for Numerical Values </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maciej+Rybinski">Maciej Rybinski</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Stephen+Wan">Stephen Wan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sarvnaz+Karimi">Sarvnaz Karimi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cecile+Paris">Cecile Paris</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Brian+Jin">Brian Jin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Neil+Huth">Neil Huth</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peter+Thorburn">Peter Thorburn</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dean+Holzworth">Dean Holzworth</a> (2) </u>  <br>
        1:  CSIRO, 2:  CSIRO, 3:  CSIRO <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591808">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SciHarvester: Searching Scientific Documents for Numerical Values">Google Scholar</a></div>
        (380)
        <br>
        <b>概要:　</b> 科学文献調査を支援する検索技術において、特定の物理的特性に関する報告された数値を概観できることは課題となっています。本研究では、農学分野に特化したこの問題に対処するためにSciHarvesterというシステムを提案します。SciHarvesterはPubAg文書を検索するインターフェースを提供し、数値の制約を含む複雑なクエリに対応します。このシステムは関連する文書を識別し、報告されたパラメータ値の概観を生成します。さらに、システムのパフォーマンスを説明するために結果の検証を可能にします。我々の評価では、情報抽出技術とニューラルスコアリングメカニズムの利用を組み合わせることで有望であることを示しています。
        </label>
        <input type="checkbox" id="Panel380" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> A challenge for search technologies is to support scientific literature surveys that present overviews of the reported numerical values documented for specific physical properties. We present SciHarvester, a system tailored to address this problem for agronomic science. It provides an interface to search PubAg documents, allowing complex queries involving restrictions on numerical values. SciHarvester identifies relevant documents and generates overview of reported parameter values. The system allows interrogation of the results to explain the system's performance. Our evaluations demonstrate the promise of incorporating information extraction techniques with the use of neural scoring mechanisms.
        </div> </ul> <br>



        <label for="Panel381">
        <strong> NeuralKG-ind: A Python Library for Inductive Knowledge Graph Representation Learning </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wen+Zhang">Wen Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhen+Yao">Zhen Yao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mingyang+Chen">Mingyang Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiwei+Huang">Zhiwei Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Huajun+Chen">Huajun Chen</a> (2) </u>  <br>
        1:  Zhejiang University, 2:  Zhejiang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591809">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=NeuralKG-ind: A Python Library for Inductive Knowledge Graph Representation Learning">Google Scholar</a></div>
        (381)
        <br>
        <b>概要:　</b> 知識グラフの動的特性により、新しいエンティティに対する予測を可能にする帰納的知識グラフ表現学習（KGRL）の研究が近年多く提案されています。NeuralKG-indは、NeuralKGライブラリの重要なアップデートとして初の帰納的KGRLライブラリです。標準化されたプロセス、豊富な既存手法、モジュールの分離、包括的な評価指標が含まれています。NeuralKG-indを使用することで、研究者やエンジニアは帰納的KGRL手法を再現、再開発、および比較することが容易になります。このライブラリ、実験方法論、およびNeuralKG-indのモデル再実装結果は、すべてhttps://github.com/zjukg/NeuralKG/tree/indで公開されています。
        </label>
        <input type="checkbox" id="Panel381" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Since the dynamic characteristics of knowledge graphs, many inductive knowledge graph representation learning (KGRL) works have been proposed in recent years, focusing on enabling prediction over new entities. NeuralKG-ind is the first library of inductive KGRL as an important update of NeuralKG library. It includes standardized processes, rich existing methods, decoupled modules, and comprehensive evaluation metrics. With NeuralKG-ind, it is easy for researchers and engineers to reproduce, redevelop, and compare inductive KGRL methods. The library, experimental methodologies, and model re-implementing results of NeuralKG-ind are all publicly released at https://github.com/zjukg/NeuralKG/tree/ind https://github.com/zjukg/NeuralKG/tree/ind.
        </div> </ul> <br>



        <label for="Panel382">
        <strong> AMICA: Alleviating Misinformation for Chinese Americans </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoxiao+Shang">Xiaoxiao Shang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ye+Chen">Ye Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Fang">Yi Fang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuhong+Liu">Yuhong Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Subramaniam+Vincent">Subramaniam Vincent</a> (1) </u>  <br>
        1:  Santa Clara University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591810">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=AMICA: Alleviating Misinformation for Chinese Americans">Google Scholar</a></div>
        (382)
        <br>
        <b>概要:　</b> ソーシャルメディアの普及に伴い、特に中国語を話すディアスポラのコミュニティにおいて、誤情報の拡散が増加し、社会に重大な悪影響を及ぼしています。さらに、既存の誤情報の緩和に向けた取り組みの多くは英語や他の西洋諸語に焦点を当てているため、海外に住む多くの中国人はオンラインデマキャンペーンに非常に脆弱な状態にあります。本論文では、中国系アメリカ人向けの誤情報緩和のための情報検索システムであるAMICAを紹介します。AMICAは、中国系アメリカ人に人気のあるWeChat、Twitter、YouTube、そして中国のフォーラムなどのソーシャルメディアプラットフォームから動的にデータを収集します。収集されたデータはElasticsearchに保存およびインデックス化され、高度な検索機能を提供します。ユーザーのクエリに対して、ソーシャルメディア投稿のランク付けは、トピックの関連性と誤情報である可能性の両方を考慮します。
        </label>
        <input type="checkbox" id="Panel382" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The increasing popularity of social media promotes the proliferation of misinformation, especially in the communities of Chinese-speaking diasporas, which has caused significant negative societal impacts. In addition, most of the existing efforts on misinformation mitigation have focused on English and other western languages, which makes numerous overseas Chinese a very vulnerable population to online disinformation campaigns. In this paper, we present AMICA, an information retrieval system for alleviating misinformation for Chinese Americans. AMICA dynamically collects data from popular social media platforms for Chinese Americans, including WeChat, Twitter, YouTube, and Chinese forums. The data are stored and indexed in Elasticsearch to provide advanced search functionalities. Given a user query, the ranking of social media posts considers both topical relevance and the likelihood of being misinformation.
        </div> </ul> <br>



        <label for="Panel383">
        <strong> PEPO: Petition Executing Processing Optimizer Based on Natural Language Processing </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yin-Wei+Chiu">Yin-Wei Chiu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hsiao-Ching+Huang">Hsiao-Ching Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Cheng-Ju+Lee">Cheng-Ju Lee</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hsun-Ping+Hsieh">Hsun-Ping Hsieh</a> (1) </u>  <br>
        1:  National Cheng Kung University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591811">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=PEPO: Petition Executing Processing Optimizer Based on Natural Language Processing">Google Scholar</a></div>
        (383)
        <br>
        <b>概要:　</b> 本論文では、「Petition Executing Process Optimizer (PEPO)」というAIベースの請願処理システムを提案します。このシステムは、(a) 部門分類、(b) 重要度評価、(c) 応答生成の3つのコンポーネントを備えており、台湾の公共事業局 (PWB) が1999年に設置したホットライン請願処理プロセスを改善することを目的としています。部門分類アルゴリズムはNDCGで評価され、86.48%という高得点を達成しました。一方、重要度評価機能は85%の精度率を誇ります。加えて、応答生成機能は政府と市民の間の通信効率を向上させます。PEPOシステムは台南市政府の公共事業局のオンラインウェブサービスとして導入されています。PEPOの導入により、PWBは市民の請願処理の有効性と効率性が大幅に向上しました。
        </label>
        <input type="checkbox" id="Panel383" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this paper, we propose "Petition Executing Process Optimizer (PEPO)," an AI-based petition processing system that features three components, (a) Department Classification, (b) Importance Assessment, and (c) Response Generation for improving the Public Work Bureau (PWB) 1999 Hotline petitions handling process in Taiwan. Our Department Classification algorithm has been evaluated with NDCG, achieving an impressive score of 86.48%, while the Important Assessment function has an accuracy rate of 85%. Besides, Response Generation enhances communication efficiency between the government and citizens. The PEPO system has been deployed as an online web service for the Public Works Bureau of the Tainan City Government. With PEPO, the PWB benefits greatly from the effectiveness and efficiency of handling citizens' petitions.
        </div> </ul> <br>



        <label for="Panel384">
        <strong> HeteroCS: A Heterogeneous Community Search System With Semantic Explanation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weibin+Cai">Weibin Cai</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fanwei+Zhu">Fanwei Zhu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zemin+Liu">Zemin Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Minghui+Wu">Minghui Wu</a> (1) </u>  <br>
        1:  Hangzhou City University, 2:  Hangzhou City University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591812">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=HeteroCS: A Heterogeneous Community Search System With Semantic Explanation">Google Scholar</a></div>
        (384)
        <br>
        <b>概要:　</b> グラフ中のクエリ依存コミュニティを探すコミュニティ検索は、グラフ分析において重要なタスクです。既存のコミュニティ検索研究は、クエリを含む密に接続された部分グラフを見つけることによってこの問題に対処しています。しかし、多くの実世界のネットワークは、豊かなセマンティクスを持つ異質なものです。異質なネットワークのクエリは一般に、異なるセマンティックな接続を持つ複数のコミュニティに関与する一方、混在したセマンティクスを持つ単一のコミュニティを返すことには限られた応用しかありません。本論文では、異質ネットワークにおけるコミュニティ検索の問題を再評価し、異質コミュニティ検索とランキングの新たなパラダイムを紹介します。我々は、クエリのセマンティクスを自動的に発見し、異なるセマンティックコミュニティの検索を可能にし、さらに結果のランキングをサポートする包括的なコミュニティ評価モデルを開発します。我々のセマンティックコミュニティモデルに基づき、HeteroCSというセマンティックな説明を持つ異質コミュニティ検索システムを構築し、二つの実世界のグラフに展開しました。その斬新さと有効性を示すためのデモンストレーションケースを提示します。
        </label>
        <input type="checkbox" id="Panel384" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Community search, which looks for query-dependent communities in a graph, is an important task in graph analysis. Existing community search studies address the problem by finding a densely-connected subgraph containing the query. However, many real-world networks are heterogeneous with rich semantics. Queries in heterogeneous networks generally involve in multiple communities with different semantic connections, while returning a single community with mixed semantics has limited applications. In this paper, we revisit the community search problem on heterogeneous networks and introduce a novel paradigm of heterogeneous community search and ranking. We propose to automatically discover the query semantics to enable the search of different semantic communities and develop a comprehensive community evaluation model to support the ranking of results. We build HeteroCS, a heterogeneous community search system with semantic explanation, upon our semantic community model, and deploy it on two real-world graphs. We present a demonstration case to illustrate the novelty and effectiveness of the system.
        </div> </ul> <br>



        <label for="Panel385">
        <strong> OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shi+Yu">Shi Yu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhenghao+Liu">Zhenghao Liu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenyan+Xiong">Chenyan Xiong</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiyuan+Liu">Zhiyuan Liu</a> (1) </u>  <br>
        1:  Tsinghua University, 2:  Northeastern University, 3:  Microsoft Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591813">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit">Google Scholar</a></div>
        (385)
        <br>
        <b>概要:　</b> 事前学習済み言語モデル（PLMs）は、最先端の情報検索（IR）モデルの基盤として浮上しています。PLMsによって強化された最新のIR研究は、新しいモデル、新たなドメイン適応アルゴリズム、および拡張されたデータセットを提案しています。本稿では、PythonベースのIRツールキットであるOpenMatch-v2を紹介します。 2021年に提案されたOpenMatchの完全なアップグレードであるOpenMatch-v2は、PLMベースのIR研究の最新進展を組み込み、新しいクロスモダリティモデルのサポートと、洗練された最適化されたインフラストラクチャによる強化されたドメイン適応技術を提供します。OpenMatchのコードは、https://github.com/OpenMatch/OpenMatch で公開されています。
        </label>
        <input type="checkbox" id="Panel385" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Pre-trained language models (PLMs) have emerged as the foundation of the most advanced Information Retrieval (IR) models. Powered by PLMs, the latest IR research has proposed novel models, new domain adaptation algorithms as well as enlarged datasets. In this paper, we present a Python-based IR toolkit OpenMatch-v2. As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure. The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.
        </div> </ul> <br>



        <label for="Panel386">
        <strong> FairUP: A Framework for Fairness Analysis of Graph Neural Network-Based User Profiling Models </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mohamed+Abdelrazek">Mohamed Abdelrazek</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Erasmo+Purificato">Erasmo Purificato</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ludovico+Boratto">Ludovico Boratto</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ernesto+William+De+Luca">Ernesto William De Luca</a> (2) </u>  <br>
        1:  Otto von Guericke University Magdeburg, 2:  Otto von Guericke University Magdeburg & Leibniz Institute for Educational Media | Georg Eckert Institute, 3:  University of Cagliari <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591814">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=FairUP: A Framework for Fairness Analysis of Graph Neural Network-Based User Profiling Models">Google Scholar</a></div>
        (386)
        <br>
        <b>概要:　</b> 現代のユーザープロファイリングアプローチは、ユーザーアイテム間やユーザー同士の関係など、データとのさまざまな形式の相互作用を捉えます。グラフニューラルネットワーク（GNN）は、これらの行動をモデル化し、効率的かつ効果的なユーザープロフィールを構築するための自然な方法となっています。しかし、GNNベースのユーザープロファイリングアプローチはそれぞれ独自の情報処理方法を持っており、これがこれらの技術のベンチマークを不利にする異質性を生み出しています。この問題を克服するために、我々は三つの最先端のGNNベースのモデルを用いたユーザープロファイリングタスクの実行に必要な入力を標準化するフレームワーク「FairUP」を提示します。さらに、機械学習システムの評価におけるアルゴリズムの公平性の重要性を考慮し、FairUPには次の二つの追加コンポーネントが含まれます： (1) 前処理と後処理の公平性の分析、(2) 元のデータセットに存在する可能性のある不公平性を三つの前処理によるデバイアス技術で軽減します。このフレームワークは、複数の方向に拡張可能であり、第1版では実際の4つのデータセットで実験を行うことができます。ソースコードは https://link.erasmopurif.com/FairUP-source-code で、ウェブアプリケーションは https://link.erasmopurif.com/FairUP で利用可能です。
        </label>
        <input type="checkbox" id="Panel386" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Modern user profiling approaches capture different forms of interactions with the data, from user-item to user-user relationships. Graph Neural Networks (GNNs) have become a natural way to model these behaviours and build efficient and effective user profiles. However, each GNN-based user profiling approach has its own way of processing information, thus creating heterogeneity that does not favour the benchmarking of these techniques. To overcome this issue, we present FairUP, a framework that standardises the input needed to run three state-of-the-art GNN-based models for user profiling tasks. Moreover, given the importance that algorithmic fairness is getting in the evaluation of machine learning systems, FairUP includes two additional components to (1) analyse pre-processing and post-processing fairness and (2) mitigate the potential presence of unfairness in the original datasets through three pre-processing debiasing techniques. The framework, while extensible in multiple directions, in its first version, allows the user to conduct experiments on four real-world datasets. The source code is available at https://link.erasmopurif.com/FairUP-source-code, and the web application is available at https://link.erasmopurif.com/FairUP.
        </div> </ul> <br>



        <label for="Panel387">
        <strong> Tahaqqaq: A Real-Time System for Assisting Twitter Users in Arabic Claim Verification </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zien+Sheikh+Ali">Zien Sheikh Ali</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Watheq+Mansour">Watheq Mansour</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fatima+Haouari">Fatima Haouari</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maram+Hasanain">Maram Hasanain</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tamer+Elsayed">Tamer Elsayed</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Abdulaziz+Al-Ali">Abdulaziz Al-Ali</a> (1) </u>  <br>
        1:  Qatar University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591815">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Tahaqqaq: A Real-Time System for Assisting Twitter Users in Arabic Claim Verification">Google Scholar</a></div>
        (387)
        <br>
        <b>概要:　</b> 近年、ソーシャルメディア上での誤情報拡散に対抗するための多くのファクトチェックシステムが開発され、著しい進歩が見られました。しかし、アラビア語コンテンツを対象としたシステムはほとんど存在しません。本研究では、このギャップを埋めるために、Tahaqqaq（検証）を提案します。これは、Twitter上でユーザーが情報を検証するのを支援する、リアルタイムのアラビア語システムです。Tahaqqaqは、検証する価値のある主張の特定、偽ニュース拡散に関するユーザーの信頼性の推定、信頼性の高いアカウントの発見といった機能を提供します。Tahaqqaqは使いやすいオンラインWebインターフェースを備え、さまざまなリアルタイムのユーザーシナリオに対応しています。また、RESTful APIを通じてTahaqqaqのサービスを公開し、アクセスしやすくしています。最後に、パフォーマンスの面では、Tahaqqaqの複数のコンポーネントがアラビア語データセットにおいて最先端のモデルを上回る性能を示しています。
        </label>
        <input type="checkbox" id="Panel387" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Over the past years, notable progress has been made towards fighting misinformation spread over social media, encouraging the development of many fact-checking systems. However, systems that operate over Arabic content are scarce. In this work, we bridge this gap by proposing Tahaqqaq (Verify), an Arabic real-time system that helps users verify claims over Twitter with several functionalities, such as identifying check-worthy claims, estimating credibility of users in terms of spreading fake news, and finding authoritative accounts. Tahaqqaq has a friendly online Web interface that supports various real-time user scenarios. In the same breath, we enable public access to Tahaqqaq services through a handy RESTful API. Finally, in terms of performance, multiple components of Tahaqqaq outperform the state-of-the-art models on Arabic datasets.
        </div> </ul> <br>



        <label for="Panel388">
        <strong> SEA: A Scalable Entity Alignment System </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junyang+Wu">Junyang Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tianyi+Li">Tianyi Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lu+Chen">Lu Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunjun+Gao">Yunjun Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ziheng+Wei">Ziheng Wei</a> (3) </u>  <br>
        1:  Zhejiang University, 2:  Aalborg University, 3:  Huawei <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591816">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SEA: A Scalable Entity Alignment System">Google Scholar</a></div>
        (388)
        <br>
        <b>概要:　</b> エンティティアライメント（EA）は、異なるナレッジグラフ（KG）における同等のエンティティを見つけることを目的としています。最新のEAアプローチでは一般的にグラフニューラルネットワーク（GNN）を使用してエンティティをエンコードします。しかし、これらの方法の多くはフルバッチ方式でモデルの訓練と結果の評価を行うため、大規模なデータセットに対してはスケーラビリティに問題があります。現実のアプリケーションでのGNNベースのEAモデルの実用性を向上させるために、我々はSEAを提案します。これは、（i）大規模なGNNをEAのために訓練でき、（ii）正規化と評価プロセスを高速化し、（iii）ユーザーが異なるモデルやパラメータ設定を評価するための明確な結果を報告することを可能にする、スケーラブルなエンティティアライメントシステムです。SEAは、たった1つのグラフィックカードを搭載したコンピュータ上で動作可能です。さらに、SEAには最新の6つのEAモデルが含まれており、ユーザーが自分のモデルを迅速に構築し評価するためのアクセスも提供します。これにより、SEAを利用するユーザーは、ネガティブサンプリングやGPU加速評価などの煩雑な実装に関与することなくEAを実行できます。SEAを用いることで、ユーザーはモデルの性能を明確に把握することができます。デモンストレーションでは、SEAがユーザーフレンドリーであり、限られた計算リソースでも高いスケーラビリティを発揮することを示します。
        </label>
        <input type="checkbox" id="Panel388" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Entity alignment (EA) aims to find equivalent entities in different knowledge graphs (KGs). State-of-the-art EA approaches generally use Graph Neural Networks (GNNs) to encode entities. However, most of them train the models and evaluate the results in a full-batch fashion, which prohibits EA from being scalable on large-scale datasets. To enhance the usability of GNN-based EA models in real-world applications, we present SEA, a scalable entity alignment system that enables to (i) train large-scale GNNs for EA, (ii) speed up the normalization and the evaluation process, and (iii) report clear results for users to estimate different models and parameter settings. SEA can be run on a computer with merely one graphic card. Moreover, SEA encompasses six state-of-the-art EA models and provides access for users to quickly establish and evaluate their own models. Thus, SEA allows users to perform EA without being involved in tedious implementations, such as negative sampling and GPU-accelerated evaluation. With SEA, users can gain a clear view of the model performance. In the demonstration, we show that SEA is user-friendly and is of high scalability even on computers with limited computational resources.
        </div> </ul> <br>



        <label for="Panel389">
        <strong> A Retrieval System for Images and Videos based on Aesthetic Assessment of Visuals </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daniel+Vera+Nieto">Daniel Vera Nieto</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Saikishore+Kalloori">Saikishore Kalloori</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fabio+Zund">Fabio Zund</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Clara+Fernandez+Labrador">Clara Fernandez Labrador</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Marc+Willhaus">Marc Willhaus</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Severin+Klingler">Severin Klingler</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Markus+Gross">Markus Gross</a> (1) </u>  <br>
        1:  ETH Zürich <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591817">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Retrieval System for Images and Videos based on Aesthetic Assessment of Visuals">Google Scholar</a></div>
        (389)
        <br>
        <b>概要:　</b> ジャーナリズムやソーシャルメディアにおいて、魅力的な画像やビデオはユーザーの関心を引くための視覚的基盤となっています。予告編からティーザー画像、さらには画像ギャラリーに至るまで、魅力的なビジュアルの重要性は年々増しています。しかし、大量のビデオや画像コレクションから目を引くショットや完璧な画像を選択することは、難しく時間のかかる作業です。我々は、画像およびビデオの内容を美学的観点から評価できるツールを提案します。この評価を行うためには、専門家の知識とデータ駆動の情報を組み合わせることが可能であることがわかりました。関連する美学的特徴と機械学習アルゴリズムを組み合わせた美学的検索システムを構築し、ユーザーがアップロードされたビジュアルを美学スコアに基づいて並べ替え、追加の写真撮影、映画撮影、および個別の特徴と対話できるようにします。
        </label>
        <input type="checkbox" id="Panel389" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Attractive images or videos are the visual backbones of journalism and social media to gain the user's attention. From trailers to teaser images to image galleries, appealing visuals have only grown in importance over the years. However, selecting eye-catching shots from a video or the perfect image from large image collections is a challenging and time-consuming task. We present our tool that can assess image and video content from an aesthetic standpoint. We discovered that it is possible to perform such an assessment by combining expert knowledge with data-driven information. We combine the relevant aesthetic features and machine learning algorithms into an aesthetics retrieval system, which enables users to sort uploaded visuals based on an aesthetic score and interact with additional photographic, cinematic, and person-specific features.
        </div> </ul> <br>



        <label for="Panel390">
        <strong> XpmIR: A Modular Library for Learning to Rank and Neural IR Experiments </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuxuan+Zong">Yuxuan Zong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Benjamin+Piwowarski">Benjamin Piwowarski</a> (2) </u>  <br>
        1:  Sorbonne Université, 2:  CNRS <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591818">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=XpmIR: A Modular Library for Learning to Rank and Neural IR Experiments">Google Scholar</a></div>
        (390)
        <br>
        <b>概要:　</b> 過去数年間にわたり、（ニューラル）情報検索のための複数のフレームワークが提案されてきました。しかし、これらのフレームワークは既に発表された結果を再現することは可能ですが、学習パイプラインの一部、例えば事前学習、サンプリング戦略、あるいは新たに開発されたモデルに関する損失を再利用するのは依然として非常に難しいです。また、新しいトレーニング手法を古いモデルに適用することも難しく、これがさまざまなニューラル情報検索モデルにおけるアイデアの有用性を評価することを一層困難にしています。この問題が新技術の採用を遅らせ、ひいては情報検索分野の発展を阻害しています。本論文では、再利用可能な一連の実験コンポーネントを定義したPythonライブラリ「XpmIR」を提案します。このライブラリには既に最新のモデルおよびインデックス化技術が含まれており、HuggingFaceハブと統合されています。
        </label>
        <input type="checkbox" id="Panel390" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> During past years, several frameworks for (Neural) Information Retrieval have been proposed. However, while they allow reproducing already published results, it is still very hard to re-use some parts of the learning pipelines, such as for instance the pre-training, sampling strategy, or a loss in newly developed models. It is also difficult to use new training techniques with old models, which makes it more difficult to assess the usefulness of ideas on various neural IR models. This slows the adoption of new techniques, and in turn, the development of the IR field. In this paper, we present XpmIR, a Python library defining a reusable set of experimental components. The library already contains state-of-the-art models and indexation techniques and is integrated with the HuggingFace hub.
        </div> </ul> <br>



        <label for="Panel391">
        <strong> pybool_ir: A Toolkit for Domain-Specific Search Experiments </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Harrisen+Scells">Harrisen Scells</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Martin+Potthast">Martin Potthast</a> (2) </u>  <br>
        1:  Leipzig University, 2:  Leipzig University and ScaDS.AI <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591819">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=pybool_ir: A Toolkit for Domain-Specific Search Experiments">Google Scholar</a></div>
        (391)
        <br>
        <b>概要:　</b> 系統的レビューログ文献検索、法律検索、特許検索のような特定分野における研究においては、複雑なインデックス手順とブール論理クエリ構文のため、高い参入障壁が存在します。ElasticsearchやLuceneのような市販ツールでPubMedのような文書コレクションをインデックス化し検索する場合、PubMed検索エンジンを利用する場合に比べて、精度が低く（および効果が低く）なることが多い、すなわち、同じクエリをPubMedに発行した場合に取得される結果と一致しません。さらに、市販ツールには独自の細かいクエリ言語があり、特定分野の検索シナリオで見られるような大規模で複雑なブール論理クエリを直接使用することができません。pybool_irツールキットは、これらの問題に対処し、特定分野の検索手法を開発するための参入障壁を下げることを目的としています。このツールキットは、https://github.com/hscells/pybool_irで入手可能なオープンソースパッケージです。
        </label>
        <input type="checkbox" id="Panel391" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Undertaking research in domain-specific scenarios such as systematic review literature search, legal search, and patent search can often have a high barrier of entry due to complicated indexing procedures and complex Boolean query syntax. Indexing and searching document collections like PubMed in off-the-shelf tools such as Elasticsearch and Lucene often yields less accurate (and less effective) results than the PubMed search engine, i.e., retrieval results do not match what would be retrieved if one issued the same query to PubMed. Furthermore, off-the-shelf tools have their own nuanced query languages and do not allow directly using the often large and complicated Boolean queries seen in domain-specific search scenarios. The pybool_ir toolkit aims to address these problems and to lower the barrier to entry for developing new methods for domain-specific search. The toolkit is an open source package available at https://github.com/hscells/pybool_ir.
        </div> </ul> <br>



        <label for="Panel392">
        <strong> TIB AV-Analytics: A Web-based Platform for Scholarly Video Analysis and Film Studies </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Matthias+Springstein">Matthias Springstein</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Markos+Stamatakis">Markos Stamatakis</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Margret+Plank">Margret Plank</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Julian+Sittel">Julian Sittel</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Roman+Mauer">Roman Mauer</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Oksana+Bulgakowa">Oksana Bulgakowa</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ralph+Ewerth">Ralph Ewerth</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Eric+Müller-Budack">Eric Müller-Budack</a> (1) </u>  <br>
        1:  TIB - Leibniz Information Centre for Science and Technology & Leibniz University Hannover, 2:  TIB - Leibniz Information Centre for Science and Technology, 3:  Johannes Gutenberg University Mainz <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591820">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=TIB AV-Analytics: A Web-based Platform for Scholarly Video Analysis and Film Studies">Google Scholar</a></div>
        (392)
        <br>
        <b>概要:　</b> 自動化ソリューションを統合したビデオ分析プラットフォームは、映画・メディア研究、コミュニケーション科学、教育を含む多くの分野で様々な応用が可能です。しかし、現在のビデオ分析プラットフォームは、手動の注釈に重点を置くか、または自動コンテンツ分析のためのツールが限られています。本論文では、TIB AV-Analytics（TIB-AV-A）と呼ばれる新しいウェブベースのビデオ分析プラットフォームを紹介します。TIB-AV-Aは、従来のプラットフォームとは異なり、コンピュータビジョン、音声分析、自然言語処理の最新技術をビデオ分析の多くの関連タスクに統合しています。将来の拡張を容易にし、既存のツールとの相互運用性を確保するために、ビデオ分析アプローチは適切なインターフェースとインポート・エクスポート機能を持つプラグイン構造で実装されています。TIB-AV-Aは、最新のウェブ技術を活用し、ユーザーに応答性の高いインタラクティブなウェブインターフェースを提供し、手動注釈を可能にするとともに、特定のハードウェアへの依存なしに強力なディープラーニングツールへのアクセスを提供します。ソースコードとデモは、https://service.tib.eu/tibava で公開されています。
        </label>
        <input type="checkbox" id="Panel392" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Video analysis platforms that integrate automatic solutions for multimedia and information retrieval enable various applications in many disciplines including film and media studies, communication science, and education. However, current platforms for video analysis either focus on manual annotations or include only a few tools for automatic content analysis. In this paper, we present a novel web-based video analysis platform called TIB AV-Analytics (TIB-AV-A). Unlike previous platforms, TIB-AV-A integrates state-of-the-art approaches in the fields of computer vision, audio analysis, and natural language processing for many relevant video analysis tasks. To facilitate future extensions and to ensure interoperability with existing tools, the video analysis approaches are implemented in a plugin structure with appropriate interfaces and import-export functions. TIB-AV-A leverages modern web technologies to provide users with a responsive and interactive web interface that enables manual annotation and provides access to powerful deep learning tools without a requirement for specific hardware dependencies. Source code and demo are publicly available at: https://service.tib.eu/tibava.
        </div> </ul> <br>



        <label for="Panel393">
        <strong> SONAR: Web-based Tool for Multimodal Exploration of Non-Fungible Token Inspiration Networks </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lucio+La+Cava">Lucio La Cava</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Davide+Costa">Davide Costa</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrea+Tagarelli">Andrea Tagarelli</a> (1) </u>  <br>
        1:  DIMES <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591821">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SONAR: Web-based Tool for Multimodal Exploration of Non-Fungible Token Inspiration Networks">Google Scholar</a></div>
        (393)
        <br>
        <b>概要:　</b> 本研究では、非代替性トークン（NFT）のインスピレーションネットワークを多モーダルに探索するためのWebベースのツール、SONARを紹介します。SONARは、Web3の新興市場において、クリエイターとトレーダーの両方をサポートすることを目的として設計されています。このツールは、個々のNFTおよびコレクションレベルでのインスピレーションに基づく接続をインタラクティブに可視化します。そのため、SONARは新しい投資機会の特定や異常なインスピレーションの識別に役立ちます。SONARの能力を実証するために、本稿では現在のNFTランドスケープに関する最大かつ最も代表的なデータセットに適用する事例を示し、提案ツールがどのようにスケールし、数百万のエッジに対して高レベルのユーザー体験を保証できるかを示します。
        </label>
        <input type="checkbox" id="Panel393" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this work, we present SONAR, a web-based tool for multimodal exploration of Non-Fungible Token (NFT) inspiration networks. SONAR is conceived to support both creators and traders in the emerging Web3 by providing an interactive visualization of the inspiration-driven connections between NFTs, at both individual level and collection level. SONAR can hence be useful to identify new investment opportunities as well as anomalous inspirations. To demonstrate SONAR's capabilities, we present an application to the largest and most representative dataset concerning the NFT landscape to date, showing how our proposed tool can scale and ensure high-level user experience up to millions of edges.
        </div> </ul> <br>



        <label for="Panel394">
        <strong> Searching for Reliable Facts over a Medical Knowledge Base </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fabio+Giachelle">Fabio Giachelle</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Stefano+Marchesin">Stefano Marchesin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gianmaria+Silvello">Gianmaria Silvello</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Omar+Alonso">Omar Alonso</a> (2) </u>  <br>
        1:  University of Padua, 2:  Amazon <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591822">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Searching for Reliable Facts over a Medical Knowledge Base">Google Scholar</a></div>
        (394)
        <br>
        <b>概要:　</b> 本研究は、遺伝子発現と癌の関連に関する信頼できる事実を探索するためのWebプラットフォーム、CoreKBを紹介します。CoreKBは自然言語クエリ、構造化ファセット、およびオートコンプリートを使用してRDFグラフ上での検索機能を提供します。CoreKBは、医療専門家、医学研究者、および臨床医にとって直感的で使いやすいように設計されています。このシステムは、医学的事実を裏付ける科学的証拠の包括的なを提供します。また、特定の事実が反映する可能性のある遺伝子と癌の関連性についての定量的な比較を提供します。
        </label>
        <input type="checkbox" id="Panel394" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This work presents CoreKB, a Web platform for searching reliable facts over gene expression-cancer associations Knowledge Base (KB). It provides search capabilities over an RDF graph using natural language queries, structured facets, and autocomplete. CoreKB is designed to be intuitive and easy to use for healthcare professionals, medical researchers, and clinicians. The system offers the user a comprehensive overview of the scientific evidence supporting a medical fact. It provides a quantitative comparison between the possible gene-cancer associations a particular fact can reflect.
        </div> </ul> <br>



        <label for="Panel395">
        <strong> ranxhub: An Online Repository for Information Retrieval Runs </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Elias+Bassani">Elias Bassani</a> (1) </u>  <br>
        1:  University of Milano-Bicocca <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591823">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=ranxhub: An Online Repository for Information Retrieval Runs">Google Scholar</a></div>
        (395)
        <br>
        <b>概要:　</b> ranxhubは、情報検索システムの評価に由来する成果物を共有するためのオンラインリポジトリです。具体的には、特定のクエリセットに対して検索モデルが取得したランク付けされた文書リスト（pre-computed runs）を共有するためのプラットフォームを提供しています。また、情報検索のランを評価および比較するためのPythonライブラリであるranxを拡張し、ranxhubの使用をシームレスに統合できる機能を追加しました。これにより、ユーザーは少しのコードで複数のシステムの結果を比較することが可能です。本稿では、オンラインリポジトリがもたらす多くの利点とその影響について概説します。次に、ranxhubとranxの統合について紹介し、その非常にシンプルな使用法を示します。最後に、研究コミュニティにとってranxhubが非常に価値のあるいくつかのユースケースについて議論します。
        </label>
        <input type="checkbox" id="Panel395" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> ranxhub is an online repository for sharing artifacts deriving from the evaluation of Information Retrieval systems. Specifically, we provide a platform for sharing pre-computed runs: the ranked lists of documents retrieved for a specific set of queries by a retrieval model. We also extend ranx, a Python library for the evaluation and comparison of Information Retrieval runs, adding functionalities to integrate the usage of ranxhub seamlessly, allowing the user to compare the results of multiple systems in just a few lines of code. In this paper, we first outline the many advantages and implications that an online repository for sharing runs can bring to the table. Then, we introduce ranxhub and its integration with ranx, showing its very simple usage. Finally, we discuss some use cases for which ranxhub can be highly valuable for the research community.
        </div> </ul> <br>



        <label for="Panel396">
        <strong> Podify: A Podcast Streaming Platform with Automatic Logging of User Behaviour for Academic Research </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Francesco+Meggetto">Francesco Meggetto</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yashar+Moshfeghi">Yashar Moshfeghi</a> (1) </u>  <br>
        1:  University of Strathclyde <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591824">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Podify: A Podcast Streaming Platform with Automatic Logging of User Behaviour for Academic Research">Google Scholar</a></div>
        (396)
        <br>
        <b>概要:　</b> 最近の数年間で、ポッドキャストは広く人気を集める音声ドキュメントとなっています。この分野に対する研究関心が高まっているにもかかわらず、ユーザー行動を含むデータセットの不足が原因でユーザー調査の実施は依然として困難です。特に、ユーザー調査の負担を軽減するポッドキャストストリーミングプラットフォームが求められています。この問題に対処するため、本研究ではPodifyを提案します。これは研究のために特別に設計された初のウェブベースのポッドキャストストリーミングおよび消費プラットフォームです。デスクトップおよびモバイルの両方でユーザーに高い親しみを提供するために、既存のストリーミングシステムに非常に似ています。ポッドキャストのエピソードのカタログはRSSフィードを使って簡単に作成できます。また、Elasticsearchベースのインデックスおよび検索機能を提供し、カスタマイズ可能なポッドキャスト検索の研究および実験が可能です。ユーザーはポッドキャストエピソードのプレイリストを手動でキュレートできます。ユーザーからの明示的なフィードバック（例えば、「いいね」と「よくないね」の行動）を収集するメカニズムに加え、Podifyは暗黙的なフィードバック（すべてのユーザーのインタラクション）も自動的に収集します。ユーザーの行動は実験的な分析のために読みやすい形式で簡単にエクスポートできます。プラットフォームのデモはhttps://youtu.be/k9Z5w_KKHr8で、コードおよびドキュメントはhttps://github.com/NeuraSearch/Podifyで確認できます。
        </label>
        <input type="checkbox" id="Panel396" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Podcasts are spoken documents that, in recent years, have gained widespread popularity. Despite the growing research interest in this domain, conducting user studies remains challenging due to the lack of datasets that include user behaviour. In particular, there is a need for a podcast streaming platform that reduces the overhead of conducting user studies. To address these issues, in this work, we present Podify. It is the first web-based platform for podcast streaming and consumption specifically designed for research. The platform highly resembles existing streaming systems to provide users with a high level of familiarity on both desktop and mobile. A catalogue of podcast episodes can be easily created via RSS feeds. The platform also offers Elasticsearch-based indexing and search that is highly customisable, allowing research and experimentation in podcast search. Users can manually curate playlists of podcast episodes for consumption. With mechanisms to collect explicit feedback from users (i.e., liking and disliking behaviour), Podify also automatically collects implicit feedback (i.e., all user interactions). Users' behaviour can be easily exported to a readable format for subsequent experimental analysis. A demonstration of the platform is available at https://youtu.be/k9Z5w_KKHr8, with the code and documentation available at https://github.com/NeuraSearch/Podify.
        </div> </ul> <br>



        <label for="Panel397">
        <strong> Exploratory Visualization Tool for the Continuous Evaluation of Information Retrieval Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gabriela+González-Sáez">Gabriela González-Sáez</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Petra+Galuscáková">Petra Galuscáková</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Romain+Deveaud">Romain Deveaud</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lorraine+Goeuriot">Lorraine Goeuriot</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philippe+Mulhem">Philippe Mulhem</a> (1) </u>  <br>
        1:  Université Grenoble Alpes, 2:  Qwant <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591825">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Exploratory Visualization Tool for the Continuous Evaluation of Information Retrieval Systems">Google Scholar</a></div>
        (397)
        <br>
        <b>概要:　</b> 本論文では、情報検索システムの連続評価の探索的分析を容易にする新規の可視化ツールを紹介します。我々の分析は、スコアの標準化とメタ分析技術を情報検索評価に適用することに基づいています。ツールの機能は、評価、デルタ評価、およびメタ分析の3つであり、これらは評価ラウンド、クエリ、システムの3つの観点から応用されます。ツールの使用例として、TREC-COVIDテストコレクションを用いた実例を提供します。
        </label>
        <input type="checkbox" id="Panel397" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This paper introduces a novel visualization tool that facilitates the exploratory analysis of continuous evaluation for information retrieval systems. We base our analysis on score standardization and meta-analysis techniques applied to Information Retrieval evaluation. We present three functionalities: evaluation overview, delta evaluation, and meta-analysis applied to three perspectives: evaluation rounds, queries, and systems. To illustrate the use of the tool, we provide an example using the TREC-COVID test collection.
        </div> </ul> <br>



        <label for="Panel398">
        <strong> Multi-lingual Semantic Search for Domain-specific Applications: Adobe Photoshop and Illustrator Help Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jayant+Kumar">Jayant Kumar</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ashok+Gupta">Ashok Gupta</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaoyu+Lu">Zhaoyu Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Andrei+Stefan">Andrei Stefan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tracy+Holloway+King">Tracy Holloway King</a> (1) </u>  <br>
        1:  Adobe Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591826">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multi-lingual Semantic Search for Domain-specific Applications: Adobe Photoshop and Illustrator Help Search">Google Scholar</a></div>
        (398)
        <br>
        <b>概要:　</b> 検索はAdobe製品の不可欠な要素となり、ユーザーはツールの使用方法、ショートカット、クイックリンク、クリエイティブ効果の追加方法、背景、テンプレート、フォントなどのアセットの検索に依存しています。PhotoshopやIllustratorのようなアプリケーション内で、ユーザーは短いテキストクエリを通じて特定のドメインに特化した検索意図を表現します。本研究では、AdobeのHelpXデータで微調整されたsentence-BERTモデルを活用して、ヘルプおよびチュートリアル文書に対する多言語対応の意味検索を行います。我々は、行動データ（クエリ、クリック、表示回数）および追加の注釈データを用いて、意味的類似性のためのクエリ-文書ペアのスコアリングを行ういくつかのBERTベースのモデルを訓練しました。また、キーワードベースの既存システムと意味検索を比較するベンチマークを行いました。後続のABテストにより、このアプローチが長文クエリのエンゲージメントを向上させ、null結果を大幅に削減することが示されました。
        </label>
        <input type="checkbox" id="Panel398" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Search has become an integral part of Adobe products and users rely on it to learn about tool usage, shortcuts, quick links, and ways to add creative effects and to find assets such as backgrounds, templates, and fonts. Within applications such as Photoshop and Illustrator, users express domain-specific search intents via short text queries. In this work, we leverage sentence-BERT models fine-tuned on Adobe's HelpX data to perform multi-lingual semantic search on help and tutorial documents. We used behavioral data (queries, clicks, and impressions) and additional annotated data to train several BERT-based models for scoring query-document pairs for semantic similarity. We benchmarked the keyword-based production system against semantic search. Subsequent AB tests demonstrate that this approach improves engagement for longer queries while reducing null results significantly.
        </div> </ul> <br>



        <label for="Panel399">
        <strong> Bootstrapping Query Suggestions in Spotify's Instant Search System </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alva+Liu">Alva Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Humberto+Jesús+Corona+Pampin">Humberto Jesús Corona Pampin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Enrico+Palumbo">Enrico Palumbo</a> (3) </u>  <br>
        1:  Spotify, 2:  Spotify, 3:  Spotify <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591827">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Bootstrapping Query Suggestions in Spotify's Instant Search System">Google Scholar</a></div>
        (399)
        <br>
        <b>概要:　</b> インスタント検索システムは、ユーザーのキー入力の都度、結果を提示します。この種の検索システムは、クエリの曖昧さが低く、カタログが限定されており、かつユーザーが何を探しているか明確に知っている場合に最も効果的です。しかし、Spotifyのカタログは非常に大規模かつ多様であるため、いくつかのユーザーは検索意図を形成するのに苦労することがあります。クエリの提案は、ユーザーが意図を表現し、カタログのロングテールからコンテンツを探索するのを助ける強力なツールとなり得ます。本論文では、Spotifyのインスタント検索システムにクエリ提案を導入する方法を説明します。このシステムは、何億というユーザーを数十億の音声アイテムに接続しています。具体的には、以下の点について述べます：（1）インスタント検索ログから生成したクエリ提案を、主として不完全なプレフィックスクエリが含まれるため、直接の提案としては適用できないが、ログから生成する方法。（2）生成された提案を特定のUI機能「関連検索」で試行する方法。（3）この機能がユーザーの検索意図の表現と探索的クエリの形成に役立つかどうかを測定するための新しい指標を開発する方法。
        </label>
        <input type="checkbox" id="Panel399" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Instant search systems present results to the user at every keystroke. This type of search system works best when the query ambiguity is low, the catalog is limited, and users know what they are looking for. However, Spotify's catalog is large and diverse, leading some users to struggle when formulating search intents. Query suggestions can be a powerful tool that helps users to express intents and explore content from the long-tail of the catalog. In this paper, we explain how we introduce query suggestions in Spotify's instant search system--a system that connects hundreds of millions of users with billions of items in our audio catalog. Specifically, we describe how we: (1) generate query suggestions from instant search logs, which largely contains in-complete prefix queries that cannot be directly applied as suggestions; (2) experiment with the generated suggestions in a specific UI feature, Related Searches; and (3) develop new metrics to measure whether the feature helps users to express search intent and formulate exploratory queries.
        </div> </ul> <br>



        <label for="Panel400">
        <strong> COUPA: An Industrial Recommender System for Online to Offline Service Platforms </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sicong+Xie">Sicong Xie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Binbin+Hu">Binbin Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fengze+Li">Fengze Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ziqi+Liu">Ziqi Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Zhang">Zhiqiang Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenliang+Zhong">Wenliang Zhong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (1) </u>  <br>
        1:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591828">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=COUPA: An Industrial Recommender System for Online to Offline Service Platforms">Google Scholar</a></div>
        (400)
        <br>
        <b>概要:　</b> ユーザーがオンラインからオフライン（O2O）サービスプラットフォーム上で地域の小売サービス（例えば、エンターテイメントや飲食）を発見するのを支援するために、COUPAと呼ばれる産業システムを提案します。このシステムは、時間と位置に基づくユーザーの嗜好を考慮に入れて特徴付けることを目指しています。COUPAは、エッジ、ストリーミング、およびバッチコンピューティングを協働させ、二段階のオンライン提供モードを使用して慎重に実装され、Alipayに展開されています。このシステムは、いくつかの人気のある推薦シナリオをサポートします。広範な実験の結果、COUPAの推薦性能が優れていることが明らかになりました。
        </label>
        <input type="checkbox" id="Panel400" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Aiming at helping users locally discover retail services (e.g., entertainment and dining) on Online to Offline (O2O) service platforms, we propose COUPA, an industrial system targeting for characterizing user preference with inspiring considerations of time and position aware preferences. We carefully implement and deploy COUPA in Alipay with a cooperation of edge, streaming and batch computing, as well as a two-stage online serving mode, to support several popular recommendation scenarios. Extensive experiments reveal the superior performance of COUPA for recommendation.
        </div> </ul> <br>



        <label for="Panel401">
        <strong> A Consumer Compensation System in Ride-hailing Service </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhe+Yu">Zhe Yu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chi+Xia">Chi Xia</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shaosheng+Cao">Shaosheng Cao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lin+Zhou">Lin Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haibin+Huang">Haibin Huang</a> (1) </u>  <br>
        1:  DiDi Chuxing <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591829">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Consumer Compensation System in Ride-hailing Service">Google Scholar</a></div>
        (401)
        <br>
        <b>概要:　</b> ライドヘイリングビジネスでは、消費者がより多くの注文を行い、市場規模を拡大するための動機付けとして補償が主に使用されています。しかし、以前の研究の多くはカーへイリングサービスに焦点を当てています。都市内の貨物物流や代行運転サービスなどのローカライズされたスマート交通イノベーションを調査する研究はほとんどありません。さらに、消費者の公平性を満たし、消費者余剰を改善しながらも収益の最大化を目指すことが重要です。本論文では、消費者補償システムを提案し、転移学習を強化したアップリフトモデリングを用いて弾力性を測定し、モデル予測制御に基づく最適化を設計して予算を正確に制御します。我々の実装は効果的であり、オンライン環境を軽量に維持することができます。提案されたシステムは、実際のライドヘイリングプラットフォームのプロダクション環境に300日間展開されており、0.5%少ない補助金で14.4%多くの収益を達成し、エキスパート戦略を上回っています。
        </label>
        <input type="checkbox" id="Panel401" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In the ride-hailing business, compensation is mostly used to motivate consumers to place more orders and grow the market scale. However, most of the previous studies focus on car-hailing services. Few works investigate localized smart transportation innovations, such as intra-city freight logistics and designated driving. In addition, satisfying consumer fairness and improving consumer surplus, with the objective of maximizing revenue, are also important. In this paper, we propose a consumer compensation system, where a transfer learning enhanced uplift modeling is designed to measure the elasticity, and a model predictive control based optimization is formulated to control the budget accurately. Our implementation is effective and can keep the online environment lightweight. The proposed system has been deployed in the production environment of the real-world ride-hailing platform for 300 days, which outperforms the expert strategy by using 0.5% less subsidy and achieving 14.4% more revenue.
        </div> </ul> <br>



        <label for="Panel402">
        <strong> Interactive Recommendation System for Meituan Waimai </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chen+Ji">Chen Ji</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yacheng+Li">Yacheng Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rui+Li">Rui Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Jiang">Fei Jiang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiang+Li">Xiang Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Lin">Wei Lin</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chenglong+Zhang">Chenglong Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Wang">Wei Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuyang+Wang">Shuyang Wang</a> (1) </u>  <br>
        1:  Meituan, 2:  Independent <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591830">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Interactive Recommendation System for Meituan Waimai">Google Scholar</a></div>
        (402)
        <br>
        <b>概要:　</b> 中国最大のローカル小売 & 即時配送プラットフォームである美团外卖は、サーバー上にパーソナライズドレコメンダーシステムを展開し、APPのホームページを通じてユーザーに近隣の店舗を推薦しています。ユーザーのリアルタイムの意図を把握し、ホームページ上の推薦結果を柔軟に調整するために、我々はインタラクティブレコメンダーシステムを追加しました。業界における既存のインタラクティブレコメンダーシステムは、主に特定の質問UIへのユーザーのフィードバックに基づいて意図を把握します。しかし、ホームページを閲覧中に新たな質問UIを挿入すると、使用の流暢さが損なわれ、使用の複雑さが増すことが判明しました。そこで、我々はEmbedded Interactive Recommender System（EIRS）を開発し、ホームページ上のクリック行動に基づいてユーザーの意図を直接推測し、ホームページに動的に新しい推薦結果を挿入します。EIRSの有効性を実証するために、体系的なオンラインA/Bテストを実施したところ、挿入されたEIRS結果のクリック率およびコンバージョン率はホームページの初期結果の132%高く、全体の取引総額も0.43%効果的に向上しました。
        </label>
        <input type="checkbox" id="Panel402" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> As the largest local retail & instant delivery platform in China, Meituan Waimai has deployed a personalized recommender system on server and recommend nearby stores to users through APP homepage. To capture real-time intention of users and flexibly adjust the recommendation results on the homepage, we further add an interactive recommender system. The existing interactive recommender systems in the industry mainly capture intention of users based on their feedback on a specific UI of questions. However, we find that it will undermine use fluency and increase use complexity by rashly inserting a new question UI when users browse the homepage. Therefore, we develop an Embedded Interactive Recommender System (EIRS) that directly infers users' intention according to their click behaviors on the homepage and dynamically inserts a new recommendation result into the homepage1. To demonstrate the effectiveness of EIRS, we conduct systematic online A/B Tests, where click-through & conversion rate of the inserted EIRS result is 132% higher than that of the initial result on the homepage, and the overall gross merchandise volume is effectively enhanced by 0.43%.
        </div> </ul> <br>



        <label for="Panel403">
        <strong> Integrity and Junkiness Failure Handling for Embedding-based Retrieval: A Case Study in Social Network Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenping+Wang">Wenping Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yunxi+Guo">Yunxi Guo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chiyao+Shen">Chiyao Shen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuai+Ding">Shuai Ding</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guangdeng+Liao">Guangdeng Liao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hao+Fu">Hao Fu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pramodh+Karanth+Prabhakar">Pramodh Karanth Prabhakar</a> (1) </u>  <br>
        1:  Meta Platforms <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591831">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Integrity and Junkiness Failure Handling for Embedding-based Retrieval: A Case Study in Social Network Search">Google Scholar</a></div>
        (403)
        <br>
        <b>概要:　</b> 埋め込みベースの検索は、eコマースやソーシャルネットワーク検索など、さまざまな検索アプリケーションで使用されています。このアプローチは、意味的なマッチングやコンテキスト検索のタスクでその有効性を示している一方で、制御不能な関連性の問題に悩まされています。本論文では、2021年初頭に我々のソーシャルネットワーク検索エンジンに導入された埋め込みベースの検索の分析を行い、それによって生じた失敗を「インテグリティ」と「ジャンクネス」の二つの主要なカテゴリに分類します。前者はヘイトスピーチや攻撃的なコンテンツなど、ユーザー体験に深刻な影響を与える問題を指し、後者は曖昧なテキストマッチングや言語の不一致など、無関係な結果を含みます。モデル推論の際にこれらの問題を解決するための効果的な方法として、インデックス処理や特定のユーザーコホート処理などを提案します。これらの方法はシンプルでありながら、オフラインのNDCGやオンラインのA/Bテストで実際に良好な評価結果を示しました。我々は改善の理由を分析し、この方法が重要ではあるが難解な問題への初歩的な試みでしかないことを指摘します。最後に、将来の探求可能な方向性を提案します。
        </label>
        <input type="checkbox" id="Panel403" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Embedding based retrieval has seen its usage in a variety of search applications like e-commerce, social networking search etc. While the approach has demonstrated its efficacy in tasks like semantic matching and contextual search, it is plagued by the problem of uncontrollable relevance. In this paper, we conduct an analysis of embedding-based retrieval launched in early 2021 on our social network search engine, and define two main categories of failures introduced by it, integrity and junkiness. The former refers to issues such as hate speech and offensive content that can severely harm user experience, while the latter includes irrelevant results like fuzzy text matching or language mismatches. Efficient methods during model inference are further proposed to resolve the issue, including indexing treatments and targeted user cohort treatments, etc. Though being simple, we show the methods have good offline NDCG and online A/B tests metrics gain in practice. We analyze the reasons for the improvements, pointing out that our methods are only preliminary attempts to this important but challenging problem. We put forward potential future directions to explore.
        </div> </ul> <br>



        <label for="Panel404">
        <strong> Dialog-to-Actions: Building Task-Oriented Dialogue System via Action-Level Generation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuncheng+Hua">Yuncheng Hua</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyu+Xi">Xiangyu Xi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zheng+Jiang">Zheng Jiang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guanwei+Zhang">Guanwei Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chaobo+Sun">Chaobo Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guanglu+Wan">Guanglu Wan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Ye">Wei Ye</a> (2) </u>  <br>
        1:  Meituan Group, 2:  Peking University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591832">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Dialog-to-Actions: Building Task-Oriented Dialogue System via Action-Level Generation">Google Scholar</a></div>
        (404)
        <br>
        <b>概要:　</b> タスク指向対話システムにおいて、エンドツーエンドの生成ベースのアプローチが調査され、応用されています。しかし、産業シナリオでは、既存の方法は信頼性（例：ドメイン一貫性のない応答、繰り返し問題など）と効率性（例：長い計算時間など）のボトルネックに直面しています。本論文では、アクションレベル生成を介したタスク指向対話システムを提案します。具体的には、まず大規模対話から対話アクションを構築し、各自然言語（NL）応答を対話アクションのシーケンスとして表現します。さらに、対話履歴を入力として受け取り、対話アクションのシーケンスを出力するシーケンス・トゥ・シーケンスモデルを訓練します。生成された対話アクションは言語応答に変換されます。実験結果は、我々の軽量な方法が競争力のある性能を達成し、信頼性と効率性の点でも優位性を持っていることを示しています。
        </label>
        <input type="checkbox" id="Panel404" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> End-to-end generation-based approaches have been investigated and applied in task-oriented dialogue systems. However, in industrial scenarios, existing methods face the bottlenecks of reliability (e.g., domain-inconsistent responses, repetition problem, etc) and efficiency (e.g., long computation time, etc). In this paper, we propose a task-oriented dialogue system via action-level generation. Specifically, we first construct dialogue actions from large-scale dialogues and represent each natural language (NL) response as a sequence of dialogue actions. Further, we train a Sequence-to-Sequence model which takes the dialogue history as the input and outputs a sequence of dialogue actions. The generated dialogue actions are transformed into verbal responses. Experimental results show that our light-weighted method achieves competitive performance, and has the advantage of reliability and efficiency.
        </div> </ul> <br>



        <label for="Panel405">
        <strong> Long-Form Information Retrieval for Enterprise Matchmaking </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pengyuan+Li">Pengyuan Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guang-Jie+Ren">Guang-Jie Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anna+Lisa+Gentile">Anna Lisa Gentile</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chad+DeLuca">Chad DeLuca</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daniel+Tan">Daniel Tan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sandeep+Gopisetty">Sandeep Gopisetty</a> (1) </u>  <br>
        1:  IBM Research - Almaden <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591833">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Long-Form Information Retrieval for Enterprise Matchmaking">Google Scholar</a></div>
        (405)
        <br>
        <b>概要:　</b> 顧客の要求を理解することは、ビジネス・ツー・コンシューマー（B2C）とビジネス・ツー・ビジネス（B2B）の企業にとって、成功の鍵となる要因です。B2Cの文脈では、多くの要求は製品に直接関連しているため、キーワードベースのクエリで表現されます。それに対して、B2Bの要求は顧客のニーズに関するより多くの情報を含んでおり、そのためクエリはしばしば長文で表現されます。このような長文のクエリは、B2Bの文脈における情報検索タスクに重大な挑戦をもたらします。本研究では、この長文情報検索の課題に対処するために、（i）クエリからの語彙的一致を活用する伝統的な検索方法と、（ii）長文クエリの豊かな文脈を捕捉する最新の文変換モデルの組み合わせを提案します。我々の手法を、内部データセットに基づく12,368組の長文要求と販売された製品を使用して、従来のTF-IDFおよびBM25モデルと比較しました。その評価は有望な結果を示し、今後の研究の方向性を提供します。
        </label>
        <input type="checkbox" id="Panel405" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Understanding customer requirements is a key success factor for both business-to-consumer (B2C) and business-to-business (B2B) enterprises. In a B2C context, most requirements are directly related to products and therefore expressed in keyword-based queries. In comparison, B2B requirements contain more information about customer needs and as such the queries are often in a longer form. Such long-form queries pose significant challenges to the information retrieval task in B2B context. In this work, we address the long-form information retrieval challenges by proposing a combination of (i) traditional retrieval methods, to leverage the lexical match from the query, and (ii) state-of-the-art sentence transformers, to capture the rich context in the long queries. We compare our method against traditional TF-IDF and BM25 models on an internal dataset of 12,368 pairs of long-form requirements and products sold. The evaluation shows promising results and provides directions for future work.
        </div> </ul> <br>



        <label for="Panel406">
        <strong> Learning Query-aware Embedding Index for Improving E-commerce Dense Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mingming+Li">Mingming Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chunyuan+Yuan">Chunyuan Yuan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Binbin+Wang">Binbin Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingwei+Zhuo">Jingwei Zhuo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Songlin+Wang">Songlin Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lin+Liu">Lin Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sulong+Xu">Sulong Xu</a> (1) </u>  <br>
        1:  JD.com <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591834">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Learning Query-aware Embedding Index for Improving E-commerce Dense Retrieval">Google Scholar</a></div>
        (406)
        <br>
        <b>概要:　</b> 埋め込みインデックスは、オンラインEコマースアプリケーションにおいて、数十億のアイテムを高速検索するための密な検索（DR）システムの重要な要素となっています。産業シナリオにおいて検索プロセスを加速するため、これまでの多くの研究はアイテム埋め込みのみを利用してきました。しかし、クエリ埋め込みを含まないプロダクト量子化プロセスは、クエリとアイテム間の一貫性を欠く結果となります。一つの明快な解決策は、クエリ埋め込みをプロダクト量子化プロセスに組み込むことです。しかし、我々は正のクエリとアイテム埋め込みペア間の距離が大きすぎることを発見しました。これは、二塔アーキテクチャで学習されたクエリとアイテム埋め込みが完全に整合していないことを意味します。この問題は、クエリ埋め込みを直接プロダクト量子化に投入する際の性能低下を引き起こします。本論文では、正のペア間の距離を縮め、クエリとアイテム埋め込みを混ぜてプロダクト量子化のためのより良いクラスタ中心を学習するために、クエリ認識埋め込みインデックスフレームワークを提案します。具体的には、より良い二塔アーキテクチャを訓練して空間整合を達成するために対称損失を提案します。その後、クエリ埋め込みをプロダクト量子化プロセスに組み込み、クエリと圧縮アイテム埋め込み間のギャップを埋めるための混合量子化戦略を提案します。大規模な実験により、我々のフレームワークが実世界のデータセットで以前のモデルを大幅に上回ることが示され、その優位性と有効性が実証されました。
        </label>
        <input type="checkbox" id="Panel406" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The embedding index has become an essential part of the dense retrieval (DR) system, which enables a fast search for billion of items in online E-commerce applications. To accelerate the retrieval process in industrial scenarios, most of the previous studies only utilize item embeddings. However, the product quantization process without query embeddings will lead to inconsistency between queries and items. A straightforward solution is to put query embedding into the product quantization process. But we found that the distance of the positive query and item embedding pairs is too large, which means the query and item embeddings learned by the two-tower are not fully aligned. This problem would lead to performance decay when directly putting query embeddings into the product quantization. In this paper, we propose a novel query-aware embedding Index framework, which aligns the query and item embedding space to reduce the distance between positive pairs, thereby mixing the query and item embeddings to learn better cluster centers for product quantization. Specifically, we first propose s symmetric loss to train a better two-tower to achieve space alignment. Subsequently, we propose a mixed quantization strategy to put the query embeddings into the product quantization process for bridging the gap between queries and compressed item embeddings. Extensive experiments show that our framework significantly outperforms previous models on a real-world dataset, which demonstrates the superiority and effectiveness of the framework.
        </div> </ul> <br>



        <label for="Panel407">
        <strong> A Practical Online Allocation Framework at Industry-scale in Constrained Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daohong+Jian">Daohong Jian</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Bao">Yang Bao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hua+Wu">Hua Wu</a> (1) </u>  <br>
        1:  AntGroup <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591835">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Practical Online Allocation Framework at Industry-scale in Constrained Recommendation">Google Scholar</a></div>
        (407)
        <br>
        <b>概要:　</b> オンライン割り当ては、制約された推薦システムにおいて重要な課題です。限られたリソースを持つユーザーに対して、商品、広告、バウチャー、その他のコンテンツを効果的に配分する必要があります。既存の文献では、さまざまなシナリオにおける推薦アルゴリズムの改善に大きな進展が見られるものの、産業規模のオンライン割り当てシステムを効率的に開発および展開することには、あまり注意が払われていません。この問題に対処するために、本稿ではAlipayにおける制約付き推薦シナリオでの統合された効率的な学習フレームワークを紹介します。このフレームワークは実験を通じて検証され、他の最先端手法よりも優れていることが示されています。
        </label>
        <input type="checkbox" id="Panel407" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Online allocation is a critical challenge in constrained recommendation systems, where the distribution of goods, ads, vouchers, and other content to users with limited resources needs to be managed effectively. While the existing literature has made significant progress in improving recommendation algorithms for various scenarios, less attention has been given to developing and deploying industry-scale online allocation system in an efficient manner. To address this issue, this paper introduces an integrated and efficient learning framework in constrained recommendation scenarios at Alipay. The framework has been tested through experiments, demonstrating its superiority over other state-of-the-art methods.
        </div> </ul> <br>



        <label for="Panel408">
        <strong> TMML: Text-Guided MuliModal Product Location For Alleviating Retrieval Inconsistency in E-Commerce </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Youhua+Tang">Youhua Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiong+Xiong">Xiong Xiong</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siyang+Sun">Siyang Sun</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Baoliang+Cui">Baoliang Cui</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yun+Zheng">Yun Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haihong+Tang">Haihong Tang</a> (1) </u>  <br>
        1:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591836">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=TMML: Text-Guided MuliModal Product Location For Alleviating Retrieval Inconsistency in E-Commerce">Google Scholar</a></div>
        (408)
        <br>
        <b>概要:　</b> タイトル:画像検索システム（IRS）は、価格比較や商品推薦など、Eコマースプラットフォームで幅広い用途に使用されています。しかし、顧客は一貫性のない検索結果に悩まされることがあります。検索された画像に照会対象オブジェクトが含まれていても、検索結果の主製品が照会製品と関連付けられていない場合があります。これは、製品画像検索ライブラリを構築する際に製品インスタンスの位置が誤っていることに起因します。我々は、タイトルの手がかりから販売中の製品を簡単に特定できるため、追加の製品タイトルを使用して実際の販売製品インスタンスの特定を支援するText-Guided MultiModal Product Location（TMML）を提案します。我々は、IRSとEコマースプラットフォームのユーザー行動を利用して、領域テキスト疑似ラベルを生成する弱く整列された領域テキストデータ収集手法を設計しました。データノイズの影響を軽減するために、Mutual-Aware Contrastive Lossを提案します。結果として、提案手法TMMLは、我々のマルチオブジェクトテストセットにおいて、最先端のGLIP [11]よりもトップ1精度で3.95％向上し、AliExpressでの位置誤り画像の2.53％が修正され、IRSにおける検索の一貫性の問題が大幅に緩和されました。
        </label>
        <input type="checkbox" id="Panel408" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Image retrieval system (IRS) is commonly used in E-Commerce platforms for a wide range of applications such as price comparison and commodity recommendation. However, customers may experience inconsistent retrieval problems. Although the retrieved image contains the query object, the main product of the retrieved image is not associated with the query product. This is caused by the wrong product instance location when building the product image retrieval library. We can easily determine which product is on sale through the hint of the title, so we propose Text-Guided MuliModal Product Location (TMML) to use additional product titles to assist in locating the actual selling product instance. We design a weakly-aligned region-text data collection method to generate region-text pseudo-label by utilizing the IRS and user behavior from the E-commerce platform. To mitigate the impact of data noise, we propose a Mutual-Aware Contrastive Loss. Our results show that the proposed TMML outperforms the state-of-the-art method GLIP [11] by 3.95% in top-1 precision on our multi-objects test set, and 2.53% error located images in AliExpress has been corrected, which greatly alleviates the retrieval inconsistencies in IRS.
        </div> </ul> <br>



        <label for="Panel409">
        <strong> MDI: A Debiasing Method Combining Unbiased and Biased Data </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Han+Zhao">Han Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qing+Cui">Qing Cui</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinyu+Li">Xinyu Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rongzhou+Bao">Rongzhou Bao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Longfei+Li">Longfei Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhehao+Liu">Zhehao Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinghua+Feng">Jinghua Feng</a> (1) </u>  <br>
        1:  Ant Group, 2:  Peking University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591838">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=MDI: A Debiasing Method Combining Unbiased and Biased Data">Google Scholar</a></div>
        (409)
        <br>
        <b>概要:　</b> 近年、バイアスのかかったデータとバイアスのないデータを組み合わせることでレコメンダシステムのバイアスを緩和する多くの手法が提案されています。これらの手法の中でも、データ補完法は有効ですが、既存の研究では単純なモデルを用いて補完データを生成するため、データを十分に特徴付けることができませんでした。本研究では、バイアスのないモデルとデバイアスモデルを適応的に学習された重みと組み合わせる新しいデータ補完手法を提案します。提案手法の有効性と堅牢性を証明するために、二つの公開された推薦データセットと一つの実運用データセットで広範な実験を行いました。
        </label>
        <input type="checkbox" id="Panel409" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In recent years, many methods have been proposed to alleviate the biases in recommender systems by combining biased data and unbiased data. Among these methods, data imputation method is effective, but previous works only employ a straightforward model to generate imputed data, which can not fully characterize the data. In this paper, we propose a novel data imputation approach that combines an unbiased model and a debiasing model with adaptively learnt weights. We conduct extensive experiments on two public recommendation datasets and one production dataset to demonstrate the effectiveness and robustness of the proposed method.
        </div> </ul> <br>



        <label for="Panel410">
        <strong> Context-Aware Classification of Legal Document Pages </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pavlos+Fragkogiannis">Pavlos Fragkogiannis</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Martina+Forster">Martina Forster</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Grace+E.+Lee">Grace E. Lee</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dell+Zhang">Dell Zhang</a> (1) </u>  <br>
        1:  Thomson Reuters Labs, 2:  Thomson Reuters Labs <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591839">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Context-Aware Classification of Legal Document Pages">Google Scholar</a></div>
        (410)
        <br>
        <b>概要:　</b> 法的文書（PDF形式など）の処理、インデックス作成、検索が求められる多くのビジネスアプリケーションにおいて、文書の各ページを事前に対応するタイプに分類することがしばしば不可欠です。文書画像分類の既存の研究の多くは、単一ページの文書に焦点を当てるか、文書内の複数ページを独立して扱います。近年では、隣接するページからの文脈情報を利用して文書ページの分類を強化するいくつかの技術が提案されていますが、入力長の制約により、大規模な事前学習済み言語モデルと共に使用することは通常できません。本論文では、この制約を克服するためのシンプルだが効果的なアプローチを提示します。具体的には、前ページに関する順序情報を持つ追加トークンを入力に強化することでリカレント性を導入し、その結果、BERTのような事前学習済みTransformerモデルを使用したコンテキスト認識型のページ分類が可能となります。我々の実験は英語とポルトガル語の2つの法的データセットを用いて行われ、提案手法がリカレント性を持たない設定や他の文脈認識型ベースラインと比較して、文書ページ分類の性能を大幅に向上させることを示しています。
        </label>
        <input type="checkbox" id="Panel410" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> For many business applications that require the processing, indexing, and retrieval of professional documents such as legal briefs (in PDF format etc.), it is often essential to classify the pages of any given document into their corresponding types beforehand. Most existing studies in the field of document image classification either focus on single-page documents or treat multiple pages in a document independently. Although in recent years a few techniques have been proposed to exploit the context information from neighboring pages to enhance document page classification, they typically cannot be utilized with large pre-trained language models due to the constraint on input length. In this paper, we present a simple but effective approach that overcomes the above limitation. Specifically, we enhance the input with extra tokens carrying sequential information about previous pages --- introducing recurrence --- which enables the usage of pre-trained Transformer models like BERT for context-aware page classification. Our experiments conducted on two legal datasets in English and Portuguese respectively show that the proposed approach can significantly improve the performance of document page classification compared to the non-recurrent setup as well as the other context-aware baselines.
        </div> </ul> <br>



        <label for="Panel411">
        <strong> Facebook Content Search: Efficient and Effective Adapting Search on A Large Scale </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangyu+Niu">Xiangyu Niu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yu-Wei+Wu">Yu-Wei Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Lu">Xiao Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gautam+Nagpal">Gautam Nagpal</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philip+Pronin">Philip Pronin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kecheng+Hao">Kecheng Hao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhen+Liao">Zhen Liao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guangdeng+Liao">Guangdeng Liao</a> (1) </u>  <br>
        1:  Meta Platforms <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591840">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Facebook Content Search: Efficient and Effective Adapting Search on A Large Scale">Google Scholar</a></div>
        (411)
        <br>
        <b>概要:　</b> Facebookのコンテンツ検索は、人々が友人や家族、クリエイター、コミュニティとの交流を深めるための最適なコンテンツを発見するための重要なチャネルです。数十億のデイリーアクティブユーザーに対して、大量の候補から最高の結果を提供する高度にパーソナライズされた検索エンジンの構築は困難な課題です。この検索エンジンは、異なるコンテンツタイプ、異なるクエリの意図、ユーザーのソーシャルグラフなど、複数の次元を考慮に入れる必要があります。本論文では、Facebookコンテンツ検索の課題を深く掘り下げた上で、高度なクエリ理解、検索、および機械学習技術を用いて大量のドキュメントを効率的に処理する新しいアプローチを説明します。提案されたシステムは完全に検証され、数十億のユーザーにサービスを提供するFacebook検索の本番システムに適用されています。
        </label>
        <input type="checkbox" id="Panel411" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Facebook content search is a critical channel that enables people to discover the best content to deepen their engagement with friends and family, creators, and communities. Building a highly personalized search engine to serve billions of daily active users to find the best results from a large scale of candidates is a challenging task. The search engine must take multiple dimensions into consideration, including different content types, different query intents, and user social graph, etc. In this paper, we discuss the challenges of Facebook content search in depth, and then describe our novel approach to efficiently handling a massive number of documents with advanced query understanding, retrieval, and machine learning techniques. The proposed system has been fully verified and applied to the production system of Facebook Search, which serves billions of users.
        </div> </ul> <br>



        <label for="Panel412">
        <strong> Practice and Challenges in Building a Business-oriented Search Engine Quality Metric </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nuo+Chen">Nuo Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Donghyun+Park">Donghyun Park</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hyungae+Park">Hyungae Park</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kijun+Choi">Kijun Choi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tetsuya+Sakai">Tetsuya Sakai</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinyoung+Kim">Jinyoung Kim</a> (4) </u>  <br>
        1:  Waseda University, 2:  Naver Corp., 3:  Waseda University & Naver Corp., 4:  Naver Corp. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591841">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Practice and Challenges in Building a Business-oriented Search Engine Quality Metric">Google Scholar</a></div>
        (412)
        <br>
        <b>概要:　</b> 大規模なウェブ検索エンジンを運営する最も難しい側面の一つは、検索の種類に関わらず、検索エンジンの結果品質を正確に評価し、監視することです。ビジネスの観点から見ると、このような課題に直面した場合、全組織が容易に理解できる普遍的な検索品質指標の確立が重要となります。本論文では、Explainable Boosting Machineを分類器とし、オンラインユーザーの行動シグナルを特徴量として使用して検索品質を予測するモデルベースの品質指標を紹介します。提案する指標はさまざまな検索タイプを考慮しており、高い解釈性を持っています。この指標の性能を評価するために、プロのアノテーターによるSERP（Search Engine Results Pages）品質評価を含む大規模なユーザー行動データセットを構築しました。我々の指標のモデルと他のブラックボックス機械学習モデルの性能をデータセット上で比較しました。また、指標設計に関する組織全体での導入に関するいくつかの経験も共有します。
        </label>
        <input type="checkbox" id="Panel412" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> One of the most challenging aspects of operating a large-scale web search engine is to accurately evaluate and monitor the search engine's result quality regardless of search types. From a business perspective, in the face of such challenges, it is important to establish a universal search quality metric that can be easily understood by the entire organisation. In this paper, we introduce a model-based quality metric using Explainable Boosting Machine as the classifier and online user behaviour signals as features to predict search quality. The proposed metric takes into account a variety of search types and has good interpretability. To examine the performance of the metric, we constructed a large dataset of user behaviour on search engine results pages (SERPs) with SERP quality ratings from professional annotators. We compared the performance of the model in our metric to those of other black-box machine learning models on the dataset. We also share a few experiences within our company for the org-wide adoption of this metric relevant to metric design.
        </div> </ul> <br>



        <label for="Panel413">
        <strong> Building a Graph-Based Patent Search Engine </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sebastian+Björkqvist">Sebastian Björkqvist</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Juho+Kallio">Juho Kallio</a> (1) </u>  <br>
        1:  IPRally Technologies Oy <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591842">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Building a Graph-Based Patent Search Engine">Google Scholar</a></div>
        (413)
        <br>
        <b>概要:　</b> 先行技術調査を行うことは、特許出願の作成や無効化において必要不可欠なステップです。この作業は、既存の特許文書の膨大な数と、それらを分析するために必要な専門知識のために挑戦的です。我々はプロの特許審査官の作業を模倣しようとするグラフベースの特許検索エンジンを提案します。各特許文書は、発明の部分とそれらの部分間の関係を説明するグラフに変換されます。この検索エンジンは、特許庁の検索報告書からの新規性の引用データを使用して、先行技術を見つけることを学習するグラフニューラルネットワークによって駆動されます。我々は、グラフベースのアプローチが技術文書の検索を効率的に行う方法であることを示し、特許検索の文脈でそれを実証します。
        </label>
        <input type="checkbox" id="Panel413" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Performing prior art searches is an essential step in both patent drafting and invalidation. The task is challenging due to the large number of existing patent documents and the domain knowledge required to analyze the documents. We present a graph-based patent search engine that tries to mimic the work done by a professional patent examiner. Each patent document is converted to a graph that describes the parts of the invention and the relations between the parts. The search engine is powered by a graph neural network that learns to find prior art by using novelty citation data from patent office search reports where citations are compiled by human patent examiners. We show that a graph-based approach is an efficient way to perform searches on technical documents and demonstrate it in the context of patent searching.
        </div> </ul> <br>



        <label for="Panel414">
        <strong> A Data-centric Solution to Improve Online Performance of Customer Service Bots </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sen+Hu">Sen Hu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Changlin+Yang">Changlin Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junjie+Wang">Junjie Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Siye+Liu">Siye Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Teng+Xu">Teng Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wangshu+Zhang">Wangshu Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jing+Zheng">Jing Zheng</a> (1) </u>  <br>
        1:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591843">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Data-centric Solution to Improve Online Performance of Customer Service Bots">Google Scholar</a></div>
        (414)
        <br>
        <b>概要:　</b> カスタマーサービスボットのオンラインパフォーマンスは、限られた訓練データと実際のユーザーの質問とのギャップのために、しばしば満足のいくものではありません。オンラインパフォーマンスを向上させるための簡単な方法として、モデルの反復と再配置は時間がかかり、労働集約的であるため、継続が困難です。チャットボットの不具合を修正し、オンラインのパフォーマンスを迅速かつ継続的に向上させるために、我々はバッドケース検出、バッドケース修正、回答抽出の三つの主要モジュールからなるデータ中心の解決策を提案します。この提案された解決策は、オンラインモデルのシグナル、暗黙のユーザーフィードバック、および人工カスタマーサービスのログを十分に活用することにより、オンラインのバッドケースを自動的に修正できます。我々のソリューションは導入され、中国のデジタル決済プラットフォームである支付宝（Alipay）アプリで使用されている数百のカスタマーサービスボットに一貫してポジティブな影響を与えています。
        </label>
        <input type="checkbox" id="Panel414" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The online performance of customer service bots is often less than satisfactory because of the gap between limited training data and real-world user questions. As a straightforward way to improve online performance, model iteration and re-deployment are time consuming and labor-intensive, and therefore difficult to sustain. To fix badcases and improve online performance of chatbots in a timely and continuous manner, we propose a data-centric solution consisting of three main modules: badcase detection, bad case correction, and answer extraction. By making full use of online model signals, implicit user feedback and artificial customer service log, the proposed solution can fix online badcases automatically. Our solution has been deployed and bringing consistently positive impacts for hundreds of customer service bots used by Alipay app.
        </div> </ul> <br>



        <label for="Panel415">
        <strong> Enhancing Dynamic Image Advertising with Vision-Language Pre-training </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhoufutu+Wen">Zhoufutu Wen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinyu+Zhao">Xinyu Zhao</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhipeng+Jin">Zhipeng Jin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yi+Yang">Yi Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Jia">Wei Jia</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaodong+Chen">Xiaodong Chen</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuanglong+Li">Shuanglong Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lin+Liu">Lin Liu</a> (1) </u>  <br>
        1:  Baidu Inc., 2:  Peking University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591844">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Enhancing Dynamic Image Advertising with Vision-Language Pre-training">Google Scholar</a></div>
        (415)
        <br>
        <b>概要:　</b> マルチメディア時代において、画像は検索広告における効果的な媒体となっています。ユーザーエクスペリエンスや広告収益の向上を目指し、クエリに適した広告画像をマッチングし、マルチモーダル広告を生成するシステムであるDynamic Image Advertising (DIA)が紹介されます。DIAの核となるのは、広告画像の検索と関連性のモデリングを行うクエリ-画像マッチングモジュールです。現在のクエリ-画像マッチングには、データの不足や不整合、クロスモーダルの融合の不十分さが問題となっています。また、検索モデルと関連性モデルが個別に訓練されているため、全体的なパフォーマンスが影響を受けています。<br><br>本論文では、クエリ-画像マッチングのためのビジョン-ランゲージフレームワークを提案します。このフレームワークは二つの部分から構成されています。まず、異なるエンコーダとタスクを組み合わせたベースモデルを設計し、大規模な画像-テキストペアで訓練して、一般的なマルチモーダル表現を学習します。次に、このベースモデルを広告ビジネスデータでファインチューニングし、マルチオブジェクティブ学習を通じて関連性モデリングと検索を統一します。<br><br>我々のフレームワークは、Baiduの検索広告システム「Phoenix Nest」に実装されています。オンライン評価では、CPM（Cost Per Mille）とCTR（Click-Through Rate）がそれぞれ1.04％と1.865％向上したことが示されています。
        </label>
        <input type="checkbox" id="Panel415" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In the multimedia era, image becomes an effective medium in search advertising. Dynamic Image Advertising (DIA), a system that matches queries with appropriate ad images and generates multimodal ads, is introduced to improve user experience and ad revenue. The core of DIA is a query-image matching module performing ad image retrieval and relevance modeling. Current query-image matching suffers from data scarcity and inconsistency, and insufficient cross-modal fusion. Also, the retrieval and relevance models are separately trained, affecting overall performance. In this paper, we propose a vision-language framework for query-image matching. It consists of two parts. First, we design a base model combining different encoders and tasks, and train it on large-scale image-text pairs to learn general multimodal representation. Then, we fine-tune the base model on advertising business data, unifying relevance modeling and retrieval through multi-objective learning. Our framework has been implemented in Baidu search advertising system "Phoneix Nest". Online evaluation shows that it improves cost per mille (CPM) and click-through rate (CTR) by 1.04% and 1.865% on the system main traffic.
        </div> </ul> <br>



        <label for="Panel416">
        <strong> Graph Enhanced BERT for Query Understanding </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Juanhui+Li">Juanhui Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wei+Zeng">Wei Zeng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Suqi+Cheng">Suqi Cheng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yao+Ma">Yao Ma</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiliang+Tang">Jiliang Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuaiqiang+Wang">Shuaiqiang Wang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dawei+Yin">Dawei Yin</a> (2) </u>  <br>
        1:  Michigan State University, 2:  Baidu Inc., 3:  New Jersey Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591845">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Graph Enhanced BERT for Query Understanding">Google Scholar</a></div>
        (416)
        <br>
        <b>概要:　</b> クエリ理解は、ユーザーの検索意図を探る上で重要な役割を担っており、ユーザーが最も望む情報を見つけるのを支援します。しかし、クエリは短く曖昧であるため、そのセマンティック情報を捉えることが本質的に難しく、大量のタスク特化型ラベルデータを必要とすることが多いです。近年、事前学習された言語モデル（PLMs）は、大規模なコーパスから一般的なセマンティック情報を抽出する能力があるため、様々な自然言語処理タスクにおいて進歩を遂げています。しかし、PLMsをクエリ理解に直接適用するのは最適ではなく、既存の戦略は検索性能を向上させることを考慮することがほとんどありません。一方、検索ログにはクエリとURLの間のユーザークリック情報が含まれており、クエリの内容を超えたユーザーの検索行動情報を豊富に提供します。そこで本研究では、このギャップを埋めるために検索ログを活用することを目指します。具体的には、クエリの内容とクエリグラフの両方を活用する新しいグラフ強化事前学習フレームワーク、GE-BERTを提案します。本モデルは、ノードがクエリであり、同じURLにクリックを導く場合に接続されたクエリグラフ上で訓練され、クエリのセマンティック情報とユーザーの検索行動情報の両方を捉えます。オフラインおよびオンラインタスクでの広範な実験により、本フレームワークの有効性が実証されました。
        </label>
        <input type="checkbox" id="Panel416" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Query understanding plays a key role in exploring users' search intents and facilitating users to locate their most desired information. However, it is inherently challenging since it needs to capture semantic information from short and ambiguous queries and often requires massive task-specific labeled data. In recent years, pre-trained language models (PLMs) have advanced various natural language processing tasks because they can extract general semantic information from large-scale corpora. However, directly applying them to query understanding is sub-optimal because existing strategies rarely consider to boost the search performance. On the other hand, search logs contain user clicks between queries and urls that provide rich users' search behavioral information on queries beyond their content. Therefore, in this paper, we aim to fill this gap by exploring search logs. In particular, we propose a novel graph-enhanced pre-training framework, GE-BERT, which leverages both query content and the query graph. The model is trained on a query graph where nodes are queries and two queries are connected if they lead to clicks on the same urls, to capture both semantic information and users' search behavioral information of queries. Extensive experiments on offline and online tasks have demonstrated the effectiveness of the proposed framework.
        </div> </ul> <br>



        <label for="Panel417">
        <strong> KATIE: A System for Key Attributes Identification in Product Knowledge Graph Construction </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Btissam+Er-Rahmadi">Btissam Er-Rahmadi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Arturo+Oncevay">Arturo Oncevay</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuanyi+Ji">Yuanyi Ji</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jeff+Z.+Pan">Jeff Z. Pan</a> (3) </u>  <br>
        1:  Huawei Technologies R&D UK, 2:  The University of Edinburgh, 3:  Huawei Technologies R&D UK & The University of Edinburgh <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591846">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=KATIE: A System for Key Attributes Identification in Product Knowledge Graph Construction">Google Scholar</a></div>
        (417)
        <br>
        <b>概要:　</b> 本論文では、Huaweiのプロジェクトである製品ナレッジグラフ（PKG）の構築に関する取り組みの一部を紹介します。我々の目標は、ショッピングの意思決定に影響を与える製品属性（すなわちプロパティ）が、どの製品カテゴリ（すなわちクラス）に対して関連性および重要性を持つかを特定することです。この作業は、属性とその値がオンライン製品カタログ（すなわちHTMLページ）から抽出される場合に特に困難です。これらのウェブページは半構造化データを含み、統一されたフォーマットに従わず、同じ特徴を表現するために異なる語彙が使用されます。我々は事前学習モデル（例：DistilBERT）のファインチューニングに基づいたキー属性識別システム（KATIE）を提案し、属性がカテゴリに対して適用されるかおよびその重要性を予測します。また、ラベルの類似性だけでなく、値のセットの類似性も考慮することで、同義の属性を発見できる属性同義語識別モジュールを提案します。我々のアプローチは、Huaweiのカテゴリ分類とウェブページから内部的に抽出された一連の属性に対して評価されました。KATIEは、最新のベースラインと比較しても有望なパフォーマンス結果を保証します。
        </label>
        <input type="checkbox" id="Panel417" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> We present part of Huawei's efforts in building a Product Knowledge Graph (PKG). We want to identify which product attributes (i.e. properties) are relevant and important in terms of shopping decisions to product categories (i.e. classes). This is particularly challenging when the attributes and their values are mined from online product catalogues, i.e. HTML pages. These web pages contain semi-structured data, which do not follow a concerted format and use diverse vocabulary to designate the same features. We propose a system for key attribute identification (KATIE) based on fine-tuning pre-trained models (e.g., DistilBERT) to predict the applicability and importance of an attribute to a category. We also propose an attribute synonyms identification module that allows us to discover synonymous attributes by considering not only their labels' similarities but also the similarity of their values sets. We have evaluated our approach to Huawei categories taxonomy and a set of internally mined attributes from web pages. KATIE guarantees promising performance results compared to the most recent baselines.
        </div> </ul> <br>



        <label for="Panel418">
        <strong> A Transformer-Based Substitute Recommendation Model Incorporating Weakly Supervised Customer Behavior Data </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenting+Ye">Wenting Ye</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hongfei+Yang">Hongfei Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shuai+Zhao">Shuai Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haoyang+Fang">Haoyang Fang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xingjian+Shi">Xingjian Shi</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Naveen+Neppalli">Naveen Neppalli</a> (1) </u>  <br>
        1:  Amazon Retails, 2:  AWS AI <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591847">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=A Transformer-Based Substitute Recommendation Model Incorporating Weakly Supervised Customer Behavior Data">Google Scholar</a></div>
        (418)
        <br>
        <b>概要:　</b> サブスティチュート・ベースのレコメンデーションは、Eコマースにおいて顧客により良い代替品を提供するために広く使用されています。既存の研究では、共視や「閲覧したが別の商品を購入した」といった顧客行動シグナルを用いることが多く、サブスティチュート関係を捕捉します。しかし、このアプローチは直感的には理にかなっていますが、商品の機能や特徴を無視する可能性があります。本研究では、サブスティチュートのレコメンデーションを言語マッチングの問題に適応させ、商品の機能を考慮するために商品タイトルの説明をモデルの入力とします。我々は、製品データから得られるシグナルをノイズ除去する新しい変換方法を設計しました。さらに、エンジニアリングの観点から多言語対応を考慮しています。我々の提案するエンドツーエンドのトランスフォーマーモデルは、オフラインおよびオンライン実験の両方で成功を収めました。本モデルは、6つの言語で11の市場向けに大規模なEコマースサイトに導入されています。オンラインA/Bテストに基づく結果では、収益が19%増加したことが示されています。
        </label>
        <input type="checkbox" id="Panel418" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The substitute-based recommendation is widely used in E-commerce to provide better alternatives to customers. However, existing research typically uses customer behavior signals like co-view and view-but-purchase-another to capture the substitute relationship. Despite its intuitive soundness, such an approach might ignore the functionality and characteristics of products. In this paper, we adapt substitute recommendations into language matching problem. It takes the product title description as model input to consider product functionality. We design a new transformation method to de-noise the signals derived from production data. In addition, we consider multilingual support from the engineering point of view. Our proposed end-to-end transformer-based model achieves both successes from offline and online experiments. The proposed model has been deployed in a large-scale E-commerce website for 11 marketplaces in 6 languages. Our proposed model is demonstrated to increase revenue by 19% based on an online A/B experiment.
        </div> </ul> <br>



        <label for="Panel419">
        <strong> Embedding Based Retrieval in Friend Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiahui+Shi">Jiahui Shi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Vivek+Chaurasiya">Vivek Chaurasiya</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yozen+Liu">Yozen Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shubham+Vij">Shubham Vij</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yan+Wu">Yan Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Satya+Kanduri">Satya Kanduri</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Neil+Shah">Neil Shah</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peicheng+Yu">Peicheng Yu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nik+Srivastava">Nik Srivastava</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lei+Shi">Lei Shi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ganesh+Venkataraman">Ganesh Venkataraman</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Yu">Jun Yu</a> (1) </u>  <br>
        1:  Snap Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591848">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Embedding Based Retrieval in Friend Recommendation">Google Scholar</a></div>
        (419)
        <br>
        <b>概要:　</b> Snapchatのようなオンラインソーシャルおよびプロフェッショナルネットワークにおける友人推薦システムは、ユーザーが友人を見つけ、つながりを築くのを助け、ユーザーエンゲージメントとリテンションの向上に寄与します。従来の友人推薦システムは、局所性の原理を利用し、グラフトラバーサルを用いて友人候補を取得することが多いです。例えば、友人の友人（FoF）です。このアプローチは、LinkedInやFacebookなどの大規模なオンラインネットワークを持つ企業で採用され、その効果が示されていますが、いくつかの課題があります：(i) 離散グラフトラバーサルは、コールドスタートの状況でのリーチが制限される、(ii) レイテンシ制約により、リアルタイム設定では1ホップや2ホップを超えるリクエストは高価で実現不可能である、(iii) グラフのトポロジーや接続の強度の複雑さをうまく捉えられず、上位の候補者をランク付けし見つけるために他のメカニズムに頼る必要がある。本論文では、友人候補を取得するための新しい埋め込みベースの検索（EBR）システムを提案し、従来のFoF検索を補完しつつ、2ホップを超える候補の取得とFoF候補の自然なランク付けを可能にします。オンラインA/Bテストを通じて、低密度および高密度のネットワーク市場の両方で、追加の検索ソースとしてEBRを使用した場合の友情形成数の統計的に有意な改善を観察しました。本研究の貢献は、Snapchatの大規模な友人推薦システムに新しい検索システムを展開し、グラフニューラルネットワークを用いて数十億のユーザーのための埋め込みを生成し、Snapchat規模をサポートするためのEBRインフラストラクチャを構築したことです。
        </label>
        <input type="checkbox" id="Panel419" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Friend recommendation systems in online social and professional networks such as Snapchat helps users find friends and build connections, leading to better user engagement and retention. Traditional friend recommendation systems take advantage of the principle of locality and use graph traversal to retrieve friend candidates, e.g. Friends-of-Friends (FoF). While this approach has been adopted and shown efficacy in companies with large online networks such as Linkedin and Facebook, it suffers several challenges: (i) discrete graph traversal offers limited reach in cold-start settings, (ii) it is expensive and infeasible in realtime settings beyond 1 or 2 hop requests owing to latency constraints, and (iii) it cannot well-capture the complexity of graph topology or connection strengths, forcing one to resort to other mechanisms to rank and find top-K candidates. In this paper, we proposed a new Embedding Based Retrieval (EBR) system for retrieving friend candidates, which complements the traditional FoF retrieval by retrieving candidates beyond 2-hop, and providing a natural way to rank FoF candidates. Through online A/B test, we observe statistically significant improvements in the number of friendships made with EBR as an additional retrieval source in both low- and high-density network markets. Our contributions in this work include deploying a novel retrieval system to a large-scale friend recommendation system at Snapchat, generating embeddings for billions of users using Graph Neural Networks, and building EBR infrastructure in production to support Snapchat scale.
        </div> </ul> <br>



        <label for="Panel420">
        <strong> Modeling Spoken Information Queries for Virtual Assistants: Open Problems, Challenges and Opportunities </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Christophe+Van+Gysel">Christophe Van Gysel</a> (1) </u>  <br>
        1:  Apple <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591849">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Modeling Spoken Information Queries for Virtual Assistants: Open Problems, Challenges and Opportunities">Google Scholar</a></div>
        (420)
        <br>
        <b>概要:　</b> バーチャルアシスタントは、さまざまなタスクを支援する音声駆動の情報検索プラットフォームとしてますます重要性を増しています。本稿では、バーチャルアシスタントに対する音声情報クエリのモデリングに関する未解決の問題と課題を論じ、情報検索手法および研究がバーチャルアシスタントの音声認識の質を向上させるために適用できる機会を列挙します。具体的には、クエリドメイン分類、ナレッジグラフおよびユーザーインタラクションデータ、クエリのパーソナライズが音声情報ドメインクエリの正確な認識向上にどのように役立つかについて議論します。最後に、音声認識における現在の問題と課題のも簡潔に述べます。
        </label>
        <input type="checkbox" id="Panel420" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Virtual assistants are becoming increasingly important speech-driven Information Retrieval platforms that assist users with various tasks. We discuss open problems and challenges with respect to modeling spoken information queries for virtual assistants, and list opportunities where Information Retrieval methods and research can be applied to improve the quality of virtual assistant speech recognition. We discuss how query domain classification, knowledge graphs and user interaction data, and query personalization can be helpful to improve the accurate recognition of spoken information domain queries. Finally, we also provide a brief overview of current problems and challenges in speech recognition.
        </div> </ul> <br>



        <label for="Panel421">
        <strong> Personalized Stock Recommendation with Investors' Attention and Contextual Information </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Takehiro+Takayanagi">Takehiro Takayanagi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Kiyoshi+Izumi">Kiyoshi Izumi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Atsuo+Kato">Atsuo Kato</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Naoyuki+Tsunedomi">Naoyuki Tsunedomi</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yukina+Abe">Yukina Abe</a> (4) </u>  <br>
        1:  The University of Tokyo, 2:  Daiwa Institute of Research Ltd., 3:  Daiwa Securities Group Inc., 4:  CONNECT Co.Ltd. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591850">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Personalized Stock Recommendation with Investors' Attention and Contextual Information">Google Scholar</a></div>
        (421)
        <br>
        <b>概要:　</b> パーソナライズされた株式推薦は、各投資家に適した株式を推奨するタスクです。特に投資意思決定において、パーソナライズされた推薦は価値があります。なぜなら、個々の個人投資家の目的に応じてポートフォリオの構築が異なるからです。本論文では、投資家の注意と文脈情報を取り入れたパーソナライズされた株式推薦（PSRIC）を提案します。PSRICは、投資家の金融意思決定プロセスを株式推薦に組み込むことを目的としており、投資家モデリングモジュールと文脈モジュールの2つのモジュールで構成されています。投資家モデリングモジュールは、様々な株式情報に対する投資家の注意をモデル化します。文脈モジュールは、株式の動向と投資家のプロフィールを取り入れます。結果として、提案モデルがベースラインモデルを上回り、アブレーションスタディで両モジュールの有用性が確認されました。
        </label>
        <input type="checkbox" id="Panel421" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The personalized stock recommendation is a task to recommend suitable stocks for each investor. The personalized recommendations are valuable, especially in investment decision making as the objective of building a portfolio varies by each retail investor. In this paper, we propose a Personalized Stock Recommendation with Investors' Attention and Contextual Information (PSRIC). PSRIC aims to incorporate investors' financial decision-making process into a stock recommendation, and it consists of an investor modeling module and a context module. The investor modeling module models the investor's attention toward various stock information. The context module incorporates stock dynamics and investor profiles. The result shows that the proposed model outperforms the baseline models and verifies the usefulness of both modules in ablation studies.
        </div> </ul> <br>



        <label for="Panel422">
        <strong> Synerise Monad: A Foundation Model for Behavioral Event Data </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Barbara+Rychalska">Barbara Rychalska</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Szymon+Lukasik">Szymon Lukasik</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jacek+Dabrowski">Jacek Dabrowski</a> (3) </u>  <br>
        1:  Synerise & Warsaw University of Technology, 2:  Synerise & AGH University of Science and Technology, 3:  Synerise <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591851">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Synerise Monad: A Foundation Model for Behavioral Event Data">Google Scholar</a></div>
        (422)
        <br>
        <b>概要:　</b> 産業用グレードのイベントベースデータレイクの複雑さは、時間とともに動的に増大します。企業は、クリック、いいね、ページビュー、カード取引、バスケットに追加、購入イベントなどの複数のタイプのイベントを記録し、顧客の行動情報を活発に収集しています。この状況に対応するために、SyneriseのMonadプラットフォームが提案されました。Monadの主な焦点は、各ユーザーの行動パターンをカプセル化した大規模ベクトルであるユニバーサル行動表現（UBRs）を生成することです。UBRsは、集約された特徴や平均化された埋め込みと異なり、個々のイベントに関する情報を失いません。これらは、Syneriseで開発された受賞歴のあるアルゴリズム、CleoraとEMDEに基づいており、数十億のイベントで構成される実世界のデータセットを最速で処理することができます。本論文では、Monadの新しい側面として、UBRsを基に訓練されたプライベート基礎モデルを紹介します。基礎モデルは完全に自己教師型の方法で訓練されており、人間の行動に関する一般的な知識を活用することができ、特に複数の下流モデルを訓練する必要があり、時間の制約が厳しい場合や、ラベル付きデータが不足している場合に役立ちます。実験結果は、Monadの基礎モデルがトレーニング時間を半分に短縮し、最適な結果に到達するために必要なデータ量を3分の1に減少させることができ、しばしば最先端の結果を達成することを示しています。
        </label>
        <input type="checkbox" id="Panel422" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The complexity of industry-grade event-based datalakes grows dynamically each passing hour. Companies actively gather behavioral information on their customers, recording multiple types of events, such as clicks, likes, page views, card transactions, add-to-basket, or purchase events. In response to this, the Synerise Monad platform has been proposed. The primary focus of Monad is to produce Universal Behavioral Representations (UBRs) - large vectors encapsulating the behavioral patterns of each user. UBRs do not lose knowledge about individual events, in contrast to aggregated features or averaged embeddings. They are based on award-winning algorithms developed at Synerise - Cleora and EMDE - and allow to process real-life datasets composed of billions of events in record time. In this paper, we introduce a new aspect of Monad: private foundation models for behavioral data, trained on top of UBRs. The foundation models are trained in purely self-supervised manner and allow to exploit general knowledge about human behavior, which proves especially useful when multiple downstream models must be trained and time constraints are tight, or when labeled data is scarce. Experimental results show that the Monad foundation models can cut training time in half and require 3x less data to reach optimal results, often achieving state-of-the-art results.
        </div> </ul> <br>



        <label for="Panel423">
        <strong> Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hsiu-Wei+Yang">Hsiu-Wei Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Abhinav+Agrawal">Abhinav Agrawal</a> (2) </u>  <br>
        1:  Thomson Reuters Labs, 2:  Thomson Reuters Labs <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591852">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection">Google Scholar</a></div>
        (423)
        <br>
        <b>概要:　</b> 情報検索タスクにおいて、正確な固有表現認識（NER）は非常に重要です。しかし、従来のNER手法が大きく進展しているにもかかわらず、複雑な固有表現の抽出は未だに比較的未開拓の分野です。本論文では、文書レイアウト解析（DLA）のための物体検出と弱教師あり学習を組み合わせて、法律文書における非連続で複雑な固有表現の抽出に取り組む新しいシステムを提案します。特に、私たちの知る限り、弱い教師あり学習をDLAに適用するのは本研究が初めてです。実験結果から、擬似ラベルのみで訓練されたモデルが、標準的なデータが限られている場合において、教師ありベースラインを上回ることが示されました。これは、注釈データへの依存を減らすという我々の提案手法の有効性を強調するものです。
        </label>
        <input type="checkbox" id="Panel423" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Accurate Named Entity Recognition (NER) is crucial for various information retrieval tasks in industry. However, despite significant progress in traditional NER methods, the extraction of Complex Named Entities remains a relatively unexplored area. In this paper, we propose a novel system that combines object detection for Document Layout Analysis (DLA) with weakly supervised learning to address the challenge of extracting discontinuous complex named entities in legal documents. Notably, to the best of our knowledge, this is the first work to apply weak supervision to DLA. Our experimental results show that the model trained solely on pseudo labels outperforms the supervised baseline when gold-standard data is limited, highlighting the effectiveness of our proposed approach in reducing the dependency on annotated data.
        </div> </ul> <br>



        <label for="Panel424">
        <strong> Exploring the Spatiotemporal Features of Online Food Recommendation Service </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shaochuan+Lin">Shaochuan Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jiayan+Pei">Jiayan Pei</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Taotao+Zhou">Taotao Zhou</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hengxu+He">Hengxu He</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jia+Jia">Jia Jia</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ning+Hu">Ning Hu</a> (1) </u>  <br>
        1:  Alibaba Group, 2:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591853">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Exploring the Spatiotemporal Features of Online Food Recommendation Service">Google Scholar</a></div>
        (424)
        <br>
        <b>概要:　</b> オンライン食品推薦サービス (OFRS) は、時空間的な特徴を有しており、ユーザーのニーズを迅速かつ便利に満たす利点を持ちます。これまで、OFRS の時空間的特性を探るためのさまざまな研究が行われてきましたが、包括的かつ詳細な分析はまだ実施されていません。そこで本論文では、OFRS の時空間的特徴を三つの問いに基づいて研究します：時空間的特徴がどのように役立つか、自己注意がなぜ OFRS の時空間シーケンスのモデリングに適していないか、そして時空間的特徴をどのように組み合わせて OFRS の効率を向上させるかです。まず、実験的な分析を通じて、OFRS の時空間的特徴を体系的に抽出し、最も価値のある特徴を特定し、効果的な組み合わせ手法を設計しました。次に、時空間シーケンスの詳細な分析を行い、OFRS における自己注意の欠点を明らかにし、自己注意を代替するためのより最適化された時空間シーケンス手法を提案しました。さらに、OFRS の効率と性能を向上させるために、動的コンテキスト適応モデルを設計しました。二つの大規模データセットでのオフライン実験と、1週間にわたるオンライン実験を通じて、我々のモデルの実現可能性と優越性が証明されました。
        </label>
        <input type="checkbox" id="Panel424" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Online Food Recommendation Service (OFRS) has remarkable spatiotemporal characteristics and the advantage of being able to conveniently satisfy users' needs in a timely manner. There have been a variety of studies that have begun to explore its spatiotemporal properties, but a comprehensive and in-depth analysis of the OFRS spatiotemporal features is yet to be conducted. Therefore, this paper studies the OFRS based on three questions: how spatiotemporal features play a role; why self-attention cannot be used to model the spatiotemporal sequences of OFRS; and how to combine spatiotemporal features to improve the efficiency of OFRS. Firstly, through experimental analysis, we systemically extracted the spatiotemporal features of OFRS, identified the most valuable features and designed an effective combination method. Secondly, we conducted a detailed analysis of the spatiotemporal sequences, which revealed the shortcomings of self-attention in OFRS, and proposed a more optimized spatiotemporal sequence method for replacing self-attention. In addition, we also designed a Dynamic Context Adaptation Model to further improve the efficiency and performance of OFRS. Through the offline experiments on two large datasets and online experiments for a week, the feasibility and superiority of our model were proven.
        </div> </ul> <br>



        <label for="Panel425">
        <strong> Alleviating Matching Bias in Marketing Recommendations </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Junpeng+Fang">Junpeng Fang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qing+Cui">Qing Cui</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gongduo+Zhang">Gongduo Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Caizhi+Tang">Caizhi Tang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lihong+Gu">Lihong Gu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Longfei+Li">Longfei Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinjie+Gu">Jinjie Gu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fei+Wu">Fei Wu</a> (2) </u>  <br>
        1:  Ant Group, 2:  Zhejiang University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591854">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Alleviating Matching Bias in Marketing Recommendations">Google Scholar</a></div>
        (425)
        <br>
        <b>概要:　</b> マーケティングにおける推薦システムでは、キャンペーン主催者がユーザーに対してクーポンを配布し、消費を促進します。一般的に、クーポン配布プロセスに介入する一連の戦略が用いられ、ユーザーとクーポンの相互作用の不均衡が増大し、転換確率の推定に偏りが生じます。この推定の偏りを、我々は「マッチングバイアス」と呼びます。本論文では、因果効果の観点からマッチングバイアスを緩和する方法を探ります。ユーザーとクーポンの歴史的な分布を交絡因子とみなし、ユーザー-クーポンの表現と転換確率の間の偽相関を明らかにし、排除するために交絡効果としてマッチングバイアスを特徴付けます。次に、モデル訓練中に裏口調整を用いて交絡効果を排除する新しいトレーニングパラダイム「De-Matching Bias Recommendation (DMBR)」を提案します。我々はDMBRを2つの代表的なモデル、DNNとMMOEに実装し、提案したパラダイムの有効性を示すために広範なオフラインおよびオンライン実験を行いました。
        </label>
        <input type="checkbox" id="Panel425" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In marketing recommendations, the campaign organizers will distribute coupons to users to encourage consumption. In general, a series of strategies are employed to interfere with the coupon distribution process, leading to a growing imbalance between user-coupon interactions, resulting in a bias in the estimation of conversion probabilities. We refer to the estimation bias as the matching bias. In this paper, we explore how to alleviate the matching bias from the causal-effect perspective. We regard the historical distributions of users and coupons over each other as confounders and characterize the matching bias as a confounding effect to reveal and eliminate the spurious correlations between user-coupon representations and conversion probabilities. Then we propose a new training paradigm named De-Matching Bias Recommendation (DMBR) to remove the confounding effects during model training via the backdoor adjustment. We instantiate DMBR on two representative models: DNN and MMOE, and conduct extensive offline and online experiments to demonstrate the effectiveness of our proposed paradigm.
        </div> </ul> <br>



        <label for="Panel426">
        <strong> GreenSeq: Automatic Design of Green Networks for Sequential Recommendation Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yankun+Ren">Yankun Ren</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinxing+Yang">Xinxing Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xingyu+Lu">Xingyu Lu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Longfei+Li">Longfei Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jun+Zhou">Jun Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jinjie+Gu">Jinjie Gu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Guannan+Zhang">Guannan Zhang</a> (1) </u>  <br>
        1:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591855">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=GreenSeq: Automatic Design of Green Networks for Sequential Recommendation Systems">Google Scholar</a></div>
        (426)
        <br>
        <b>概要:　</b> トランスフォーマーベースのモデルは、シーケンシャルレコメンデーション（SR）において大きな成功を収めていますが、特に推論段階で過剰な計算リソースを消費するという問題があります。そのため、効率的でありながら効果的なSRモデルの開発が産業界において頻繁に求められています。これはGreen AIやGreen IRの理想にも合致します。本応用論文では、Alipayに導入されたGreenSeqを紹介し、SRにおいて計算コストを削減しながら適切なレコメンデーションを提供できるグリーンネットワークを自動的に設計する方法を説明します。具体的には、GreenSeqは柔軟なネットワーク設計を可能にする新しい多層の探索空間と、効率性と効果のバランスを取るための「Greenness-aware」損失項を使用しています。ベンチマークデータセットおよびA/Bテストの実験結果から、GreenSeqはリソースの使用を抑えつつ高いパフォーマンスを示すことが確認されました。さらに、GreenSeqはAlipayにおける電力消費と炭素排出量も削減します。
        </label>
        <input type="checkbox" id="Panel426" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Transformer-based models have achieved tremendous success in sequential recommendation (SR), but they suffer from consuming excessive computational resources, particularly in the inference stage. Thus, developing lightweight yet effective SR models has become a frequent demand in industrial applications, which is also in line with the ideals of Green AI and Green IR. In this applied paper, we introduce GreenSeq deployed in Alipay to automatically design Green networks that can provide appropriate recommendations with lower computational consumption in SR. Specifically, GreenSeq uses a novel multi-layer search space that allows for flexible network design and a Greenness-aware loss term for balancing efficiency and effectiveness. Experiments on benchmark datasets and A/B testing show that GreenSeq performs well while using fewer resources. GreenSeq also reduces electricity and carbon emissions in Alipay.
        </div> </ul> <br>



        <label for="Panel427">
        <strong> DCBT: A Simple But Effective Way for Unified Warm and Cold Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jieyu+Yang">Jieyu Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liang+Zhang">Liang Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yong+He">Yong He</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ke+Ding">Ke Ding</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhaoxin+Huan">Zhaoxin Huan</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaolu+Zhang">Xiaolu Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linjian+Mo">Linjian Mo</a> (2) </u>  <br>
        1:  Ant Group, 2:  Ant Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591856">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=DCBT: A Simple But Effective Way for Unified Warm and Cold Recommendation">Google Scholar</a></div>
        (427)
        <br>
        <b>概要:　</b> コンバージョン率予測のコールドスタート問題は、オンライン広告システムにおける一般的な課題です。この問題を軽減するため、多くの方法がコンテンツ情報や不確実性手法、あるいはメタラーニングに基づいた方法を使用してコールドスタートアイテムのランキング性能を向上させようとしています。しかしながら、これらの方法はコールドスタートのシナリオには有効ですが、ウォームおよびコールドな推奨を1つのモデルに適応的に統一することができないため、異なるシナリオに適応するためには追加の人的努力や知識が必要です。さらに、モデルの予測とコールドアイテムの真の確率との不一致に注意を払わず、過大評価や過小評価は広告配置のROI（投資利益率）に悪影響を与える可能性があります。本論文では、上記の問題に対処するために、Distribution-Constrained Batch Transformer（DCBT）と呼ばれるフレームワークを提案します。具体的には、このフレームワークはバッチ次元にTransformerモジュールを導入し、ウォームサンプルから適切な情報を自動的に選択してコールドサンプルの表現を強化し、ウォームサンプルの特性を保持します。さらに、コールドサンプルの分布がウォームサンプルに影響を受けないようにするため、本フレームワークはTransformerモジュールに入力する前後のサンプル分布をMMD損失で制約します。2つの実世界データセットを用いた広範なオフライン実験により、提案手法がコールドアイテムおよびウォームアイテムにおいてAUCおよびPCOC（予測CVR対CVR）の最先端の性能を達成することを示しました。オンラインA/Bテストでは、DCBTモデルがCVRで20.08%の改善およびGMV（総商品取扱高）で13.21%の増加を達成したことが確認されました。
        </label>
        <input type="checkbox" id="Panel427" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The cold-start problem of conversion rate prediction is a common challenge in online advertising systems. To alleviate this problem, a large number of methods either use content information or uncertainty methods, or use meta-learning based methods to improve the ranking performance of cold-start items. However, they can work for cold-start scenarios but fail to adaptively unify warm and cold recommendations into one model, requiring additional human efforts or knowledge to adapt to different scenarios. Meanwhile, none of them pay attention to the discrepancy between model predictions and true likelihoods of cold items, while over- or under-estimation is harmful to the ROI (Return on Investment) of advertising placements. In this paper, in order to address the above issues, we propose a framework called Distribution-Constrained Batch Transformer (DCBT). Specifically, the framework introduces a Transformer module into the batch dimension to automatically choose proper information from warm samples to enhance the representation of cold samples and preserve the property of warm samples. In addition, to avoid the distribution of cold samples being affected by the warm samples, the framework adds MMD loss to constrain the sample distribution before and after feeding into the Transformer module. Extensive offline experiments on two real-world datasets show that our proposed method attains state-of-the-art performance in AUC and PCOC (Predicted CVR over CVR) for cold items and warm items. An online A/B test demonstrates that the DCBT model obtained a 20.08% improvement in CVR and a 13.21% increase in GMV (Gross Merchandise Volume).
        </div> </ul> <br>



        <label for="Panel428">
        <strong> Building K-Anonymous User Cohorts with Consecutive Consistent Weighted Sampling (CCWS) </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xinyi+Zheng">Xinyi Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Weijie+Zhao">Weijie Zhao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoyun+Li">Xiaoyun Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ping+Li">Ping Li</a> (1) </u>  <br>
        1:  LinkedIn <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591857">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Building K-Anonymous User Cohorts with Consecutive Consistent Weighted Sampling (CCWS)">Google Scholar</a></div>
        (428)
        <br>
        <b>概要:　</b> ユーザーのプライバシーを保護しながら、パーソナライズされたキャンペーンやクリエイティブを提供するために、デジタル広告は会員ベースのアイデンティティからコホートベースのアイデンティティへと移行しています。このようなアイデンティティ体制の下で、類似した特徴を持つユーザーをグループ化するためには、正確で効率的なコホート構築アルゴリズムが求められます。本論文では、K-匿名性を確保しつつスケーラブルなコホート構築アルゴリズムとして、連続一貫性重み付きサンプリング（Consecutive Consistent Weighted Sampling: CCWS）を提案します。提案手法は、（p乗された）一貫性重み付きサンプリング（CWS）と階層クラスタリングの精神を組み合わせることで、コホートのサイズに下限を設けることによりK-匿名性を確保します。LinkedInの7,000万以上のユーザーと広告キャンペーンからなるデータセットに対する評価では、CCWSが符号付きランダム射影（SignRP）、ミンワイズハッシング（MinHash）、およびバニラCWSを含むいくつかのハッシングベースの手法に対し、顕著な改善を示すことが確認されました。
        </label>
        <input type="checkbox" id="Panel428" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> To retrieve personalized campaigns and creatives while protecting user privacy, digital advertising is shifting from member-based identity to cohort-based identity. Under such identity regime, an accurate and efficient cohort building algorithm is desired to group users with similar characteristics. In this paper, we propose a scalable K-anonymous cohort building algorithm called consecutive consistent weighted sampling (CCWS). The proposed method combines the spirit of the (p-powered) consistent weighted sampling (CWS) and hierarchical clustering, so that the K-anonymity is ensured by enforcing a lower bound on the size of cohorts. Evaluations on a LinkedIn dataset consisting of >70M users and ads campaigns demonstrate that CCWS achieves substantial improvements over several hashing-based methods including sign random projections (SignRP), minwise hashing (MinHash), as well as the vanilla CWS.
        </div> </ul> <br>



        <label for="Panel429">
        <strong> Implicit Query Parsing at Amazon Product Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chen+Luo">Chen Luo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rahul+Goutam">Rahul Goutam</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haiyang+Zhang">Haiyang Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chao+Zhang">Chao Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yangqiu+Song">Yangqiu Song</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bing+Yin">Bing Yin</a> (1) </u>  <br>
        1:  Amazon Search, 2:  Gatech, 3:  HKUST <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591858">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Implicit Query Parsing at Amazon Product Search">Google Scholar</a></div>
        (429)
        <br>
        <b>概要:　</b> クエリパーシングは、検索クエリから色、ブランド、製品タイプなどの製品属性を抽出することを目的としています。これらの属性は、検索エンジンにおいてマッチング、ランキング、推薦などのタスクにおいて重要な役割を果たします。製品属性は明示的にクエリに記載されている明示属性と、暗黙的に記載されている暗黙属性の二種類に分かれます。これまでのクエリパーシングに関する研究は、明示クエリパーシングと暗黙クエリパーシングを区別しておらず、その結果、製品検索エンジンのパフォーマンスが制限されています。本研究では、実際の製品検索エンジンにおいて暗黙属性がいかに重要であるかを示します。次に、Amazonの検索エンジンにおける暗黙クエリパーシングに対する当社の解決策を提案します。この解決策は、知識グラフ技術の最新の進歩と顧客行動分析を統合した統一フレームワークです。Amazonの検索ログデータを使ったオフライン実験を通じて、提案手法の有効性を実証します。また、このフレームワークをAmazonの検索エンジンに展開し、顧客のショッピング体験を向上させる方法についても説明します。
        </label>
        <input type="checkbox" id="Panel429" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Query Parsing aims to extract product attributes, such as color, brand, and product type, from search queries. These attributes play a crucial role in search engines for tasks such as matching, ranking, and recommendation. There are two types of attributes: explicit attributes that are mentioned explicitly in the search query, and implicit attributes that are mentioned implicitly. Existing works on query parsing do not differentiate between explicit query parsing and implicit query parsing, which limits their performance in product search engines. In this work, we demonstrate the critical importance of implicit attributes in real-world product search engines. We then present our solution for implicit query parsing at Amazon Search, which is a unified framework combining recent advancements in knowledge graph technologies and customer behavior analysis. We demonstrate the effectiveness of our proposal through offline experiments on Amazon search log data. We also show how to deploy and use the framework on Amazon search to improve customers' shopping experiences.
        </div> </ul> <br>



        <label for="Panel430">
        <strong> Delving into E-Commerce Product Retrieval with Vision-Language Pre-training </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoyang+Zheng">Xiaoyang Zheng</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuyu+Lv">Fuyu Lv</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zilong+Wang">Zilong Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Qingwen+Liu">Qingwen Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaoyi+Zeng">Xiaoyi Zeng</a> (1) </u>  <br>
        1:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591859">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Delving into E-Commerce Product Retrieval with Vision-Language Pre-training">Google Scholar</a></div>
        (430)
        <br>
        <b>概要:　</b> Eコマースの検索エンジンは、ユーザークエリに対しての候補商品のセットを返す取得フェーズと、取得された商品のランキングフェーズから成り立っています。最近では、視覚情報とテキスト情報を組み合わせた視覚言語事前学習が取得タスクにおいて人気です。本論文では、Taobao検索の取得問題を解決するための新しいV+L事前学習手法を提案します。我々は、一般的な回帰ベースの視覚事前学習タスクを凌駕する、対照学習に基づいた視覚事前学習タスクを設計しました。さらに、大規模な取得タスクに適した二つのネガティブサンプリング手法を採用しました。加えて、本手法の現実世界でのオンラインデプロイメントの詳細を紹介します。広範なオフラインおよびオンライン実験により、我々の手法が取得タスクにおいて優れた性能を示すことが証明されました。提案する手法は、Taobao検索の一つの取得チャネルとして採用され、リアルタイムで何億ものユーザーにサービスを提供しています。
        </label>
        <input type="checkbox" id="Panel430" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> E-commerce search engines comprise a retrieval phase and a ranking phase, where the first one returns a candidate product set given user queries. Recently, vision-language pre-training, combining textual information with visual clues, has been popular in the application of retrieval tasks. In this paper, we propose a novel V+L pre-training method to solve the retrieval problem in Taobao Search. We design a visual pre-training task based on contrastive learning, outperforming common regression-based visual pre-training tasks. In addition, we adopt two negative sampling schemes, tailored for the large-scale retrieval task. Besides, we introduce the details of the online deployment of our proposed method in real-world situations. Extensive offline/online experiments demonstrate the superior performance of our method on the retrieval task. Our proposed method is employed as one retrieval channel of Taobao Search and serves hundreds of millions of users in real time.
        </div> </ul> <br>



        <label for="Panel431">
        <strong> Improving Programming Q&A with Neural Generative Augmentation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Suthee+Chaidaroon">Suthee Chaidaroon</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiao+Zhang">Xiao Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shruti+Subramaniyam">Shruti Subramaniyam</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jeffrey+Svajlenko">Jeffrey Svajlenko</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tanya+Shourya">Tanya Shourya</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Iman+Keivanloo">Iman Keivanloo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ria+Joy">Ria Joy</a> (1) </u>  <br>
        1:  Amazon Web Service <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591860">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Improving Programming Q&A with Neural Generative Augmentation">Google Scholar</a></div>
        (431)
        <br>
        <b>概要:　</b> 知識集約型のプログラミングQ&Aは、産業界における活発な研究分野です。その応用は、インターネット上の膨大な情報からプログラミングの回答を速やかに見つけることを支援することで、開発者の生産性を向上させます。本研究では、プログラミングQ&Aを解決するために、ProQANSとその派生形であるReProQANSおよびReAugProQANSを提案します。ProQANSは、インターネット上のラベルなしデータ（例えばStackOverflowなど）を活用し、コールドスタート問題を緩和するニューラル検索手法です。ReProQANSは、新規のトリプレットロスを使用して再構成されたクエリを活用することで、ProQANSを拡張します。さらに、補助生成モデルを使用してトレーニングクエリを増強し、生成されたクエリに適応させるために、独自の二重トリプレットロス関数を設計し、ReProQANSの別の派生形であるReAugProQANSを構築します。我々の実証実験では、インドメインのテストセットで評価した際にはReProQANSが最良の性能を示し、アウトオブドメインの実際のプログラミング質問でも、最新のモデルをMRRメトリックで最大477%上回り、ReAugProQANSが優れた性能を発揮することを示しました。これらの結果は、これらのモデルが未見の質問に対しても頑強であり、実際のプログラミング質問に幅広く応用できることを示唆しています。
        </label>
        <input type="checkbox" id="Panel431" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge-intensive programming Q&A is an active research area in industry. Its application boosts developer productivity by aiding developers in quickly finding programming answers from the vast amount of information on the Internet. In this study, we propose ProQANS and its variants ReProQANS and ReAugProQANS to tackle programming Q&A. ProQANS is a neural search approach that leverages unlabeled data on the Internet (such as StackOverflow) to mitigate the cold-start problem. ReProQANS extends ProQANS by utilizing reformulated queries with a novel triplet loss. We further use an auxiliary generative model to augment the training queries, and design a novel dual triplet loss function to adapt these generated queries, to build another variant of ReProQANS termed as ReAugProQANS. In our empirical experiments, we show ReProQANS has the best performance when evaluated on the in-domain test set, while ReAugProQANS has the superior performance on the out-of-domain real programming questions, by outperforming the state-of-the-art model by up to 477% lift on the MRR metric respectively. The results suggest their robustness to previously unseen questions and its wide application to real programming questions.
        </div> </ul> <br>



        <label for="Panel432">
        <strong> Contextual Multilingual Spellchecker for User Queries </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sanat+Sharma">Sanat Sharma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Josep+Valls-Vargas">Josep Valls-Vargas</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tracy+Holloway+King">Tracy Holloway King</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Francois+Guerin">Francois Guerin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chirag+Arora">Chirag Arora</a> (1) </u>  <br>
        1:  Adobe Inc. <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591861">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Contextual Multilingual Spellchecker for User Queries">Google Scholar</a></div>
        (432)
        <br>
        <b>概要:　</b> スペルチェックは最も基本的かつ広く使用されている検索機能の一つである。誤ってスペルされたユーザークエリを修正することは、ユーザーエクスペリエンスを向上させるだけでなく、ユーザーにも期待されている。しかし、広く利用可能なスペルチェックソリューションのほとんどは、最先端のソリューションと比較して精度が低いか、あるいはレイテンシーが重要な要件である検索ユースケースに使用するには遅すぎる。また、最近の革新的なアーキテクチャの多くは英語に焦点を当てており、多言語対応で訓練されていないことが多く、長いテキストのスペル修正のために訓練されているが、これは多くの場合1〜2語のクエリが多いユーザークエリのスペル修正とは異なるパラダイムである。さらに、多くの企業は製品名のように独自のボキャブラリーを持っているため、市販のスペルチェックソリューションではユーザーのニーズを満たすことができない。本研究では、非常に高速かつスケーラブルで、特定の製品のニーズに基づいてボキャブラリーとスペル出力を適応させる多言語スペルチェッカーを構築する。さらに、我々のスペルチェッカーは、汎用スペルチェッカーを大きく上回る精度で、ドメイン内データセットで性能を発揮する。我々の多言語スペルチェッカーは、Adobe製品内の検索に使用され、さまざまなアプリケーションでオートコンプリートをサポートしている。
        </label>
        <input type="checkbox" id="Panel432" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Spellchecking is one of the most fundamental and widely used search features. Correcting incorrectly spelled user queries not only enhances the user experience but is expected by the user. However, most widely available spellchecking solutions are either lower accuracy than state-of-the-art solutions or too slow to be used for search use cases where latency is a key requirement. Furthermore, most innovative recent architectures focus on English and are not trained in a multilingual fashion and are trained for spell correction in longer text, which is a different paradigm from spell correction for user queries, where context is sparse (most queries are 1-2 words long). Finally, since most enterprises have unique vocabularies such as product names, off-the-shelf spelling solutions fall short of users' needs. In this work, we build a multilingual spellchecker that is extremely fast and scalable and that adapts its vocabulary and hence speller output based on a specific product's needs. Furthermore our speller out-performs general purpose spellers by a wide margin on in-domain datasets. Our multilingual speller is used in search in Adobe products, powering autocomplete in various applications.
        </div> </ul> <br>



        <label for="Panel433">
        <strong> Exploring 360-Degree View of Customers for Lookalike Modeling </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Md+Mostafizur+Rahman">Md Mostafizur Rahman</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Daisuke+Kikuta">Daisuke Kikuta</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Satyen+Abrol">Satyen Abrol</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yu+Hirate">Yu Hirate</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Toyotaro+Suzumura">Toyotaro Suzumura</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pablo+Loyola">Pablo Loyola</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Takuma+Ebisu">Takuma Ebisu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Manoj+Kondapaka">Manoj Kondapaka</a> (2) </u>  <br>
        1:  Rakuten Institute of Technology, 2:  Rakuten Institute of Technology, 3:  The University of Tokyo <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591862">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Exploring 360-Degree View of Customers for Lookalike Modeling">Google Scholar</a></div>
        (433)
        <br>
        <b>概要:　</b> ルックアライクモデルは、ユーザーの類似性が製品販売や広告キャンペーンの向上に重要な役割を果たすという仮定に基づいています。これらのモデルに関連する課題は、ユーザーベースの異質性とその疎さにあります。本研究では、顧客の異なる行動や特徴（例：人口統計データ、異なるプラットフォームでの購買行動、顧客のロイヤルティ行動など）を統合する新しいフレームワークを提案し、楽天グループ株式会社のカスタマーターゲティングを改善するためのルックアライクモデルを構築します。本ルックアライクモデルのユーザーターゲティングタスクにおける有効性は、実際の電子商取引および旅行のデータセットに対する広範な実験を通じて実証されました。
        </label>
        <input type="checkbox" id="Panel433" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Lookalike models are based on the assumption that user similarity plays an important role towards product selling and enhancing the existing advertising campaigns from a very large user base. Challenges associated to these models reside on the heterogeneity of the user base and its sparsity. In this work, we propose a novel framework that unifies the customers' different behaviors or features such as demographics, buying behaviors on different platforms, customer loyalty behaviors and build a lookalike model to improve customer targeting for Rakuten Group, Inc. Extensive experiments on real e-commerce and travel datasets demonstrate the effectiveness of our proposed lookalike model for user targeting task.
        </div> </ul> <br>



        <label for="Panel434">
        <strong> Semantic-enhanced Modality-asymmetric Retrieval for Online E-commerce Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhigong+Zhou">Zhigong Zhou</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ning+Ding">Ning Ding</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaochuan+Fan">Xiaochuan Fan</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yue+Shang">Yue Shang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yiming+Qiu">Yiming Qiu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jingwei+Zhuo">Jingwei Zhuo</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiwei+Ge">Zhiwei Ge</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Songlin+Wang">Songlin Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lin+Liu">Lin Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sulong+Xu">Sulong Xu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Han+Zhang">Han Zhang</a> (1) </u>  <br>
        1:  JD.com, 2:  JD.com <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591863">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Semantic-enhanced Modality-asymmetric Retrieval for Online E-commerce Search">Google Scholar</a></div>
        (434)
        <br>
        <b>概要:　</b> セマンティックリトリーバル（意味検索リトリーバル）は、テキストクエリに基づいて意味的に一致するアイテムを検索するものであり、eコマース検索のシステム効果を向上させるための重要な要素です。本論文では、マルチモーダルリトリーバルの問題を研究します。これは、アイテムの視覚情報（例：画像）をテキスト情報の補足として活用し、アイテムの表現を豊かにし、検索性能をさらに向上させるものです。クロスモダリティデータからの学習は、視覚質問応答やメディアなどのタスクで広く研究されていますが、マルチモーダルリトリーバルは、特にクエリが単一モダリティでアイテムがマルチモダリティである非対称シナリオにおいて、依然として非自明かつ未解決の問題です。本論文では、このような非対称シナリオにおけるモダリティ融合と整合の問題を解決するために、SMAR（Semantic-enhanced Modality-Asymmetric Retrieval）という新しいモデルを提案します。産業データセットにおける広範な実験結果から、提案モデルがリトリーバル精度においてベースラインモデルを大幅に上回ることが示されました。我々は、再現性および将来の研究のために、産業データセットをオープンソース化しています。
        </label>
        <input type="checkbox" id="Panel434" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Semantic retrieval, which retrieves semantically matched items given a textual query, has been an essential component to enhance system effectiveness in e-commerce search. In this paper, we study the multimodal retrieval problem, where the visual information (e.g, image) of item is leveraged as supplementary of textual information to enrich item representation and further improve retrieval performance. Though learning from cross-modality data has been studied extensively in tasks such as visual question answering or media summarization, multimodal retrieval remains a non-trivial and unsolved problem especially in the asymmetric scenario where the query is unimodal while the item is multimodal. In this paper, we propose a novel model named SMAR, which stands for Semantic-enhanced Modality-Asymmetric Retrieval, to tackle the problem of modality fusion and alignment in this kind of asymmetric scenario. Extensive experimental results on an industrial dataset show that the proposed model outperforms baseline models significantly in retrieval accuracy. We have open sourced our industrial dataset for the sake of reproducibility and future research works.
        </div> </ul> <br>



        <label for="Panel435">
        <strong> OFAR: A Multimodal Evidence Retrieval Framework for Illegal Live-streaming Identification </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dengtian+Lin">Dengtian Lin</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Ma">Yang Ma</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yuhong+Li">Yuhong Li</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuemeng+Song">Xuemeng Song</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jianlong+Wu">Jianlong Wu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Liqiang+Nie">Liqiang Nie</a> (1) </u>  <br>
        1:  Shandong University, 2:  Alibaba Group <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591864">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=OFAR: A Multimodal Evidence Retrieval Framework for Illegal Live-streaming Identification">Google Scholar</a></div>
        (435)
        <br>
        <b>概要:　</b> 違法ライブストリーミングの識別は、貴重で絶滅危惧種の動物の販売など、ライブストリーミング中の違法行為を即座に認識するために、ライブストリーミングプラットフォームがネットワーク環境を浄化する上で重要な役割を果たします。従来、ライブストリーミングプラットフォームは、潜在的な違法ライブストリーミングを手動で識別するために、プロフェッショナルを雇う必要がありました。具体的には、プロフェッショナルは、大規模な知識データベースから関連する証拠を検索し、特定のライブストリーミングクリップが違法行為を含んでいるかどうかを評価する必要があり、これは時間がかかり、労力を要します。この問題に対処するために、本研究では、違法ライブストリーミング識別を支援するためのマルチモーダル証拠検索システムOFARを提案します。OFARは、クエリエンコーダ、ドキュメントエンコーダ、およびMaxSimに基づくコントラスト学習の3つのモジュールで構成されています。クエリエンコーダとドキュメントエンコーダは、最先端のOFAエンコーダを使用しており、大規模なマルチモーダルデータセットで事前学習されています。最後のモジュールでは、クエリとドキュメントの一致能力を強化するために、MaxiSimベースの後期交差に基づいたコントラスト学習を導入しています。提案されたフレームワークは、我々の産業用データセットTaoLiveで顕著な改善を達成し、技術の進歩を実証しています。
        </label>
        <input type="checkbox" id="Panel435" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Illegal live-streaming identification, which aims to help live-streaming platforms immediately recognize the illegal behaviors in the live-streaming, such as selling precious and endangered animals, plays a crucial role in purifying the network environment. Traditionally, the live-streaming platform needs to employ some professionals to manually identify the potential illegal live-streaming. Specifically, the professional needs to search for related evidence from a large-scale knowledge database for evaluating whether a given live-streaming clip contains illegal behavior, which is time-consuming and laborious. To address this issue, in this work, we propose a multimodal evidence retrieval system, named OFAR, to facilitate the illegal live-streaming identification. OFAR consists of three modules: Query Encoder, Document Encoder, and MaxSim-based Contrastive Late Intersection. Both query encoder and document encoder are implemented with the advanced OFA encoder, which is pretrained on a large-scale multimodal dataset. In the last module, we introduce contrastive learning on the basis of the MaxiSim-based late intersection, to enhance the model's ability of query-document matching. The proposed framework achieves significant improvement on our industrial dataset TaoLive, demonstrating the advances of our scheme.
        </div> </ul> <br>



        <label for="Panel436">
        <strong> How Well do Offline Metrics Predict Online Performance of Product Ranking Models? </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaojie+Wang">Xiaojie Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruoyuan+Gao">Ruoyuan Gao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Anoop+Jain">Anoop Jain</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Graham+Edge">Graham Edge</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sachin+Ahuja">Sachin Ahuja</a> (1) </u>  <br>
        1:  Amazon.com, 2:  Amazon.com <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591865">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=How Well do Offline Metrics Predict Online Performance of Product Ranking Models?">Google Scholar</a></div>
        (436)
        <br>
        <b>概要:　</b> オンライン評価技術は、産業用検索エンジンによって広く採用されており、ビジネス指標の下でどのランキングモデルがより優れているかを判断するために利用されています。しかし、オンライン評価では評価できるランカーの数が限られているため、多くの人は良好なオンラインパフォーマンスをもたらす可能性が高いランカーを選択するためにオフライン評価に頼ります。効果的なモデル選択のためにオフライン指標を使用する際の主要な課題は、オフライン指標がどの程度オンライン実験でより良いパフォーマンスを発揮するランキングモデルを予測するか理解することです。本論文は、商品検索ランキングにおけるこの課題に取り組むことを目指しています。具体的には、eコマース検索エンジンにおけるビジネス指標の下でランカーペアに対する好みの形でゴールドデータを収集しました。初めて、このようなゴールドデータを使用して、ビジネス指標との方向性の一致に基づいてオフライン指標を評価します。さらに、対応のあるサンプルのt検定やオフライン指標間の順位相関を通じて、オフライン指標の識別力を分析します。広範なオンラインおよびオフライン実験を通じて、36のオフライン指標を研究し、以下のことを観察しました：(1) オフライン指標はオンライン指標とよく一致しており、二つのランキングモデルのどちらが優れているかについて最大97%の確率で一致します；(2) 特にNDCG（正規化割引累積利得）において、オフライン指標は大規模な検索ランキングデータにおいて99%以上の識別力を有します。
        </label>
        <input type="checkbox" id="Panel436" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Online evaluation techniques are widely adopted by industrial search engines to determine which ranking models perform better under a certain business metric. However, online evaluation can only evaluate a small number of rankers and people resort to offline evaluation to select rankers that are likely to yield good online performance. To use offline metrics for effective model selection, a major challenge is to understand how well offline metrics predict which ranking models perform better in online experiments. This paper aims to address this challenge in product search ranking. Towards this end, we collect gold data in the form of preferences over ranker pairs under a business metric in e-commerce search engine. For the first time, we use such gold data to evaluate offline metrics in terms of directional agreement with the business metric. Furthermore, we analyze offline metrics in terms of discriminative power through paired sample t-test and rank correlations among offline metrics. Through extensive online and offline experiments, we studied 36 offline metrics and observed that: (1) Offline metrics align well with online metrics: they agree on which one of two ranking models is better up to 97% of times; (2) Offline metrics are highly discriminative on large-scale search ranking data, especially NDCG (Normalized Discounted Cumulative Gain) which has a discriminative power over 99%.
        </div> </ul> <br>



        <label for="Panel437">
        <strong> AttriBERT - Session-based Product Attribute Recommendation with BERT </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Akshay+Jagatap">Akshay Jagatap</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Nikki+Gupta">Nikki Gupta</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sachin+Farfade">Sachin Farfade</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Prakash+Mandayam+Comar">Prakash Mandayam Comar</a> (1) </u>  <br>
        1:  Amazon <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3594714">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=AttriBERT - Session-based Product Attribute Recommendation with BERT">Google Scholar</a></div>
        (437)
        <br>
        <b>概要:　</b> 数百万の製品が存在するeコマースサイトで適切な製品を見つけることは、多くの顧客にとって非常に困難な作業です。検索ページでは、製品属性フィルター、いわゆる「絞り込み」が、顧客が選択した製品属性（例：シャツの場合、素材:コットン、カラー:ブラック）に基づいて検索結果を絞り込むための便利なナビゲーションオプションとして浮上します。しかし、モバイルデバイスでは、画面スペースの制約により絞り込みが容易には発見されません。この発見性を向上させるために、絞り込み推薦システムによって文脈に関連した絞り込みが検索ページ内で提案されます。現存の絞り込み推奨方式は主に検索コンテキストを入力として利用し、顧客が明示的（explicit）に示した集約された絞り込みの好みに基づいて訓練されています。しかし、これらのソリューションは、顧客が買い物中に示す暗黙的（implicit）な好みをセッション内の閲覧活動を通じて捉えることができません。本論文では、セッション内で以前に閲覧された製品のシーケンスに基づいて顧客の製品属性の好みを推論し、絞り込みを推奨するセッションベースの推薦システム（SBRS）を提案します。絞り込み推奨のタスクに対して、a) BERTアーキテクチャを拡張して製品の属性値から学習するAttriBERTモデルと、b) 各製品を属性:値ペア（例：メモリサイズ:64GB）の辞書として表現する新しい製品表現戦略を提案します。我々のアプローチは、RecSys 2022 ChallengeおよびAmazonのeコマースデータセットを用いて評価されました。その結果、我々のアプローチはセッションベースの絞り込み推薦のタスクにおいて、さまざまな最新のシーケンスモデルを一貫して上回るパフォーマンスを示しました。
        </label>
        <input type="checkbox" id="Panel437" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Finding the right product on e-commerce websites with millions of products is a daunting task for a large set of customers. On the search page, product attribute filters a.k.a. "refinements" emerge as a convenient navigational option for customers to narrow down the search results along product attributes of their choice (e.g., Material:Cotton, Color:Black for 'shirt'). However, on mobile devices, refinements are not easily discoverable due to lack of screen space. To improve discoverability, contextually relevant refinements are suggested in-line on search page by refinement recommendation systems. Existing works on refinement recommendations primarily rely on the search context as input, and are trained using aggregated refinement preferences 'explicitly' expressed by customers. These solutions fail to capture 'implicit' preferences expressed during the customer shopping mission through in-session browsing activity. In this paper, we propose a session-based recommendation system (SBRS) which recommends refinements by inferring product attribute preferences of customers based on the sequence of products viewed earlier in the session. For the task of refinement recommendation, we propose a) AttriBERT, a model which extends BERT architecture to learn from the attribute values of products and b) a novel product representation strategy, which represents each product as a dictionary of attribute:value pairs (e.g., RAM Size:64GB). We evaluate our approach on RecSys 2022 Challenge and Amazon e-commerce datasets. Our approach consistently outperforms various state-of-the-art sequence models on the task of session-based refinement recommendation.
        </div> </ul> <br>



        <label for="Panel438">
        <strong> Uncertainty Quantification for Text Classification </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dell+Zhang">Dell Zhang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Murat+Sensoy">Murat Sensoy</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Masoud+Makrehchi">Masoud Makrehchi</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Bilyana+Taneva-Popova">Bilyana Taneva-Popova</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lin+Gui">Lin Gui</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yulan+He">Yulan He</a> (6) </u>  <br>
        1:  Thomson Reuters Labs, 2:  Amazon Alexa AI, 3:  Thomson Reuters Labs, 4:  Thomson Reuters Labs, 5:  King's College London, 6:  King's College London & The Alan Turing Institute <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3594243">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Uncertainty Quantification for Text Classification">Google Scholar</a></div>
        (438)
        <br>
        <b>概要:　</b> この一日チュートリアルは、マルチクラスおよびマルチラベルのテキスト分類における実用的な不確実性定量化のための現代的技術を紹介します。まず、テキスト分類モデルにおけるアレアトリック・アンセレティとエピステミック・アンセレティの推定の有用性を説明します。次に、不確実性定量化におけるいくつかの最先端のアプローチを記述し、それらの大規模テキストデータに対するスケーラビリティを分析します。具体的には、GBDTにおけるバーチャルアンサンブル、ベイジアンディープラーニング（ディープアンサンブル、モンテカルロドロップアウト、バックプロップによるベイズ、およびその一般化としてのエピステミックニューラルネットワークを含む）、証拠深層学習（プライアネットワークおよびポスタネットワークを含む）、および距離認識手法（スペクトラル正規化ニューラルガウス過程やディープディターミニスティック不確実性を含む）を取り上げます。次に、事前学習言語モデルにおける不確実性定量化の最新の進展について説明します（言語モデルに不確実性を表現させる方法、大規模言語モデルに基づいたテキスト分類器の不確実性解釈、テキスト生成における不確実性推定、言語モデルのキャリブレーション、およびコンテクスト学習におけるキャリブレーションを含む）。その後、不確実性定量化の典型的な応用シナリオについて議論します（ドメイン内キャリブレーション、クロスドメインロバストネス、および新しいクラスの検出を含む）。最後に、テキスト分類における不確実性定量化の効果を評価するための人気のある性能指標を紹介します。参加者には、CLINC150などの実データセットにおいてさまざまな不確実性定量化方法を実験するための実践的な例題や演習が提供されます。
        </label>
        <input type="checkbox" id="Panel438" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This full-day tutorial introduces modern techniques for practical uncertainty quantification specifically in the context of multi-class and multi-label text classification. First, we explain the usefulness of estimating aleatoric uncertainty and epistemic uncertainty for text classification models. Then, we describe several state-of-the-art approaches to uncertainty quantification and analyze their scalability to big text data: Virtual Ensemble in GBDT, Bayesian Deep Learning (including Deep Ensemble, Monte-Carlo Dropout, Bayes by Backprop, and their generalization Epistemic Neural Networks), Evidential Deep Learning (including Prior Networks and Posterior Networks), as well as Distance Awareness (including Spectral-normalized Neural Gaussian Process and Deep Deterministic Uncertainty). Next, we talk about the latest advances in uncertainty quantification for pre-trained language models (including asking language models to express their uncertainty, interpreting uncertainties of text classifiers built on large-scale language models, uncertainty estimation in text generation, calibration of language models, and calibration for in-context learning). After that, we discuss typical application scenarios of uncertainty quantification in text classification (including in-domain calibration, cross-domain robustness, and novel class detection). Finally, we list popular performance metrics for the evaluation of uncertainty quantification effectiveness in text classification. Practical hands-on examples/exercises are provided to the attendees for them to experiment with different uncertainty quantification methods on a few real-world text classification datasets such as CLINC150.
        </div> </ul> <br>



        <label for="Panel439">
        <strong> Neural Methods for Cross-Language Information Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Eugene+Yang">Eugene Yang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dawn+Lawrie">Dawn Lawrie</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=James+Mayfield">James Mayfield</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Suraj+Nair">Suraj Nair</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Douglas+W.+Oard">Douglas W. Oard</a> (2) </u>  <br>
        1:  Johns Hopkins University, 2:  University of Maryland <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3594244">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Neural Methods for Cross-Language Information Retrieval">Google Scholar</a></div>
        (439)
        <br>
        <b>概要:　</b> 本半日のチュートリアルは、参加者にニューラルクロスランゲージ情報検索（CLIR）の基本概念を紹介します。主に現代的なニューラル手法に焦点を当て、CLIRの歴史、CLIRのトレーニングコレクション、テストコレクション、ベースラインシステムの入手方法と使用方法、CLIRトレーニングおよびテストコレクションの構築方法、そしてCLIRにおけるオープンな研究課題について論じます。
        </label>
        <input type="checkbox" id="Panel439" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This half day tutorial introduces the participant to the basic concepts underlying neural Cross-Language Information Retrieval (CLIR). It discusses the most common algorithmic approaches to CLIR, focusing on modern neural methods; the history of CLIR; where to find and how to use CLIR training collections, test collections and baseline systems; how CLIR training and test collections are constructed; and open research questions in CLIR.
        </div> </ul> <br>



        <label for="Panel440">
        <strong> Causal Recommendation: Progresses and Future Directions </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenjie+Wang">Wenjie Wang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Zhang">Yang Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Haoxuan+Li">Haoxuan Li</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Peng+Wu">Peng Wu</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fuli+Feng">Fuli Feng</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiangnan+He">Xiangnan He</a> (2) </u>  <br>
        1:  University of Science and Technology of China, 2:  University of Science and Technology of China, 3:  University of Science and Technology of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3594245">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Causal Recommendation: Progresses and Future Directions">Google Scholar</a></div>
        (440)
        <br>
        <b>概要:　</b> データ駆動型のレコメンダーシステムは、ユーザーの行動からパターン（即ち相関）を認識する機械学習モデルの卓越した能力のおかげで、様々なWebアプリケーションにおいて大きな成功を収めています。しかし、それでもなお、虚偽の相関によるバイアスや不公平といったいくつかの問題に悩まされ続けています。データの背後にある因果メカニズムを考慮することにより、このような虚偽の相関の影響を避けることができます。この観点から、因果関係に基づくレコメンダーモデリングを採用することは非常に興味深く有望な方向性です。本チュートリアルでは、因果関係の主要な概念を紹介し、因果レコメンデーションに関する既存の研究について体系的なレビューを提供することを目指しています。我々は、潜在結果（PO）フレームワークと構造因果モデル（SCM）の二つの異なる因果フレームワークから既存の方法を紹介します。これら二つのフレームワークの下で、レコメンデーションの問題をモデル化し解決するために、異なる因果ツールをどのように活用するかについて、例と議論を提供します。さらに、POベースとSCMベースのレコメンデーションのパラダイムをまとめ、比較します。また、この分野における未解決の課題と今後の可能性についても指摘します。本チュートリアルがこのトピックに関する新しいアイデアを喚起し、因果関係を考慮したレコメンダーシステムの発展を促進する一助となることを期待しています。
        </label>
        <input type="checkbox" id="Panel440" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Data-driven recommender systems have demonstrated great success in various Web applications owing to the extraordinary ability of machine learning models to recognize patterns (ie correlation) from users' behaviors. However, they still suffer from several issues such as biases and unfairness due to spurious correlations. Considering the causal mechanism behind data can avoid the influences of such spurious correlations. In this light, embracing causal recommender modeling is an exciting and promising direction. In this tutorial, we aim to introduce the key concepts in causality and provide a systemic review of existing work on causal recommendation. We will introduce existing methods from two different causal frameworks --- the potential outcome (PO) framework and the structural causal model (SCM). We will give examples and discussions regarding how to utilize different causal tools under these two frameworks to model and solve problems in recommendation. Moreover, we will summarize and compare the paradigms of PO-based and SCM-based recommendation. Besides, we identify some open challenges and potential future directions for this area. We hope this tutorial could stimulate more ideas on this topic and facilitate the development of causality-aware recommender systems.
        </div> </ul> <br>



        <label for="Panel441">
        <strong> Neuro-Symbolic Representations for Information Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Laura+Dietz">Laura Dietz</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hannah+Bast">Hannah Bast</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shubham+Chatterjee">Shubham Chatterjee</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jeffrey+Dalton">Jeffrey Dalton</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jian-Yun+Nie">Jian-Yun Nie</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Rodrigo+Nogueira">Rodrigo Nogueira</a> (5) </u>  <br>
        1:  University of New Hampshire, 2:  University of Freiburg, 3:  University of Glasgow, 4:  University of Montreal, 5:  State University of Campinas <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3594246">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Neuro-Symbolic Representations for Information Retrieval">Google Scholar</a></div>
        (441)
        <br>
        <b>概要:　</b> 本チュートリアルでは、情報検索におけるニューラルシンボリックアプローチ（neuro-symbolic approaches）の最近の進展について概説します。10年前、知識グラフとセマンティックアノテーション技術は、シンボリック知識を最適に活用するための研究を活発化させました。同時に、ニューラルネットワーク手法は多用途で非常に効果的であることが証明されました。ニューラルネットワークの観点から見ると、同じ表現手法が文書ランキングや知識グラフ推論に応用できます。エンドツーエンドのトレーニングにより、下流タスクのために複雑な手法を最適化することが可能です。現在、シンボリックおよびニューラルの研究進展が融合しつつあり、ニューラルシンボリックアプローチが形成されています。根底にある研究課題は、シンボリックとニューラルアプローチをいかに最適に組み合わせるか、どのようなシンボリック/ニューラルアプローチがどの利用ケースに最も適しているか、そして、情報検索の最先端を押し進めるために両方のアイデアをどのように最善に統合するかです。資料はオンラインで利用可能です：https://github.com/laura-dietz/neurosymbolic-representations-for-IR
        </label>
        <input type="checkbox" id="Panel441" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This tutorial will provide an overview of recent advances on neuro-symbolic approaches for information retrieval. A decade ago, knowledge graphs and semantic annotations technology led to active research on how to best leverage symbolic knowledge. At the same time, neural methods have demonstrated to be versatile and highly effective. From a neural network perspective, the same representation approach can service document ranking or knowledge graph reasoning. End-to-end training allows to optimize complex methods for downstream tasks. We are at the point where both the symbolic and the neural research advances are coalescing into neuro-symbolic approaches. The underlying research questions are how to best combine symbolic and neural approaches, what kind of symbolic/neural approaches are most suitable for which use case, and how to best integrate both ideas to advance the state of the art in information retrieval. Materials are available online: https://github.com/laura-dietz/neurosymbolic-representations-for-IR
        </div> </ul> <br>



        <label for="Panel442">
        <strong> Recent Advances in the Foundations and Applications of Unbiased Learning to Rank </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shashank+Gupta">Shashank Gupta</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Philipp+Hager">Philipp Hager</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jin+Huang">Jin Huang</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ali+Vardasbi">Ali Vardasbi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Harrie+Oosterhuis">Harrie Oosterhuis</a> (2) </u>  <br>
        1:  University of Amsterdam, 2:  Radboud University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3594247">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Recent Advances in the Foundations and Applications of Unbiased Learning to Rank">Google Scholar</a></div>
        (442)
        <br>
        <b>概要:　</b> バイアスのないランキング学習（ULTR）分野は、その創設以来非常に活発であり、近年いくつかの影響力のある進展を遂げてきました。このチュートリアルでは、まず本分野の核心となる概念の紹介と、その基礎に関する最近の進展、およびその手法のいくつかの応用を概観します。チュートリアルは四つの部分に分かれています。第一に、ULTR手法で対処できる様々なバイアスの形式のを説明します。第二に、ULTR分野における最新の推定技術について包括的な議論を行います。第三に、現実世界の応用におけるULTRの発表された成果を調査します。第四に、ULTRとランキングの公平性との関連性を議論します。最後に、ULTR研究とその応用の未来について簡潔に考察します。このチュートリアルは、新しいULTRソリューションを開発したり、現実世界の応用に利用することに関心のある研究者や業界の実務者の両方に利益をもたらすことを意図しています。
        </label>
        <input type="checkbox" id="Panel442" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Since its inception, the field of unbiased learning to rank (ULTR) has remained very active and has seen several impactful advancements in recent years. This tutorial provides both an introduction to the core concepts of the field and an overview of recent advancements in its foundations along with several applications of its methods. The tutorial is divided into four parts: Firstly, we give an overview of the different forms of bias that can be addressed with ULTR methods. Secondly, we present a comprehensive discussion of the latest estimation techniques in the ULTR field. Thirdly, we survey published results of ULTR in real-world applications. Fourthly, we discuss the connection between ULTR and fairness in ranking. We end by briefly reflecting on the future of ULTR research and its applications. This tutorial is intended to benefit both researchers and industry practitioners who are interested in developing new ULTR solutions or utilizing them in real-world applications.
        </div> </ul> <br>



        <label for="Panel443">
        <strong> Complex Item Set Recommendation </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mozhdeh+Ariannezhad">Mozhdeh Ariannezhad</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ming+Li">Ming Li</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sami+Jullien">Sami Jullien</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (1) </u>  <br>
        1:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3594248">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Complex Item Set Recommendation">Google Scholar</a></div>
        (443)
        <br>
        <b>概要:　</b> 本チュートリアルでは、複数のアイテムを一度に推奨するタスクについて解説します。このシナリオでは、ユーザーとアイテム間の過去のインタラクションデータが、アイテムのセットとのインタラクションのシーケンスとして存在することもあります。複雑なアイテムのセットが一緒に推奨される状況は、異なる多様なドメインで発生し、例えば「バスケット」と呼ばれる食料品の買い物や、個々の衣料品よりもアウトフィットに焦点を置いたファッションセットの推奨などがあります。現在の研究環境を説明し、アイテムセット推薦の実世界の例を参加者に提示します。さらに、ハンズオンセッションを通じて実践的な経験を提供します。最後に、未解決の課題について説明し、この分野でのさらなる研究を求めます。このことが、初期段階の研究者と経験豊富な研究者の双方にインスピレーションを与えることを期待しています。
        </label>
        <input type="checkbox" id="Panel443" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In this tutorial, we aim to shed light on the task of recommending a set of multiple items at once. In this scenario, historical interaction data between users and items could also be in the form of a sequence of interactions with sets of items. Complex sets of items being recommended together occur in different and diverse domains, such as grocery shopping with so-called baskets and fashion set recommendation with a focus on outfits rather than individual clothing items. We describe the current landscape of research and expose our participants to real-world examples of item set recommendation. We further provide our audience with hands-on experience via a notebook session. Finally, we describe open challenges and call for further research in the area, which we hope will inspire both early stage and more experienced researchers.
        </div> </ul> <br>



        <label for="Panel444">
        <strong> Explainable Information Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Avishek+Anand">Avishek Anand</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Procheta+Sen">Procheta Sen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sourav+Saha">Sourav Saha</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Manisha+Verma">Manisha Verma</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Mandar+Mitra">Mandar Mitra</a> (3) </u>  <br>
        1:  Delft University of Technology, 2:  University of Liverpool, 3:  Indian Statistical Institute, 4:  Amazon New York <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3594249">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Explainable Information Retrieval">Google Scholar</a></div>
        (444)
        <br>
        <b>概要:　</b> このチュートリアルは、情報検索（IR）の文脈で機械学習システムの責任ある信頼性の高い展開を促進することに焦点を当てた新興分野である説明可能な情報検索（ExIR）を紹介します。この分野は過去4〜5年で急速に進化しており、さまざまなアクセスモードや利害関係者、モデル開発段階に焦点を当てた多くのアプローチが提案されています。本チュートリアルでは、IRに特化した概念、分類、評価方法を紹介し、ランキング、テキスト分類、学習-to-ランクシステムなどのIR特有のタスクに焦点を当てます。方法のファミリーとそのIRへの適応について詳述し、事後的手法、公理的およびプロービングアプローチ、そして設計段階での解釈可能性に関する最近の進展を広範にカバーします。また、ウェブ検索、特許および法的検索、重要な意思決定タスクなど、さまざまなコンテキストでの研究者、実務者、エンドユーザーといった異なる利害関係者に対するExIRの適用についても議論します。実践的な理解を促進するために、ExIR手法の適用に関するハンズオンセッションを提供し、学生、研究者、実務者が直面する参入障壁を低減します。
        </label>
        <input type="checkbox" id="Panel444" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> This tutorial presents explainable information retrieval (ExIR), an emerging area focused on fostering responsible and trustworthy deployment of machine learning systems in the context of information retrieval. As the field has rapidly evolved in the past 4-5 years, numerous approaches have been proposed that focus on different access modes, stakeholders, and model development stages. This tutorial aims to introduce IR-centric notions, classification, and evaluation styles in ExIR, while focusing on IR-specific tasks such as ranking, text classification, and learning-to-rank systems. We will delve into method families and their adaptations to IR, extensively covering post-hoc methods, axiomatic and probing approaches, and recent advances in interpretability-by-design approaches. We will also discuss ExIR applications for different stakeholders, such as researchers, practitioners, and end-users, in contexts like web search, patent and legal search, and high-stakes decision-making tasks. To facilitate practical understanding, we will provide a hands-on session on applying ExIR methods, reducing the entry barrier for students, researchers, and practitioners alike.
        </div> </ul> <br>



        <label for="Panel445">
        <strong> Proactive Conversational Agents in the Post-ChatGPT World </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Lizi+Liao">Lizi Liao</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Grace+Hui+Yang">Grace Hui Yang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Chirag+Shah">Chirag Shah</a> (3) </u>  <br>
        1:  Singapore Management University, 2:  Georgetown University, 3:  University of Washington <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3594250">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Proactive Conversational Agents in the Post-ChatGPT World">Google Scholar</a></div>
        (445)
        <br>
        <b>概要:　</b> ChatGPTやその他の大規模言語モデル（LLM）を基盤とする対話型エージェントは、研究界に大きな衝撃を与えました。その人間らしい性能には驚かされるものの、これらのエージェントは他の多くの既存対話エージェントと共通した重大な弱点を持っています。それは、すべてがユーザーのクエリに受動的に応答するアプローチを取っている点です。これにより、ユーザーやタスクの理解を深め、与えられた会話の範囲を超えた広範な文脈に基づいておすすめを提供する能力が制限されます。これらのエージェントには、会話を開始したり、トピックをシフトしたり、より広範な文脈を考慮に入れたおすすめを提供したりするプロアクティブさがまだ欠けています。この問題に対処するため、本チュートリアルでは対話型エージェントにプロアクティブな対話能力を持たせるための方法をレビューします。全日チュートリアルは四つの部分に分かれ、複数のインタラクティブな演習が含まれています。まず、インタラクティブな演習から始め、既存の対話システムのアーキテクチャと課題について説明します。内容には、ChatGPTやBardのようなLLMベースの最近の進展や、人間のフィードバックを用いた強化学習（RLHF）技術が含まれます。それから、プロアクティブな対話エージェントの概念を紹介し、質問をすることで会話を積極的に進めたり、トピックをシフトしたり、戦略的な会話の計画をサポートする方法など、プロアクティブな対話エージェントの最近の進展を紹介します。次に、対話応答の品質管理における重要な問題、例えば安全性、適切性、言語のデトキシフィケーション（毒素排除）、錯覚（ハルシネーション）、アラインメントについて議論します。最後に、インタラクティブな演習と聴衆とのディスカッションを実施し、結論として未解決の課題と新たな方向性を展望します。本チュートリアルの目的は、ユーザーエンゲージメントを向上させるための対話エージェントのプロアクティブな行動を強化する新技術を探求し、研究者や実務者がユーザーのニーズにプロアクティブかつ安全に応えるより効果的な対話エージェントを開発する手助けをすることです。
        </label>
        <input type="checkbox" id="Panel445" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> ChatGPT and similar large language model (LLM) based conversational agents have brought shock waves to the research world. Although astonished by their human-like performance, we find they share a significant weakness with many other existing conversational agents in that they all take a passive approach in responding to user queries. This limits their capacity to understand the users and the task better and to offer recommendations based on a broader context than a given conversation. Proactiveness is still missing in these agents, including their ability to initiate a conversation, shift topics, or offer recommendations that take into account a more extensive context. To address this limitation, this tutorial reviews methods for equipping conversational agents with proactive interaction abilities. The full-day tutorial is divided into four parts, including multiple interactive exercises. We will begin the tutorial with an interactive exercise and cover the design of existing conversational systems architecture and challenges. The content includes coverage of LLM-based recent advancements such as ChatGPT and Bard, along with reinforcement learning with human feedback (RLHF) technique. Then we will introduce the concept of proactive conversation agents and preset recent advancements in proactiveness of conversational agents, including actively driving conversations by asking questions, topic shifting, and methods that support strategic planning of conversation. Next, we will discuss important issues in conversational responses' quality control, including safety, appropriateness, language detoxication, hallucination, and alignment. Lastly, we will launch another interactive exercise and discussion with the audience to arrive at concluding remarks, prospecting open challenges and new directions. By exploring new techniques for enhancing conversational agents' proactive behavior to improve user engagement, this tutorial aims to help researchers and practitioners develop more effective conversational agents that can better understand and respond to user needs proactively and safely.
        </div> </ul> <br>



        <label for="Panel446">
        <strong> ReNeuIR at SIGIR 2023: The Second Workshop on Reaching Efficiency in Neural Information Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sebastian+Bruch">Sebastian Bruch</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Joel+Mackenzie">Joel Mackenzie</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maria+Maistro">Maria Maistro</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Franco+Maria+Nardini">Franco Maria Nardini</a> (4) </u>  <br>
        1:  Pinecone, 2:  The University of Queensland, 3:  University of Copenagen, 4:  ISTI-CNR <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591922">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=ReNeuIR at SIGIR 2023: The Second Workshop on Reaching Efficiency in Neural Information Retrieval">Google Scholar</a></div>
        (446)
        <br>
        <b>概要:　</b> アルゴリズムのアイデアに対する多面的かつ実証的な評価は、情報検索（IR）研究の中心的な柱の一つです。IRコミュニティは、インデックス、検索アルゴリズム、そして複雑な機械学習ランカーの有効性を研究する豊かな歴史を持ち、それと同時に、作成や訓練から適用および推論に至るまでの計算コストを定量化してきました。コミュニティがさらに複雑な深層学習モデルへと進む中で、効率に関する問題は再び切迫した緊急性を持って浮上しています。実際、効率性はもはや時間と空間に限定されるものではなく、資源効率、サンプル効率、そしてエネルギー効率といった新しい挑戦的な次元にまで及び、その影響は研究者、ユーザー、そして環境にまで及びます。アルゴリズムやモデルを包括的な効率性の観点から検討するためには、関連する概念の定義、メトリクスの設計、新しい発見の意義を理解するためのガイドラインの作成といった基準や原則の確立が求められます。ReNeuIRワークショップの第二回目の開催は、これらの問題について議論するためにコミュニティを一つにまとめ、効率性の共通ベンチマークフレームワークへと向かうことを明確な目的としています。
        </label>
        <input type="checkbox" id="Panel446" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multifaceted, empirical evaluation of algorithmic ideas is one of the central pillars of Information Retrieval (IR) research. The IR community has a rich history of studying the effectiveness of indexes, retrieval algorithms, and complex machine learning rankers and, at the same time, quantifying their computational costs, from creation and training to application and inference. As the community moves towards even more complex deep learning models, questions on efficiency have once again become relevant with renewed urgency. Indeed, efficiency is no longer limited to time and space; instead it has found new, challenging dimensions that stretch to resource-, sample- and energy-efficiency with ramifications for researchers, users, and the environment alike. Examining algorithms and models through the lens of holistic efficiency requires the establishment of standards and principles, from defining relevant concepts, to designing metrics, to creating guidelines for making sense of the significance of new findings. The second iteration of the ReNeuIR workshop aims to bring the community together to debate these questions, with the express purpose of moving towards a common benchmarking framework for efficiency.
        </div> </ul> <br>



        <label for="Panel447">
        <strong> Gen-IR@SIGIR 2023: The First Workshop on Generative Information Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Garbiel+Bénédict">Garbiel Bénédict</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ruqing+Zhang">Ruqing Zhang</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Donald+Metzler">Donald Metzler</a> (3) </u>  <br>
        1:  University of Amsterdam and RTL NL, 2:  ICT, 3:  Google Research <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591923">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Gen-IR@SIGIR 2023: The First Workshop on Generative Information Retrieval">Google Scholar</a></div>
        (447)
        <br>
        <b>概要:　</b> 生成型情報検索（IR）は、情報検索、コンピュータビジョン、自然言語処理、機械学習など、複数の研究コミュニティで大きな成長を遂げており、大衆メディアでも非常に注目されています。入力要求に対してドキュメントを生成によって取得したり、直接回答を生成したりする理論的、実証的、実際のユーザ向けの製品がリリースされてきました。我々は、エンドツーエンドの生成モデルが単なる一過性のトレンドなのか、あるいは一部が主張するようにIRのパラダイムシフトなのかを検討したいと考えています。これには、新しい指標、理論的基盤、評価方法、タスク定義、モデル、ユーザーインターフェースなどが必要です。このワークショップの目標は、文書検索や直接的な基盤付け回答生成など、これまでに探求されてきた生成型IR技術に焦点を当てると同時に、推薦システムや生成など新しい分野への応用についての議論と探求の場を提供することです。ワークショップの形式はインタラクティブで、ラウンドテーブルや基調講演を含み、ミニ会議の一方的な対話を避ける傾向にあります。
        </label>
        <input type="checkbox" id="Panel447" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Generative information retrieval (IR) has experienced substantial growth across multiple research communities (e.g., information retrieval, computer vision, natural language processing, and machine learning), and has been highly visible in the popular press. Theoretical, empirical, and actual user-facing products have been released that retrieve documents (via generation) or directly generate answers given an input request. We would like to investigate whether end-to-end generative models are just another trend or, as some claim, a paradigm change for IR. This necessitates new metrics, theoretical grounding, evaluation methods, task definitions, models, user interfaces, etc. The goal of this workshop1 is to focus on previously explored Generative IR techniques like document retrieval and direct Grounded Answer Generation, while also offering a venue for the discussion and exploration of how Generative IR can be applied to new domains like recommendation systems, summarization, etc. The format of the workshop is interactive, including roundtable and keynote sessions and tends to avoid the one-sided dialogue of a mini-conference.
        </div> </ul> <br>



        <label for="Panel448">
        <strong> Knowledge Discovery from Unstructured Data in Financial Services (KDF) Workshop </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sameena+Shah">Sameena Shah</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaodan+Zhu">Xiaodan Zhu</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Wenhu+Chen">Wenhu Chen</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Manling+Li">Manling Li</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Armineh+Nourbakhsh">Armineh Nourbakhsh</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xiaomo+Liu">Xiaomo Liu</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Zhiqiang+Ma">Zhiqiang Ma</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Charese+Smiley">Charese Smiley</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yulong+Pei">Yulong Pei</a> (6), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Akshat+Gupta">Akshat Gupta</a> (1) </u>  <br>
        1:  JPMorgan Chase, 2:  Queen's University, 3:  University of Waterloo, 4:  University of Illinois Urbana-Champaign, 5:  JPMorgan Chase, 6:  JPMorgan Chase <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591924">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Knowledge Discovery from Unstructured Data in Financial Services (KDF) Workshop">Google Scholar</a></div>
        (448)
        <br>
        <b>概要:　</b> ビジネス文書、ウェブコンテンツ、ニュース記事を含む非構造化データからの知識発見は、金融サービス業界における重要なAI課題となっています。これらのコーパスを理解し、そこからテキスト、表形式、またはグラフィック形式の知識を発見することは、情報検索とコンテンツ分析技術が基本的な重要性を持つ金融サービス領域におけるビジネス意思決定の支柱です。2023年に開催されるSIGIRでの金融サービスにおける非構造化データからの知識発見に関するワークショップを提案し、現状および新たな機会の注目、独自研究の招待、研究者間の成功体験の共有を促進することを目指します。
        </label>
        <input type="checkbox" id="Panel448" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Knowledge discovery from unstructured data, including business documents, web content, and news articles, has been a key AI challenge for the financial services industry. Comprehending these corpora and discovering knowledge from them, which could be textual, tabular, or graphic, are the cornerstone of supporting business decisions in the financial services domain, where information retrieval and content analysis techniques are of fundamental importance. We propose a workshop on knowledge discovery from unstructured data in financial services at SIGIR 2023 to highlight the current and emerging opportunities, invite original research, and prompt success sharing between researchers.
        </div> </ul> <br>



        <label for="Panel449">
        <strong> SIGIR 2023 Workshop on Retrieval Enhanced Machine Learning (REML @ SIGIR 2023) </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Michael+Bendersky">Michael Bendersky</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Danqi+Chen">Danqi Chen</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fernando+Diaz">Fernando Diaz</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hamed+Zamani">Hamed Zamani</a> (4) </u>  <br>
        1:  Google Research, 2:  Princeton University, 3:  Google Research, 4:  University of Massachusetts Amherst <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591925">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=SIGIR 2023 Workshop on Retrieval Enhanced Machine Learning (REML @ SIGIR 2023)">Google Scholar</a></div>
        (449)
        <br>
        <b>概要:　</b> ほとんどの機械学習モデルは自己完結型として設計されており、「知識」と「推論」の両方をそのパラメータにエンコードしています。しかし、このようなモデルは知識の裏付けを必要とするタスクやニュースやソーシャルメディアなどの非定常データを扱うタスクには効果的に機能しません。さらに、これらのモデルは必要な知識をすべてエンコードするために大量のパラメータを要することがしばしばあります。これらの問題はリトリーバルモデルとの拡張によって対処可能です。このカテゴリーの機械学習モデルは、リトリーバル強化機械学習（REML）と呼ばれ、最近では複数の研究コミュニティで注目を集めています。例えば、REMLモデルは、オープンドメインの質問応答、事実検証、対話システムの文脈で研究されており、また、言語モデルやメモリーネットワークにおける記憶を通じた一般化の文脈でも研究されています。情報検索コミュニティは、REMLタスクに対するリトリーバルモデルの設計、実装、分析、評価の各側面で大いに貢献できると考えています。この終日ハイブリッドワークショップの目標は、業界や学界からの研究者を集めて、リトリーバル強化機械学習のさまざまな側面について、特にその効果・効率・堅牢性や実世界の応用への影響を議論することです。
        </label>
        <input type="checkbox" id="Panel449" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Most machine learning models are designed to be self-contained and encode both "knowledge" and "reasoning" in their parameters. However, such models cannot perform effectively for tasks that require knowledge grounding and tasks that deal with non-stationary data, such as news and social media. Besides, these models often require huge number of parameters to encode all the required knowledge. These issues can be addressed via augmentation with a retrieval model. This category of machine learning models, which is called Retrieval-enhanced machine learning (REML), has recently attracted considerable attention in multiple research communities. For instance, REML models have been studied in the context of open-domain question answering, fact verification, and dialogue systems and also in the context of generalization through memorization in language models and memory networks. We believe that the information retrieval community can significantly contribute to this growing research area by designing, implementing, analyzing, and evaluating various aspects of retrieval models with applications to REML tasks. The goal of this full-day hybrid workshop is to bring together researchers from industry and academia to discuss various aspects of retrieval-enhanced machine learning, including effectiveness, efficiency, and robustness of these models in addition to their impact on real-world applications.
        </div> </ul> <br>



        <label for="Panel450">
        <strong> FLIRT: Federated Learning for Information Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Fabio+Pinelli">Fabio Pinelli</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Gabriele+Tolomei">Gabriele Tolomei</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Giovanni+Trappolini">Giovanni Trappolini</a> (2) </u>  <br>
        1:  IMT Lucca, 2:  Sapienza University of Rome <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591926">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=FLIRT: Federated Learning for Information Retrieval">Google Scholar</a></div>
        (450)
        <br>
        <b>概要:　</b> 検索、ランキング、フィルタリングなど、幅広いコア情報検索（IR）タスクは、機械学習（ML）および人工知能（AI）のおかげで飛躍的な進歩を遂げています。従来の集中型アプローチによるAI/MLモデルのトレーニングは依然として主流ですが、エンドユーザーによって生成された大量のデータは、その起源から遠隔地に転送され、処理される必要があります。しかし、この集中型パラダイムは重大なプライバシー問題を抱えており、現代のスマートフォンのようなクライアントデバイスの計算能力を十分に活用していません。この必要性に対する可能な回答は、フェデレーテッドラーニング（FL）であり、協力するエッジデバイス間でプライベートなローカルデータを公開することなく、予測モデルの共同トレーニングを可能にします。残念ながら、IRエコシステムにおいてFLはまだ十分に活用されていません。このワークショップ提案では、このギャップを埋めることを目指しています。具体的には、「Federated Learning for Information ReTrieval」（FLIRT）という初のワークショップが、研究者や実務者がアイデアを交換し、主要な課題を特定し、広範なIR領域におけるFLの成功した応用に向けたロードマップを定義するためのオープンフォーラムを提供することを目指しています。
        </label>
        <input type="checkbox" id="Panel450" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> A wide range of core information retrieval (IR) tasks, such as searching, ranking, and filtering, to name a few, have seen tremendous improvements thanks to machine learning (ML) and artificial intelligence (AI). The traditional centralized approach to training AI/ML models is still predominant: large volumes of data generated by end users must be transferred from their origins and shared with remote locations for processing. However, this centralized paradigm suffers from significant privacy issues and does not take full advantage of the computing power of client devices like modern smartphones. A possible answer to this need is provided by federated learning (FL), which enables collaborative training of predictive models among a set of cooperating edge devices without disclosing any private local data. Unfortunately, FL is still far from being fully exploited in the IR ecosystem. In this workshop proposal, we have the ambition to start filling this gap. More specifically, the first workshop on ''Federated Learning for Information ReTrieval'' (FLIRT) is willing to provide an open forum for researchers and practitioners where they can exchange ideas, identify key challenges, and define the roadmap toward a successful application of FL in the broad IR area.
        </div> </ul> <br>



        <label for="Panel451">
        <strong> eCom'23: The SIGIR 2023 Workshop on eCommerce </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Surya+Kallumadi">Surya Kallumadi</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yubin+Kim">Yubin Kim</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Tracy+Holloway+King">Tracy Holloway King</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Shervin+Malmasi">Shervin Malmasi</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Maarten+de+Rijke">Maarten de Rijke</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Jacopo+Tagliabue">Jacopo Tagliabue</a> (6) </u>  <br>
        1:  Lowe's Companies, 2:  Etsy, 3:  Adobe Inc., 4:  Amazon, 5:  University of Amsterdam, 6:  New York University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591927">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=eCom'23: The SIGIR 2023 Workshop on eCommerce">Google Scholar</a></div>
        (451)
        <br>
        <b>概要:　</b> eコマースの情報検索（IR）は、学術文献の中でますます注目を集めており、Airbnb、Alibaba、Amazon、eBay、Facebook、Flipkart、Lowe's、Taobao、Target などの大規模なウェブサイトの重要な構成要素となっています。SIGIR は数年前から eコマース組織からのスポンサーシップを受け、その研究の重要性を反映しています。このワークショップの目的は、（1）eコマース IR の研究者や実務者を集め、この分野に固有のトピックについて議論すること、（2）eコマースの特有の組み合わせである自由テキスト、構造化データ、および顧客行動データを活用して検索の関連性を向上させる方法を決定すること、（3）この領域でデータセットを構築し、アルゴリズムを評価する方法を検討することです。今年の eコマース IR ワークショップのテーマは、「eコマースにおける基礎モデルと統合情報アクセス」です。本ワークショップはこのトピックに関する論文を募集し、この分野に焦点を当てたパネルを含みます。さらに、Lowe's がスポンサーとなる「eコマースのためのクロスモーダルとマルチモーダルのビジュアル検索に関するデータチャレンジ」も開催されます。このデータチャレンジは、2017年から2022年までの成功した SIGIR ワークショップのテーマが反映されています。ECOM23 は、多様な参加を可能にするために、フルデイのハイブリッドワークショップとして開催されます。
        </label>
        <input type="checkbox" id="Panel451" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> eCommerce Information Retrieval (IR) is receiving increasing attention in the academic literature and is an essential component of some of the largest web sites (e.g. Airbnb, Alibaba, Amazon, eBay, Facebook, Flipkart, Lowes's, Taobao, Target). SIGIR has for several years seen sponsorship from eCommerce organizations, reflecting the importance of IR research to them. The purpose of this workshop is (1) to bring together researchers and practitioners of eCommerce IR to discuss topics unique to it, (2) to determine how to use eCommerce's unique combination of free text, structured data, and customer behavior data to improve search relevance, and (3) to examine how to build datasets and evaluate algorithms in this domain. The theme of this year's eCommerce IR workshop is Foundation Models and Unified Information Access in eCommerce. The workshop solicits papers on this topic and includes a panel focused on this area. In addition, Lowe's is sponsoring an eCommerce data challenge on Cross-modal and Multi-modal Visual Search for eCommerce. The data challenge reflects themes from the successful SIGIR workshops in 2017, 2018, 2019, 2020, 2021, and 2022. ECOM23 will be held as a full day hybrid workshop to accommodate for diverse participation.
        </div> </ul> <br>



        <label for="Panel452">
        <strong> The 1st International Workshop on Implicit Author Characterization from Texts for Search and Retrieval (IACT'23) </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Marina+Litvak">Marina Litvak</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Irina+Rabaev">Irina Rabaev</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ricardo+Campos">Ricardo Campos</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Alípio+Mário+Jorge">Alípio Mário Jorge</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Adam+Jatowt">Adam Jatowt</a> (4) </u>  <br>
        1:  Shamoon College of Engineering, 2:  Polytechnic Institute of Tomar & INESC TEC, 3:  University of Porto, 4:  University of Innsbruck <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591928">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=The 1st International Workshop on Implicit Author Characterization from Texts for Search and Retrieval (IACT'23)">Google Scholar</a></div>
        (452)
        <br>
        <b>概要:　</b> 検索と情報検索（IR）のためのテキストからの暗黙的な著者特性抽出（IACT'23）の第一回会議は、著者（例えば、人間やAI）に関する暗黙的な情報をテキストから識別・抽出し、それをIRタスクに利用する際の課題を浮き彫りにすることを目的としています。IACTワークショップは、多分野の取り組みを統合し、テキストコンテンツから著者に関連する暗黙的な情報を抽出するタスク、及び新しいタスクやデータセットに関連する広範な課題を特定するための議論を促進する共通のフォーラムを提供します。また、暗黙的情報抽出の倫理的な側面についても議論します。さらに、書籍の文学的時代を自動的に判定することに焦点を当てた共有タスクも発表いたします。
        </label>
        <input type="checkbox" id="Panel452" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The first edition of the Implicit Author Characterization from Texts for Search and Retrieval (IACT'23) aims at bringing to the forefront the challenges involved in identifying and extracting from texts implicit information about authors (e.g., human or AI) and using it in IR tasks. The IACT workshop provides a common forum to consolidate multi-disciplinary efforts and foster discussions to identify the wide-ranging issues related to the task of extracting implicit author-related information from the textual content, including novel tasks and datasets. We will also discuss the ethical implications of implicit information extraction. In addition, we announce a shared task focused on automatically determining the literary epochs of written books.
        </div> </ul> <br>



        <label for="Panel453">
        <strong> 4th Workshop on Patent Text Mining and Semantic Technologies (PatentSemTech2023) </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Ralf+Krestel">Ralf Krestel</a> (1), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Hidir+Aras">Hidir Aras</a> (2), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Linda+Andersson">Linda Andersson</a> (3), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Florina+Piroi">Florina Piroi</a> (4), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Allan+Hanbury">Allan Hanbury</a> (5), <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dean+Alderucci">Dean Alderucci</a> (6) </u>  <br>
        1:  ZBW - Leibniz Information Centre for Economics & Kiel Universit, 2:  FIZ Karlsruhe - Leibniz Institute for Information Infrastructure, 3:  Artificial Researcher IT GmbH, 4:  TU Wien & Research Studios Austria, 5:  TU Wien, 6:  Carnegie Mellon University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591929">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=4th Workshop on Patent Text Mining and Semantic Technologies (PatentSemTech2023)">Google Scholar</a></div>
        (453)
        <br>
        <b>概要:　</b> 特許分野向けの情報検索システムは、長い歴史を持っています。これらのシステムは、特許の専門家に対して、特許の地形を分析することから、特許取得プロセスを支援すること、大規模な情報抽出に至るまで、様々な日常業務をサポートします。機械学習と自然言語処理の進展により、段落検索や特許文書生成などのタスクをさらに自動化することが可能になっています。知的財産（IP）業界におけるセマンティック技術の可能性を明らかにすることは、まだ始まったばかりです。特許分野で人工知能手法の利用を調査することは、学術的な関心だけでなく、実務家にとっても非常に重要です。他の分野と比較して、高品質で半構造化された注釈付きデータが大量に利用可能であり（これは教師あり機械学習モデルの要件である）、大規模モデルの訓練を容易にします。一方で、特許文書の非常に専門的な言語や法的要件など、特有の課題も存在します。このワークショップの第4版の焦点は、特にアジアのコミュニティと情報検索のあらゆる分野における産業界と学術界の双方向コミュニケーションにあります。私たちは、この分野での最新のシステムや方法を専門家が使用する最新の研究結果と結びつけたいと考えています。
        </label>
        <input type="checkbox" id="Panel453" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Information retrieval systems for the patent domain have a long history. They can support patent experts in a variety of daily tasks: from analyzing the patent landscape to support experts in the patenting process and large-scale information extraction. Advances in machine learning and natural language processing allow to further automate tasks, such as paragraph retrieval or even patent text generation. Uncovering the potential of semantic technologies for the intellectual property (IP) industry is just getting started. Investigating the use of artificial intelligence methods for the patent domain is therefore not only of academic interest, but also highly relevant for practitioners. Compared to other domains, high quality, semi-structured, annotated data is available in large volumes (a requirement for supervised machine learning models), making training large models easier. On the other hand, domain-specific challenges arise, such as very technical language or legal requirements for patent documents. The focus of the 4th edition of this workshop will be on two-way communication between industry and academia from all areas of information retrieval in particular with the Asian community. We want to bring together novel research results and the latest systems and methods employed by practitioners in the field.
        </div> </ul> <br>



        <label for="Panel454">
        <strong> Quantifying and Advancing Information Retrieval System Explainability </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Catherine+Chen">Catherine Chen</a> (1) </u>  <br>
        1:  Brown University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591792">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Quantifying and Advancing Information Retrieval System Explainability">Google Scholar</a></div>
        (454)
        <br>
        <b>概要:　</b> 情報検索（IR）システム、例えば検索エンジンや会話型エージェントが様々な分野で普及する中、透明性と説明可能性を持つシステムの必要性が高まっており、それにより説明責任、公平性、偏りのない結果を保証することが求められています。説明可能なAIやIR技術に関する最近の多くの進展にもかかわらず、システムの説明可能性が何を意味するのかについてのコンセンサスはありません。増え続ける文献は、説明可能性が複数のサブファクターで構成されていることを示唆しているものの、ほとんどの既存アプローチはこれを単一の概念として扱っています。また、ニューラル検索モデル（NRM）は高い性能を達成する能力で人気を博していますが、NRMの説明可能性に関する研究は近年までほとんど進んでいません。これらの複雑なモデルがどのようにしてその決定に至るのかを理解するための最も効果的な手段や、これらの手法が開発者とエンドユーザーの双方に対してどれだけ効率的に機能するかについて、多くの未解決の問題が残っています。本研究は、説明可能な検索システムを評価・進展させる効果的な方法を開発し、潜在的なバイアスをより識別しやすくする技術の作成という広範な研究分野の目標に向けた一歩を目指します。具体的には、以下の点を調査します：RQ1: 説明可能性を定量的に測定する方法は？RQ2: 機能属性を使用して、異なる検索ドメイン環境で堅牢な、説明可能なNRMをどのように開発するか？RQ3: 影響力のあるトレーニングインスタンスに関する知識を活用して、NRMをよりよく理解し、より効率的な検索実践を促進する方法は？RQ1に取り組むために、心理計測学とクラウドソーシングを活用して、Web検索システムの説明可能性の多次元モデルを導入します。我々のアプローチは、多次元関連性モデリングに関する先行研究に基づき、最近の文献が提唱する説明可能性の多次元性を支持します。これにより、検索システムの説明可能性の有用性と障害を説明する正負の側面にグループ化されるこれらの要因の経験的証拠を提供します。さらに、説明可能な検索システムの連続スケール評価指標を導入し、研究者が説明の効果を直接比較・評価できるようにします。将来的な研究では、機能ベースとインスタンスベースの2つの属性方法を調査し、一連の説明可能なNRMを開発することで、RQ2とRQ3に取り組む予定です。一般的なML分野、特にビジョンと言語ドメインにおける深層ニューラルネットワークアーキテクチャの解釈性の調査には多くの研究がなされていますが、IRにおける本質的に説明可能なニューラルアーキテクチャの作成はほとんど探求されていません。したがって、NLPおよびMLの広範な分野での先行研究に基づいて、NRMがどのようにランク決定を行うかについてのより深い洞察を提供する方法を開発するつもりです。説明可能なIRシステムを開発することで、ユーザーが複雑で非線形なメカニズムがどのように検索クエリを高ランクのコンテンツと結びつけるかを理解しやすくします。適切に適用されれば、この研究は偽情報の検出や臨床意思決定支援など、広範なアプリケーション分野で社会に利益をもたらす可能性があります。現代社会においてこれらの分野は非常に重要であり、偽情報の拡散を抑えるためには堅牢な解決策が求められています。これらのシステムの透明性と説明責任を向上させることで、説明可能なシステムはこの傾向を抑制する上で重要な役割を果たすことができます。
        </label>
        <input type="checkbox" id="Panel454" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> As information retrieval (IR) systems, such as search engines and conversational agents, become ubiquitous in various domains, the need for transparent and explainable systems grows to ensure accountability, fairness, and unbiased results. Despite many recent advances toward explainable AI and IR techniques, there is no consensus on what it means for a system to be explainable. Although a growing body of literature suggests that explainability is comprised of multiple subfactors [2, 5, 6], virtually all existing approaches treat it as a singular notion. Additionally, while neural retrieval models (NRMs) have become popular for their ability to achieve high performance[3, 4, 7, 8], research on the explainability of NRMs has been largely unexplored until recent years. Numerous questions remain unanswered regarding the most effective means of comprehending how these intricate models arrive at their decisions and the extent to which these methods will function efficiently for both developers and end-users. This research aims to develop effective methods to evaluate and advance explainable retrieval systems toward the broader research field goal of creating techniques to make potential biases more identifiable. Specifically, I aim to investigate the following: RQ1: How do we quantitatively measure explainability?RQ2: How can we develop a set of inherently explainable NRMs using feature attributions that are robust across different retrieval domain contexts?RQ3: How can we leverage knowledge about influential training instances to better understand NRMs and promote more efficient search practices? To address RQ1, we leverage psychometrics and crowdsourcing to introduce a multidimensional model of explainability for Web search systems[1]. Our approach builds upon prior research on multidimensional relevance modeling [9] and supports the multidimensionality of explainability posited by recent literature. In doing so, we provide empirical evidence that these factors group between positive and negative facets that describe the utility and roadblocks to explainability of search systems. Additionally, we introduce a continuous-scale evaluation metric for explainable search systems which enables researchers to directly compare and evaluate the efficacy of their explanations. In future work, I plan to address RQ2 and RQ3 by investigating two avenues of attribution methods, feature-based and instance-based, to develop a suite of explainable NRMs. While much work has been done on investigating the interpretability of deep neural network architectures in the general ML field, particularly in vision and language domains, creating inherently explainable neural architectures remains largely unexplored in IR. Thus, I intend to draw on previous work in the broader fields of NLP and ML to develop methods that offer deeper insights into the inner workings of NRMs and how ranking decisions are made. By developing explainable IR systems, we can facilitate users' comprehension of the intricate, non-linear mechanisms that link their search queries to highly ranked content. If applied correctly, this research has the potential to benefit society in a broad range of applications, such as disinformation detection and clinical decision support. Given their critical importance in modern society, these areas demand robust solutions to combat the escalating dissemination of false information. By enhancing the transparency and accountability of these systems, explainable systems can play a crucial role in curbing this trend.
        </div> </ul> <br>



        <label for="Panel455">
        <strong> Multimodal Named Entity Recognition and Relation Extraction with Retrieval-Augmented Strategy </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Xuming+Hu">Xuming Hu</a> (1) </u>  <br>
        1:  Tsinghua University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591790">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Multimodal Named Entity Recognition and Relation Extraction with Retrieval-Augmented Strategy">Google Scholar</a></div>
        (455)
        <br>
        <b>概要:　</b> 要翻訳:英語から日本語への翻訳<br>対象ジャーナル: 機械学習<br>ゴール: 分かりやすく明確な文章<br>読者層: 専門分野の専門家<br>スタイル: 分析的で博士号レベル<br><br>以下の英語テキストを与えられた仕様に基づいて日本語に翻訳してください。<br><br>Multimodal Named Entity Recognition (MNER) and Multimodal Relation Extraction (MRE) are tasks in information retrieval that aim to recognize entities and extract relations among them using information from multiple modalities, such as text and images. Although current methods have attempted a variety of modality fusion approaches to enhance the information in text, a large amount of readily available internet retrieval data has not been considered. Therefore, we attempt to retrieve real-world text related to images, objects, and entire sentences from the internet and use this retrieved text as input for cross-modal fusion to improve the performance of entity and relation extraction tasks in the text.<br><br>---<br><br>翻訳:<br><br>マルチモーダル固有表現認識（MNER）とマルチモーダル関係抽出（MRE）は、テキストや画像などの複数のモダリティからの情報を用いてエンティティを認識し、それらのエンティティ間の関係を抽出することを目的とする情報検索のタスクです。現在の手法は、テキストの情報を強化するためにさまざまなモダリティ融合アプローチを試みていますが、大量の利用可能なインターネット検索データは考慮されていません。そこで、本研究では、インターネットから画像やオブジェクト、または全体の文章に関連する実世界のテキストを取得し、この取得したテキストをクロスモーダル融合の入力として使用し、テキスト内のエンティティ認識と関係抽出タスクの性能を向上させることを目指します。
        </label>
        <input type="checkbox" id="Panel455" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Multimodal Named Entity Recognition (MNER) and Multimodal Relation Extraction (MRE) are tasks in information retrieval that aim to recognize entities and extract relations among them using information from multiple modalities, such as text and images. Although current methods have attempted a variety of modality fusion approaches to enhance the information in text, a large amount of readily available internet retrieval data has not been considered. Therefore, we attempt to retrieve real-world text related to images, objects, and entire sentences from the internet and use this retrieved text as input for cross-modal fusion to improve the performance of entity and relation extraction tasks in the text.
        </div> </ul> <br>



        <label for="Panel456">
        <strong> Large-Scale Data Processing for Information Retrieval Applications </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Pooya+Khandel">Pooya Khandel</a> (1) </u>  <br>
        1:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591797">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Large-Scale Data Processing for Information Retrieval Applications">Google Scholar</a></div>
        (456)
        <br>
        <b>概要:　</b> 検索エンジンやレコメンデーションシステムなどの情報検索（IR）アプリケーションの開発は、文書やアイテムのテキスト、ユーザープロファイル、インタラクションなど多次元のデータを扱いながら、そのモデルの複雑さと規模が増大する中でのトレーニングを必要とします。IR研究の多くはランキングモデルの性能向上に焦点を当てていますが、性能を向上させるための新モデル設計には、高いトレーニング時間と膨大な計算資源が必要です。そのため、大規模なIRアプリケーションの設計と展開において効率性の視点を重視することが不可欠です。本論文では、データセットを蒸留するアプローチを用いてデータセットのサイズを削減しつつランキングの品質を維持し、高性能計算（HPC）ソリューションを活用して処理速度を向上させることで、IRアプリケーションのトレーニング効率を改善し、新モデルの開発フェーズを加速することを目指します。
        </label>
        <input type="checkbox" id="Panel456" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Developing Information Retrieval (IR) applications such as search engines and recommendation systems require training of models that are growing in complexity and size with immense collections of data that contain multiple dimensions (documents/items text, user profiles, and interactions). Much of the research in IR concentrates on improving the performance of ranking models; however, given the high training time and high computational resources required to improve the performance by designing new models, it is crucial to address efficiency aspects of the design and deployment of IR applications at large-scale. In my thesis, I aim to improve the training efficiency of IR applications and speed up the development phase of new models, by applying dataset distillation approaches to reduce the dataset size while preserving the ranking quality and employing efficient High-Performance Computing (HPC) solutions to increase the processing speed.
        </div> </ul> <br>



        <label for="Panel457">
        <strong> Defining and Measuring Cost, Effort, and Load in Information Retrieval </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Molly+McGregor">Molly McGregor</a> (1) </u>  <br>
        1:  University of Strathclyde <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591794">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Defining and Measuring Cost, Effort, and Load in Information Retrieval">Google Scholar</a></div>
        (457)
        <br>
        <b>概要:　</b> 情報検索（IR）プロセスにおいてユーザーに課される要求は広く認識されており、多くの研究がコスト、労力、および負荷がユーザーの検索行動と体験にどのような影響を与えるかを強調しています。この理解にもかかわらず、IR 分野ではこれらの構成要素の普遍的な定義や標準化された測定方法が存在しません。その結果、これらの構成要素がどのように定義され、解釈され、そして測定されてきたかに関連する未解決の研究問題が発生しています。この研究問題に対処するために、本研究は二つの目的を持っています。まず、コスト、労力、および負荷を定義するための作業定義と概念フレームワークを確立すること。そして次に、IRの文脈における既存の労力と負荷の測定方法を検討し、評価することです。
        </label>
        <input type="checkbox" id="Panel457" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The demands imposed on the user during the Information Retrieval (IR) process are well-recognised, with numerous studies highlighting the influence and importance of cost, effort, and load in explaining user search behaviour and experience. Despite this understanding, there exists no universal definitions of these constructs or standardised methods of measuring them within the field of IR. As a result, an open research problem has emerged in relation to how these constructs have been defined, interpreted, and subsequently measured. To address this research problem, the aim of this research is two-fold. Firstly, to establish working definitions and a conceptual framework for defining cost, effort, and load; and secondly, to examine and evaluate existing measures of effort and load within an IR context.
        </div> </ul> <br>



        <label for="Panel458">
        <strong> Conversational Bibliographic Search </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Markus+Nilles">Markus Nilles</a> (1) </u>  <br>
        1:  Trier University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591789">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Conversational Bibliographic Search">Google Scholar</a></div>
        (458)
        <br>
        <b>概要:　</b> ほぼすべての研究分野において、専門家やその研究成果を見つけることが必要です。しかし、専門家や論文を見つけることはコンピューターだけでなく人間にとっても困難な作業です。例えば、専門家を探す場合、ユーザーはしばしば検索エンジンにトピックを入力し、そのトピックに関する論文を発表している人物を検索します。問題が生じるのは、ユーザーが意図的に（例えばナビゲーショナル検索時）、あるいは意図せず（例えば知識不足のため）問い合わせ内容を十分に具体化しない場合です。その結果、検索結果の品質が非常に高くない場合があり、最良の結果を見つけられないことがあります。dblp[2]、ResearchGate、Google Scholar、Semantic Scholarなどの現在広く使用されている書誌情報の検索エンジンは、キーワードベースの検索しか許可していません。Kreutz et al.[1] は、SQLよりも簡単かつ正確にクエリを設定できる書誌情報用クエリ言語であるSchenQLを提案しました。しかし、この言語を理解するにはトレーニングが必要であり、Google Scholarなどと比べても非専門家にとっては使いやすくありません。ユーザーの検索意図への十分な配慮と検索支援の欠如という制限に対処するために、書誌情報の分野における対話型検索システムを開発することを目指しています。この対話型検索システムは、自然言語対話を通じてユーザーが検索意図を達成するのを助けます。このシステムを使うことで、専門家を見つけるだけでなく、事前知識なしでも書誌情報を検索できるようにすることが可能です。本研究では、「対話型情報検索システムが書誌情報の検索にどれだけ有益であるか？」という研究課題に答えることを目指しています。研究課題に取り組むために、我々の貢献は三つあります。第一に、書誌情報のための対話型情報検索システムのアーキテクチャを提示します。第二に、このシステムのすべてのコンポーネントを実装し、既存の書誌情報検索エンジンと比較して有効性、効率性、ユーザー満足度の観点から評価します。第三に、システムの訓練に使用するユーザークエリのデータセットを作成し公開します。我々が提案するアーキテクチャは、五つの主要なコンポーネントで構成されています。i) ユーザー意図の分類、ii) キーワード抽出、iii) 検索モジュール、iv) 対話モジュール、v) 会話履歴。i) ユーザー意図の分類のタスクは、ユーザーが検索クエリで達成したいゴールを決定することです。ユーザー意図の分類は、対応するユーザー意図の分類器のセットで構成されており、それぞれが特定の意図を担当します。もしも分類器がユーザーのクエリを意図に一致させることができない場合、あるいは複数の分類器がクエリがそれぞれの意図に一致すると結論付けた場合、システムはユーザーにクエリの具体化を求めます。ii) 意図が正しく特定された場合、キーワード抽出器がクエリから実際の検索語を抽出します。iii) 意図と検索語が特定された後、実際の検索が検索モジュールで行われます。ユーザーのクエリはSchenQLクエリ（Kreutz et al.[1]）としてデータベースに送信される可能性があります。iv) 対話モジュールでは、結果が自然言語の応答に変換され、ユーザーには前のクエリに関連する追加のクエリの提案が行われます。v) 会話履歴は、ユーザーのクエリとシステムの応答を保存し、意図の決定やシステムのコンポーネントの改善に全体のセッションを考慮します。例えば、新しい質問の定式化はユーザー意図の分類器の精度を改善するだけでなく、このような対話型検索システムを使用するユーザーが持っているがまだ実装されていない新しい意図を明らかにする可能性があります。最初の実験では、四つのユーザー意図を定義し、ユーザー意図の分類を評価しました。四つのユーザー意図は、（1）トピックに関する人物/著者/専門家を検索する、（2）著者名による論文を検索する、（3）トピックに関する論文を検索する、（4）トピックの類似トピックを検索する、です。我々の分類器は、ユーザー意図を正しく特定する精度の0.998を達成しました。将来的には、書誌情報のための対話型情報検索システムの個々のコンポーネントを評価するだけでなく、自然言語の会話を介してユーザーを検索プロセスでサポートしない既存のシステムと比較して、対話型情報検索システムの利点と欠点も明らかにしていきたいと考えています。
        </label>
        <input type="checkbox" id="Panel458" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> In almost every area of research, it is necessary to find experts and publications on a topic. However, finding experts and publications is a difficult task not only for computers, but also for humans. For example, searching for experts, a user often enters a topic into a search engine, which then checks which people have published on that topic. A problem arises when a user does not make their query specific enough which can happen intentionally, e.g. when the user is doing a navigational search, or unintentionally, e.g., when the user lacks knowledge. As a result, the quality of the search results may not be very high and the best results may not be found. Current and widely used search engines for bibliographic metadata, such as dblp[2], ResearchGate, Google Scholar or Semantic Scholar allow only keyword-based searches. Kreutz et al.[1] presented SchenQL, a query language for bibliographic metadata that allows users to formulate their queries more easily and precisely than SQL. However, it requires training to understand the language and is not as easy for non-experts to use e.g. Google Scholar. To address the limitations of insufficient attention to the user's search intent and lack of search support, we aim to develop a conversational retrieval system in the domain of bibliographic metadata. This conversational search system assists users in achieving their search intent through a natural language dialog. It should be possible not only to find experts, but also to search for bibliographic metadata with the help of the system without prior knowledge. In this work, we aim to answer the research question: How beneficial is a conversational information retrieval system for searching bibliographic data? To address the research question, our contribution is threefold. First, we present an architecture for such a conversational information retrieval system for bibliographic metadata. Second, we will implement all the components of this system and evaluate our system by comparing it to existing bibliographic data search engines in terms of effectiveness, efficiency, and user satisfaction. Third, we will create and publish a dataset consisting of user queries that we will use to train our system. The architecture we propose consists of five main components: i) user intent classification, ii) a keyword extractor, iii) a search module, iv) a conversational module and v) the conversation history. i) The task of user intent classification is to determine the goal the user wants to achieve with their search query. The user intent classification consists of a set of corresponding user intent classifiers, each of which is responsible for one intent. If no classifier can match the user's query to their intent, or multiple classifiers conclude that the query matches their intents, the system asks the user to specify the query accordingly. ii) If the intent is correctly determined, a keyword extractor extracts the actual search term from the query. iii) After the intent and the search term have been determined, the actual search takes place in the search module. The user's query could be reformulated into a SchenQL query (Kreutz et al.[1] and sent to the database. iv) In the conversational module, the results are converted into a natural language response and the user is given suggestions for further queries related to the previous ones. v) The conversation history stores the user's queries and the system's responses, both to consider the entire session when determining intent and to improve the system's components. For example, new question formulations could improve the accuracy of the user intent classifiers as well as reveal what new intents a user of such a conversational search system might have that have not yet been implemented. In first experiments, we defined four user intents and already evaluated the user intent classification. The four user intents are: (1) searching for persons/authors/experts on a topic, (2) searching for publications by author name, (3) searching for publications on a topic and (4) searching for similar topics of a topic. Our classifiers achieved an accuracy of 0.998 in correctly determining user intent. In the future, we not only want to evaluate the individual components of a conversational information retrieval system for bibliographic data, but also want to work out the advantages and disadvantages of the conversational information retrieval system for bibliographic data, in comparison to already existing systems that do not support the user in their search process via natural language conversations.
        </div> </ul> <br>



        <label for="Panel459">
        <strong> Resilient Retrieval Models for Large Collection </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Dipannita+Podder">Dipannita Podder</a> (1) </u>  <br>
        1:  Indian Institute of Technology <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591793">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Resilient Retrieval Models for Large Collection">Google Scholar</a></div>
        (459)
        <br>
        <b>概要:　</b> 現代の検索エンジンは、大規模なコレクションに対する検索効率と効果のバランスを取るために、マルチステージランキングパイプラインを使用しています。これらのパイプラインは、初めにBM25やLMのようなコスト効果の高いリトリーバルモデルを用いて初期候補文書集合をリポジトリから取得し、その後、これらの候補文書をニューラルリトリーバルモデルで再ランク付けします。このパイプラインは、第一段階のランカーが高いリコールを達成した場合にうまく機能します[2]。これを達成するために、第一段階のランカーはミリ秒単位で問題を解決する必要があります。検索エンジンの主な問題の一つは、クエリに含まれる余分な用語の存在です。クエリ文書と用語のマッチングはあらゆるリトリーバルモデルの基本構造であり、文書がこれらの余分なクエリ用語とマッチングされると、リトリーバル効果が低下します。既存のモデル[4, 5]は、用語の重みを学習されたアプローチを使用するか、初期のトップランク文書の情報を利用して最終ランク付け関数に組み込むことで、この問題に対処しています。後者の手法は教師なしですが、大規模なコレクションのランク付けを行うために初期トップランク文書を取得するのは計算コストが高いです。さらに、実際のコレクションでは、用語が複数回出現することがあり、これには異なるコンテキストでの出現や、著者による用語の集中使用、外れ値などの理由があります。このため、既存のリトリーバルモデルは、あるクエリ用語が極端に高頻度で出現する場合、無関係な文書の関連性スコアを過大評価します。Paikら[3]は、用語の高頻度出現の寄与を削減するための、切断分布に基づく確率モデルを提案しています。しかし、切断点の選択は用語固有の分布情報を活用しておらず、すべての関連文書をクエリのセットとして一括りにするため、用語の分布を適切に捉える方法ではありません。また、このモデルは用語の集中性を捉えておらず、単に外れ値の影響を軽減するだけです。Cumminsら[1]は、用語の集中性を捉えることができるディリクレ混合多項分布に基づく言語モデルを提案しましたが、このモデルは言語モデルに特化しています。<br><br>以上の研究ギャップを考慮し、本博士論文では以下の研究課題に焦点を当てます。研究課題1：初期ランクリストや関連性判断に依存せずに冗長なクエリから中心的なクエリ用語をどのように識別し、ランク付け関数を修正して派生した中心用語に焦点を当てることができるか？RQ1に対処するために、事前学習済みBERT（双方向エンコーダ表現変換器）モデルを用いてクエリ全体および個別のクエリ用語の文脈ベクトルを生成し、それらの相関を分析して用語の中心性スコアを推定し、ランク付け関数が用語のマッチング中に中心用語に焦点を当てるようにします。研究課題2：大規模コレクションの外れ値用語をどのように識別し、ランク付け関数でペナルティを課すか？RQ2に対処するために、クエリセットの用語に対する関連文書の最大正規化頻度値の分布をモデル化します。次に、新しい用語の正規化頻度がその分布の右端から発生する確率を推定し、その確率をランク付け関数でペナルティとして使用します。研究課題3：集中性の高い用語をどのように検出し、ランク付け関数に組み込むか？RQ3に対処するために、ドキュメント内の用語の情報量から集中スコアを推定し、このスコアを使用して集中用語をランク付け関数でペナルティとして扱うモデルを提案します。用語の情報量を推定するために、事前学習済みBERTモデルを使用して用語の各出現の文脈情報を捉え、その出現が以前の出現からどれだけ異なるかの文脈的な変動を推定します。
        </label>
        <input type="checkbox" id="Panel459" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Modern search engines employ multi-stage ranking pipeline to balance retrieval efficiency and effectiveness for large collections. These pipelines retrieve an initial set of candidate documents from the large repository by some cost-effective retrieval model (such as BM25, LM), then re-rank these candidate documents by neural retrieval models. These pipelines perform well if the first-stage ranker achieves high recall [2]. To achieve this, the first-stage ranker should address the problems in milliseconds. One of the major problems of the search engine is the presence of extraneous terms in the query. Since the query document term matching is the fundamental block of any retrieval model, the retrieval effectiveness drops when the documents are getting matched with these extraneous query terms. The existing models [4, 5] address this issue by estimating weights of the terms either by using supervised approaches or by utilizing the information of a set of initial top-ranked documents and incorporating it into the final ranking function. Although the later category of methods is unsupervised, they are inefficient as ranking the large collection to get the initial top-ranked documents is computationally expensive. Besides, in the real-world collection, some terms may appear multiple times in the documents for several reasons, such as a term may appear for different contexts, the author bursts this term, or it is an outlier. Thus, the existing retrieval models overestimate the relevance score of the irrelevant documents if they contain some query term with extremely high frequency. Paik et al. [3] propose a probabilistic model based on truncated distributions that reduce the contribution of such high-frequency occurrences of the terms in relevance score. But, the truncation point selection does not leverage term-specific distribution information. It treats all the relevant documents as a bag for a set of queries which is not a good way to capture the distribution of terms. Furthermore, this model does not capture the term burstiness; it only reduces the effect of the outliers. Cummins et al. [1] propose a language model based on Dirichlet compound multinomial distribution that can capture the term burstiness. But this model is explicitly specific to the language model. Considering the above research gaps, we focus on the following research questions in this doctoral work. Research Question 1: How can we identify the central query terms from the verbose query without relying on an initial ranked list or relevance judgment and modify the ranking function so that it can focus on the derived central query terms? To address RQ1, we generate the contextual vector of the entire query and individual query terms using the pre-trained BERT (Bidi-rectional Encoder Representations from Transformers) model and subsequently analyze their correlation to estimate the term centrality score so that the ranking function may focus on the central terms while term matching. Research Question 2: How can we identify the outlier terms of the large collection and penalize them in the ranking function? For RQ2, we model the distribution of maximum normalized term frequency values of relevant documents for the terms of a set of queries. Then we estimate the probability that the normalized frequency of a new term is coming from the right extreme of that distribution and uses this probability to penalize them in the ranking function. Research Question 3: How can we detect the bursty terms and incorporate them in the ranking function? To address RQ3, we propose a model that estimates the burstiness score of a term from its information content in a document and use this score to penalize the bursty term in the ranking function. To estimate the information content of a term, we capture the contextual information of each occurrence of a term by utilizing the pre-trained BERT model and estimate the contextual divergence of the occurrence of a term from its previous occurrences.
        </div> </ul> <br>



        <label for="Panel460">
        <strong> Neural Architectures for Searching Subgraph Structures </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Radin+Hamidi+Rad">Radin Hamidi Rad</a> (1) </u>  <br>
        1:  Toronto Metropolitan University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591791">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Neural Architectures for Searching Subgraph Structures">Google Scholar</a></div>
        (460)
        <br>
        <b>概要:　</b> 近年、グラフ学習における新しいニューラルネットワークアーキテクチャの発展により、データを保存、表現、処理するためにグラフを使用することがますます流行しています。現在、グラフは豊かな構造化データの形式として、多くの現実世界のプロジェクトで利用されています。これらのプロジェクトでは、オブジェクトはしばしば他のものとの接続に基づいて定義されます。実用的な応用分野として、抗菌剤の発見、物理シミュレーション、フェイクニュースの検出、交通予測、推奨システムなどがあります。増え続けるニューラルグラフ表現学習技術により、効果的なグラフ表現を学習することが可能となっています[1-3, 5]。しかし、いくつかの理由でこれらの技術はグラフ検索のタスクには必ずしも適していません。第一に、グラフ内のノードは一連の属性から成り、これが検索プロセスの対象となります。しかし、グラフ上のユニークな属性の数に比べて各ノード上の属性の数が非常に希薄であるため、このような希薄な情報に対して効果的なグラフ表現を学習することは非常に困難です。第二に、グラフニューラルネットワークはノードやエンティティに対して豊かな埋め込み表現を生成することができますが、下流のタスクに応じて埋め込みベクトルが期待通りに機能しないことがあります。そのため研究者は、特定のタスクにアーキテクチャを適応させるためにカスタム損失関数や事前学習タスクなどの解決策を適用する必要があります。下流タスクとしてのグラフ検索も同様の傾向をたどり、豊かな埋め込み表現を特にサブグラフ検索の目的に合わせて作成するため、カスタマイズされたグラフニューラルネットワーク表現が必要です。私の研究は、完全および不完全な異種グラフ上でサブグラフ構造を検索することに焦点を当てています。私の研究方向の重要性は、正確なサブグラフ検索がNP困難な問題であり、既存の方法が正確であっても実用的に非常に遅いか、効率的であるが効果が低いかのどちらかである点にあります。完全および不完全なグラフに対して堅牢なニューラル表現を学習することに焦点を当て、効果的かつ効率的な検索方法を開発することを目指しています。具体的には、私の研究は以下の研究課題に取り組みます：RQ1) 異種グラフから効果的な埋め込みベクトルを生成し、効果的かつ効率的なサブグラフ検索をサポートできるグラフ表現学習方法を設計・開発することは可能か？RQ2) 欠損値の度合いが異なるグラフの問題に対処することは可能か？不完全なグラフは欠損属性や欠損エッジに苦しみます。欠損情報に対して効果的に検索可能な堅牢なグラフ表現学習モデルの設計を探求します。RQ3) 私のサブグラフ検索方法の効率的かつ効果的な派生形を、チーム編成や知識グラフ上のキーワード検索などの実世界の応用分野に適用することは可能か？私の博士課程の研究はこれまで、完全な異種グラフ上でのサブグラフの特定と取得に焦点を当ててきました。ケーススタディとしてチーム編成問題を用いて私の研究を評価しました[4]。次のステップとして、不完全なグラフを含むように研究を拡大し、グラフ検索の特定のタスクのために最適化されたグラフ表現を作成する方法論を調査する予定です。
        </label>
        <input type="checkbox" id="Panel460" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> With the development of new neural network architectures for graph learning in recent years, the use of graphs to store, represent and process data become more trendy. Nowadays, graphs as a rich structured form of data representation are used in many real-world projects. In these projects, objects are often defined in terms of their connections to other things. There are many practical applications in areas such as antibacterial discovery, physics simulations, fake news detection, traffic prediction and recommendation systems. While there are a growing number of neural graph representation learning techniques that allow one to learn effective graph representations [1-3, 5], they may not necessarily be appropriate for the task of searching over graphs for several reasons: (1) nodes within a graph consist of a set of attributes, which are the subject of the search process. However, the number of unique attributes on the graph compared to the number of attributes on each node is extremely sparse; therefore, this makes it very difficult to learn effective graph representations for such sparse information; (2) graph neural networks are capable of generating rich embedding representations for nodes and entities in graph however, depending on the downstream task, the embedding vectors may perform not well as expected. Therefore, researchers need to apply solutions such as custom loss functions or pre-training tasks to adapt mentioned architectures for their specific task. Search in the graph as a downstream task follows the same trend and therefore a tailored graph neural network representation is needed to particularly address the need for a rich embedding representation for the sole purpose of subgraph search. My work focuses on searching for subgraph structures over both complete and incomplete heterogeneous graphs. The significance of my research direction lies in the fact that exact subgraph search is an NP-hard problem and as such existing methods are either accurate but impractically slow, or efficient yet suffering from low effectiveness. With a focus on learning robust neural representations for complete and incomplete graphs, my research focuses on developing search methods that are both effective and efficient. Specifically, my research addresses the following research questions: RQ1) Would it be possible to design and develop graph representation learning methods for heterogeneous graphs that can generate effective embedding vectors from a heterogeneous graph and support effective and efficient subgraph search? RQ2) Whether it would be possible to address the issue of graphs with varying degrees of missing values. Incomplete graphs suffer from missing attributes and/or missing edges. I explore the design of robust graph representation learning models capable of effectively searching in light of missing information. RQ3) Can efficient and effective derivations of my subgraph search methods be used to address practical applications in real-world domains such as team formation, and keyword search over knowledge graphs? Research conducted as a part of my Ph.D. has so far focused on identifying and retrieving subgraphs over complete heterogeneous graphs. I have used the Team Formation problem as a case study in order to evaluate my work [4]. As the next step, I am planning to focus on expanding my research to include incomplete graphs and investigate methodologies to craft optimized graph representations for the specific task of searching on graphs.
        </div> </ul> <br>



        <label for="Panel461">
        <strong> Dense Passage Retrieval: Architectures and Augmentation Methods </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Thilina+C.+Rajapakse">Thilina C. Rajapakse</a> (1) </u>  <br>
        1:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591796">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Dense Passage Retrieval: Architectures and Augmentation Methods">Google Scholar</a></div>
        (461)
        <br>
        <b>概要:　</b> デュアルエンコーダーモデルは二つのエンコーダーモデルから構成される密な検索アーキテクチャであり、オープンドメイン検索において伝統的なスパース検索方法を凌駕しています[1]。しかし、特に未知の文やクエリに対して密な検索システムが曝される場合、改善の余地があります。トレーニングを受けたドメインとは異なるドメインから発生するクエリ、すなわちアウトオブドメインクエリを考慮すると、精度の低下は顕著になる可能性があります。その主な一因は、トレーニング中にコンテキストエンコーダーとクエリエンコーダーに提供される情報の不一致に起因します。一般的な検索トレーニングデータセットには、ある文からの単一クエリを含むパッセージが圧倒的に多数を占めます。このため、デュアルエンコーダーモデル、特にパッセージエンコーダーが、あるパッセージからの単一の潜在的クエリに過度に適合し、アウトオブドメイン性能が損なわれる可能性があります。これに基づき、以下の研究質問に答えることを目指します：（RQ1.1）複数のクエリを含むデータでDPRモデルをトレーニングすることで、モデルの汎化性が向上するか？ RQ1.1に答えるために、ほとんどのパッセージに複数のクエリを含む生成データセットを構築し、これらのデータセットでトレーニングされた密なパッセージ検索モデルを、主に単一クエリを持つパッセージデータセットでトレーニングされたモデルと比較します。複数のクエリを持つパッセージでトレーニングすることで、アウトオブディストリビューションおよびアウトオブドメインのテストデータセットに対してより良い汎化が可能なモデルが生成されることを示します[2]。<br><br>密な検索の文脈で、言語もまた別のドメインと見なすことができます。特に英語以外の言語においては、トレーニングデータの不足から密な検索モデルのトレーニングは特に挑戦的です。私は、特にアウトオブディストリビューションおよびゼロショット設定において検索品質を向上させることを目的とした、クラスタートレーニングと呼ばれる新しいトレーニング手法を提案します。次の研究質問に取り組みます：（RQ2.1）クラスタートレーニングは多言語DPRモデルのインディストリビューションデータに対する効果を向上させるか？（RQ2.2）クラスタートレーニングは、トレーニングされた言語からのアウトオブディストリビューションデータに対する多言語DPRモデルの効果を向上させるか？（RQ2.3）クラスタートレーニングは多言語DPRモデルが新しい言語（ゼロショット）に汎化するのに役立つか？クラスタートレーニングが、Mr. TyDi [3] データセットを使用して、インディストリビューション性能の明確な低下なしに、DPRモデルのアウトオブディストリビューションおよびゼロショット性能を向上させることを示します。<br><br>最後に、単一のフォワードパスで同じモデルが検索と再ランキングの両方を実行できるようにする修正デュアルエンコーダーアーキテクチャを提案します。デュアルエンコーダーモデルは従来のスパース検索方法を上回るものの、検索品質においては二段階検索パイプラインに遅れを取っています。デュアルエンコーダーモデルにおいて、最初の表現を用いて検索されたパッセージを再ランキングするために第二の表現を使用するという修正を提案します。ここでは、二段階のモデルは不要であり、両方の表現はデュアルエンコーダーから単一のフォワードパスで生成されます。この研究では以下の研究質問に答えることを目指します：（RQ3.1）同じモデルが2つの異なる用途を意図した2つの表現を効果的に生成するようにトレーニングできるか？（RQ3.2）検索と再ランキングを同時に行うことで、モデルの検索品質を向上させることができるか？（RQ3.3）提案手法と二段階検索手法の間で、検索品質とレイテンシおよび計算資源効率のトレードオフはどのようになっているか？提案するアーキテクチャがスループットを犠牲にすることなく、または追加の計算資源を必要とせずにデュアルエンコーダーの検索品質を改善することを期待します。
        </label>
        <input type="checkbox" id="Panel461" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> The dual-encoder model is a dense retrieval architecture, consisting of two encoder models, that has surpassed traditional sparse retrieval methods for open-domain retrieval [1]. But, room exists for improvement, particularly when dense retrievers are exposed to unseen passages or queries. Considering out-of-domain queries, i.e., queries originating from domains other than the one the model was trained on, the loss in accuracy may be significant. A main factor for this is the mismatch in the information available to the context encoder and the query encoder during training. Common retireval training datasets contain an overwhelming majority of passages with one query from a passage. I hypothesize that this could lead the dual-encoder model, particularly the passage encoder, to overfit to a single potential query from a given passage to the detriment of out-of-domain performance. Based on this, I seek to answer the following research question: (RQ1.1) Does training a DPR model on data containing multiple queries per passage improve the generalizability of the model? To answer RQ1.1, I build generated datasets that have multiple queries for most passages, and compare dense passage retriever models trained on these datasets against models trained on (mostly) single query per passage datasets. I show that training on passages with multiple queries leads to models that generalize better to out-of-distribution and out-of-domain test datasets [2]. Language can be considered another domain in the context of a dense retrieval. Training a dense retrieval model is especially challenging in languages other than English due to the scarcity of training data. I propose a novel training technique, clustered training, aimed at improving the retrieval quality of dense retrievers, especially in out-of-distribution and zero-shot settings. I address the following research questions: (RQ2.1)Does clustered training improve the effectiveness of multilingual DPR models on in-distribution data? (RQ2.2) Does clustered training improve the effectiveness of multilingual DPR models on out-of-distribution data from languages that it is trained on? (RQ2.2 Does clustered training improve the effectiveness of multilingual DPR models on out-of-distribution data from languages that it is trained on? (RQ2.3) Does clustered training help multilingual DPR models to generalize to new languages (zero-shot)? I show that clustered training improves the out-of-distribution and zero-shot performance of a DPR model without a clear loss in in-distribution performance using the Mr. TyDi [3] dataset. Finally, I propose a modified dual-encoder architecture that can perform both retrieval and reranking with the same model in a single forward pass. While dual encoder models can surpass traditional sparse retrieval methods, they lag behind two stage retrieval pipelines in retrieval quality. I propose a modification to the dual encoder model where a second representation is used to rerank the passages retrieved using the first representation. Here, a second stage model is not required and both representations are generated in a single forward pass from the dual encoder. I aim to answer the following research questions in this work: (RQ3.1), Can the same model be trained to effectively generate two representations intended for two uses? RQ3.2 Can the retrieval quality of the model be improved by simultaneously performing retrieval and reranking? (RQ3.3 What is the tradeoff between retrieval quality vs. latency and compute resource efficiency for the proposed method vs. a two stage retriever? I expect that my proposed architecture would improve the dual encoder retrieval quality without sacrificing throughput or needing more computational resources.
        </div> </ul> <br>



        <label for="Panel462">
        <strong> Evaluating Task-oriented Dialogue Systems with Users </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Clemencia+Siro">Clemencia Siro</a> (1) </u>  <br>
        1:  University of Amsterdam <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591788">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Evaluating Task-oriented Dialogue Systems with Users">Google Scholar</a></div>
        (462)
        <br>
        <b>概要:　</b> 情報検索システムの開発において、評価は主要な懸念事項の一つです。特に対話型AIの分野では、このトピックは非タスク指向およびタスク指向の対話エージェント（対話システム）の設定下で広く研究されています。最近、対話システムの評価のために提案されたBLEUやROUGEなどのいくつかの自動評価指標は、人間の判断と低い相関を示しており、対話システムの評価には効果的でないことが明らかとなっています。その結果、多くの研究が対話システムの有効性を推定するために人間による評価に依存しています。タスク指向対話システム（TDS）の評価のための新たなアプローチとして、明示的および暗黙的なユーザーインタラクションのシグナルからシステムに対するユーザーの全体的な満足度を推定する方法があります。この方法は有用で効果的ですが、全体的なユーザー満足度はTDSがどの側面や次元で良好に機能しているかについての洞察を必ずしも提供しません。ユーザーが満足している理由や不満な理由を理解することは、TDSがエラーから回復し、対話セッション中の全体的な不満を避けるために特定の側面を最適化するのに役立ちます。TDSに対するユーザーの満足度を理解することは主に二つの理由から重要です。第一に、システム設計者が異なるユーザーの満足度に関する認識を理解することができ、それによりより良いユーザーパーソナライゼーションを実現できます。第二に、システムが失敗回復やトピック変更などの適応型対話アプローチを展開することで、全体的な対話の失敗を避けることができます。このように、TDSの詳細な評価はシステムに個々のユーザーのインタラクションの嗜好を学習する機会を与え、ユーザーの目標達成をつながります。したがって、この研究では、TDSに対するユーザー満足度を理解するための最初の試みを行います。我々は主に、タスク指向の設定における対話システムの詳細な評価に焦点を当てます。
        </label>
        <input type="checkbox" id="Panel462" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Evaluation is one of the major concerns when developing information retrieval systems. Especially in the field of conversational AI, this topic has been heavily studied in the setting of both non-task and task-oriented conversational agents (dialogue systems).[1] Recently, several automatic metrics e.g., BLEU and ROUGE, proposed for the evaluation of dialogue systems, have shown poor correlation with human judgment and are thus ineffective for the evaluation of dialogue systems. As a consequence, a significant amount of research relies on human evaluation to estimate the effectiveness of dialogue systems[1, 4}. An emerging approach for evaluating task-oriented dialogue systems (TDS) is to estimate a user's overall satisfaction with the system from explicit and implicit user interaction signals [2, 3]. Though useful and effective, overall user satisfaction does not necessarily give insights into what aspects or dimensions a TDS is performing well on. Understanding why a user is satisfied or dissatisfied helps the TDS recover from an error and optimize towards an individual aspect to avoid total dissatisfaction during an interaction session. Understanding a user's satisfaction with TDS is crucial, mainly for two reasons. First, it allows system designers to understand different user perceptions regarding satisfaction, which in turn leads to better user personalization. Secondly, it can be used to avoid total dialogue failure by the system by deploying adaptive conversational approaches, such as failure recovery or switching topics. And, thus, fine-grained evaluation of TDS gives the system an opportunity to learn an individual user's interaction preferences leading to a fulfilled user goal. Therefore in this research, we take the first initiative toward understanding user satisfaction with TDS. We mainly focus on the fine-grained evaluation of conversational systems in a task-oriented setting.
        </div> </ul> <br>



        <label for="Panel463">
        <strong> Exploring User and Item Representation, Justification Generation, and Data Augmentation for Conversational Recommender Systems </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Sergey+Volokhin">Sergey Volokhin</a> (1) </u>  <br>
        1:  Emory University <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591795">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Exploring User and Item Representation, Justification Generation, and Data Augmentation for Conversational Recommender Systems">Google Scholar</a></div>
        (463)
        <br>
        <b>概要:　</b> 会話型レコメンダーシステム（CRS）は、ユーザーとの自然言語会話を通じてパーソナライズされた文脈に即した推薦を提供することを目的としています。私の提案する学位論文の目標は、会話型インターフェースの最近の発展を活用し、レコメンダーシステムの分野をいくつかの方向で前進させることです。本論文では、レコメンダーシステムにおけるユーザーとアイテムの表現、説明生成、データ希少性の問題に対処します。<br><br>CRSにおける重要な課題は、ユーザーおよびアイテムの効果的な表現を学び、その嗜好や特性を捉えることです。まず、ユーザー表現に焦点を当て、レビュー用の別のコーパス（データセット）を使用してユーザー表現を学習します。会話とレビューのテキスト間の意味的な類似性を用いて、会話ユーザーをレビュアーのスペースにマッピングすることを試みます。次に、アイテム表現を向上させるために、アイテムの説明などのテキスト情報をユーザー・アイテム間の相互作用グラフに組み込みます。これにより、単なるトポロジカルな構造からは得られない意味的および行動的な情報を多く取り込むことができます。<br><br>推薦の正当性を説明することは、CRSの説明可能性と透明性を高めますが、ルールベースおよびテンプレートベースの方法など既存のアプローチには限界があります。本研究では、レビューのコーパスを使用して、簡潔で一貫性のある正当性を生成するために関連情報を特定する抽出法を提案します。<br><br>CRSにおけるデータ希少性の課題には、最先端の生成型事前学習トランスフォーマー（GPT）を使用して合成会話を生成することで対応します。これらの合成会話は、CRSのトレーニングに使用されるデータを増強するために使用されます。さらに、GPTが大量のデータ（ユーザーのレビューや意見を含む）でトレーニングされているため、CRS（もしくは非会話型レコメンダーシステム）の新たな能力を発揮するかどうかも評価します。
        </label>
        <input type="checkbox" id="Panel463" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Conversational Recommender Systems (CRS) aim to provide personalized and contextualized recommendations through natural language conversations with users. The objective of my proposed dissertation is to capitalize on the recent developments in conversational interfaces to advance the field of Recommender Systems in several directions. I aim to address several problems in recommender systems: user and item representation, justification generation, and data sparsity.  A critical challenge in CRS is learning effective representations of users and items that capture their preferences and characteristics. First, we focus on user representation, where we use a separate corpus of reviews to learn user representation. We attempt to map conversational users into the space of reviewers using semantic similarity between the conversation and the texts of reviews. Second, we improve item representation by incorporating textual features such as item descriptions into the user-item interaction graph, which captures a great deal of semantic and behavioral information unavailable from the purely topological structure of the interaction graph.  Justifications for recommendations enhance the explainability and transparency of CRS; however, existing approaches, such as rule-based and template-based methods, have limitations. In this work, we propose an extractive method using a corpus of reviews to identify relevant information for generating concise and coherent justifications. We address the challenge of data scarcity for CRS by generating synthetic conversations using SOTA generative pre trained transformers (GPT). These synthetic conversations are used to augment the data used for training the CRS. In addition, we also evaluate if the GPTs exhibit emerging abilities of CRS (or a non-conversational RecSys) due to the large amount of data they are trained on, which potentially includes the reviews and opinions of users.
        </div> </ul> <br>



        <label for="Panel464">
        <strong> Towards Trustworthy Recommender System: A Faithful and Responsible Recommendation Perspective </strong> <br>
        <u> <b> Authors: </b> <a href="https://scholar.google.co.jp/citations?view_op=search_authors&mauthors=Yang+Zhang">Yang Zhang</a> (1) </u>  <br>
        1:  University of Science and Technology of China <br>
        <div class="mybtn3"><a href="https://dl.acm.org/doi/10.1145/3539618.3591798">ACM DL</a></div>
        <div class="mybtn3"><a href="https://scholar.google.co.jp/scholar?q=Towards Trustworthy Recommender System: A Faithful and Responsible Recommendation Perspective">Google Scholar</a></div>
        (464)
        <br>
        <b>概要:　</b> 推薦システム（RecSys）は、現代社会においてますます重要性を増しており、情報過多を軽減するためにパーソナライズされた情報フィルタリングを提供し、さまざまなオンライン活動に大きな影響を与えています。機械学習に基づく推薦方法は、より正確な推薦を実現するために近年大幅に進化しており、その一部はDeep Interest Network（DIN）のように産業用途で広く展開されています。しかし、その広範な利用にもかかわらず、研究者や実務者はこれらのシステムに内在する信頼性の問題、例えばバイアスや極性促進の問題を指摘しています。ユーザーにより良いサービスを提供し、各国が設けた推薦アルゴリズムに関する規制に準拠するためには、推薦システムの信頼性の問題を考慮することが不可欠です。本研究は、ユーザー中心の原則である「忠実性」と「責任性」の2つの観点から推薦システムの信頼性に焦点を当てます。一方では、収集された推薦データは、特にサービスの段階において、バイアス[2, 3]や時間的影響[4, 5]などにより、ユーザーの好みを忠実に反映するとは限りません。そのようなデータで忠実な推薦を実現することは、テスト中にユーザーの好みを忠実に反映させるために重要です。他方では、推薦システムはユーザーの好みに応えるだけでなく、無意識的または意図せぬ形でユーザーの好みに影響を与え（あるいは操る）こともあります。推薦プロセスにおいて、例えば潜在的な意見の分極化を避けるなど、推薦システムの影響を制御して責任ある推薦を提供することも、信頼できる推薦システムを構築するための重要な側面です。したがって、次の4つの研究質問が2つの側面に関して提起されます：RQ1: 訓練データがユーザーの現在の好みを忠実に反映しない場合、どのように本物のユーザーの好みをモデル化できるか？ RQ2: 推薦モデルがユーザーの将来の好みに忠実に対応することをどのように保証するか？ RQ3: 推薦システムがユーザーの好みに与える影響をどのように量化および評価するか？ RQ4: 推薦システムがユーザーの好みに与える影響をどのように制御して、負の副作用を避けるか？我々の目的は、これらの研究質問に取り組みながら、ユーザーに対して忠実かつ責任ある推薦を実現することです。忠実でない推薦は、訓練データとサービス目的との間の不一致に起因すると考え、これを異なるデータシフト問題として定式化します（RQ1およびRQ2）。これらのデータシフト問題を因果的視点から体系的に分析し、推薦の忠実性を向上させるためにいくつかの因果に基づく解決策を開発します。責任ある推薦の追求においては、推薦システムがユーザーに与える影響を因果的視点から調査します。我々は、推薦システムがユーザーの好みに与える影響を量化および制御するための因果効果評価と調整フレームワークを開発します（RQ3およびRQ4）。
        </label>
        <input type="checkbox" id="Panel464" class="on-off"/>
        <ul> <div class="abst"> <b>Abstract:　</b> Recommender systems (RecSys) become increasingly prevalent in modern society, offering personalized information filtering to alleviate information overload and significantly impacting various human online activities. Machine learning-based recommendation methods have been extensively developed in recent years to achieve more accurate recommendations, with some of these approaches having been extensively deployed in industrial applications, such as the Deep Interest Network (DIN). Despite their widespread use, researchers and practitioners have highlighted various trustworthiness issues inherent in these systems, including bias and promoting polarization issues. In order to better serve users and comply with regulations pertaining to recommendation algorithms established by different countries, it is essential to consider the trustworthiness issues of recommender systems. This research focuses on trustworthiness in recommendation from two perspectives of user-centered principles: faithfulness and responsibility. On the one hand, collected recommendation data may not faithfully reflect user preferences, especially those of the service stage, due to bias[2, 3] and temporal effects,[4,5]etc. Achieving faithful recommendations with such data is crucial to ensure user satisfaction, i.e., making recommendations faithfully reflect user preferences during the testing. On the other hand, recommender systems could not only cater to user preferences [1] but also unconsciously and unintentionally affect (or even manipulate) user preferences. In the recommendation process, controlling the influence of recommender systems, such as avoiding potential opinion polarization, to provide responsible recommendations is also an important aspect of building trustworthy recommender systems. Consequently, there raise four research questions on the two aspects: RQ1: How can we model genuine user preferences when training data fails to faithfully reflect the user's current preferences?RQ2: How can we ensure that recommender models faithfully match the user's future preferences?RQ3: How can we quantify and evaluate the impact of a recommender system on user preferences?RQ4: How can we control the impact of a recommender system on user preferences to avoid negative side effects?  Our objective is to achieve faithful and responsible recommendations for users while addressing these research questions. We attribute unfaithful recommendation to the discrepancies between the training data and the service objectives, which we formulate as different data shift problems (RQ1 and RQ2). We provide systematic analyses for these data shift problems from causal perspectives and develop several causality-inspired solutions to enhance recommendation faithfulness. In pursuit of responsible recommendations, we investigate the effect of recommender systems on users from a causal perspective. We develop a causal effect evaluation and adjustment framework to quantify and control the influence of recommender systems on user preferences (RQ3 and RQ4).
        </div> </ul> <br>


    </dib>
