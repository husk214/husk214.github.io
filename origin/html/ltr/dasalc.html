<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Zhen ICLR’21 Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees? &#8212; papers  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=db26dd79" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=579adecb" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=eab45d89" />
    <link rel="stylesheet" href="../_static/bootswatch-3.3.6/simplex/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=13a9ecda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/js/jquery-fix.js"></script>
    <script src="../_static/bootstrap-3.3.6/js/bootstrap.min.js"></script>
    <script src="../_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Zhuang SIGIR’20 Feature Transformation for Neural Ranking Models" href="mixture_transformation.html" />
    <link rel="prev" title="Learning to Rank" href="../ltr.html" />
<link rel="stylesheet" href="_static/custom.css" type="text/css" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-74773673-1', 'auto');
  ga('send', 'pageview');
</script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          ashibaga</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../metriclearning.html">Metric Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/reality_check.html">Musgrave ECCV’20 A Metric Learning Reality Check</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/lifted_structured.html">Song CVPR’16 Deep Metric Learning via Lifted Structured Feature Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/multi_similarity.html">Wang CVPR19 Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/multi_similarity.html#wang-cvpr-20-cross-batch-memory-for-embedding-learning">Wang CVPR’20 Cross-Batch Memory for Embedding Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/proxy_nca.html">Movshovitz ICCV’17 No fuss distance metric learning using proxies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/proxy_anchor.html">Kim CVPR’20 Proxy Anchor Loss for Deep Metric Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/s2sd.html">Roth ICML’21 Simultaneous Similarity-based Self-Distillation for Deep Metric Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/clip.html">Radford ICML’21 CLIP (Learning Transferable Visual Models From Natural Language Supervision)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/lang_guide.html">Roth CVPR’22 Integrating Language Guidance into Vision-based Deep Metric Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../noisylabel.html">Learning from Noisy Labels</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../noisylabel/confident_learning.html">Northcutt ICML’20 Confident Learning: Estimating Uncertainty in Dataset Labels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../noisylabel/pervasive_label_errors.html">Northcutt NeurIPS’21 Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../ssl.html">Self Supervised Learning (SSL)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../ssl/simclr.html">Chen ICML’20 SimCLR (A Simple Framework for Contrastive Learning of Visual Representations)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ssl/byol.html">Grill NIPS’20 BYOL (Bootstrap Your Own Latent A New Approach to Self-Supervised Learning)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ssl/simsiam.html">Chen CVPR’21 SimSiam (Exploring Simple Siamese Representation Learning)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ssl/how_avoid.html">Does ICLR’22 How Does SimSiam Avoid Collapse Without Negative Samples?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../representation.html">Representation Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../representation/understaing_crl.html">Wang ICML’20 Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../other.html">Other</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../other/sentencepiece.html">Kudo EMNLP’18 SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/optimizer_benchmark.html">Teja ICML’20 Optimizer Benchmarking Needs to Account for Hyperparameter Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/user_centric_ranking.html">Zhao (KDD’23) Breaking the Curse of Quality Saturation with User-Centric Ranking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/quert.html">Xie (KDD’23) QUERT: Continual Pre-training of Language Model for Query Understanding in Travel Domain Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/tensorflow_serving.html">Tensorflow Serving</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/search_engine_qu.html">検索システム 実務者のための開発改善ガイドブック 11章 検索を成功させるための支援</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../proceedings.html">Proceedings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir23_abst.html">SIGIR’23 ABSTRACT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir22_abst.html">SIGIR’22 ABSTRACT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir21_abst.html">SIGIR’21 ABSTRACT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir20_abst.html">SIGIR’20 ABSTRACT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir19_abst.html">SIGIR’19 ABSTRACT</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../ltr.html">Learning to Rank</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Zhen ICLR’21 Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?</a></li>
<li class="toctree-l2"><a class="reference internal" href="mixture_transformation.html">Zhuang SIGIR’20 Feature Transformation for Neural Ranking Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="neuralsort.html">Grover ICLR’19 Stochastic Optimization of Sorting Networks via Continuous Relaxations</a></li>
<li class="toctree-l2"><a class="reference internal" href="otsort.html">Cuturi NeurIPS’19 Differentiable Ranks and Sorting using Optimal Transport</a></li>
<li class="toctree-l2"><a class="reference internal" href="fastsort.html">Blondel ICML’20 Fast Differentiable Sorting and Ranking</a></li>
<li class="toctree-l2"><a class="reference internal" href="diffsortnet.html">Petersen ICML’21 Differentiable Sorting Networks for Scalable Sorting and Ranking Supervision</a></li>
<li class="toctree-l2"><a class="reference internal" href="monodiffsort.html">Petersen ICLR’22 Monotonic Differentiable Sorting Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="algorithm.html">Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="metric.html">Metric</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Zhen ICLR’21 Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?</a><ul>
<li><a class="reference internal" href="#id1">概要</a></li>
<li><a class="reference internal" href="#id2">既存手法のベンチマーク</a><ul>
<li><a class="reference internal" href="#dlcm">DLCM</a></li>
<li><a class="reference internal" href="#setrank">SetRank</a></li>
</ul>
</li>
<li><a class="reference internal" href="#nn">NNモデルの弱さ</a></li>
<li><a class="reference internal" href="#id3">提案フレームワーク</a><ul>
<li><a class="reference internal" href="#id4">ロス関数</a><ul>
<li><a class="reference internal" href="#id5">ロス関数の比較</a></li>
<li><a class="reference internal" href="#approx-ndcg">Approx NDCGについて詳しく</a></li>
</ul>
</li>
<li><a class="reference internal" href="#remark">Remark</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6">実験</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="../ltr.html" title="Previous Chapter: Learning to Rank"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Learning to Rank</span>
    </a>
  </li>
  <li>
    <a href="mixture_transformation.html" title="Next Chapter: Zhuang SIGIR’20 Feature Transformation for Neural Ranking Models"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Zhuang SIGIR’... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Zhen ICLR’21 Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?</a><ul>
<li><a class="reference internal" href="#id1">概要</a></li>
<li><a class="reference internal" href="#id2">既存手法のベンチマーク</a><ul>
<li><a class="reference internal" href="#dlcm">DLCM</a></li>
<li><a class="reference internal" href="#setrank">SetRank</a></li>
</ul>
</li>
<li><a class="reference internal" href="#nn">NNモデルの弱さ</a></li>
<li><a class="reference internal" href="#id3">提案フレームワーク</a><ul>
<li><a class="reference internal" href="#id4">ロス関数</a><ul>
<li><a class="reference internal" href="#id5">ロス関数の比較</a></li>
<li><a class="reference internal" href="#approx-ndcg">Approx NDCGについて詳しく</a></li>
</ul>
</li>
<li><a class="reference internal" href="#remark">Remark</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6">実験</a></li>
</ul>
</li>
</ul>

  <li>
    <a href="../ltr.html" title="Previous Chapter: Learning to Rank"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Learning to Rank</span>
    </a>
  </li>
  <li>
    <a href="mixture_transformation.html" title="Next Chapter: Zhuang SIGIR’20 Feature Transformation for Neural Ranking Models"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Zhuang SIGIR’... &raquo;</span>
    </a>
  </li>
<div id="sourcelink">
  <a href="../_sources/ltr/dasalc.rst.txt"
     rel="nofollow">Source</a>
</div>
<form action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="col-md-9 content">
      
  <section id="zhen-iclr-21-are-neural-rankers-still-outperformed-by-gradient-boosted-decision-trees">
<h1>Zhen ICLR’21 Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?<a class="headerlink" href="#zhen-iclr-21-are-neural-rankers-still-outperformed-by-gradient-boosted-decision-trees" title="Link to this heading">¶</a></h1>
<p><a class="reference external" href="https://openreview.net/forum?id=Ut1vF_q_vC">https://openreview.net/forum?id=Ut1vF_q_vC</a></p>
<p>著者 (全員 Google Research)</p>
<ul class="simple">
<li><p>Zhen Qin</p></li>
<li><p>Le Yan</p></li>
<li><p>Honglei Zhuang</p></li>
<li><p>Yi Tay</p></li>
<li><p>Rama Kumar Pasumarthi</p></li>
<li><p>Xuanhui Wang</p></li>
<li><p>Michael Bendersky</p></li>
<li><p>Marc Najork</p></li>
</ul>
<section id="id1">
<h2>概要<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>多くの分野でNNモデルが成功しているが、伝統的なLTRの分野ではまだ有効性は認められていない</p>
<ul>
<li><p>まず最初に、最新のNNモデルがGBDTに大差で劣っていることを示す</p></li>
</ul>
</li>
<li><p>なぜ neraul LTRがGBDTに劣っているかを調査して、弱点を明らかにし、改善方法を考える</p></li>
<li><p>GBDTと同等な性能を発揮するNNモデルを提案する (最新のNNモデルには大勝する)</p></li>
</ul>
</section>
<section id="id2">
<h2>既存手法のベンチマーク<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h2>
<section id="dlcm">
<h3>DLCM<a class="headerlink" href="#dlcm" title="Link to this heading">¶</a></h3>
<p><a class="reference external" href="https://arxiv.org/abs/1804.05936">Learning a Deep Listwise Context Model for Ranking Refinement</a> (SIGIR’18)</p>
<ul class="simple">
<li><p>何らかのモデルで文書リストを並び替えたものをGRUに突っ込む</p></li>
<li><p>GRUの各文書に対するstateと最終stateを使って、最終的な出力とする</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_dlcm_f1.png"><img alt="../_images/ltr_dlcm_f1.png" class="align-center" src="../_images/ltr_dlcm_f1.png" style="width: 796.1999999999999px; height: 289.2px;" />
</a>
<div class="math notranslate nohighlight">
\begin{align}
  \phi(o_{n+1-i}, s_n)
  = V_{\phi} \cdot (o_{n+1-i}  \text{tanh}(W_\phi s_n + b_{\phi} ))
\end{align}</div><p><strong>Attention Rank Loss</strong></p>
<div class="math notranslate nohighlight">
\begin{align}
 - &amp;\sum_{i \in [n]} a^y_i \log a^s_i + (1-a^y_i) \log (1-a^s_i) \\
  , &amp; \text{where}~~ a^y_i = \frac{\exp(y_i)}{\sum_{k \in [n]} \exp(y_k)}
  , ~ a^s_i = \frac{\exp(s_i)}{\sum_{k \in [n]} \exp(s_k)}
\end{align}</div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> : 教師スコア, <span class="math notranslate nohighlight">\(s_i\)</span> 予測スコア</p></li>
</ul>
<p><strong>設定と比較手法</strong></p>
<ul class="simple">
<li><p>初期リストはRank-SVM, LambdaMART (ranklib) で作る</p></li>
<li><p>LIDNN : FFNの入力として、文書リストの特徴量をconcatと入れて、出力は文書リストのスコア</p>
<ul>
<li><p>入力文書リスト数が40, 各文書の特徴量が700だとすると、入力次元数は28000, 出力次元数は40</p></li>
<li><p>文書リスト全体を使える単純なモデルとして用意</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_dlcm_t2.png"><img alt="../_images/ltr_dlcm_t2.png" class="align-center" src="../_images/ltr_dlcm_t2.png" style="width: 781.8px; height: 442.8px;" />
</a>
</section>
<section id="setrank">
<h3>SetRank<a class="headerlink" href="#setrank" title="Link to this heading">¶</a></h3>
<p><a class="reference external" href="https://arxiv.org/abs/1912.05891">SetRank Learning a Permutation Invariant Ranking Model for Information Retrieval</a> (SIGIR’20)</p>
<ul class="simple">
<li><p>Multi-head Self Attention Block (MSAB)使ったやつ</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_setrank_f1.png"><img alt="../_images/ltr_setrank_f1.png" class="align-center" src="../_images/ltr_setrank_f1.png" style="width: 479.4px; height: 492.59999999999997px;" />
</a>
<ul class="simple">
<li><p>Ordinal EmbeddingはDLCMみたいに初期のランクが与える場合、その文書のランクを入力にしたembedding (詳しく書いてないが、たぶん普通の学習可能なembedding)</p></li>
</ul>
<p><strong>Induced Multi-head Self attention Block (IMSAB)</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1810.00825">Set Transformer A Framework for Attention based Permutation Invariant Neural Networks</a> (ICML’19) で提案されている</p></li>
<li><p>MASBの問題は入力のセットのサイズに敏感であること</p></li>
<li><p>学習時と実際に使いときは入力のセットのサイズが違うことが多いので、問題</p></li>
<li><p>その問題に対応するために induces multi-head self atteion blockを導入した</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_setrank_f2.png"><img alt="../_images/ltr_setrank_f2.png" class="align-center" src="../_images/ltr_setrank_f2.png" style="width: 472.2px; height: 528.6px;" />
</a>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(I \in \mathbb{RR}^{M \times E}\)</span> は学習可能なパラメータ (Mはハイパーパラメータ)</p></li>
<li><p>SetTransformerの論文では、IMSABを導入した理由は計算コストを:math:<cite>O(n^2)</cite> から <span class="math notranslate nohighlight">\(O(mn)\)</span> に下げるため</p></li>
<li><p>なぜ IMSABが↑の問題の解決策になるのか理解できない</p></li>
</ul>
<p><strong>実験結果</strong></p>
<a class="reference internal image-reference" href="../_images/ltr_setrank_t2.png"><img alt="../_images/ltr_setrank_t2.png" class="align-center" src="../_images/ltr_setrank_t2.png" style="width: 181.2px; height: 459.0px;" />
</a>
<p><strong>DASALC論文の実験</strong></p>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_t1.png"><img alt="../_images/ltr_dasalc_t1.png" class="align-center" src="../_images/ltr_dasalc_t1.png" style="width: 714.0px; height: 409.8px;" />
</a>
<ul class="simple">
<li><p>LightGBM最強</p></li>
<li><p>DLCM, <span class="math notranslate nohighlight">\(\text{SetRank}^{re}\)</span> は別モデルを使った初期リストが必要だが、DASALC論文ではその初期リストはRanklibのLambdaMARTを使っている</p>
<ul>
<li><p>DLCM, SetRankの論文ではRanklibが使われているからと書いてあったが、lightgbmのほうがとても強いといっているので、lightgbmにしてほしかった</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="nn">
<h2>NNモデルの弱さ<a class="headerlink" href="#nn" title="Link to this heading">¶</a></h2>
<p><strong>Feature transformation</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="mixture_transformation.html"><span class="doc">Zhuang SIGIR’20 Feature Transformation for Neural Ranking Models</span></a> によると、NNは特徴量変換にセンシティブ (そんなにセンシティブというほどではないのでは..?)</p>
<ul>
<li><p>LTR datasetsはアイテムのクリック数などロングテールな分布を持つ多様なスケールの特徴量で構築されている</p></li>
<li><p>木構造モデルを用いものは特徴空間を効率的に分割することができて、数値特徴のみをもつデータセットで強い</p></li>
</ul>
</li>
<li><p>最近の研究ではガウス正規化よりも優れた変換が示されているが、neural LTRのパイオニア的な論文ではその影響は議論されていない</p></li>
</ul>
<p><strong>Network architecture</strong></p>
<ul class="simple">
<li><p>neural LTRの論文ではアーキテクチャに焦点を当てていないものは、大概FC層を重ねたものを使っている</p>
<ul>
<li><p>FC層は高次のインタラクションを捉えるのに非効率的 (以下の論文を参照している)</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1708.05123.pdf">Deep Cross Network</a> (AdKDD’17)</p></li>
<li><p><a class="reference external" href="https://research.google/pubs/pub46488/">Latent Cross</a> (WSDM’18)</p></li>
</ul>
</li>
<li><p>その問題は広告CTR予測(Deep Cross Network), レコメンデーション(Latent Cross)では注目されているが、LTRでは注目されていない</p></li>
</ul>
</li>
</ul>
<p><strong>Data sparsity (特徴量がスパースということではなく、標本数が少ない)</strong></p>
<ul class="simple">
<li><p>nerural LTRの論文のモデルは小さく、パラメータの多いモデルを使っていない</p>
<ul>
<li><p>おそらくoverfitしてしまうから、パラメータの多いモデルにできない</p>
<ul>
<li><p>大規模なデータセットは、他のドメインのNNモデルの多くの最近の成功の重要な要因である</p></li>
<li><p>publicなLTR データセットは比較的小さい</p></li>
</ul>
</li>
<li><p>パラメータの多いモデルでoverfitを回避するためのData augmentationは他領域でもよく使われている</p>
<ul>
<li><p>しかし、LTRデータセットではどうData augmentationは直感的でない (CVにおける画像を回転させるとかと比べると)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="id3">
<h2>提案フレームワーク<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h2>
<p>DASALC (Data Augmented SelfAttentive Latent Cross)</p>
<p><strong>Feature Transofrmation</strong></p>
<p>Log1p transformation を使う</p>
<div class="math notranslate nohighlight">
\begin{align}
  x = \log_e(1+|x|) \odot \text{sign}(x)
\end{align}</div><p>(<span class="math notranslate nohighlight">\(\odot\)</span> : element-wise multiplication operator)</p>
<p><strong>Data Augmentation</strong></p>
<p>Gaussian noiseを加える (Log1pのあとに)</p>
<div class="math notranslate nohighlight">
\begin{align}
  x = x + \mathcal{N}(0, \sigma^2 I)
\end{align}</div><ul class="simple">
<li><p>特徴量はLog1p変換で正規化されているので、<span class="math notranslate nohighlight">\(\sigma\)</span> を特徴量ごとに変えないのは合理的だと言っている</p></li>
<li><p>このようなシンプルなData AugmentationはDASALCだからうまくいって、そうでない場合うまくいかない (実験的に後で示す)</p></li>
</ul>
<p><strong>LEVERAGING LISTWISE CONTEXT</strong></p>
<ul class="simple">
<li><p>LTRでは、文書 :math:<cite>x_i</cite> のリストをNNモデルに活用できる</p>
<ul>
<li><p>-&gt; LTRのNNアーキテクチャを強くするための重要な鍵</p></li>
<li><p>-&gt; リスト情報をencodeするために、Multi-head self-attention (MHSA)を使う</p></li>
</ul>
</li>
<li><p>普通のDNN(FC-ReLU-BNを重ねたもの)の出力とMHSA側の出力をLaten Crossで統合する</p></li>
</ul>
<div class="math notranslate nohighlight">
\begin{align}
  h_i^{\text{cross}} = (1 + a_i) \odot h_{\text{out}}(x_i)
\end{align}</div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(a_i\)</span> : MHSA側の出力</p></li>
<li><p><span class="math notranslate nohighlight">\(h_{\text{out}}(x_i)\)</span> : 普通のDNN側の出力</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_f1.png"><img alt="../_images/ltr_dasalc_f1.png" class="align-center" src="../_images/ltr_dasalc_f1.png" style="width: 656.8000000000001px; height: 508.0px;" />
</a>
<p><strong>疑問: リストの順番よって出力が変わってしまうとまずくないですか?</strong></p>
<p><strong>Proposition 1</strong></p>
<p>DASALCの出力スコアは permutationによって変化しない(permutation equivariant), つまり</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\pi\)</span> : (任意の)文書リストの順番並び替え関数</p></li>
<li><p><span class="math notranslate nohighlight">\(x \in \mathbb{R}^{n \times k}\)</span> : 文書リスト</p></li>
<li><p><span class="math notranslate nohighlight">\(s_{DASALC}(x)\)</span> : DASALCモデルの出力値</p></li>
</ul>
<p>として</p>
<div class="math notranslate nohighlight">
\begin{align}
  s_{DASALC}(\pi(x)) = \pi(s_{DASALC}(x))
\end{align}</div><p>(MHSAがpermutation equivariantなので by <a class="reference external" href="https://arxiv.org/abs/1912.05891">https://arxiv.org/abs/1912.05891</a> (SetRank論文) )</p>
<section id="id4">
<h3>ロス関数<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>ロス関数はsoftmax cross entropy loss <span class="math notranslate nohighlight">\(l(y, s(x)) = - \sum_{i=1}^n y_i \log_e \frac{\exp(s_i)}{\sum_j \exp(s_j)}\)</span></p>
<ul>
<li><p>pointwise, pairwise, listwiseいろいろな関数を比較したが、robustで性能が良かったから使っているらしい</p></li>
</ul>
</li>
</ul>
<section id="id5">
<h4>ロス関数の比較<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>SigmoidCrossEntropy:  よく使われているpointwise loss</p></li>
</ul>
<div class="math notranslate nohighlight">
\begin{align}
  l(y, s(x)) = \sum_{i=1}^n -y_i s_i + \log(1+\exp(s_i))
\end{align}</div><ul class="simple">
<li><p><a class="reference external" href="https://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf">RankNet</a> (ICML’05): ポピュラーなpairwise loss</p></li>
</ul>
<div class="math notranslate nohighlight">
\begin{align}
  l(y, s(x)) = \sum_{y_i &gt; y_j} \log(1+\exp(s_j - s_i))
\end{align}</div><ul class="simple">
<li><p><a class="reference external" href="https://papers.nips.cc/paper/2006/hash/af44c4c56f385c43f2529f9b1b018f6a-Abstract.html">LambdaRank</a> (NIPS’07) : <span class="math notranslate nohighlight">\(\Delta NDCG(i,j)\)</span> (iとjを入れ替えたときのNDCGの変化量の絶対値) で重み付けしたpairwise lossで <a class="reference external" href="https://www.microsoft.com/en-us/research/uploads/prod/2016/02/MSR-TR-2010-82.pdf">LambdaMART</a> で使われている</p></li>
</ul>
<div class="math notranslate nohighlight">
\begin{align}
  l(y, s(x)) = \sum_{y_i &gt; y_j} \Delta NDCG(i,j) \log_2 (1+\exp(-\alpha (s_i - s_j )))
\end{align}</div><ul class="simple">
<li><p><a class="reference external" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf">Softmax</a> (ICML’07) : ListNet論文のやつ。ポピュラーなlistwise loss</p></li>
</ul>
<div class="math notranslate nohighlight">
\begin{align}
  l(y, s(x)) = - \sum_{i=1}^n y_i \log_e \cfrac{\exp(s_i)}{\sum_j \exp(s_j)}
\end{align}</div><ul class="simple">
<li><p><a class="reference external" href="https://link.springer.com/article/10.1007/s10791-009-9124-x">ApproxNDCG</a> (IR’10) : 微分可能にするためにNDCGを近似したもの (listwise loss)</p></li>
</ul>
<div class="math notranslate nohighlight">
\begin{align}
  l(y, s(x)) &amp;= - \frac{1}{DCG(\pi^*, y)} \sum_{i=1}^n \cfrac{2^{y_i} -1 }{\log_2 (1+\pi_s(i))} \\
  , \text{where}~~ \pi_s(i) &amp;= \cfrac{1}{2} + \sum_j \text{sigmoid} \left( \frac{s_j - s_i}{T} \right) ~~ (\text{ T : smooth parameter})
\end{align}</div><ul class="simple">
<li><p><a class="reference external" href="https://dl.acm.org/doi/10.1145/3336191.3371844">GumbelApproxNDCG</a> (SIGIR’19, WSDM’20) : ApproxNDCGにstochastic treatmentをしたもの.</p>
<ul>
<li><p>ApproxNDCGのスコアsにgumbel noise <span class="math notranslate nohighlight">\(g\)</span> を加えたもの (<span class="math notranslate nohighlight">\(s_i  + g_i\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(g_i = -\log_e(-log_e U_i), ~~ U_i\)</span>  uniformly sampled in <span class="math notranslate nohighlight">\([0, 1]\)</span></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://openreview.net/forum?id=H1eSS3CcKX">NeuralSortNDCG</a> (ICLR’19) NeuralSort trickを使ってNDCGを近似したもの (listwise loss)</p></li>
</ul>
<div class="math notranslate nohighlight">
\begin{align}
  l(y, s(x)) &amp;= - \frac{1}{DCG(\pi^*, y)} \sum_{i, r=1}^n \cfrac{(2^{y_i} -1) P_{ir}^s }{\log_2 (1+r))} \\
  , \text{where}~~ P_{ir}^s &amp;= \text{softmax}\left(\cfrac{(n+1-2i)s_r - \sum_j |s_r -s_j | }{T}\right)
\end{align}</div><ul class="simple">
<li><p>GumbelNeuralSortNDCG: NeuralSortNDCGのsにgumbel noise <span class="math notranslate nohighlight">\(g\)</span> を加えたもの</p></li>
</ul>
<p><strong>実験による制度比較</strong></p>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_t6.png"><img alt="../_images/ltr_dasalc_t6.png" class="align-center" src="../_images/ltr_dasalc_t6.png" style="width: 692.0px; height: 216.8px;" />
</a>
<ul class="simple">
<li><p>モデルは standard feed-forward network</p></li>
<li><p>ハイパーパラメータチューニング</p>
<ul>
<li><p>Optmizerとlearning rate</p>
<ul>
<li><p>Adam (learning rate <span class="math notranslate nohighlight">\(\in \{10^{-4}, 10^{-3}, 10^{-2}\}\)</span> )</p></li>
<li><p>Adagrad (learning rate <span class="math notranslate nohighlight">\(\in \{0.01, 0.1, 0.5\}\)</span> )</p></li>
</ul>
</li>
<li><p>smooth paramter <span class="math notranslate nohighlight">\(T \in \{0.1, 1, 10\}\)</span></p></li>
<li><p>で NDCG&#64;5でベストだったものをレポート</p></li>
</ul>
</li>
</ul>
<p>得られた知見</p>
<ul class="simple">
<li><p>listwiseがpointwise, pairwiseより良かった</p></li>
<li><p>listwiseはどれもcomparableで (本当か?) softmax cross entropyは異なるモデルや異なるデータセットでも一貫して良い性能を発揮していたので、他の実験では使っている</p></li>
<li><p>LambdaRankはNNモデルではうまくいかない</p>
<ul>
<li><p>一方 <a class="reference external" href="https://research.google/pubs/pub48321/">Bruch et al</a>  ., (SIGIR’19)では、ツリーモデル + Sotfmatx lossはLambdaMARTより弱いと指摘されている</p></li>
<li><p>-&gt; ツリーモデルとneural LTRモデルは異なる損失関数で異なる挙動を示す</p></li>
</ul>
</li>
</ul>
</section>
<section id="approx-ndcg">
<span id="labelapproxndcg"></span><h4>Approx NDCGについて詳しく<a class="headerlink" href="#approx-ndcg" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>DASALC論文では <a class="reference external" href="https://research.google/pubs/pub48168/">Revisiting Approximate Metric Optimization in the Age of Deep Neural Networks</a>  (SIGIR’19) を引用している</p>
<ul>
<li><p>ApproxNDCG理論的にもいいし、実験的も強いことを確認している論文</p>
<ul>
<li><p>LambdaMARTが出てきた時期に提案されていたので注目されてなかった</p></li>
<li><p>その時期はNNを学習するテクニックが発展途上だった</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>ApproxNDCG再掲</p>
<div class="math notranslate nohighlight">
\begin{align}
  l(y, s(x)) &amp;= - \frac{1}{DCG(\pi^*, y)} \sum_{i=1}^n \cfrac{2^{y_i} -1 }{\log_2 (1+\pi_s(i))} \\
  , \text{where}~~ \pi_s(i) &amp;= \cfrac{1}{2} + \sum_j \text{sigmoid} \left( \frac{s_j - s_i}{T} \right) ~~ (\text{ T : smooth parameter})
\end{align}</div><p>NDCGとはなんだっか</p>
<div class="math notranslate nohighlight">
\begin{align}
  \text{NDCG}&#64;k = N_k^{-1} \sum_{j=1}^k g(r_j)d(j)
\end{align}</div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(r_j\)</span>: ランキングのj番目の relevance score</p></li>
<li><p><span class="math notranslate nohighlight">\(g(r_j)\)</span> : gain function (e.g., <span class="math notranslate nohighlight">\(2^{r_j} - 1\)</span> )</p></li>
<li><p><span class="math notranslate nohighlight">\(d(j)\)</span> : discount function (e.g., <span class="math notranslate nohighlight">\(1 / \log_2 (1+j)\)</span> ) (下位ほど値が下がっていく)</p></li>
<li><p><span class="math notranslate nohighlight">\(N_k: ~ \sum_{j=1}^k g(r_j)d(j)\)</span> が最大になるようにランキングの並び替えたときのそれの値</p></li>
</ul>
<div class="math notranslate nohighlight">
\begin{align}
  \text{NDCG} = N_n^{-1} \sum_{x \in \mathcal{X}} \frac{2^{r(x)} - 1}{\log_2 (1 + \pi(x) )}
\end{align}</div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\pi(x)\)</span> : 文書xがランキングの何位にいるかを返す関数 (position function)</p></li>
</ul>
<p>position functionが微分できないので、これを近似していくわけですが、 指示関数を使って以下のように表現できる</p>
<p>(自分よりスコアの高い文書を数えていくだけなんですが)</p>
<div class="math notranslate nohighlight">
\begin{align}
  \pi(x) = 1 + \sum_{y \in \mathcal{X}, y \neq x } I \{s_{x,y} &lt; 0 \}
\end{align}</div><ul class="simple">
<li><p>where <span class="math notranslate nohighlight">\(s_{x,y} = s_x - s_y\)</span></p></li>
</ul>
<p>指示関数 <span class="math notranslate nohighlight">\(I\)</span> が微分できないわけですが、ここをおなじみのlogistic functionで近似する</p>
<div class="math notranslate nohighlight">
\begin{align}
  \hat{\pi}(x) =
  1 + \sum_{y \in \mathcal{X}, y \neq x } \frac{\exp(-\alpha s_{x,y})}{1+\exp(-\alpha s_{x,y})}
\end{align}</div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\alpha=100\)</span> にするとよく近似できているのがわかる</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_approx_ndcg_t1.png"><img alt="../_images/ltr_approx_ndcg_t1.png" class="align-center" src="../_images/ltr_approx_ndcg_t1.png" style="width: 348.59999999999997px; height: 150.0px;" />
</a>
<p><strong>近似誤差のバウンド</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(s_{x,y} = 0\)</span> (xとyが同じrelevance scoreを持っている)が存在するケースを考えると複雑になってしまうので、以下を仮定する</p></li>
</ul>
<div class="math notranslate nohighlight">
\begin{align}
  \delta :=  \min_{x, y \in \mathcal{X}, x \neq y } |s_{x,y}| &gt; 0
\end{align}</div><p>Theorem 3. 文書集合 <span class="math notranslate nohighlight">\(\mathcal{X}, \forall \alpha &gt; 0\)</span>  に対して、以下が成り立つ</p>
<div class="math notranslate nohighlight">
\begin{align}
  | \hat{\pi}(x) - \pi(x) | &lt; \frac{n-1}{\exp(\delta_x \alpha) + 1}
\end{align}</div><ul class="simple">
<li><p>where <span class="math notranslate nohighlight">\(\delta_x = \min_{y \in \mathcal{X}, y \neq x} |s_{x,y}|\)</span></p></li>
</ul>
<p>Corollary 4.  文書集合 <span class="math notranslate nohighlight">\(\mathcal{X}, \forall \alpha &gt; 0\)</span>  に対して、以下が成り立つ</p>
<div class="math notranslate nohighlight">
\begin{align}
  \epsilon := \max_{x \in \mathcal{X}} | \hat{\pi}(x) - \pi(x) | &lt; \frac{n-1}{\exp(\delta \alpha) + 1}
\end{align}</div><p>Table 1の例で確認すると、</p>
<div class="math notranslate nohighlight">
\begin{align}
  0.00118 = \epsilon &lt; \frac{5-1}{\exp(0.06744 \times \alpha) + 1} \approx 0.00471
\end{align}</div><p>Theorem 6. ApproxNDCGの近似誤差は以下のようにバウンドできる</p>
<div class="math notranslate nohighlight">
\begin{align}
  | \hat{NDCG} - NDCG | &lt; \frac{\epsilon}{2 \ln 2}
\end{align}</div><p>Table 1の例で確認すると <span class="math notranslate nohighlight">\(| \hat{NDCG} - NDCG | &lt; \frac{\epsilon}{2 \ln 2} \approx 0.00085\)</span></p>
</section>
</section>
<section id="remark">
<h3>Remark<a class="headerlink" href="#remark" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>より柔軟なデータ変換の学習 (<a class="reference internal" href="mixture_transformation.html"><span class="doc">Zhuang SIGIR’20 Feature Transformation for Neural Ranking Models</span></a>) や <a class="reference external" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Cubuk_AutoAugment_Learning_Augmentation_Strategies_From_Data_CVPR_2019_paper.pdf">Autoaugment</a> (最適なdata augmentationを探索して見つける) を使わなかった理由</p>
<ul>
<li><p>NNモデルがツリーモデルに劣る原因を特定することが目的なので、意図的にシンプル or ポピュラーな手法を使っている (?)</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="id6">
<h2>実験<a class="headerlink" href="#id6" title="Link to this heading">¶</a></h2>
<p>ハイパーパラメータチューニング: valid data使ってチューニングする</p>
<ul class="simple">
<li><p>LambdaMARTGBM (grid search)</p>
<ul>
<li><p>the number of trees <span class="math notranslate nohighlight">\(\in \{300, 500, 1000\}\)</span></p></li>
<li><p>number of leaves <span class="math notranslate nohighlight">\(\in \{200, 500, 1000\}\)</span></p></li>
<li><p>learning rate <span class="math notranslate nohighlight">\(\in \{0.01, 0.05, 0.1, 0.5\}\)</span></p></li>
</ul>
</li>
<li><p>DASALC</p>
<ul>
<li><p>hidden layer size <span class="math notranslate nohighlight">\(\in \{256, 512, 1024, 2048, 3072, 4096 \}\)</span></p>
<ul>
<li><p>既存研究との顕著な違いは、Data augmentationをする場合4096のような大きなモデルのほうが上手くいく</p></li>
</ul>
</li>
<li><p>the number of layers <span class="math notranslate nohighlight">\(\in \{3, 4, 5, 6\}\)</span></p></li>
<li><p>data augmentation noise <span class="math notranslate nohighlight">\(\in [0, 0.5]\)</span> using binary search with step 0.1</p></li>
<li><p>the number of attention layers <span class="math notranslate nohighlight">\(\in \{3, 4, 5, 6\}\)</span></p></li>
<li><p>the number of attention heads <span class="math notranslate nohighlight">\(\in \{2, 3, 4, 5\}\)</span></p></li>
</ul>
</li>
</ul>
<p><strong>Main Results</strong></p>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_t3.png"><img alt="../_images/ltr_dasalc_t3.png" class="align-center" src="../_images/ltr_dasalc_t3.png" style="width: 750.4000000000001px; height: 200.8px;" />
</a>
<ul class="simple">
<li><p>DASALCはLambdaMARTGBM (lightgbm) と comparable or better</p></li>
<li><p>DASALC-ens (学習時のrandomnessを使った3-5 modelsの平均をとったもの) は有意に LambdaMARTGBMより強い</p></li>
<li><p>Yahooデータセットでの成績は悪いが、これはYahooデータセットが最初から正規化された状態で公開されていて、その正則化はNNにとって理想的ではない可能性がある (ので、生の状態で公開すべきだ)</p></li>
</ul>
<p><strong>LambdaMARTGBMもensembleすると</strong></p>
<ul class="simple">
<li><p>NNモデルは学習時のrandomnessによって、単純なensembleでも意味があったが</p></li>
<li><p>LambdaMARTは毎回似たような結果になってしまって、単純なensembleでは意味がない</p></li>
<li><p>-&gt; 異なるtree数, leaf数, 学習率でモデルを作ってensembleしている</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_t11.png"><img alt="../_images/ltr_dasalc_t11.png" class="align-center" src="../_images/ltr_dasalc_t11.png" style="width: 587.2px; height: 123.2px;" />
</a>
<ul class="simple">
<li><p>LambdaMARTのensembleはNNのそれよりも改善が小さい</p></li>
<li><p>NNのアンサンブルはより強い確率的な性質をもっているので、ensembleがより効果的だったではと主張している</p></li>
</ul>
<p><strong>Ablation study</strong></p>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_t4.png"><img alt="../_images/ltr_dasalc_t4.png" class="align-center" src="../_images/ltr_dasalc_t4.png" style="width: 538.4px; height: 80.80000000000001px;" />
</a>
<ul class="simple">
<li><p>左から右に向かって累積的にコンポーネントを追加</p></li>
<li><p>全部突っ込んだやつが強い</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_t7.png"><img alt="../_images/ltr_dasalc_t7.png" class="align-center" src="../_images/ltr_dasalc_t7.png" style="width: 669.6px; height: 147.20000000000002px;" />
</a>
<ul class="simple">
<li><p>Listwise contextを使ったコンポーネントを入れたとき</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_t8.png"><img alt="../_images/ltr_dasalc_t8.png" class="align-center" src="../_images/ltr_dasalc_t8.png" style="width: 733.6px; height: 216.8px;" />
</a>
<ul class="simple">
<li><p>普通のDNNだとDeta augmentationの効果がないが、DASALCでは意味がある</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_t9.png"><img alt="../_images/ltr_dasalc_t9.png" class="align-center" src="../_images/ltr_dasalc_t9.png" style="width: 720.0px; height: 159.20000000000002px;" />
</a>
<ul class="simple">
<li><p>LambdaMARTにData augmentationすると、ひどい結果になる</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_dasalc_t10.png"><img alt="../_images/ltr_dasalc_t10.png" class="align-center" src="../_images/ltr_dasalc_t10.png" style="width: 755.2px; height: 188.8px;" />
</a>
<ul class="simple">
<li><p>他のLambdaMARTの実装(RankLib),CatBoostと比較した結果</p></li>
<li><p>普通にlightgbmが強い</p></li>
</ul>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 8.2.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>