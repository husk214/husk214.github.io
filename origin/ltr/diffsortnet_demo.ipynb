{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f522a3f-2074-4585-9131-a6fec57595c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Felix-Petersen/diffsort\n",
    "\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def odd_even_network(n):\n",
    "    layers = n\n",
    "\n",
    "    network = []\n",
    "\n",
    "    shifted: bool = False\n",
    "    even: bool = n % 2 == 0\n",
    "\n",
    "    for layer in range(layers):\n",
    "\n",
    "        if even:\n",
    "            k = n // 2 + shifted\n",
    "        else:\n",
    "            k = n // 2 + 1\n",
    "\n",
    "        split_a, split_b = np.zeros((k, n)), np.zeros((k, n))\n",
    "        combine_min, combine_max = np.zeros((n, k)), np.zeros((n, k))\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        # for i in range(n // 2 if not (even and shifted) else n // 2 - 1):\n",
    "        for i in range(int(shifted), n-1, 2):\n",
    "            a, b = i, i + 1\n",
    "            split_a[count, a], split_b[count, b] = 1, 1\n",
    "            combine_min[a, count], combine_max[b, count] = 1, 1\n",
    "            count += 1\n",
    "\n",
    "        if even and shifted:\n",
    "            # Make sure that the corner values stay where they are/were:\n",
    "            a, b = 0, 0\n",
    "            split_a[count, a], split_b[count, b] = 1, 1\n",
    "            combine_min[a, count], combine_max[b, count] = .5, .5\n",
    "            count += 1\n",
    "            a, b = n - 1, n - 1\n",
    "            split_a[count, a], split_b[count, b] = 1, 1\n",
    "            combine_min[a, count], combine_max[b, count] = .5, .5\n",
    "            count += 1\n",
    "\n",
    "        elif not even:\n",
    "            if shifted:\n",
    "                a, b = 0, 0\n",
    "            else:\n",
    "                a, b = n - 1, n - 1\n",
    "            split_a[count, a], split_b[count, b] = 1, 1\n",
    "            combine_min[a, count], combine_max[b, count] = .5, .5\n",
    "            count += 1\n",
    "\n",
    "        assert count == k\n",
    "\n",
    "        network.append((split_a, split_b, combine_min, combine_max))\n",
    "        shifted = not shifted\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def get_sorting_network(type, n, device):\n",
    "    def matrix_to_torch(m):\n",
    "        return [[torch.from_numpy(matrix).float().to(device) for matrix in matrix_set] for matrix_set in m]\n",
    "    if type == 'odd_even':\n",
    "        return matrix_to_torch(odd_even_network(n))\n",
    "    else:\n",
    "        raise NotImplementedError('Sorting network `{}` unknown.'.format(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a98901e-7f3a-4091-9369-e710118b0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "SORTING_NETWORK_TYPE = List[torch.tensor]\n",
    "\n",
    "def s_best(x):\n",
    "    return torch.clamp(x, -0.25, 0.25) + .5 + \\\n",
    "        ((x > 0.25).float() - (x < -0.25).float()) * (0.25 - 1/16/(x.abs()+1e-10))\n",
    "\n",
    "\n",
    "class NormalCDF(torch.autograd.Function):\n",
    "    def forward(ctx, x, sigma):\n",
    "        ctx.save_for_backward(x, torch.tensor(sigma))\n",
    "        return 0.5 + 0.5 * torch.erf(x / sigma / math.sqrt(2))\n",
    "\n",
    "    def backward(ctx, grad_y):\n",
    "        x, sigma = ctx.saved_tensors\n",
    "        return grad_y * 1 / sigma / math.sqrt(math.pi * 2) * torch.exp(-0.5 * (x/sigma).pow(2)), None\n",
    "\n",
    "\n",
    "def execute_sort(\n",
    "        sorting_network,\n",
    "        vectors,\n",
    "        steepness=10.,\n",
    "        art_lambda=0.25,\n",
    "        distribution='cauchy'\n",
    "):\n",
    "    x = vectors\n",
    "    X = torch.eye(vectors.shape[1], dtype=x.dtype, device=x.device).repeat(x.shape[0], 1, 1)\n",
    "\n",
    "    for split_a, split_b, combine_min, combine_max in sorting_network:\n",
    "        split_a = split_a.type(x.dtype)\n",
    "        split_b = split_b.type(x.dtype)\n",
    "        combine_min = combine_min.type(x.dtype)\n",
    "        combine_max = combine_max.type(x.dtype)\n",
    "\n",
    "        a, b = x @ split_a.T, x @ split_b.T\n",
    "\n",
    "        # float conversion necessary as PyTorch doesn't support Half for sigmoid as of 25. August 2021\n",
    "        new_type = torch.float32 if x.dtype == torch.float16 else x.dtype\n",
    "\n",
    "        if distribution == 'logistic':\n",
    "            alpha = torch.sigmoid((b-a).type(new_type) * steepness).type(x.dtype)\n",
    "\n",
    "        elif distribution == 'logistic_phi':\n",
    "            alpha = torch.sigmoid((b-a).type(new_type) * steepness / ((a-b).type(new_type).abs() + 1.e-10).pow(art_lambda)).type(x.dtype)\n",
    "\n",
    "        elif distribution == 'gaussian':\n",
    "            v = (b - a).type(new_type)\n",
    "            alpha = NormalCDF.apply(v, 1 / steepness)\n",
    "            alpha = alpha.type(x.dtype)\n",
    "\n",
    "        elif distribution == 'reciprocal':\n",
    "            v = steepness * (b - a).type(new_type)\n",
    "            alpha = 0.5 * (v / (2 + v.abs()) + 1)\n",
    "            alpha = alpha.type(x.dtype)\n",
    "\n",
    "        elif distribution == 'cauchy':\n",
    "            v = steepness * (b - a).type(new_type)\n",
    "            alpha = 1 / math.pi * torch.atan(v) + .5\n",
    "            alpha = alpha.type(x.dtype)\n",
    "\n",
    "        elif distribution == 'optimal':\n",
    "            v = steepness * (b - a).type(new_type)\n",
    "            alpha = s_best(v)\n",
    "            alpha = alpha.type(x.dtype)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError('softmax method `{}` unknown'.format(distribution))\n",
    "\n",
    "        aX = X @ split_a.T\n",
    "        bX = X @ split_b.T\n",
    "        w_min = alpha.unsqueeze(-2) * aX + (1-alpha).unsqueeze(-2) * bX\n",
    "        w_max = (1-alpha).unsqueeze(-2) * aX + alpha.unsqueeze(-2) * bX\n",
    "        X = (w_max @ combine_max.T.unsqueeze(-3)) + (w_min @ combine_min.T.unsqueeze(-3))\n",
    "        x = (alpha * a + (1-alpha) * b) @ combine_min.T + ((1-alpha) * a + alpha * b) @ combine_max.T\n",
    "    return x, X\n",
    "\n",
    "\n",
    "def sort(\n",
    "        sorting_network: SORTING_NETWORK_TYPE,\n",
    "        vectors: torch.Tensor,\n",
    "        steepness: float = 10.0,\n",
    "        art_lambda: float = 0.25,\n",
    "        distribution: str = 'cauchy'\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    return execute_sort(\n",
    "        sorting_network=sorting_network,\n",
    "        vectors=vectors,\n",
    "        steepness=steepness,\n",
    "        art_lambda=art_lambda,\n",
    "        distribution=distribution\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c5e4f03-9757-4e7e-9cbf-ccc12c70dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([\n",
    "    [6.5, 0.4, 1.5, 3.8,],\n",
    "    [3.5, 9.2, 2.4, 0.8,]\n",
    "])\n",
    "sn = get_sorting_network('odd_even', x.shape[1], 'cpu')\n",
    "\n",
    "def check(distribution):\n",
    "    sx, pm = execute_sort(sn, x, distribution=distribution)\n",
    "    b_hat = torch.arange(1, x.shape[1] + 1, dtype=x.dtype).repeat(x.shape[0], 1).unsqueeze(2)\n",
    "    sr = torch.matmul(pm, b_hat)[...,0]\n",
    "    \n",
    "    print(\"x =\", x)\n",
    "    print(\"sort(x) =\", sx)\n",
    "    print(\"rank(x) =\", sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fa45ab-b296-4dd9-a25c-278a7542a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[6.5000, 0.4000, 1.5000, 3.8000],\n",
      "        [3.5000, 9.2000, 2.4000, 0.8000]])\n",
      "sort(x) = tensor([[0.4000, 1.5000, 3.8000, 6.5000],\n",
      "        [0.8000, 2.4000, 3.5000, 9.2000]])\n",
      "rank(x) = tensor([[4.0000, 1.0000, 2.0000, 3.0000],\n",
      "        [3.0000, 4.0000, 2.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "check(\"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315f247e-84cd-4d4b-8a49-fda3dcb999dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[6.5000, 0.4000, 1.5000, 3.8000],\n",
      "        [3.5000, 9.2000, 2.4000, 0.8000]])\n",
      "sort(x) = tensor([[0.4000, 1.5000, 3.8000, 6.5000],\n",
      "        [0.8000, 2.4000, 3.5000, 9.2000]])\n",
      "rank(x) = tensor([[4.0000, 1.0000, 2.0000, 3.0000],\n",
      "        [3.0000, 4.0000, 2.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "check(\"logistic_phi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8475c514-7f16-4252-b7d0-ab3bb759f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[6.5000, 0.4000, 1.5000, 3.8000],\n",
      "        [3.5000, 9.2000, 2.4000, 0.8000]])\n",
      "sort(x) = tensor([[0.4636, 1.5637, 3.7682, 6.4045],\n",
      "        [0.8954, 2.4318, 3.4683, 9.1045]])\n",
      "rank(x) = tensor([[3.9596, 1.0438, 2.0123, 2.9842],\n",
      "        [2.9534, 3.9736, 2.0182, 1.0548]])\n"
     ]
    }
   ],
   "source": [
    "check(\"cauchy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef338a37-d5a5-47ba-8705-e485698a830d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
