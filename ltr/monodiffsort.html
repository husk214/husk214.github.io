<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Petersen ICLR’22 Monotonic Differentiable Sorting Networks &#8212; papers  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=db26dd79" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=579adecb" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=eab45d89" />
    <link rel="stylesheet" href="../_static/bootswatch-3.3.6/simplex/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=13a9ecda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/js/jquery-fix.js"></script>
    <script src="../_static/bootstrap-3.3.6/js/bootstrap.min.js"></script>
    <script src="../_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Algorithm" href="algorithm.html" />
    <link rel="prev" title="Petersen ICML’21 Differentiable Sorting Networks for Scalable Sorting and Ranking Supervision" href="diffsortnet.html" />
<link rel="stylesheet" href="_static/custom.css" type="text/css" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-74773673-1', 'auto');
  ga('send', 'pageview');
</script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          ashibaga</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../metriclearning.html">Metric Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/reality_check.html">Musgrave ECCV’20 A Metric Learning Reality Check</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/lifted_structured.html">Song CVPR’16 Deep Metric Learning via Lifted Structured Feature Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/multi_similarity.html">Wang CVPR19 Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/multi_similarity.html#wang-cvpr-20-cross-batch-memory-for-embedding-learning">Wang CVPR’20 Cross-Batch Memory for Embedding Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/proxy_nca.html">Movshovitz ICCV’17 No fuss distance metric learning using proxies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/proxy_anchor.html">Kim CVPR’20 Proxy Anchor Loss for Deep Metric Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/s2sd.html">Roth ICML’21 Simultaneous Similarity-based Self-Distillation for Deep Metric Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/clip.html">Radford ICML’21 CLIP (Learning Transferable Visual Models From Natural Language Supervision)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../metriclearning/lang_guide.html">Roth CVPR’22 Integrating Language Guidance into Vision-based Deep Metric Learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../noisylabel.html">Learning from Noisy Labels</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../noisylabel/confident_learning.html">Northcutt ICML’20 Confident Learning: Estimating Uncertainty in Dataset Labels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../noisylabel/pervasive_label_errors.html">Northcutt NeurIPS’21 Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../ssl.html">Self Supervised Learning (SSL)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../ssl/simclr.html">Chen ICML’20 SimCLR (A Simple Framework for Contrastive Learning of Visual Representations)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ssl/byol.html">Grill NIPS’20 BYOL (Bootstrap Your Own Latent A New Approach to Self-Supervised Learning)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ssl/simsiam.html">Chen CVPR’21 SimSiam (Exploring Simple Siamese Representation Learning)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ssl/how_avoid.html">Does ICLR’22 How Does SimSiam Avoid Collapse Without Negative Samples?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../representation.html">Representation Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../representation/understaing_crl.html">Wang ICML’20 Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../other.html">Other</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../other/sentencepiece.html">Kudo EMNLP’18 SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/optimizer_benchmark.html">Teja ICML’20 Optimizer Benchmarking Needs to Account for Hyperparameter Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/user_centric_ranking.html">Zhao (KDD’23) Breaking the Curse of Quality Saturation with User-Centric Ranking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/quert.html">Xie (KDD’23) QUERT: Continual Pre-training of Language Model for Query Understanding in Travel Domain Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/tensorflow_serving.html">Tensorflow Serving</a></li>
<li class="toctree-l2"><a class="reference internal" href="../other/search_engine_qu.html">検索システム 実務者のための開発改善ガイドブック 11章 検索を成功させるための支援</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../proceedings.html">Proceedings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir23_abst.html">SIGIR’23 ABSTRACT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir22_abst.html">SIGIR’22 ABSTRACT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir21_abst.html">SIGIR’21 ABSTRACT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir20_abst.html">SIGIR’20 ABSTRACT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../proceedings/sigir19_abst.html">SIGIR’19 ABSTRACT</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../ltr.html">Learning to Rank</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="dasalc.html">Zhen ICLR’21 Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?</a></li>
<li class="toctree-l2"><a class="reference internal" href="mixture_transformation.html">Zhuang SIGIR’20 Feature Transformation for Neural Ranking Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="neuralsort.html">Grover ICLR’19 Stochastic Optimization of Sorting Networks via Continuous Relaxations</a></li>
<li class="toctree-l2"><a class="reference internal" href="otsort.html">Cuturi NeurIPS’19 Differentiable Ranks and Sorting using Optimal Transport</a></li>
<li class="toctree-l2"><a class="reference internal" href="fastsort.html">Blondel ICML’20 Fast Differentiable Sorting and Ranking</a></li>
<li class="toctree-l2"><a class="reference internal" href="diffsortnet.html">Petersen ICML’21 Differentiable Sorting Networks for Scalable Sorting and Ranking Supervision</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Petersen ICLR’22 Monotonic Differentiable Sorting Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="algorithm.html">Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="metric.html">Metric</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Petersen ICLR’22 Monotonic Differentiable Sorting Networks</a><ul>
<li><a class="reference internal" href="#id1">概要</a></li>
<li><a class="reference internal" href="#theory">Theory</a></li>
<li><a class="reference internal" href="#sigmoid-functions">Sigmoid Functions</a></li>
<li><a class="reference internal" href="#monotonicity-of-other-differentiable-sorting-operators">Monotonicity of Other Differentiable Sorting Operators</a></li>
<li><a class="reference internal" href="#empirical-evaluation">Empirical Evaluation</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="diffsortnet.html" title="Previous Chapter: Petersen ICML’21 Differentiable Sorting Networks for Scalable Sorting and Ranking Supervision"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Petersen ICML...</span>
    </a>
  </li>
  <li>
    <a href="algorithm.html" title="Next Chapter: Algorithm"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Algorithm &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Petersen ICLR’22 Monotonic Differentiable Sorting Networks</a><ul>
<li><a class="reference internal" href="#id1">概要</a></li>
<li><a class="reference internal" href="#theory">Theory</a></li>
<li><a class="reference internal" href="#sigmoid-functions">Sigmoid Functions</a></li>
<li><a class="reference internal" href="#monotonicity-of-other-differentiable-sorting-operators">Monotonicity of Other Differentiable Sorting Operators</a></li>
<li><a class="reference internal" href="#empirical-evaluation">Empirical Evaluation</a></li>
</ul>
</li>
</ul>

  <li>
    <a href="diffsortnet.html" title="Previous Chapter: Petersen ICML’21 Differentiable Sorting Networks for Scalable Sorting and Ranking Supervision"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Petersen ICML...</span>
    </a>
  </li>
  <li>
    <a href="algorithm.html" title="Next Chapter: Algorithm"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Algorithm &raquo;</span>
    </a>
  </li>
<div id="sourcelink">
  <a href="../_sources/ltr/monodiffsort.rst.txt"
     rel="nofollow">Source</a>
</div>
<form action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="col-md-9 content">
      
  <section id="petersen-iclr-22-monotonic-differentiable-sorting-networks">
<h1>Petersen ICLR’22 Monotonic Differentiable Sorting Networks<a class="headerlink" href="#petersen-iclr-22-monotonic-differentiable-sorting-networks" title="Link to this heading">¶</a></h1>
<p><a class="reference external" href="https://openreview.net/forum?id=IcUWShptD7d">https://openreview.net/forum?id=IcUWShptD7d</a></p>
<p>著者</p>
<ul class="simple">
<li><p>Felix Petersen (University of Konstanz)</p></li>
<li><p>Christian Borgelt (University of Salzburg)</p></li>
<li><p>Hilde Kuehne (University of Frankfurt, MIT-IBM Watson AI)</p></li>
<li><p>Oliver Deussen (University of Konstanz)</p></li>
</ul>
<section id="id1">
<h2>概要<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>Differentiable Sorting Networks (ICML’21) の著者らによる改良版</p></li>
<li><p>学習において関数の単調性が重要 (ちょっと疑問、論文中でも軽く議論されているだけ)</p></li>
<li><p>Differentiable Sorting Networksで導入したmin, maxをrelaxedしたものが単調になるように関数を設計すると精度がよくなる</p></li>
</ul>
</section>
<section id="theory">
<h2>Theory<a class="headerlink" href="#theory" title="Link to this heading">¶</a></h2>
<div class="line-block">
<div class="line"><br /></div>
</div>
<ul class="simple">
<li><p>「min, maxをrelaxedしたものが単調になる」の定義をする</p></li>
<li><p>それを達成する関数の条件を見る</p></li>
<li><p>また緩和したmin, maxと真のmin, maxの誤差をバウンドするための条件も見る</p></li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Definition 1 (Sigmoid Function)</strong></p>
<p>sigmoid(つまりS字の)関数を連続単調非減少で入力=0.5あたりで対称になる関数 <span class="math notranslate nohighlight">\(f\)</span> として定義する。</p>
<div class="math notranslate nohighlight">
\[f: \mathbb{R} \rightarrow [0, 1] ~~ \text{with} ~~ \lim_{x\rightarrow -\infty} f(x) = 0 ~~ \text{and} ~~ \lim_{x\rightarrow \infty} f(x) = 1\]</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Definition 2 (Continuous Conditional Swaps)</strong></p>
<p>sigmoid関数 <span class="math notranslate nohighlight">\(f\)</span> についてのcontinuous conditional swapを次のように定義する</p>
<div class="math notranslate nohighlight">
\begin{align}
  \text{min}_f (a, b) &amp;= a f(b-a) + b (a-b), ~~ \text{max}_f (a, b) =  a f(a-b) + b (b-a)
\end{align}</div><div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Definition 4 (Monotonic Continuous Conditional Swaps)</strong></p>
<p><span class="math notranslate nohighlight">\(\text{min}_f (x, 0) \ge 0, ~~ \forall x\)</span> が成り立つとき、 <span class="math notranslate nohighlight">\(f\)</span> がmonotonic conditional swapを生成するという。</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Theorem 5 (Monotonicity of Continuous Conditional Swaps)</strong></p>
<p><span class="math notranslate nohighlight">\(f\)</span> が 非減少monotonic conditional swapを生成するには、導関数が <span class="math notranslate nohighlight">\(1/x^2\)</span> より早く減退しない必要。つまり、</p>
<div class="math notranslate nohighlight">
\[f'(x) \in \Omega \left(\frac{1}{x^2} \right).\]</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Definition 7 (Error-Bounded Continuous Conditional Swaps).</strong></p>
<p>Continuous conditional swapsは <span class="math notranslate nohighlight">\(\sup_x \min_{f} (x, 0) = c\)</span> が有限である場合に限り、bounded errorを持つ。またその Continuous conditional swapsを <span class="math notranslate nohighlight">\(c\)</span> の error boundedを持つという。</p>
<p><strong>Theorem 8 (Error-Bounds of Continuous Conditional Swaps)</strong></p>
<p>もし式 <a class="reference internal" href="#equation-mds-eq8">(1)</a> が成り立つならばContinuous conditional swapsはbounded errorを持つ。</p>
<div class="math notranslate nohighlight" id="equation-mds-eq8">
<span class="eqno">(1)<a class="headerlink" href="#equation-mds-eq8" title="Link to this equation">¶</a></span>\[f'(x) \in \mathcal{O} \left(\frac{1}{x^2} \right)\]</div>
<p>さらに単調である場合、誤差の境界は <span class="math notranslate nohighlight">\(\lim_{x \rightarrow \infty} \min_f (x, 0)\)</span> として求められ、さらに式 <a class="reference internal" href="#equation-mds-eq8">(1)</a> が成り立つ場合にのみエラーがboundされる。</p>
</section>
<section id="sigmoid-functions">
<h2>Sigmoid Functions<a class="headerlink" href="#sigmoid-functions" title="Link to this heading">¶</a></h2>
<p><a class="reference internal" href="diffsortnet.html#labeldiffsortnet"><span class="std std-ref">Differentiable Sorting Networks</span></a> で提案された logistic sigmoid <span class="math notranslate nohighlight">\(\sigma(x) := 1 / (1 + \exp(-\beta x))\)</span> は error boundはあるが、monotonic conditional swapにはならない。 (Fig.2の青線)</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<a class="reference internal image-reference" href="../_images/ltr_monodsn_fig2.png"><img alt="../_images/ltr_monodsn_fig2.png" class="align-center" src="../_images/ltr_monodsn_fig2.png" style="width: 422.40000000000003px; height: 250.0px;" />
</a>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>ここではerror boundがあってmonotonic conditional swapとなる <span class="math notranslate nohighlight">\(f\)</span> を3つ見ていく。</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Reciprocal Sigmoid Function</strong></p>
<p><span class="math notranslate nohighlight">\(f\)</span> が error boundを持つ非減少monotonic conditional swapを生成するには、Theorem 5と8より <span class="math notranslate nohighlight">\(f'(x) \in \Theta \left(1/x^2 \right)\)</span> となる必要があるので、<span class="math notranslate nohighlight">\(f_{\mathcal{R}}' (x) = \cfrac{1}{(2|x| + 1)^2}\)</span> は自然な選択で、<span class="math notranslate nohighlight">\(f_{\mathcal{R}}\)</span> は以下で、 誤差は <span class="math notranslate nohighlight">\(\epsilon =0.25\)</span> となる。</p>
<div class="math notranslate nohighlight">
\[f_{\mathcal{R}}(x) = \int_{-\infty}^{x} \cfrac{1}{(2\beta |t| + 1)^2} dt = \cfrac{1}{2} \cfrac{2\beta x}{1 + 2\beta |x| } + \cfrac{1}{2}\]</div>
<p><span class="math notranslate nohighlight">\(\min(x, 0) ~ \forall x &gt; 0\)</span> は0であることが望ましいので、<span class="math notranslate nohighlight">\(\min_f(x, 0)\)</span> を減らすことを考えていく。</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Cauchy distributions</strong></p>
<p>Cauchy distributionの累積分布関数を使うことで誤差を <span class="math notranslate nohighlight">\(\epsilon = 1/\pi^2\)</span> へ減らすことができる。</p>
<div class="math notranslate nohighlight">
\[f_{\mathcal{C}}(x) = \int_{-\infty}^{x} \cfrac{\beta}{1 + (\beta)^2} dt = \cfrac{1}{\pi} \arctan (\beta x) + \cfrac{1}{2}\]</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Optimal Monotonic Sigmoid Function</strong></p>
<p>誤差限界を達成し、monotonicかつ1-Lipschitz continuousなconditional swapとなる <span class="math notranslate nohighlight">\(f_{\mathcal{O}}\)</span> は以下になる。</p>
<div class="math notranslate nohighlight">
\begin{align}
f_{\mathcal{O}}(x) =
  \left\{
  \begin{array}{ll}
    -\frac{1}{16 \beta x} &amp; \text{if} ~~ \beta x &lt; -\frac{1}{4} \\
    1 -\frac{1}{16 \beta x} &amp; \text{if} ~~ \beta x &gt; \frac{1}{4} \\
    \beta x + \frac{1}{2} &amp; \text{otherwise}.
  \end{array}
  \right.
\end{align}</div><p>論文中に証明あり (Theorem 10)</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>Fig.3は 3-wire odd-even sorting newtorkで logistic sigmoid(左)とoptimal sigmoid(右)のロスをプロットしたもの。</p>
<p>logistic sigmoidの場合、(3 , 2, 1)でランクの1つが正しいにもかかわらず、 すべてのランクが異なる(2, 3, 1)と同じ損失になってしまっている。</p>
<a class="reference internal image-reference" href="../_images/ltr_monodsn_fig3.png"><img alt="../_images/ltr_monodsn_fig3.png" class="align-center" src="../_images/ltr_monodsn_fig3.png" style="width: 544.1999999999999px; height: 331.8px;" />
</a>
</section>
<section id="monotonicity-of-other-differentiable-sorting-operators">
<h2>Monotonicity of Other Differentiable Sorting Operators<a class="headerlink" href="#monotonicity-of-other-differentiable-sorting-operators" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>既存手法の <span class="math notranslate nohighlight">\(\min(x, 0)\)</span> がどうなっているか見てみる。</p></li>
<li><p>他の手法の <span class="math notranslate nohighlight">\(\min(x, 0)\)</span> ってなにかというと、 softsortをdifferentiableなsort, 入力を <span class="math notranslate nohighlight">\(s=[0, x]\)</span> として <span class="math notranslate nohighlight">\(\min(\text{softsort(s)})\)</span> の値を見る</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_monodsn_fig4.png"><img alt="../_images/ltr_monodsn_fig4.png" class="align-center" src="../_images/ltr_monodsn_fig4.png" style="width: 341.6px; height: 225.20000000000002px;" />
</a>
<ul class="simple">
<li><p>FastSortはmonotonicだが一定の値を超えると線形にエラーが伸びていく</p></li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>実際にプロットしてみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>

<span class="o">%</span><span class="n">run</span> <span class="n">neuralsort_demo</span><span class="o">.</span><span class="n">ipynb</span>
<span class="o">%</span><span class="n">run</span> <span class="n">otsort_demo</span><span class="o">.</span><span class="n">ipynb</span>
<span class="o">%</span><span class="n">run</span> <span class="n">fastsort_demo</span><span class="o">.</span><span class="n">ipynb</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot</span><span class="p">(</span><span class="n">sx</span><span class="p">):</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">sx</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;min(softsort(x, 0))&#39;</span><span class="p">],</span>
    <span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neural_sort</span>

<span class="n">i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="n">e</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">i</span><span class="p">])</span>
<span class="n">sx</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">neural_sort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plot</span><span class="p">(</span><span class="n">sx</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/36083b063a5249cd77d691b2ca2f546a780a7a67ad560167d9f6dd81fb742bb5.png" src="../_images/36083b063a5249cd77d691b2ca2f546a780a7a67ad560167d9f6dd81fb742bb5.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ot_sort</span>

<span class="n">sr</span><span class="p">,</span> <span class="n">sx</span> <span class="o">=</span> <span class="n">ot_sort_batch</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plot</span><span class="p">(</span><span class="n">sx</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/349a29b6050ab75a81c2335004b3cc3e7abd529e5de449811d1e24e9fd27c0b4.png" src="../_images/349a29b6050ab75a81c2335004b3cc3e7abd529e5de449811d1e24e9fd27c0b4.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fast_sort reg=1.0</span>
<span class="n">sx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span><span class="n">soft_sort</span><span class="p">([</span><span class="n">e</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">regularization_strength</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">i</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">plot</span><span class="p">(</span><span class="n">sx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d9a49218647bd5eaae7232aee32982bf42eeca1c7fc3419c33c4a330f168c3e3.png" src="../_images/d9a49218647bd5eaae7232aee32982bf42eeca1c7fc3419c33c4a330f168c3e3.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fast_sort reg=0.1</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>    
<span class="n">sx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span><span class="n">soft_sort</span><span class="p">([</span><span class="n">e</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">regularization_strength</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">i</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="n">sx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/77814db9429731d5b0897ca9e6f4b8c263366f1f8cbf98f1e42072fee0603525.png" src="../_images/77814db9429731d5b0897ca9e6f4b8c263366f1f8cbf98f1e42072fee0603525.png" />
</div>
</div>
</section>
<section id="empirical-evaluation">
<h2>Empirical Evaluation<a class="headerlink" href="#empirical-evaluation" title="Link to this heading">¶</a></h2>
<p>Differentiableなsort論文で毎回やられている実験で性能比較</p>
<ul class="simple">
<li><p>MNISTやSVHNを4桁の数字になるように並べ、<span class="math notranslate nohighlight">\(n\)</span> 個を1セットにして、ソートするモデルをend-to-endで学習する</p></li>
<li><p>そのソートの正答率で各手法を比較する</p></li>
</ul>
<p>イメージは↓の画像のtask 1 (Grover ICLR’19のFig. 4)</p>
<a class="reference internal image-reference" href="../_images/ltr_ns_fig4.png"><img alt="../_images/ltr_ns_fig4.png" class="align-center" src="../_images/ltr_ns_fig4.png" style="width: 683.4px; height: 274.8px;" />
</a>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>結果 (数値は5回実行した結果の平均で、カッコ)</p>
<ul class="simple">
<li><p>数値はすべての要素が正確にソートされている割合、カッコ内の数値は個別に見たときにランクがあっている割合 (5回実行した結果の平均)</p></li>
<li><p>Diffsort (Logistic with Activation Replacement Trick) も結構強いが、この論文で提案されているもののほうが強い</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/ltr_monodsn_tab3.png"><img alt="../_images/ltr_monodsn_tab3.png" class="align-center" src="../_images/ltr_monodsn_tab3.png" style="width: 859.2px; height: 441.6px;" />
</a>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 8.2.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>